idea handbook arose late working title handbook ethics ai context time solicitations went potential contributors sum mer title streamlined handbook ethics ai essential contextual approach however remained unchanged broadly conceived framed interdisciplinary international collection designed capture shape muchneeded reflection normative frameworks production application use artificial intelligence diverse spheres individual commercial social public life approach ethics ai runs handbook contextual four senses normative analysis including legal regulatory philosophical policy approaches logical innovation including machine learning big data robotics ethics artificial intelligence beyond computer science related fields include fields scholarly endeavor including social sciences humani ties professions law medicine engineering etc continuously expanding artificial intelligence complex production commercialization consumption technical experts venture capitalists selfregulating professionals government officials general public ideal handbooks combine stocktaking genredefining devoted field inquiry new quickly evolving ethics ai handbook fal closer forwardfacing literaturereviewing end spectrum mapping exist ing discourse important also beginning crucial attempt place current developments historical context time recognized need leave room flexibility contributors volume broke new ground pursuing fresh approaches taking novel subjects spirit handbook operates inclusive flexible conception “artificial intelligence” ranges exploring normative constraints specific applications machine learning algo rithms reflecting potential status ai form consciousness x editors’ preface attendant rights duties general stil investigating basic conceptual terms frameworks necessary understand tasks requiring intelligence whether chapter handbook aims provide original critical accessible account current state debate domain help shape scholarly research public discourse welcomed forwardlooking ideasdriven contributions serve catalysts guiding debate ethics ai months years come chapters intended function individual collectively lively freestanding essays targeted international interdisciplinary audience scholars interested laypersons chapter also provides end bibliography ten titles readers would like read deeply topic handbook’s inclusive flexible approach subject matter reflected roster contributors includes authors several countries continents ranging emergent established authorities representing wide variety methodological approaches areas expertise research agendas handbook’s content similarly ambitious diverse scope substance covering broad range topics perspectives handbook consists five parts introduction overview ii frameworks modes iii concepts issues iv perspectives approaches v cases applications part provides general introduction subject field “artificial intelli gence” within context research discourse related fields technological innovation laying accessible yet nuanced foundation exploration various normative frameworks critical analysis ai also locates “ethics” artifi cial intelligence relation cognate fields ethical inquiry eg data ethics informa tion ethics robot ethics internet ethics considering ways conceptualizing challenges eg sui generis inquiry form applied ethics traditional ethics ai terms distinguishing aspects within extent taxonomy sort proves il uminating capturing key substantive formal features discourse part ii places subject handbook ethics ai within context alternative frameworks normative assessment governance including various institutional procedural modes implementation dissemination questions raised part include “what distinguishes ethics ai normative frameworks techniques eg law policy regulation governance” “how ethics ground inform legal constraints regulatory guidance ai” “how ethics ai navigate possible tension private commercial norms one hand public norms other” “how ethical norms generated formulated disseminated implemented whom” “what role selfregulation professional ethics insofar enterprise regarded defining enforcing notion good sound ‘professional’ judgment” part iii tackles central concepts issues may serve points departure reflecting ethical dimensions challenges artificial intelligence general editors’ preface xi cutting across technologies applications many cases across disciplines wel ranging sources types bias production application ai research concerns privacy collection use data potential effect aidriven “disruption” labor markets future work socioeco nomic life broadly distinction “prediction” “judgment” ethical status aidriven machines possible implications humanmachine interaction wide spectrum disciplinary national supranational perspectives reflected throughout handbook part iv homes selection methodological approaches domestic regional contexts early chapters part capture distinctive texture salience actual potential discourse around ethics ai range disciplinary contexts effort il ustrate—and expand—the disciplinary scope scholarly public debate ethics ai remaining chapters highlight variety discourses around ethics ai selected national regional contexts broaden diversify dialogue normative dimen sions artificial intelligence global phenomenon time geographical culturally part v concludes handbook sharpening focus selected applications artificial intelligence without however treating sui generis instead way fits handbook’s overall ambition expand conversation eth ics artificial intelligence specific general superficial fundamental parochial contextual contributors reflect ethical aspects design dissemination use aidriven devices tools today future along broad spectrum applications health care law immigration education transportation military workplace smart cities beyond deeply grateful international interdisciplinary group scholars signed largescale longterm project somehow made time see completion among flurry activities opportunities mark start new momentous endeavor like scholarly public scrutiny ethics artificial intelligence markus dubber frank pasquale sunit das august chapter artificial intelligence ethics artificial intelligence introductory overview law regulation joanna j bryson many decades artificial intelligence ai schizophrenic field pursuing two different goals improved understanding computer science use psychological sciences improved understanding psychological sci ences use computer science although apparently orthogonal goals seen complementary since progress one often informs even advances indeed found two factors proven unify two pursuits first costs computation indeed actual computable facts nature constrain natural artificial intelligence second given con straints computability costs computation greater intelligence relies reuse prior computation therefore extent natural artificial intel ligence able reuse findings prior computation pursuits advanced neither dual pursuits ai entirely readied researchers glaringly evident ethical importance field intelligence key component nearly every human social endeavor social endeavors constitute activities explicit conscious awareness social endeavors also purview law general politics diplomacy short everything humans deliberately altered digital revolution well much unthinkingly joanna j bryson often alteration terms do—for example check spelling document book travel recall last contacted particular employee client politician plan budgets influence voters countries decide movie watch earn money performing artistical discover sexual life partners makes impact ubiquitous everything done chosen least theory knowable awareness fundamen tal alters society alters act directly also well know regulate great deal written ai ethics recently unfortunately many discussions focused either science computable social science ready access information mechanical computational power altered human lives behavior rather great deal studies focus ai thought experiment “intuition pump” better understand human condition nature ethical obligation handbook focus law—the daytoday means regulate societies defend liberties chapter sets context volume introducing ai applied discipline science engineering intelligence ordinary process purpose introduction use exceedingly wellestablished defini tion intelligence dating seminal monograph animal behavior1 intel igence capacity right thing right time ability respond opportunities challenges presented context simple definition important demystifies intelligence ai clarifies intelligence’s limits social responsibilities two ways first note intelligence process one operates place moment special case computation physical transformation information2 information abstraction3 physical manifested energy light sound materials computation intelligence therefore also abstractions require time space energy why—when get it—no one real ever smart physical impossible think everything make trade offs example double number computers use cut time computation nearly half time never cut quite half always artificial intelligence ethics ai extra cost splitting task recombining outcomes processing4 near halving requires ful double space two computers double energy moment computation sum total energy used slightly original single computer due extra energy needed overheads evidence quantum computing change cost equation fundamental save time also space however energy costs poorly understood date look fiendishly high second note difference intelligence artificial intel igence qualifier artificial means something made human process means default humans responsible artifact actual even interesting ai concept responsible animals trained inten tional limit place example even fairly unintentional byproducts digestive process far know humans communicate and—crucial y—can negotiate explicit concept responsibility time recognize consequences actions societies tend give us responsibility accountability consequences—credit blame depending whether consequences positive negative artificial intelligence changes responsibility special case changing every part social behavior digital technology provides us better capacity perceive maintain accounts actions consequences easier harder maintain responsibility enforce law however whether accountability easier ai depends whether ways deploy capacities digital technol ogy affords without care proper measures increased capacity communica tion information communication technology ict provides may used diffuse obscure responsibility one solution recognize lack care mea sures promoting accountability processes concerning digital artifacts form negligence law similarly could declare unnecessary obfuscation public commercial processes deliberate culpable evasion responsibility note simplicity definitions introduced section extremely important move toward law regulation systems societies infused ai order evade regulation responsibility definition intelligence often complicated manifestos notions sentience consciousness intentionality forth return issues later chapter essential considering ai context law understanding fact either biology point human responsibility end responsibility fact nature rather problem governance always design artifacts—including law itself—in way helps us maintain enough social order sustain human dignity flourishing joanna j bryson ai including machine learning occurs design artificial intelligence occurs design thus ai produced inten tional purpose one members human society act produc tion requires design decisions concerning minimum information input output system also computation required transform information run decisions entail also considerations energy con sumption time taken producing good system possible final system defended levels cyber physical security appropriate value data transmitted retained well physi cal capacities system acts world5 tautology ai always generated design extends machine learning ml one means developing ai wherein computation used discover useful regularities data systems built exploit regularities whether categorize make predictions select actions directly mere fact part process design automated mean system designed choice ml algorithm data fed train point considered adequately trained released point detected testing whether testing ongoing learning continues system’s operation—all things design decisions must made also easily documented individual organization produces ai could always held account asked produce documentation processes documentation decisions records testing outcomes easy pro duce good practice always followed6 much matter law sloppy inadequate manufacturing technique7 development processes deemed adequate commercial products even private enjoyment determined combination expertise precedent whether processes followed documented easily checked either product licensed complaint made part routine inspection although actual algorithms abstractions means algorithms selves ai computer science algorithm list instructions fol lowed like recipe baking8 strand dna life—it capacity reproduce itself—so instruction sets require input data also note observations show basic systems engineering demonstrates informed idea machine converting world paperclips per nick bostrom superintel igence paths dangers strategies oxford oxford university press –michael huttermann devops developers new york apressspringer joshua kroll et al “accountable algorithms” univ penn l rev –the term algorithm currently often misused mean ai system unclear distinctions design programs data physical computing systems artificial intelligence ethics ai physical computation run without significant complex physical infrastructure execute instructions dna ai algorithms inert largest global technology corporations almost inconceivably vast infrastructure every aspect storing processing transmitting information business infrastructure includes means generate electric power provide secure communi cation well means computation leading corporations provide capacities also service infrastructure significant percentage world’s ict companies—of course cost european union eu committed investing substantial pub lic resources developing localized equivalent computational infrastructure resource previously done commercial aviation global posi tioning systems eu may also attempt build parallel data resource though controversial also discussion “nationalizing” sig nificant technology infrastructure though idea problematic given internet transnational trans nationalizing technology “giants” discussed later chapter digital technology empowers us sorts things including obfuscating simply deleting records control systems refer make systems either harder easier understand using ai9 design decisions extent transparency accountability required legal products also design decision though legislators courts regulators design regula tory framework important realize perfectly possible mandate technology designed comply laws including ensure traceability accountability human actions involved design running mainte nance intelligent systems fact given limits “machine nature” far plastic human nature sensible minimize amount change laws instead maximize extent required compliance facilitation extant laws10 performance designed artifacts readily explainable perhaps desire evade either laws nations laws nature many deeply respected ai professionals claimed promising aspects ai kroll et al “accountable algorithms” joanna j bryson mihailis e diamantis thomas grant “of people legal lacuna synthetic persons” artificial intel igence law sept –margaret boden et al principles robotics united kingdom’s engineering physical sciences research council epsrc april httpswwwepsrcacukresearchourportfoliothemesengineering activitiesprinciplesofrobotics joanna j bryson would compromised ai regulated11 example claim main taining standard rights explanation—that demonstration due process—would eliminate utilization many advanced machine learning techniques based fact methods produce systems exact workings complex knowable claim fails take account present standards accountabil ity corporate law company audited audit never extends explaining workings brain synapses gene regulation company’s employees rather look audit trails—or perhaps witnesses—indicating humans followed appropriate procedures automation exploiting artificial intelligence may reduce number people put witness stand describe recollections events motivations enables standard record keeping would unbearably tedious nondigital processes case ai systems programmed keep records records maintained indefinitely case ai system programmed perform documentation programming development ai always use good systems engineering practice including logging data design development training testing operation systems individuals institutions choose long store logged data design decisions ai systems institutions create already available standards adequate logging generate proof due diligence even explanations ai behavior norms use standards set enforced12 matters human justice humans right things need completely understand exactly machinelearning algorithm works need completely understand physics torque regulate bicycle riding traf fic concerns ai used way lawful want know example products comply claims individual users spied upon unfairly disadvantaged foreign agencies able illicitly insert false information machinelearning dataset newsfeed ai affords possibility maintaining precise accounts motivation system deploying constructed indeed true artifacts general digital artifacts particularly amenable automating process tools used build intelligent systems also set capture prompt kind information similarly track construction appli cation outcomes validating tests even obscure ai system assertion “deeply respected” relates claims i’ve heard highlevel policy settings haven’t able find print however examples rhetoric see cassie kozyrkov explainableaiwontdeliverhereswhy6738f54216be cassie kozyrkov“the tradeoff machine learning accuracy vs explainability” medium dec httpsmediumcomerdemkalayci thetradeoffinmachinelearningaccuracyvsexplainabilityfbb13914fde2 joanna j bryson alan f winfield “standardizing ethical design artificial intelligence autonomous systems” computer may –the artificial intelligence ethics ai development treated entirely blackbox still tested see varia tion inputs creates variation outputs13 even performance stochastic statistics tell us probability various outcomes type information law already accustomed eg medical outcomes practice though sys tems ai general far less opaque human reasoning less complex problems deal routinely workings government ecosys tem decadesold science examining complex models using simpler ones recently accelerating serve sectors already well regulated course like sectors increasingly use ai14 course many forms ai built either without use ml readily produce explanations themselves15 return one assertions beginning section also wrong assume ai already regulated human activity particularly commercial activity occurs context sort regulatory framework16 question continue optimize framework light changes society capacities introduced ai ict general intelligence increases exploiting prior computation fact computation physical process limits much done de novo instant intelligence must expressed—when action must taken save system threat empower opportunity reason much intelligence exploits computation already done rather exploits arti facts produced preserve outcomes computation recognising value reuse prior computation helps us understand designs culture also biology organisms solely exploit opportunities perceive also tend perceive solely equipped exploit—capacities per ception action evolve together similarly culture passes us every tool others invented inventions ones produce greatest impact relative costs transmission costs transmission include time spent transmitting process coming called writing “forensic analysis” see eg joseph r barr joseph cavanaugh “forensics assessing model goodness machine learning view” escri –patrick hal “on art science machine learning explanations” arxiv preprint arxiv181002909 stephen cranefield et al “no pizza valuebased plan selection bdi agents” ijcai proceedings ed carles sierra melbourne –jiaming zeng berk ustun cynthia rudin “interpretable classification models recidivism prediction” journal royal statistical society series statistics society –miles brundage joanna j bryson smart policies artificial intel igence preparation available arxiv160808196 joanna j bryson creating hazardous behaviour17 culture evolves frequently changes generate increased efficacy learn them18 much recent immense growth ai due specifical improved capacities “mine” using ml prior discoveries humanity nature general y19 course mining good comes bad mine knowledge also stereotypes—and allow ai take action prejudice—when mine human culture20 special feature ai mentioned previously nature works wel evolution collect preserve best presently available already computed even within range process stochastic sometimes make errors examining ai prod ucts ml shown least call “stereotypes” reflect aspects presentday conditions proportion job holders particular position particular gender thus things agreed bad eg sexist expect programmers male aspects present culture programmers male least implicitly agreed wish change machine learning data present employment–or even ordinary word use necessarily impacted present employment–cannot also discover implicit agree ments social intentions one theory explaining explosion recognize ai ai rich demonstrably humanlike previously humanspecific capacities speech production face recognition less consequence new algorithms new troves data increased computation speeds explosions capaci ties based strategy mining past solutions expect improvement plateau artificial human intelligence come share nearly boundary extant knowledge though boundary continue expand fact also ivana čače joanna j bryson “agent based modelling communication costs information free” emergence evolution linguistic communication ed c lyon c l nehaniv cangelosi london springer –kenny smith elizabeth wonnacott “eliminating unpredictable variation iterated learning” cognition –alex mesoudi andrew whiten kevin n laland “towards unified science cultural evolution” behavioral brain sciences –joanna j bryson “embodiment versus memetics” mind soc’y june –joanna j bryson “artificial intelligence prosocial behaviour” col ective agency cooperation natural artificial systems explanation implementation simulation ed catrin misselhorn vol philosophical studies berlin springer –daniel c dennett bacteria bach back london allen lane thomas b moeslund erik granum “a survey computer vision–based human motion capture” computer vision image understanding –sylvain calinon et al –aylin caliskan joanna j bryson arvind narayanan “semantics derived automatical language corpora contain humanlike biases” sci –mol lewis gary lupyan “language use shapes cultural norms large scale evidence gender” nature human behaviour accepted publication artificial intelligence ethics ai expect human knowledge expanding faster given extra computational resources bringing digital hardware also increasing access human minds humanity ict reduces aforementioned overhead costs discovering combining transmitting prior computational outcomes get smarter culture expands embrace more—and diverse—minds22 however fact exploit computation build ai increase native well systemic intelligence using ai mean replaceable ai explained next sections ai cannot used replicate humans substantial consequences law regulation ai cannot produce fully replicated humans models wrong computer science often mistaken branch mathematics happens many important implications computation physical process lost example ai wrongly perceived path toward human immortality first potential “uploading” human intelligence meaningful sense highly dubious technological brains cannot “scanned” replicated material another brain computational properties depend trillions temporal minutiae23 creating second identical human host new brain physical intractable also would cloning—both unethical illegal least european union second even could somehow upload adequate abstractions minds confuse actual spawned digital replica24 example abstracted digital clone might use manufacture canned email replies25 create interactive interfaces historical storytelling26 make human anita williams woolley et al “evidence collective intelligence factor performance human groups” sci october –barton h hamilton jack nickerson hideo owan “diversity productivity production teams” advances econ analysis participatory labormanaged firms –feng shi et al “the wisdom polarized crowds” nature hum behaviour –yoonsuck choe jaerock kwon ji ryang chung “time consciousness mind uploading” int’l j machine consciousness –as would suggest see murray shanahan technological singularity cambridge mit press review mark dredze et al “intelligent email reply attachment prediction” proceedings 13th international conference intel igent user interfaces new york acm –david traum et al “new dimensions testimony digital preserving holocaust survivor’s interactive storytelling” proceedings eighth international conference interactive digital storytelling cham switzerland springer –joanna j bryson many argued moral intuitions motivations even aesthetics enculturated ape way meaningful embedded device shares noth ing embodied physical “phenomenological” experience27 nothing build metal silicon ever share phenomenology much rat cow see cows rats viable vessels posterity yet whether digital artifacts viewed adequate substitutes real person depends one values person example value capacity control lives oth ers many turn simple technology control intimate aspects lives chosen heirs therefore seems likely spend millions even billions dol ars euros rubles producing digital clones literal deeply invested believing least forcing oth ers treat extensions themselves28 even could somehow replicate artifact mean time obso lescence digital technologies formats far far shorter average human life expectancy presently nears ninety years quick obsolescence true physical technology also fashion unquestionably abstracted digital selfportrait would follow fashion reflecting aspect complex selves cultural appropriate specific moment would possible abstraction ful model rich individual would progressed extended lifetime let alone biological gen erations complete modeling opposes meaning abstraction unabstracted model would require biological cloning even many generations would fall ecological fashion appropriateness evolution progresses apologies eisenhower box29 abstractions wrong pro ducing abstractions essential definition used chapter intelligence— intelligent action—is abstraction present context therefore producing abstraction essence intelligence abstraction snapshot organism organism models wrong build perform actions feasible using original reproducing full organism required many aspects called fiction otherwise making lasting contribution culture society irrevocable impact ecosystem purpose chapter introduce ai perspective maintaining social order—that perspective frank pasquale “two concepts immortality reframing public debate stemcell research” yale j l hum14 –bryson “embodiment versus memetics” guy claxton intel igence flesh mind needs body much thinks new ct yale university press dennett bacteria bach back pasquale “two concepts immortality” questions expenditures even vitro fertilization grounds economic fairness g e p box “robustness strategy scientific model building” robustness statistics ed r l launer g n wilkinson new york academic press –pasquale “two concepts immortality” artificial intelligence ethics ai law regulation discussed following section methods enforcing law regulation founded evolved priorities social animals therefore intelligent artifacts representing highly abstracted versions individual human relevant law except perhaps intellectual property creator ai cannot dissuaded law treaty way ensure artifact could held legal accountable31 many peo ple think purpose law compensate obviously allow machine property least wealth could sense compensate errors misfortune however law real primarily designed maintain social order dissuading people wrong law dissuades making clear actions considered wrong determining costs penalties committing wrong acts even true policies treaties often constructed long periods negotiated agreement among peers least sufficiently powerful fellow actors direct control worth expense acts would wrong costs would adequately dissuade iran nuclear deal excellent example process32 course systems governance also generate revenue may used governments extent right wrongs however none costs pen alties courts impose matter ai system easily write program says “don’t put jail” however cannot program ful systemic aversion loss social status years finite life span vast majority humans experience birthright fact humans many social species find isolation confinement deeply aversive—guppies die fright separated school factory farming shown drive pigs exhibit symp toms severe mental illness33 might add bomb camera timer robot program bomb destruct camera seen humans robots ten minutes reasoning empathy might think machine far disuadable human easily spend ten minutes alone without self destructing empathy terrible system establishing universal ethics—it works best like human components christian list philip pettit group agency possibility design status corporate agents oxford oxford university press kenneth katzman paul k kerr iran nuclear agreement tech rep r43333 library congress congressional research service may httpscrsreportscongressgovproductpdfrr43333 françoise wemelsfelder “the scientific validity subjective concepts models animal welfare” applied animal behaviour sci –joanna j bryson yourself34 robot’s behavior could easily utterly unaltered contrivance could said suffer technical definitions suffering35 certainly could said dissuaded even robot could detect reason consequences new situation would feel fear panic systemic aversion isolation although depending goals might alter planning favor shorter planning horizons law invented by—we might even say “coevolved with”—our societies order hold humans accountable unintended consequence humans held accountable law even extension legal personality corporations works extent real humans real control corporations suffer corporation wrong overextension legal personhood corpo ration designed fail eg launder money known creating shell company build ai system allow operate autonomously similarly essential person chooses allow system operate autonomously one go jail fined ai system transgresses law simply way hold ai system accountable dissuade artificial intelli gence held accountable would ultimate shell company36 implicit principles underlie capacity coordinate cooperate law dissuasions also coevolved complex societies share many cognitive attributes—including perception action capacities importantly motivations—with apes yet also specialist motivations capacities reflecting highly social nature37 amount intelligence necessitates social competitiveness neither demand acceptance ingroup dominance outgroup need achieve social status either motivations underlie human social species’ cooperation competi tion result evolutionary history38 none necessary—and much paul bloom empathy case rational compassion new york harper collins wemelsfelder “scientific validity subjective concepts” daniel c dennett “why can’t make computer feels pain” brainstorms pp –page numbers cambridge mit press original edition montgomery vt bradford books bryson “artificial intelligence prosocial behaviour” margaret boden “robot says whatever robots won’t take couldn’t care less” aeon august original lecture leerhulme centre future intelligence httpsaeoncoessaystherobotswonttakeoverbecausetheycouldntcareless note particular none millions currently extant robots would behave differently additions unless programming also altered weight additions stopped moving bryson diamantis grant “of people” david michael stoddart scented ape biology culture human odour cambridge cambridge university press stoddart scented ape ruth mace “the coevolution human fertility wealth inheritance strategies” philosophical transactions royal society london b biological sciences –jillian j jordan et al “uncalculating cooperation used signal trustworthiness” proceedings nat’l academy sciences –simon powers carel p van schaik laurent lehmann “how institutions shaped last major evolutionary transition largescale human societies” philosophical transactions royal society b biological sciences artificial intelligence ethics ai even incoherent—from perspective artifact artifacts definitional designed human intent directly evolution intentional acts authored human creation39 come human responsibility also entirely different landscape potential rewards design constraints40 ai ict impact every human endeavor given ai always built explainable humans held account assertions ai trustworthy accountable responsible completely misguided humans held account legal per spective goal ai transparency ensure human blame correctly apportioned course sorts transparency support ordinary users establishing correct boundaries systems ability debug customize ai system41 artificial intelligence reliable trustworthy—it require social compact leap faith42 consumers governments alike confidence determine responsible aiinfused systems incorporate homes business processes security every task apply conscious minds to—and great deal implicitly—we using intelligence artificial intelligence therefore affect everything aware great deal always done without intent mentioned earlier even fairly trivial ubiquitous ai recently demonstrated human language contains implicit biases biases many cases reflect lived realities43 reusing reframing previous computation ai allows us see truths previously known including transmit stereotypes44 automatical magical improve us without effort caliskan bryson narayanan discuss outcome famous study choice create life childbirth may author child rearing dispositions discussed shared primates options left parents conspecifics determine cf joanna j bryson “patiency virtue design intelligent systems systems ethics” ethics info tech mar –bryson winfield “standardizing ethical design” onora o’neil question trust bbc reith lectures cambridge cambridge university press caliskan bryson narayanan “semantics derived automatical language corpora” lewis lupyan “language use shapes cultural norms” marianne bertrand sendhil mul ainathan “are emily greg employable lakisha jamal field experiment labor market discrimination” econ rev –joanna j bryson showing given otherwiseidentical resumes individuals stereotypical african american names half likely invited job interview individuals european american names45 smart corporations using careful pro grammed ai avoid implicit biases early stages human resources processes select diverse cvs short list demonstrates ai can—with explicit care intention—be used avoid perpetuating mistakes past idea “autonomous” ai systems “valuealigned” therefore likely misguided certainly necessary acknowledge understand extent implicit values expectations must embedded artifact46 designing embedding sufficient create system autonomously moral indeed system cannot made accountable may also held moral agent issue embedding intended asserted values machines rather ensuring machines allow firstly expression mutable inten tions human operators secondly transparency accountability intentions order ensure least govern operators’ morality correctly expressing intentions ai incidental telegraph values individual liberty including freedom opinion thought absolutely critical human wellbeing also robust creative society47 allowing values enforced enfolding curtains interconnected technology invites gross excesses powerful actors consider vulnerable threat unimportant48 even supposing power demonstrably benign allowing mechanisms tech nological autocracy creates niche may facilitate lessbenign power—whether change hands corruption original power corruption systems communicating wil final powerful actor also altered ict clandestine networks assemble—or assembled—out small numbers anony mous individuals acting wellcoordinated way even across borders49 theoretical biology tel us greater communication higher probability cooperation50 cooperation nearly entirely positive connotations marianne bertrand sendhil mul ainathan “are emily greg employable lakisha jamal field experiment labor market discrimination” american economic review –jeroen van den hoven “ict value sensitive design” information society innovation legitimacy ethics democracy honor professor jacques berleur sj ed philippe goujon et al valuesensitive design” sci engineering ethics june –julie e cohen “what privacy for” harv l rev may –brett frischmann evan selinger reengineering humanity cambridge cambridge university press miles brundage et al malicious use artificial intel igence forecasting prevention mitigation tech rep httpsmaliciousaireportcom future humanity institute university oxford centre study existential risk university cambridge center new american security electronic frontier foundation openai feb carole cadwal adr “ ‘i made steve bannon’s psychological warfare tool’ meet data war whistleblower” observer march httpswwwtheguardiancomnews2018mar17 datawarwhistleblowerchristopherwyliefaceooknixbannontrump joan roughgarden meeko oishi erol akçay “reproductive social behavior cooperative games replace sexual selection” sci –the artificial intelligence ethics ai many senses almost neutral—nearly human endeavors involve cooperation general benefit many humans destructive many others essence cooperation moving portion autonomy individual group51 extent autonomy entity extent determines actions52 individual group autonomy must extent trade though means organizing groups offer less liberty constituent parts many people falsely preaching ml new ai falsely data ml trained smarter ai machine learning actual statistical process use programming aspects ai thinking ‘bigger’ data necessarily better begs question better basic statistics teaches us number data points need make prediction limited amount variation data providing data true random sample pop ulation measured53 natural limits particular task much data actual needed build intelligence perform it—except perhaps surveil lance need science medicine may require minuscule fraction population however want spot specific individuals controlled dissuaded even promoted course want “know things”the changing costs benefits investment group level roughgarden oishi akçay describe consequences beyond privacy liberty information communication technology facilitates blurring distinction customer corporation blurs even definition economic transaction customers real labor corporations give custom pricing bagging groceries punching data atms banks filling forms airlines forth55 value labor directly remunerated—we assume receive cheaper products return loss agency corporations might seen form bartering “free” services like internet searches email may better understood information bartering56 transactions denominated price means ict facilitates black least opaque market reducing measured custom therefore tax revenue true every one uses internet services interfaces even ignoring present controversies bryson “artificial intelligence prosocial behaviour” harvey armstrong robert read “western european microstates eu autonomous regions advantages size sovereignty” world dev –maeve cooke meng xiaoli “statistical paradises paradoxes big data law large populations big data paradox us presidential election” annals applied statistics –mark andrejevic “automating surveil ance” surveil ance society –bryson “artificial intelligence prosocial behaviour” joanna j bryson “the past decade future ai’s impact society” towards new enlightenment transcendent decade openmind bbva commissioned based previous whitepaper oecd also commissioned madrid taylor joanna j bryson definitions employment raised platforms57 failure assign monetary value transactions may also explain mystery ai seem increasing productivity58 artificial intelligence gives us new ways everything intentional great deal extent ai makes different tasks easier harder varies ways intuitive also increases decreases values human skil knowledge social networks personality traits even locations ai alters calculations identity security fortunately ai also gives us tools reasoning communicating changes adjusting makes grouplevel identity fluid complicating ability govern who’s charge ai governance despite fluctuation certain things invariant extent computational resources communicative capacities basic nature humans animals certain size metabolic cost basic drives determine gives us pleasure pain stress engagement altered much live always enormously impacted neighbors live share geographi cal related decisions concerning investment air water education health secu rity reason always kind geographybased governance fundamental ethical framework negotiating last century human rights based responsibility geographical defined governments individuals within sphere influence governments59 wise actors like european union extended notion individual’s sovereignty cyberassets personal data60 makes sense almost exactly reason rights airspace make sense bidirectional information access influ ence individual’s behavior could physical force recently good reason hope real start mandating devel opers follow best practice software engineering61 sensible also ensure information systems spreading engulfing us also entirely cf tim o’reil wtf what’s future it’s us new york random house erik brynjolfsson daniel rock chad syverson “artificial intelligence modern productivity paradox clash expectations statistics” economics artificial intel igence agrawal gans goldfab eds chicago university chicago press –sabine c carey mark gibney steven c poe politics human rights quest dignity cambridge cambridge university press paul nemitz “constitutional democracy technology age artificial intelligence” philosophical transactions royal soc mathematical physical engineering sciences oecd recommendation council artificial intel igence oecd legal instruments oecdlegal0449 includes oecd principles ai paris organisation economic cooperation development may artificial intelligence ethics ai cybersecure else internet clearly documented accountability lines responsibility62 nevertheless even visions achieved still areas law governance concerned last focus present chapter new foci power wealth explained previous section also parts “everything human” ai ict altering clear achieving secure accountable ai requires coopera tion adequate sources power counter wish avoid consensus law therefore wealth power distribution like cybersecurity clearly orthogonal technological ai also irrevocably intertwined ethical regulated application problems ai accountability grotesquely uneven wealth distribution unlikely solved independently section noted describing work progress colleagues63 aspects seem sufficiently evident justify inclusion hypothesize new technologies reduce economic cost distance turn reduces amount easilysustained competition sector locale becomes less part value higherquality products services domi nate everlarger regions including cases entire globe process may sparked gross inequality late nineteenth early twentieth centuries rail news telecommunication oil far easier transport coal wood new monopolies inequality spirals capital allowed cap ture regulation seems recently happened “big tech” global also finance united kingdom oil saudi arabia russia leading midtwentieth century lower inequality political polarization cooccurred innovation welfare state countries including united states united kingdom preceded least world war ii though cooperation even states seemed require motivation previous war financial crash governance almost defined redistribution certainly allocation resources solve communal problems create public goods governance’s core characteris tic65 thus excessive inequality seen failure governance66 right clearly able govern interestingly sides great firewall cf filippo santoni de sio jeroen van den hoven “meaningful human control autonomous systems philosophical account” frontiers robotics ai alexander j stewart nolan mccarty joanna j bryson “explaining parochialism causal account political polarization changing economic environments” arxiv preprint arxiv180711477 john christensen nick shaxson duncan wigan “the finance curse britain world economy” british j pol int’l relations –nolan mccarty keith poole howard rosenthal polarized america dance ideology unequal riches 2nd ed cambridge mit press jeanpierre landau “populism debt europe different us” talk princeton woodrow wilson school preparation feb eg gini coefficient francesco grigoli adrian robles inequality overhang imf working paper wp1776 international monetary fund note low gini coefficient problematic joanna j bryson china internet companies perhaps similar market commercial aircraft costs distance sufficiently negligible best products likely become global monopolies unless substantial government investment eg great firewall china67 airbus europe68 governance fails local region county also likely see political polarization success populist candidates referendum outcomes69 many problems associate present moment necessarily cre ated ai ict directly rather formed indirectly facilitating increased inequality regulatory capture problems may much created exposed ai70 exceptions ict—particularly capacity digital media ful reproduced distance inexpen sively—does produce qualitative change include changing meaning ownership71 generating truly novel means recognizing disrupting human intentions even implicit intentions consciously known actors72 hand things treated invariant example mentioned earlier human rights painstakingly agreed foundation international law obligations state treated core ethical ai systems73 one disturbing things come understand learn algorithms extent humans algorithmic law make us particularly constrain example mandatory sentencing ordinar ily humans wiggle room74 trust form cooperation arising contexts ignorance ignorance may important feature society ict threatens roya ensafi et al “analyzing great firewall china space time” proceedings privacy enhancing tech –damien neven paul seabright “european industrial policy airbus case” econ pol’y july –yuri zhukov “trading hard hats combat helmets economics rebellion eastern ukraine” special issue ukraine escape postsoviet legacy j comp econ –sascha becker thiemo fetzer dennis novy “who voted brexit comprehensive districtlevel analysis” econ pol’y oct –florian dorn et al “inequality extremist voting evidence germany”annual conference freiburg breisgau digital economy verein für socialpolitik german economic association nemitz “constitutional democracy technology age artificial intelligence” orly mazur “taxing robots” pepperdine l rev –aaron perzanowski jason schultz end ownership personal property digital economy cambridge mit press caio machado marco konopacki “computational power automated use whatsapp brazilian elections” medium october httpsfeeditsrioorgcomputationalpower automateduseofwhatsappintheelections59f62b857033 cadwal adr “‘i made steve bannon’s psychological warfare tool’” zhe wu et al “deception detection videos” thirtysecond aaai conference artificial intel igence new orleans la philip alston mary robinson human rights development towards mutual reinforcement oxford oxford university press david kaye “state execution international covenant civil political rights” uc irvine l rev –cohen “what privacy for” artificial intelligence ethics ai remove75 trust allows cheating innovating sometimes may essential first allowing innovation makes tractable level detail exceptions needs specified second course innovation allows us adjust unex pected find novel sometimes better solutions some—perhaps many—nations may danger allowing digital era make innovation free thought dif ficult individual risky creating nationwide fragility security threats well impinging important human right freedom opinion76 countries law may bend much toward rigidly preserving group inadequately defend individual mentioned issue rights also robustness individuals variation produce alternatives–choosing among available options rapid way change behavior crisis demonstrates change needed77 given digital revolution fundamental changed nature privacy everyone societies need find way reintroduce defend “wiggle room” innovation opinion believe strongly would preferable done destroy ing access history acknowledging defending individual differences including shortcomings necessity learning psychological political realities remain explored understood may vary polity summary robots reiterate main points computer science mistaken branch mathe matics many important implications computation physical process lost impact society dissemination information power influ ence adequately noted either two disciplines law social sciences awareness technological reality affordances building slowly ironical impacts recently also much noticed political science primarily impacts noted sociology unfortunately imploding time ai exploding similar myopia computer science psychology primarily seen studying humans organ isms primary ethical considerations field seen similar medical subjects concerns patient privacy related disci plines media studies marketing raised issue better understood human behavior might effectively manipulate control observation made little headway popular academic understanding ai direct interventions o’neil question trust paul rauwolf joanna j bryson “expectations fairness trust coevolve environments partial information” dynamic games applications cf frischmann selinger reengineering humanity cohen “what privacy for” luke stark “the emotional context information privacy” info soc’y –joanna j bryson via neuroscience drugs received attention potential indirect manipulations particularly adults seemingly dismissed historic errors may consequence fact human adults neces sity ultimate moral agents centers accountability societies expected capacity take care ethics ai therefore often reduced popular culture edifice extension civil rights movement78 discovered—astonishingly—that people ethnicities genders human “we” “we” therefore obliged consider anything might human position seems rejection inclusivity civil human rights appropriate extension powerful attractive many seem particularly likely members recently dominant forms gender ethnicity perhaps intuit extension would raise power clique making notion rights less meaningful comprehensibly suggested must extend human rights protec tions anything humans might identify order protect self concept even identification objects implicit mistaken79 follows kant’s observation treat animals reminiscent humans badly also likely treat humans badly extending principle ai though likely also mistake avoidable one remember ai definitional artifact therefore designed almost certainly makes sense tractable change ai radical change law rather kant motivating us treat ai appears human human use kant motivate building ai appear human first place approach first united kingdom80 recently oecd81 whose ai ethics principles recommend ai never deceptively appear human may seem like heavy restrictiction present society becomes familiar ai—and process better understands human requires deserves protection—we able broaden scope humanlike devices still likeness deceive82 recent calls ground ai governance “ethics” viewed illdefined international human rights law course may false dichotomy procedures classical ethics theories may still use determining tony j prescott “robots tools” connection sci –david j gunkel “the question robots rights” ethics info tech –daniel estrada “value alignment fair play rights service robots” proceedings aaaiacm conference ai ethics society aies ’new york ny acm –joel parthemore blay whitby “what makes agent moral agent reflections machine consciousness moral agency” int’l j machine consciousness –david j gunkel robot rights cambridge mit press boden et al principles robotics oecd recommendation council artificial intel igence joanna j bryson “the meaning epsrc principles robotics” connection sci –the artificial intelligence ethics ai ambiguities tradeoffs law’s application83 certainly expect ongoing consideration localized variation term ethics perhaps better communi cates rights ethics always identity communicated codes con duct confound fundamental principles may able codify rights things essential identity markers identity essential security constructing defendable community84 identity obviously defini tional defines group groups often best means humans achiev ing security therefore viability breaking different groups sometimes efficient governance resource constraints also groups different fundamental security tradeoffs based geological ecological situation simply relations neighbors identity also often rests shared historical narratives afford different organizational strategies course may secondary essential geoecological concerns il ustrated apparent ease new ethnicities invented85 course also make contribution security get wrapped localised ethical systems conclusion artifact transforms perception relevant information including action ai—and note ai adjective noun unless referring academic discipline question ai digital technologies general introducing enormous transformations society nevertheless impacts governable less transformative legislative change vast major ity ai—particularly social impact—is remain consequence corporate commercial processes subject existing regulations regulat ing strategies may need regulatory bodies expertise examining accounts software development critical remember holding accountable machines people build operate them—including alter operation assault cybersecurity need govern human application technology need oversee human processes development testing operation monitoring artificial intelligence also offers us opportunity discover societies work allowing us construct artifacts mimic aspects nature provide new affordances modularity decoupling allow novel means selfexamination including examination crucial capacities morality political behavior exciting time scientific artistic exploration well commerce law better knowledge also cansu canca “human rights ai ethics ethics cannot replaced udhr” united nations univ ai global governance articles insights july httpscprunuedu aiglobalgovernancehumanrightsandaiethicswhyethicscannotbereplacedbytheudhrhtml bill mcsweeney security identity interests sociology international relations cambridge university press simon powers “the institutional approach modeling evolution human societies” artif life –erin k jenne stephen saideman lowe “separatism bargaining posture role leverage minority radicalization” j peace research –joanna j bryson offers opportunity better control role law crafting individual societal protections never crucial acknowledgments small proportion material review derived document previously delivered oecd karine perset may title “current potential impacts artificial intelligence autonomous systems society” contributed oecd ai policy efforts documents –and also reused permis sion expanded bryson bbva debt probably owed frank pasquale extremely useful feedback suggestions first draft thanks also lowe patrick slavenburg jeanpaul skeete supported part axa research fellowship ai ethics writing chapter references boden margaret et al principles robotics united kingdom’s engineering physical sciences research council epsrc apr httpswwwepsrcacukresearchourportfolio themesengineeringactivitiesprinciplesofrobotics brundage miles et al malicious use artificial intel igence forecasting prevention mitigation tech rep httpsmaliciousaireportcom future humanity institute university oxford centre study existential risk university cambridge center new american security electronic frontier foundation openai feb bryson joanna j “the past decade future ai’s impact society” towards new enlightenment transcendent decade openmind bbva commissioned based white paper also commissioned oecd madrid taylor mar bryson joanna j mihailis e diamantis thomas grant “of people legal lacuna synthetic persons” artificial intel igence law sept –cadwal adr carole “ ‘i made steve bannon’s psychological warfare tool’ meet data war whistleblower” observer march claxton guy intel igence flesh mind needs body much thinks new ct yale university press cohen julie e “what privacy for” harv l rev may –dennett daniel c “why can’t make computer feels pain” brainstorms reprint montgomery vt bradford books –gunkel david j robot rights cambridge mit press hüttermann michael devops developers new york apressspringer krol joshua et al “accountable algorithms” univ penn l rev –list christian philip pettit group agency possibility design status corporate agents oxford oxford university press nemitz paul “constitutional democracy technology age artificial intelligence” philosophical transactions royal soc mathematical physical engineering sciences artificial intelligence ethics ai oecd recommendation council artificial intel igence oecd legal instruments oecdlegal0449 includes oecd principles ai paris organisation economic cooperation development may o’neil onora question trust bbc reith lectures cambridge cambridge university press o’reil tim wtf what’s future it’s us new york random house santoni desio filippo jeroen van den hoven “meaningful human control autonomous systems philosophical account” frontiers robotics ai shanahan murray technological singularity cambridge mit press sipser michael introduction theory computation 2nd ed boston pws thompson chapter ethics ethics ai thomas powers jeangabriel ganascia introduction broad outlines ethics ai coming focus researchers advance state art applications enter private public sectors like earlier technologies nuclear fission recombinant dna ai technologies bring risks rewards individuals societies instance safety pedestrians path autonomous vehicles privacy consumers analyzed data subjects fairness selection procedures loan job applicants—as affect societies grapple moral legal status new artificial agents increasingly act without direct human supervision risks largely seen justifying rewards latter expected significant indeed economic forecasts tout robust relatively certain revenue growth productivity gains ai next decades1 yet time increased unemployment expected industrial labor markets shrink due rapid ai outsourcing skilled unskilled labor global level ai continue transform science engineering also used afford leisure expand knowledge humanities2 combined efficient datagathering techniques break throughs genetics nanoscience cognitive science ai almost certainly entice philippe aghion benjamin f jones charles jones “artificial intelligence economic growth” economics artificial intel igence agenda ed ajay agrawal joshua gans avi goldfarb chicago university chicago press –jeangabriel ganascia “epistemology ai revisited light philosophy information” knowledge technology policy –accessible httpsdoiorg101007 s1213001091010 thomas powers jeangabriel ganascia us effect greater mastery planet perhaps ai first pass stage attempts via surveil ance policing militarization also master human beings faced panoply ethical concerns implicate fundamental human rights privacy security equal opportunity ethical principles fairness respect equitable distributions burdens benefits may useful first ask ought approach ethics ai words ethics ethics ai preceding account suggests issues might engaged individual social global levels sure ethicists begun make progress ethical concerns ai working within particular level approaches deontological consequentialist virtue ethics etc common fields applied ethics scholarship machine ethics robotic ethics data science ethics military ethics fields generating interest within without academia ethics ai may “work progress” least call answered enough thesis present chapter common approaches may sufficient primarily due transformational nature ai within science engineering human culture heretofore ethicists understood key ethical concepts agency responsibility intention autonomy virtue right moral status preference interest along models drawn almost exclusively examples human cognitive ability reasoned behavior ethicists “applied” ethics accordingly conceptual tools hand artificial intelligence chal lenge concepts ethicists begin digest problem continued human coexistence alternate perhaps superior intelligences say ai challenge way tried reason ethics millennia correct novel approaches needed address ethics ai future go implement ethics ai need overcome serious barri ers formalization ethics complicating factors ethics ai concern epistemic issues broadly speaking first ethicists general learn ai applications appear point attempt “catch up” possibly alter limit applica tions essential rearguard action time lag owes fact ethicists business predicting emergence technologies would good could figure ethics technology prior released market place public sphere—if could “anticipatory ethics”—the necessary predictive skill would domain ethics ethicists try predict trajectory new technology future applications order critique often get trajectory wrong overestimation future technologicalethical problems leads ethicists become amateur futurists futurists often spend inordinate amount time worrying technological applications never come pass second epistemic complications ai turn fact ai changing know especial realm science computational data science cds philip e brey “anticipatory ethics emerging technologies” nanoethics –the ethics ethics ai includes “big data” science discoverybased techniques adds immensely body accessible information correlations natural social worlds thus changing scientists think process inquiry computational data science cal question whether new knowledge real adds human scientific understanding since many ethical analyses depend scientifical derived knowledge—especial knowledge social facts relations—we placed diffi cult epistemic position whether one conceives body knowledge coherentist epistemic gift time cannot ful understand real getting goal following reflections resolve even attempt analyze spe cific ethical issues arise ai rather survey believe important challenges progress ethics ai present moment many ai applications driving interest ethics among autono mous vehicles battlefield lethal robots recommender systems commerce social media facial recognition software near future may grapple disruptions human social sexual relationships caused androids juris prudence administered primarily intelligent software developments ai—now foreseeable future—are sufficiently worrisome progress ethics ai ethical issue discussion challenges incorporates longstanding philosophical issues well issues related computer science computer engineering leave reader pursue technical details philosophical scientific issues presented reference background literature inquiries challenges fall five major categories conceptual ambiguities estimation risks implement ing machine ethics epistemic issues scientific explanation prediction oppo sitional versus systemic ethics approaches conceptual ambiguities research ethics ai respectively involves distinct scholarly communities surprising terminological problems arise key concepts contemporary agent autonomy intelligence—though typical ethicists ai experts attach dif ferent meanings terms section explain standard meanings attach three polysemous concepts fields cannot hope dis solve ambiguities favor one another meaning want draw attention sources potential problems within ethics ai ernest sosa “the raft pyramid coherence versus foundations theory knowledge” midwest studies philosophy –thomas powers jeangabriel ganascia agent central modern ai since 1980s notion agent—and one supposed “intelligent”—has often seen main unifying theme discipline particularly apparent renowned manual artificial intelligence stuart j russell peter norvig artificial intel igence modern approach defines ai “as study agents receive percepts environment per form actions”the theme repeated classical “human problem solving” account alan newell herbert simon’s human problem solving6 also published newel ’s work “the knowledge level”and widely used notion multiagent systems mas refers systems composed plurality agents interacting together context ai notion agent closely related meaning economics cognitive sciences since terms characterize entities act precisely following russell norvig say ai “agent implements function maps percept sequences actions” within definition structure actions reduced mechanical consequences objectives—the goals agent pursues philosophical terms intentions—are speci fied given outside means artificial agents initiate actions aware acting philosophy agent intends upon reflection actions aware selec tion intentions initiates actions based words artificial agents differences two conceptions agents—the technical one ai economics psychology well philosophical one—have important conse quences ethical point view obviously since ai agent lacks true proper goals personal intentions real freedom cannot considered responsible actions part cannot explain behaves way ways notion “agent” understood philo sophical sense explanation accounting action expected issue widely debated philosophical community instance con nection daniel dennett’s notion “intentional system”which used describe computers people ascribe intentions desires beliefs calling intentional agents9 however even case dennett clearly specifies cal “intentional stance” prerequisite “moral stance” stuart j russell peter norvig artificial intel igence modern approach 3rd ed upper saddle river nj prenticehal alan newell herbert simon human problem solving englewood cliffs nj prenticehal alan newel “the knowledge level” artificial intel igence –daniel c dennett “intentional systems” journal philosophy –daniel c dennett intentional stance cambridge mit press ethics ethics ai cannot ful assimilated10 words “moral agent” “intentional system” many “intentional systems” like artificial agents autonomy adjective “autonomous” concept autonomy connected widely employed last years characterize systems behave without human intervention precisely device said autonomous exists sequence causeeffect relations—from capture information sensors execution action—without intervention human referring definition ai researchers currently speak autonomous cars weapons perhaps frightening way “lethal autonomous weapon systems” also referred laws usages difficult distinguish autonomy automaticity since cases relevant behavior corresponds entities act clearly corresponds etymology automaton αυτο self ματος move ment however etymology autonomy—αυτο self νομος law— differ automaticity usual meaning least philosophers designates entity able define laws rules behavior case automaton rules given imposed outside original adjective “autonomous” described political entity eg sovereign city kingdom state decided constitution laws meaning survives granting limited selfrule several “autonomous regions” various nation states following philosophers enlightenment particular rousseau kant meaning autonomy extended human beings denotes ideal situation individuals would decide maxims conduct selves without commanded kings presidents others way auton omous obeys rules choose thus reflect automaton acts obeying rules imposed without reflection see semantics matters let us consider example suppose want autonomous vehicle drive us safely destination indicated instance want go swimming pool clearly indicate car want expect technology adopt specified goal let us assume car autonomous according philosophical understanding ie decides following person’s order goal rule conduct may choose make appointment dentist perhaps paternalistic way drive movie theater parking looks comfortable consequence “real” autonomous car al daniel c dennett “mechanism responsibility” ted honderich ed essays freedom action london routledge kegan paul –thomas powers jeangabriel ganascia somewhat unpredictable person conveyed consequently desirable mode transportation worse stil imagine “real” philosophical autonomous weapon would choose would target would nightmare civilians noncombatants also military personnel need first foremost weapon systems ful control trust point view quite unlikely military would develop “real” autonomous weapons even though autonomous weapons fit ai engineering definition seem quite desirable many philosophical traditions agency autonomy properties adult ra tional beings moral persons ability choose regulate behaviors agency autonomy necessary conditions responsibility ai agent piece software within larger computer system performs function behalf user another software agent autonomous agent ai piece soft ware functions less continuously without direct intervention user ai concepts agent autonomy used without obvious connection responsibility result conceptual differences important recognize philosophical autonomous agent acts behalf ability concept “its behalf” say inconceivable someday software agents act absolutely without human interven tion behalf perhaps make sense attribute responsibility actions point ai agents case nonetheless still ethical issues arise ai agents act behalf users software agents also act relatively de pend ently human intervention intelligence though philosophical studies intelligence going back vico’s work eighteenth century considered distinctively human ability acknowledged intelligence instantiations plays important role ai public imagination computation general concept intelli gence needs clarified early modern philosophy intelligence typical inter changeable understanding indicated ability comprehend grasp aspects internal external reality contemporary philosophical usage intelligence largely supplanted concept mind natural social sciences espe cial psychology intelligence denotes cognitive abilities susceptible meas ure ment—for instance via intelligence quotient aggregates results different tests order grade relative abilities people population technical meaning “intelligence” ai—one assumes engineer intelligence—derives significance psychology proposal dartmouth summer research project artificial intelligence written mainly john ethics ethics ai mccarthy marvin minsky contains introduction central motivating claim ai “the study artificial intelligence proceed basis con jecture every aspect learning feature intelligence principle precisely described machine made simulate it”intelligence conceived set mathematical describable cognitive functions ai aims model simulate machines despite narrowing intelligence technical concept taken meaning public imagination marketing literature compa nies along significance includes mixture different capacities wil consciousness reflection even aptness perceive feel emotions unfortunately discussions intelligence ai systems often admixture popular philosophical scientific conceptions closely connected intelligence work philosophy mind philo sophical notion consciousness one standard assumption philosophy intelligent entities consciousness “backdrop” “framework” intel ligence happens though philosophers david chalmers see consciousness “hard problem”which suggests may never integrated physical sciences consciousness sometimes employed writers ai charac terize possible capacity future intelligent systems unlike philosophy assumption intelligent computer’s “firstperson perspective” “having” computational states equivalent mental states philosophers cal middleground notion consciousness suggested according machine would behave though conscious global availability relevant information access “internal global workspace” selfmonitoring measure behaviorism thrown conclude section conceptual ambiguities arise ethical debates around ai let us consider two broadly used terms field “intelligent agent” meanings terms seem resemble famous lichtenberg knife lacks blade handle since “autonomous agents” neither autonomous agents philosophers likewise “intelligent agents” neither intelligent agents john mccarthy marvin minsky nathaniel rochester claude e shannon “a proposal dartmouth summer research project artificial intelligence” accessible http raysolomonoffcomdartmouthboxadart564propspdf david j chalmers “facing problem consciousness ” journal consciousness studies –stanislas dehaene hakwan lau sid kouider “what consciousness could machines it” science –thomas powers jeangabriel ganascia risk overestimation underestimation partly due aforementioned ambiguities partly current social demand driven popular media14 overemphasize “dangers” ai estima tions risks ai suffer excess deficiency side excess presumed dangers include allegedly autonomous ais operate without human control weaponization ai global development ai would confusion agency autonomy machines indicated earlier may become fixated speculative risks one example recent focus driverless cars claim introduce potential unsolvable “trolley problems” applica tion ai technologies side deficiency ai systems present real underestimated risks instance using ai techniques deepfake soft ware synthesizes fake human pornographic videos combine superimpose existing person’s face prerecorded video different body person seems say things heshe never another overlooked application ai comes facial recognition recommending techniques implemented china give “reputation score” system automatical identifies minor law infractions citizens instance crossing road green light aggregates examples suggest identity sexual orientation consumer tendencies like subject ai tools section discuss ethical implica tions overestimation ai risks overestimations existential threats ai among current overestimations ai critiques revisit earlier fears tech nology general mimicking human behaviors abilities ai feared creates joel achenbach “driverless cars colliding creepy trolley problem” washington post december accessible httpswwwwashingtonpostcomnewsinnovations wp20151229willselfdrivingcarseversolvethefamousandcreepytrolleyproblem joel achenbach “the ai anxiety” washington post december accessible http wwwwashingtonpostcomsfnational20151227aianxiety patrick lin “the ethics autonomous cars” atlantic october accessible httpwwwtheatlanticcomtechnologyarchive201310theethicsofautonomouscars280360 henry kissinger “how enlightenment ends philosophical intellectual y—in every way—human society unprepared rise artificial intelligence” atlantic june accessible httpswwwtheatlanticcommagazinearchive201806henrykissingerai couldmeantheendofhumanhistory559124 ethics ethics ai least symbolic transgression il ustration consider enthusiasm fear attended public unveiling japanese roboticist hirochi ishiguro’s geminoids18 closely approximating appearance robot ishiguro invited com parison myth pygmalion fal love statue galatea nonetheless ishiguro’s robot autonomous remotely controlled way robot “sophia” developed company hanson robotics received “citizenship” saudi arabia speech united nations meeting speech auto matical generated “sophia” prerecorded organic human female instances “overselling” scientific results seem also subject amplification ai techniques involved psychologists recently published claims deep neural network trained better detect sexual orientation facial images humans19 ethical issues multiple unclear ai fact capable results given assumption sexual orientation fixed genetics uncertainty notwithstanding use techniques could damaging homosexuals regardless robustness results likewise considerable interest braincomputer interfaces bci supposed directly plug brain alleged “mind reads” drawn attention famous technologists mark zuckerberg20 however current state art warrant belief generic humanmachine interface though research shown stroke patients may regain motor control limb interfaces21 doubts notwithstanding neuralink firm founded elon musk offers another il ustration al ure direct connection mortal minds immortal digital world company aims developing plugin chips skull increase cognitive abilities specifical memory order “save human race” ai hopes double overestimation ai first ai constitute existential threat humanity second ai technology used avoid disaster according musk one difficult task merging mind digital “it’s mostly bandwidth speed connection brain digital version particularly output”however contemporary erico guizzo “the man made copy himself” ieee spectrum april –yilun wang michal kosinski “deep neural networks accurate humans detecting sexual orientation facial images” journal personality social psychology noam cohen “zuckerberg wants facebook build mindreading machine” wired mindreadingmachine society neuroscience “potential brainmachine interface hand paralysis combining brain stimulation robotic device could help restore hand function stroke patients” science daily january accessible wwwsciencedailycomreleases201801180115151611htm nick statt “elon musk launches neuralink venture merge human brain ai” verge march accessible httpswwwthevergecom201732715077864elonmusk neuralinkbraincomputerinterfaceaicyborgs thomas powers jeangabriel ganascia neurosciences idea cortex’s internal code means issue plugged brains owners technologies could always load whatever information wanted “linked” mind would give considerable power us besides specific examples ai technology hopes fears exist overestimations ai progress might called “existential” purportedly threaten future humanity among particular importance claim humankind soon become obsolete günther anders announced thesis book would eventual translated obsolescence man23 pessimistic view would repeated famous astro physicist stephen hawking theoretical physicist nobel laureate frank wilczek slightly less pessimistic view humans join machines kind hybrid would offer least extension life possibly immortal ity proponents last view scientists ray kurzweil philosopher nick boström musk obsolescence replacement views sometimes based singularity hypothesis possibility superintelligence one first expressions ideas goes back proposed british statistician irvin john good24 worked alan turing world war ii good discussed possibility “intelligence explosion” would follow development “ultraintelligent machines” able build intelligent machinery polish mathemati cian stanislaw ulam science fiction writers including isaac asimov also cred ited inventing idea 1950s “singularity” could consequence considerably accelerating progress computer technology25 science fiction novelist vernor vinge popularized idea essay entitled “the coming technological singularity”he argued within less thirty years progress information technology would allow making superhuman intelli gent entity would dramatical change status humankind particular connection humans machines mutual hybridization would allow us considerably increase intelligence lifespan capacities kinds key idea acceleration technological progress would suddenly irreversibly alter regime knowledge production creating technological developments beyond hope control günther anders die antiquiertheit des menschen bd über die seele im zeitalter der zweiten industriellen revolution munich c h beck irving j good “speculations concerning first ultraintelligent machine” advances computers –isaac asimov “the last question” science fiction quarterly nov vernor vinge “the coming technological singularity survive posthuman era” vision interdisciplinary science engineering era cyberspace cleveland nasa lewis research center –the ethics ethics ai recently technologists like ray kurzweil27 hans moravec28 hugo de garis29 kevin warwick30 bill joy31 even philosophers nick boström julian savulescu32 theorized future technological singularity supposed play major role differences among writers consider new plagues generated development computing power others proclaim end humankind emergence new species common views rather credulous leap conclusion singularity coherent scientific eventuality despite popularity main idea singularity quite dubious fact appears inference exponential increase computing power char acterized moore’s law somehow lead ultraintelligent machines however moore’s law—put forward —is empirical description evolu tion hardware describes increase computing speed along exponen tial diminution cost storage devices borne historical evidence held less sixty years moore’s law makes inductive prediction based rigorous foundations computer science main scope origi nal economical scientific consequence good reasons doubt hold indefinitely addition “amount” intelligence—a strange notion assumed advocates singularity—can neither measured frequency computer’s processing speed quantity bits stored electronic devices since beginning ai progress related algorithms statistics mathematical probability theory knowledge representation formalisms logic computing power though efficiency modern computers ren ders possible implementation parallel algorithms huge quantities data assurance developments get us closer singularity underestimation ai risks along abundant overestimations ai capacities supposed either excessively beneficial humankind excessively maleficent many predatory applications ai techniques partly ignored least potential harm ray kurzweil singularity near humans transcend biology new york penguin books hans moravec “when computer hardware match human brain” journal evolution technology hugo de garis artilect war cosmists vs terrans bitter controversy concerning whether humanity build godlike massively intel igent machines palm springs ca etc publications kevin warwick march machines breakthrough artificial intel igence champaign university illinois press bill joy “why future doesn’t need us” wired –nick bostrom julian savulescu eds human enhancement oxford oxford university press thomas powers jeangabriel ganascia scarcely noticed characterize “underestimations” ai risks problematic ethical point view overstatements nonexistent threats consider neglected “underestimations” ai techniques many famous people seem fear laws—lethal autonomous weapon systems—and propose official multilateral ban stop research military applications area33 nonetheless serious doubts whether ful autonomous weapons ever developed since mentioned armies need robust trust worthy weapons34 however revealed “the drones papers”information tech nologies incorporating many ai components used drone war afghanistan target supposed terrorists drones general unmanned weap ons autonomous since remotely controlled choice objectives done partial automatical based informational indices instance conversa tions phone localizations provided targets military uses ai contribute considerable col ateral damage probably already second example concerns state use facial recognition techniques without proper safeguards techniques infringe individual rights well threaten “dignity person” constant surveil ance guilt association could used track record movement individuals especial urban environments high density population reported china using tech niques track minority uighur population36 facial recognition china could combined farreaching “social credit system” entire country37 security reasons cities countries instance city nice france plan use facial recognition detect suspects terrorism worry place scope application ais would extended citizens underestimated risk involves machine learning predict risk insurers apportion risk individualizing insurance premiums least two perverse effects first concerns opacity decision criteria given clients time explicit due deep learning techniques based researchers become aware problems opacity tried introduce explainable ai systems explanation crucial order earn public confidence since without explanation decisions insur ance company could total arbitrary based marketing factors future life institute “autonomous weapons open letter ai robotics researchers” published online july accessible httpsfutureoflifeorgopenletter autonomousweapons jeangabriel ganascia catherine tessier thomas powers “on autonomy threat ‘killer robots’ ” apa newsletter philosophy computers –the intercept “the drone papers” published online october accessible https theinterceptcomdronepapers paul mozur “one month face scans china using ai profile minority” new york times april accessible httpswwwnytimescom20190414technology chinasurveil anceartificialintelligenceracialprofilinghtml rachel botsman “big data meets big brother china moves rate citizens” wired creditscoreprivacyinvasion ethics ethics ai risk38 second perverse effect would change original nature insurance relies mutualizing pooling risks consequently weaken solidarity sense community final underestimated risk ai considered concerns predictive justice aims establishing sanctions according risk repeat offenses law depending criteria used applications could unjust also deny relevance redemption contrition addition raises fundamen tal questions nature juridical sanction principle based actual infringement laws potential offense short story “the minority report” philip k dick film adaptation minority report directed steven spielberg ai application could lead punishment persons guilty precrime say crime yet committed probability implementing ethics making machines moral undoubtedly would tempting introduce human values machines make moral means make behave accordance criteria moral behavior general deontologist act according duty might ponder distinction attributed kant acting merely conformity duty versus acting sense good alone achieves however since machine determine ends goals action acts goals given outside invoking will—that diving errantly machine motivations—would seem foolish thus shall consider ability machine behave moral without invoking moral motivations past years ai researchers39 attempted theorize intelligent agents appeal ethical considerations choosing actions cathy o’neil weapons math destruction new york crown publishers fiona berreby gauvain bourgne jeangabriel ganascia “eventbased scenariobased causality computational ethics” proceedings 17th conference autonomous agents multiagent systems richland south carolina international foundation autonomous agents multiagent systems –selmer bringsjord konstantine arkoudas paul bello “toward general logicist methodology engineering ethical correct robots” ieee intel igent systems –jeangabriel ganascia “modelling ethical rules lying answer set programming” ethics information technology –wendell wal ach colin allen iva smit “machine morality bottomup topdown approaches modelling human moral faculties” ai society –thomas powers “prospects kantian machine” ieee intel igent systems –amitai etzioni oren etzioni “incorporating ethics artificial intelligence” journal ethics –thomas powers jeangabriel ganascia perform work seen response potential unpredictable behaviors machines machinelearning techniques build opaque programs huge quantities training examples human would able assimilate situa tions machines unable explain behavior terms understandable humans also decisions could produce significant harms therefore seems crucial control machine behaviors ensure conform shared social norms values section give overview ways introduce ethical controls also describe intrinsic limitations note approaches quite remote actual ethical issues related current applications ai may become relevant ai advances modeling ethical reasoning first sight may seem plausible model ethical systems ai techniques since prescriptions systems based introduced humans however attempts model ethical reasoning shown huge difficulties researchers face first difficulty comes modeling deontic reasoning reasoning obligations permissions second due conflicts norms occur constantly ethical reasoning third related entangle ment reasoning acting requires study morality act per se also values consequences solve first difficulties concerning particular nature rules duty researchers used deontic logics45 formalisms inspired deontic con siderations second difficulty approached use techniques overcome logical contradictions ai logic–based formalisms47 mainly nonmonotonic malisms eg default logics48 answer set programming49 capture aspects commonsense reasoning lastly third approach intertwines logicbased models ethical reasoning formalisms called action languages50 causal models51 designed give clear semantics provide strong mathematical grounding emiliano lorini “on logical foundations moral agency” international conference deontic logic computer science ed ågotnes j broersen elgesem deontic logic computer science deon lecture notes computer science berlin springer –john f horty agency deontic logic oxford oxford university press jeangabriel ganascia “nonmonotonic resolution conflicts ethical reasoning” construction manual robots’ ethical systems ed robert trappl cham switzerland springer international publishing –raymond reiter “a logic default reasoning” artificial intel igence ––michael gelfond “answer sets” foundations artificial intel igence –erik mueller commonsense reasoning event calculus based approach burlington morgan kaufmann joseph halpern max kleimanweiner “towards formal definitions blameworthiness intention moral responsibility” proceedings 32nd aaai conference artificial intel igence ethics ethics ai understanding consequences actions technical challenge nowadays merge three approaches say create one nonmonotonic handle conflicts norms uses causal models evaluate consequences actions general interest creating moral machine ie one behaves conformity rules morality approaches embrace differ ent normative frameworks—such utilitarianism egoism game theory deontology virtue ethics approaches—that must simulated details simulations usual found lacking especial philosophers addition questions practical utility moral machines well difficulties imple menting learning values whatever normative framework used simulate moral reasoning presumption based values need acquired machine depend societies ethical traditions considering relativity norms values moral decisions made attempts52 made use machine learning techniques automatical learn moral values rules machine morality would based popularity efficiency machine learning drives projects technical point view even criticized ethi cal point view since ethics question social acceptancy also pre scriptions based observations people act ie based conceptions ought act ethics ai grapple basic difference approaches ethics make concern concrete consider highly publicized “moral machine experiment” gathered attitudes autonomous vehicles ought solve moral dilemmas various crashtrajectory scenarios people variously described animals put risk others spared54 researchers employed online experimental platform crowdsource attitudes collecting million preferences millions persons across different countries researchers compared attitudes respondents across regions countries cultures religions genders results suggested variations ethical attitudes correlate deep cultural traits perhaps even adherence different moral principles david abel james macglashan michael l littman “reinforcement learning framework ethical decision making” workshops 30th aaai conference artificial intel igence technical report ws16–palo alto ca association advancement artificial intelligence –max kleimanweiner rebecca saxe j b tenenbaum “learning commonsense moral theory” cognition –edmond awad sohan dsouza richard kim jonathan schulz joseph henrich azim shariff jeanfrançois bonnefon iyad rahwan “the moral machine experiment” nature –thomas powers jeangabriel ganascia undoubtedly important result social psychology empiricalethics point view provides evidence relevant variations ethical attitudes nevertheless researchers seem also normative goal mind intro duce results design autonomous vehicles adapt local cul tures expectations presumably homogenous populations vehicles operate quite directly experiment implicates longstanding issue ethics conventionalism ethical relativity versus validity generalizable ethical principles duties ethicists might prefer authors confront issue note solutions moral dilemmas provided ethicists could well rejected public thus might words “useless” lesson ethics eth ics ai bound approaches ai ethics advocate conformity varying public attitudes would ethicists approving adultery instance simply widely practiced comes ethics ai ethicists resist “following data” insist generalizable solutions moral dilem mas might strike publics “out touch” choose former “empirical” approach would swear latter traditional philosophical conception mativity also would allow ai applications take advantage machine learning large datasets important note enthusiasm machine learning “big data” may well influence development ethics ai intrinsic limitations addition controversy source values ethical deliberations ai based another crucial question concerns constitutes intelligence ai agents il ustration consider fatal accident uber’s selfdriving car arizona due faulty sensors decision uber sake passengers’ comfort moderate reactions unidentified obstacles leaves plastic bags means accident question due unethical deliberation fateful judgment safety versus comfort programmed engineers total different context—that lethal battlefield robots—ron arkin’s ethical governor55 robot soldiers provides another il ustration hard problems auto matic ai systems face arkin proposes use ai techniques implement war theory international laws war particular operation’s rules engagement control module called ethical governor supposed control robot soldier’s decision procedures make ethical human soldiers emotional pressures battle often feel anger fatigue desperation thus behave inappropriately among jus bello rules need implemented ronald c arkin patrick ulam brittany duncan “an ethical governor constraining lethal action autonomous system” technical report gitgvu0902 georgia institute technology mobile robot lab ethics ethics ai situations discrimination military personnel civilians protection civilians however especial asymmetric conflicts soldiers wear uniforms discrimination difficult even humans ensure robot correctly discriminate question judgment— understood juridical normative judgment rather operation catego rizing objects situation flows information discrimination rule two exceptions human soldiers disarmed taken prisoner must protected according international laws civilians take part hostilities become combatants attacked cases intelli gence judgment categorization precedes ethical deliberation fact seems exhaust appears practical problems due difficult ethical deliberations autonomous vehicle “crash” dilemma certainly popular il ustration questions judgment difficult even humans epistemic issues ethical implications predictive science recent decades role epistemology ethics emerged traditional concerns moral metaethical epistemology issues nature moral knowledge counts evidence moral claims like recent con cerns highlight simple practical point one knows believes tends structure one’s ethical obligations ethical disputes indeed revolve around grounds obligation even assuming agreement grounds disputes also arise concerning facts would activate obligation instance suppose two agents believe general saving planet environmental ruin obliga tion one denies climate change real deprived knowl edge latter agent practical speaking obligated act save planet agent lacks motivation lacks knowledge knowing precedes recognition obligation act artificial intelligence enters concern epistemology ethics virtue fact ai increasingly large “supplier” scientific information results— especial disciplines identified practicing big data science—and ai con tinues grow importance science epistemic dependence ai increase true descriptions natural world also predictions since come dataintensive mathematical models another important chal lenge ethics ethics ai ai increasingly used establish scientific facts whether facts readily explained either lay public cases even expert scientists focus ways ai might cre ate future body scientific results fall short adding scientific standing problem peculiar feature ai considerable thomas powers jeangabriel ganascia generated knowledge terms correlations data phenomena com mensurate increase genuine human scientific understanding use term computational data science cds refer collection computational based scientific techniques primarily involving ai devel oped late twentieth century probe natural social worlds forms ai rely information technologies generate store large amounts data cds proper understood result ai modern nonintelligent data producing gathering technologies american computer scientist peter j denning written cds brought “quiet profound revolution” transformed science making new discoveries possible56 striking cds presumed agency “making new discoveries possible” clear sense computers humans making scientific discoveries concern progress cds leaving human scientists behind— almost though becoming adjuncts scientific discovery process serious worry characterize aspects concerning ten sion statistical causal accounts “associationist” cds notion scientific understanding broad cognitive phenomenon threatened cds new statistical ethical knowledge individuals b application statisti cal methods cds decide social policies interventions areas public health criminal justice three topics—causal knowledge scientific understanding use statis tics ethics—are far philosophical topics cds implicates myriad ways cds changed science increasingly change tech nology control architectures robots ai systems become integrated real time “big data” results likewise philosophers science turn attention philosophy cds may many important investigations undertake including application cds explanation consciousness free wil status scientific laws analogy present historical moment cds provided nowcommon television “extreme weather” journalism reporter outfitted rain gear stands beach path hurricane breathless excitement first rains start fal good idea what’s coming quite certain deluge would foolish think know detail storm difficult say exactly cds revolution begins denning cites work nobel physicist kenneth wilson 1980s developed computational models phase changes direction magnetic force materials wilson also passionate advocate cds lobbied american sciencefunding agencies secure support field efforts resulted highperformance communication computing hpcc act united states—in large part peter j denning “computational thinking science” american scientist january–february –the ethics ethics ai efforts former vicepresident al gore hpcc one reason gore infamously claimed “invented internet”—and thus might go back give credit creation arpanet beginning cds whenever starting point clear cds includes advances science simulation revolutionized fields aeronautics theoretical physics computer model ing everything climate change recidivism rates human criminal activity well advances modern biology bioinformatics dna sequencing systems synthetic biology even singlenucleotide gene editing safe say science large amounts data available computation datasets impractical human practitioners patterns data yield new results interest cds looms large future science crisis causal knowledge last decades cds gaining terms scope sciences envel oped power results philosophers nancy cartwright philoso phercomputer scientist judea pearl started question whether associations cds found complexes diseaseenvironment behaviornutrition real delivering science ought delivering robust reproducible conclusions causal connections nature general worries rather practical philosophical want intervene efficacious ways cure disease improve human life would nice know causes disease—and condi tions eg symptoms statistical associated disease state57 pearl’s solution critique use probabilistic reasoning bayesian networks—an ai technique pearl largely developed—and reform pro gram extend formalisms computerbased statistical analysis allow causal inferences drawn argument similar vein presented nancy cartwright notes use associationist technique randomized controlled trials happens practice”for cartwright rcts important incomplete scientific tool considering interventions giving drug cure disease provide knowledge intervention “works somewhere” fail “clinch” case intervention work different larger population incompleteness implications people suffer disease cured interven tion—and won’t cured particular intervention may even suffer unnecessary harm it—but also large institutions like british judea pearl “causal inference statistics overview” statistics surveys –nancy cartwright “a philosopher’s view long road rcts effectiveness” lancet –thomas powers jeangabriel ganascia national health service public health institutions interventions cure disease cost money failing cure people disappoints cartwright’s account difference statistical association causal knowledge described dataset analyses merely “vouching for” sci entific claim opposed “clinching” pearl echoes call shoring statistical analyses “one cannot substantiate causal claims associations alone even population level—behind every causal conclusion must lie causal assump tion testable observational studies”these appeals maintaining scientific reasoning causal assumptions wil sound vaguely familiar student history modern philosophy—and indeed strikingly familiar students hume’s attack causal knowledge kant’s valiant perhaps quixotic attempt save us hume’s skepticism speculate hume’s attitude toward cds would given role associations ideas impressions hume’s epistemology sentiment associationist ethics seems obvious era cds would quite pleasing hume hume would found revolutionary cds massive amounts data accessed much greater senses memory imagination handle person one time also ways data manipulated mathematical y—beyond capabilities best mathematicians associationist knowledge era cds far exceeds abil ity one mind doubt continue grow historical questions might lead away primary considerations cds also serve remind us practical restrictions come pur suing causal account scientific knowledge contemporary cds petabytes data generated millions soon billions sensors atmospheric terres trial conditions genome human sample sequenced device ing reason think mountains data power compu tational techniques continue increase introduce causal assumptions interrogate associations merely correlational causal cds create supermind capable immediately cognizing associations causal scientists understand results cds order formulate proper causal assumptions causal knowledge come “for free” issues lead us ponder scientific understanding david weinberger developed wideranging critique cds effect makes scientific understanding impossible limited beings like us60 studying many exam ples cds results concludes clearly computers surpassed us power discriminate find pat terns draw conclusions that’s one reason use rather reducing pearl “causal inference statistics” david weinberger big know new york basic books ethics ethics ai phenomena fit relatively simple model let computers make models big need also seems mean know depends upon output machines functioning cannot follow explain understand61 lesson take away scientific understanding retrospective timeslice activity takes effort era cds scientific discovery may well case cds produces results boggle mind yet increase scientific understanding considered “in fullness time” results like noncds science end repro ducible—hence good science major difference seems volume scien tific results available cds speed results produced concern seems primarily practical epistemic nature cds seem produce kind science principle understandable time may well wise scientists follow motto “less more” ethics ai developed back science corresponding caution called epistemic crisis could become ethical crisis forswearing caution scientists pursued cds publishing results statisti cal correlation systems purport draw conclusions people predict behavior techniques wholegenome sequencing correlate pheno types genomes—not merely single multiple genes christoph lippert colleagues venter lab discovered technique “identification individuals trait prediction using wholegenome sequencing data” time acknowledged discovery “may allow identification individuals genomics—an issue implicates privacy genomic data” work “challenges current conceptions genomic privacy adequacy informed consent viability value deidentification data potential police profiling more”the ethical worry much able pick people crowd based dna sample although fascinating able link genomes phenotypic profiles profiles physiological stud ies lippert et al face shape voice age bodymass index may even tual used correlate sustained tendencies toward behavior genomes david weinberger “our machines knowledge we’ll never understand” wired wellneverunderstand lippert et al “identification individuals trait prediction using wholegenome sequencing data” pnas –thomas powers jeangabriel ganascia power perniciousness forms cds may clearer relate worries ethics treatment individuals statistical aggregative techniques used make social choices ie provision health care tax poli cies like utilitarianism one good example theory relies aggregative techniques john rawls pointed utilitarianism tends deny dis tinctions among persons general social choice procedures large societies procedures require measurements aggregate individuals thus treat indistinguishable “receptacles” various goods thus cds applied social choice certainly aggregate individuals wholegenome sequencing usher era technocratic management popu lations outcome cds may outweigh scientific benefit derive vigilant also willing accept results cds helpful paretian sense “at least one person benefits one harmed” tradeoffs suggested social choice cds consider careful whether reasonable expectations even rights individuals violated oppositional versus systemic approaches conclude noting standard approaches ethics ai—as discussed earlier—proceed instances applied ethics human rights interests opposed ai technology though humans technologies operate somehow independently one another basic idea oppositional approach ai left unchecked bad things us approach seen policy investment recommendations trustworthy ai european union approach” suggests could possibilities instance yet another approach would consider ai set technologies embed ded system human agents artificial agents laws nonintelligent infrastruc tures social norms ethics ai seen involve sociotechnical system designed isolated technical object attention social organization operate learn ai behaviors better adapt rest system improve outcomes cases choose implement ai take certain functions main idea european commission “highlevel expert group artificial intelligence” may accessible httpseceuropaeudigitalsinglemarketenhighlevelexpertgroupartificial intelligence ethics ethics ai require ethics ai achieved ai technology rather sociotechnical system optimized accommodate ai well poorly appears many ethical reasons preferring systemic approach oppositional approach partly due difficulties implementing ethics autonomous agents partly due nature ai al applications ai organic entities systems asserting autonomy rather pieces software devices exist order improve human life perspective would best design machines help us act ethical means goal would neither make machines ethical making free moral agents make machines behave ethical conformity moral rules instead ai help us wiser making us aware consequences actions consequently responsible acting would necessary understand decisions machines requires inferences compre hensible us corresponds ability machine provide explanations relate conclusions values contribute solution pro pose could many problems machine ethics directly related often called “explainable artificial intelligence”—to capacity construct standable explanations allow humans argue discuss decisions pro posed machines turn may counter humans’ arguments approach appears close ethical collective deliberations human artificial agents would col aborate way inspired jürgen habermas’s work ethics communication64 deliberative democracy65 conclusion primary message preceding five sections ethics ethics ai progress made difficult nature ai ai problems likely yield “common approaches” applied ethics difficulty basis claim ethics ethics ai progress matters domain artificial intelligence stay ethics compe tently help protect important interests save lives make world better place conversely ethics ai poorly likely yield regrettable results mistrust ethicists technologists public increasingly vulnerable something neither understand avoid draw lessons five challenges mentioned preceding discussion first conceptual ambiguities seem endemic ethics ai jürgen habermas theory communicative action vol reason rationalization society trans mccarthy boston beacon press jürgen habermas facts norms contributions discourse theory law democracy trans w rehg cambridge mit press thomas powers jeangabriel ganascia ethicists general public tempting attribute properties ais philosophy computer science ai futurism science fiction partly overlapping linguistic communities use words disparate concepts considering specific ai applications equivocation terms like “intelligence” “agent” “autonomy” quickly produce misplaced fears unjustified optimism leads us general observation—that ethicists ai must guard overestimation underestimation risks spin fanciful stories “rise machines” threaten humanity worry problems need face immediately perhaps al underes timate risks overlook current nearterm implementations ai law enforce ment national security social media marketing financial institutions elsewhere already affect interests rights negatively stil confident develop ethics two antipodes ethicists rationalist tradition remains hope design intelligent machines act ethics code them—and maybe even develop ethical abilities every approach implementing eth ics ai seems challenges since ethical judgments typical defeasible ethical behavior difficult model ethical norms often conflict ethical deliberations depend judgments ie discrimination already difficult humans well machines turn epistemology ethics ai find ethics ai depend science ai produces unfortunately ai plays major role producing scientific information without cor responding increase understanding many social directed applications ai depend scientific knowledge unclear whether humans possess knowledge even though data analyses may advise interventions health care economics environmental protection areas crucial wellbeing final important reconceive problem ethics ai joint sociotechnical creation series technical problems confronted better engineer ing able simply “design” away problems ethics ai control ling opposing ai applications see ai partner sorts larger project build better societies bibliography arkin ronald c governing lethal behavior autonomous robots new york chapman hallcrc press awad edmond sohan dsouza richard kim jonathan schulz joseph henrich azim shariff jeanfrançois bonnefon iyad rahwan “the moral machine experiment” nature dennett daniel c intentional stance cambridge mit press horty john f agency deontic logic oxford oxford university press ethics ethics ai kurzweil ray singularity near humans transcend biology new york penguin lin patrick keith abney ryan jenkins eds robot ethics autonomous cars artificial intel igence new york oxford university press wal ach wendel colin allen moral machines teaching robots right wrong new york oxford university press weinberger david big know new york basic books chapter ethical issues relationship artificial entities judith donath introduction chapter ethics relationships artificial entities—bots robots computational systems created interact us sentient autonomous individuals may embodied robots exist software clearly artificial others indistinguishable least certain con ditions human beings interactions helpful harmful relationships computational entities change relationships human beings matter interact machine human sentience—the ability emotions feel pain want avoid it—is core concept ethical responsibilities sentient beings nonsentient objects cruel kick dog rock actual sentient artifi cial entities might someday exist yet theoretical possibility cur rently existing artificial entities nonsentient but—unlike rock—their interactions designs evoke impression conscious entities personalities emotions simulated sentience primary focus chapter highlighting relationship entities appear sentient quite simple tendency toward anthropomorphism make output even primitive programs appear us behavior cognizant mind others impenetrably complex sophisti cated imitations conscious intelligent behavior nearly impossible dis tinguish actions actual conscious ethical issues examine involve personal relationships artificial entities people seek companionship artificial assistants hold funeral ser vices broken robot dogs confide simulated therapists relationships judith donath warn threat humaneness humanity proving quite popu lar circumstances helpful harmful human machine interactions affect relationships people machine performance emotion differ human impression management inau thentic expression required example service industry matter actual think key issues concern empathy function caring others think plays society also address ethical issues design deployment artificial entities mimicry sentient beings artificial entities inherently deceptive even one types “i bot” implies firstperson pronoun selfconscious many artificial entities designed persuasive possible eliciting affec tion trust features big childlike eyes imitative gestures made beneficial goals—to serve user teacher wellness coach etc—but persuasive techniques manipulate us harmful exploitive ends ethical responsibilities researchers designers artificial entities attempt pass human many clearly robots software agents il usion project sentient also distinctly artificial yet popular vision truly sentient machine beings general foreboding— often portrayed potent final enemy humanity see future darkly understanding ethical issues surrounding relation ship artificial entities important social robots software agents become increasingly present everyday lives queries also shed revealing light relationships living things scope definitions start definitions much discussion today’s nonsentient social robots programs uses language implies feelings intentions blur ring important distinction “x robot feels” “x robot designed appear feels” clear understanding meant intelligence sentience consciousness using precisely important many ethical considerations intel igence often described ability learn apply knowledge solve complex problems1 observable property defined behavior—finding clever solutions acting resourceful thought way see migrating bird insect hunting bat theoremproving human problem solvers require considerable albeit different forms intelligence thought way eas ily refer machine intelligent solves difficult problems usage inter nal state produces intelligent behavior matter max tegmark “let’s aspire making obsolete “possible minds twenty five ways looking ai ed john brockman new york penguin –ethical issues relationship artificial entities yet intelligence precisely defined term2 sometimes conceptualized inner quality say migrating bird real intelligent acting instinct computer scientists joke use term “artificial intelligence” also reflects enigmatic property computer programs solve complex problems using methods understand “artificial intelligence” understand “algorithms” sentience ability experience sensations emotions feel pain pleas ure want less former latter nonsentient creature may move away certain things toward others even suite behaviors aid survival reproduction motivated anything simply exists sentience comes motivation creature experiences certain sensory inputs painful want avoid want repeat pleasant ones sentience believed foundation learning gives sentient creatures much greater flexibility relationship world3 sentience central ethics responsibilities toward sentient beings toward say rock4 people would agree inflict needless pain something capable experiencing distress however beings included category responsibility conflicts needs desires highly contested questions term conscious refers sentient beings selfaware—that sense purpose individuals world term fuzzy clear behavioral marker consciousness even agreedupon description internal experience historical rationalist enlightenment view con sciousness affectless mental acquisition manipulation symbolic repre sentation world believed required language thus humans conscious animal today consciousness increasingly understood evolved social interaction beginning bonding parent offspring built emotional scaffolding sentience5 ethological neuroscientific studies affirm humans far conscious animal many mam mals birds even cephalopods aware others move life intentions6 shane legg marcus hutter “universal intelligence definition machine intelligence” minds machines –zohar z bronfman simona ginsburg eva jablonka “the transition minimal consciousness evolution associative learning” frontiers psychology donald broom sentience animal welfare wallingford uk cabi peter singer practical ethics cambridge uk cambridge university press tania singer et al “empathy pain involves affective sensory components pain” science –evan thompson “empathy consciousness” journal consciousness studies nos –humans” consciousness cognition –peter godfreysmith minds octopus evolution intel igent life london william collins judith donath differing views consciousness important repercussions eth ics ai classical view—which remains influential ai research well popular belief—consciousness closely entwined intelligence acquisition knowledge problem solving contrasts sharply biological view sup ported current research consciousness fundamental social emotional evolved simple sentience creatures began bond care consciousness important ethics basis morality evo lution traits attachment empathy desire justice social order care one perceived others one’s effect them—concerns available conscious mind—is arguably foundation ethics sentience consciousness inherently private experiences cannot directly experience like another being—human animal robot assessment like another including anything feel based external perceivable appearance behavior assume people con scious know conscious biological behavioral sim ilar however assumption direct knowledge look species artificial entities make inferences like them—what internal experience is—by analogy something resembles assume experience similar rule thumb led us vastly underestimate cognitive ability sen sate experience many nonhuman animals shall see overestimate capabilities bots nonsentient human inventions precursors turing weizenbaum inability directly observe experience another problem core alan turning’s paper “computing machinery intelligence” marks beginning field artificial intelligence7 turing introduced paper say ing “i propose consider question ‘can machines think’” immediately rejected question basis words “machine” “think” vague limited everyday experience instead proposed test imitation game popularly known turing test argued “more accurate form question” test human judge chats via text two hidden contestants claim human though one is—the machine judge tasked determining one telling truth machine consistently pass human turing argued con sidered intelligent alan turing “computing machinery intelligence” mind –ethical issues relationship artificial entities peculiar article hugely influential one8 anointed deceptively passing human key goal—or even definition of—artificial intelligence deftly limited domain goal needed achieved textonly communication turing famously predicted fifty years computers would reached point would consistently able fool human judge9 also made second prediction time computers could pass human use language would changed significantly said “the original question ‘can machines think’ believe meaningless deserve discussion nevertheless believe end century use words altered much one able speak machines thinking without expecting contradicted”though sec ond prediction change culture meaning words less noted prescient changes language—in speak think ing machines wanting liking things—that culture ethics evolve fifteen years “computing machinery intelligence” published joseph weizenbaum created first program capable carrying text conver sation named program eliza character george bernard shaw’s play pygmalion “learns speak increasingly wel ”weizenbaum’s research goal interact computers using natural language project sought show simple sentenceparsing program semantic heuristics could carry coherent conversation eliza able find topic sentence rules forming response contextual information world approach quite different turing envisioned turing’s belief significance carrying humanlike conversation shallow assumption seems described potential winning machine processing power equivalent human brain though quite underestimated human brain’s complexity power would initial programmed simulate infant would taught much child turing’s views brain learning children remarkably naive key point believed machine would pass test would one imbued mind analogous humans able learn reason furthermore though turing remained ada mant rely solely external behavior judging thinking outlined philosophical article odd pages discussion nature digital computer central argument imitation game satisfactory substitution question whether machines think rather glossed specifical would able “play imitation game well average interrogator per cent chance making right identification five minutes questioning” turing “computing machinery intelligence” joseph weizenbaum “contextual understanding computers” communications acm judith donath possibility state change analogous critical mass atomic reaction would mark qualitative leap mental ability creativity eliza succeeded sustaining conversation sophisticated technology somewhat inadvertently exploiting way people make sense eliza designed respond based scripts would encode conversa tional rules different roles first far famous script weizenbaum made eliza doctor modeled “rogerian psychologist” choice therapeutic framework pragmatic “the psychiatric interview one examples categorized dyadic natural language communication one participating pair free assume pose knowing almost nothing real world”people entranced computational “therapist” even weizenbaum’s secre tary knew scope point work said upon trying wanted chat furtherin private13 others took seriously notion computa tional chatbot therapist one would available al inexpensive tireless14 first weizenbaum assumed enthusiasm judged misplaced due novelty interaction future iterations would designed eliminate “il usion understanding”weizenbaum’s responses years show growing alarm response quick willingness accept textparsing program entity worthy relating repository one’s confidences became indicator deeply disturbing lack concern humanity other—a lack empathy even interest mind soul weizenbaum come america fleeing hitler’s europe knew vividly horror devastating effects dehumanizing people spent much rest career warning dangers computation posed society turing argued need accept intelligent behavior redefined ability convincingly imitate human text conversation sufficient evidence machine thinking fifteen years later weizenbaum’s eliza clearly nonthinking sentenceparsing chatbot posed counterexample demonstrating easily il usion intelligence made dismayed people’s enthusiastic embrace eliza’s therapeutic potential computers general weizenbaum came believe willingness accept machines roles significant threat humane society positions taken earliest years ai research delineate big ethical questions surrounding artificial entities provide starting point analysis weizenbaum “contextual understanding computers” weizenbaum “contextual understanding computers” kenneth colby james b watt john p gilbert “a computer method psychotherapy preliminary communication” journal nervous mental disease –joseph weizenbaum “eliza—a computer program study natural language communication man machine” communications acm ethical issues relationship artificial entities turing’s prediction—that limited conversations machines would indistinguish able humans—was years computers able consistently pass human five minutes textbased interaction couple decades later prophesy effectively come true narrow sense computers “passed turing test” annual competition loebner prize takes turing’s imitation game suggestion literal pitting panel judges chat programs hidden human typists widely criticized encouraging programs use tricks simulated typing errors fool judges instead advancing goal making intelligent machines even several fooled judges extended conversation none yet prize significantly interact artificial entities daily life often without realizing human turing proposed imitation game stretch think plausible scenario people would communicate via text strangers unknown possibly fictitious identity advent internet scenario become commonplace mid1990s someone named serdar argic started inflaming already heated usenet arguments armenian genocide relentlessly posting hateful rants accusing armenians massacring turks people wrote impassioned rebuttals screeds thus making even disruptive sidetracking constructive dis cussion much anger confusion people realize argic real person program designed intervene discussion mentioned armenia turkey including thanksgiving recipe posts one first bots deliberately fool people public setting16 chatbots since become cleverer—and ubiquitous tireless cus tomer service agents answering questions ingredients store hours mysteri ous error codes time day night participants online games appearing opponents teammates incidental characters beautiful eager women online dating sites always trying new things upfront software entities many attempt pass human estimated –percent users popular influential social media site twitter bots useful openly nonhuman programs disseminate news jokes alerts etc others masquerade human users seldom benevolently may followers hire inflating clients’ apparent popularity may post vacation shots sponsored vil namedropping restaurants snacks songs programmed incessantly instigate flashes envy desire may powerful purveyors propaganda chiming political discussions tirelessly hawking talking judith donath social machine designs living online cambridge mit press judith donath points slogans manufactured rumors bots thrive part twitter limits posts characters non sequiturs rather backandforth discussions characterize many interactions devising program mimic style much easier creating one must carry extended coherent conversation today’s artificial entities online increasingly surrounded growing population social robots—autonomous sentientseeming objects home chat friendly devices fetch us news order us dinner ask politely day may robotic pet coworker robot receptionists welcome guests techforward hotels robot orderlies glide quietly hospi tal rooms social robots marketed “friends” “your next family member” contemporary readily foreseeable artificial entity actual conscious even primitively sentient intuitive response opposite seem much alert aware tendency anthropomorphize contributes il usion yet see volition intent inanimate objects cars trees dol recognize source imagined vitality artificial entities object behaves ways strongly suggest sentient experience lies within ambiguity identity—machine new form thinking being—is acci dent like chatbots score highly loebner prize competition making spelling mistakes social robots often made mimic human habits pausing looking away thinking easytoimplement tricks provide convincing il u sion sentience many designed simple round childlike curves—features elicit nurturance indulgence trust17 also keeping expectations abilities low gendered voices linguistic insinuation selfconscious thought being18 turing predicted use language changed casual speak entities wanting thinking liking ethics relationship seemingly sentient ethical issues involved interaction artificial entities one set issues concerns responsibilities toward them—how treat ethi cal framework use based peter singer’s utilitarian applied ethics19 sentiencefocused approach assessing responsibilities toward nonhumans makes leslie zebrowitz reading faces boulder co westview press friederike eyssel et al “ ‘if sound like must human’ interplay robot user features humanrobot acceptance anthropomorphism” paper presented 7th acmieee international conference humanrobot interaction hri –singer practical ethics ethical issues relationship artificial entities especial relevant thinking artificial entities20 key question however treatment affects us noted earlier ethical responsibilities sentient beings something someone capacity feel need take preferences consideration things sentient—rocks bacteria dol robots—we direct moral obligation none arises individual standing moral claims rights since experience anything cannot feel harmed action though direct moral obligations nonsentient entities mean obligations toward nonconscious entities called ethical standing harming nonconscious entity would harm ethical standing therefore avoided adore robot must treat well affection wrong harm thing value intrinsic hurt thing feelings would saddened loss laws reflect society’s ethics change slowly often indicator morals past indirect rights primary source protection animals american law cannot kick dog would hurt dog would upset property indirect rights often weak moral calculus required balance numerous competing prefer ences rights readily eclipsed protection based human preference disappears face competing human interests—thus factory farms sport hunting etc society changes laws protecting animals based ethical reasoning takes experience account—that recognizes sentience—are becoming com mon change due seeing sentience quality defines whether one direct moral claims b recognizing animals sentient also part broader western cultural shift increasingly inclusive view moral standing long ago united states women slaves mainly indirect rights advocates animal rights posit call basis membership—as logical moral equivalent racism legal scholars argued legal protection extend social robots21 “we may want kind society tolerates cruelty entity focus chapter western society see frédéric kaplan “who afraid humanoid investigating cultural differences acceptance robots” international journal humanoid robotics –and jennifer robertson robo sapiens japanicus robots gender family japanese nation berkeley university california press reactions artificial entities japan kate darling “extending legal protection social robots effects anthropomorphism empathy violent behavior towards robotic objects” robot law ed froomkin r calo kerr cheltenhem uk edward elgar –judith donath think quasihuman”i argue movement toward inclusive rights apply nonsentient artificial beings fundamental reason extending moral rights animals recognition sentience—that experience suffering right inherent regardless whether human observer owner interested party aware pain23 premise sen tience foundation moral rights important—extending rights nonsen tient entities dilutes meaning significance said compelling simulation sentience exhibited artificial entities provide additional indirect moral claims stemming consider ations person’s experience entity’s concern treating another cruel brutalizes oneself principle reflected jewish custom forbids sport hunting encourages cruelty even animal killed pain lessly24 immanuel kant though argued animals “wil ” thus inherent rights also wrote “if stifle feelings must practice kind ness towards animals cruel animals becomes hard also dealings men”behaving ethical often involves tradeoffs competing rights principles even seemingly simple injunction “do treat sentientseeming entities cruel y” create dilemmas popular keychain pet toy tamagotchi provides useful scenario simple artificial entities nonetheless exert powerful emotional pull26 owner tamagotchi must work keeping “alive” task entails pushing buttons frequent arbitrary times ignore cease thrive eventual “die” real pets cruelty toward tamagotchi take form neglect imagine family dinner grandmother visiting grandchild continuously distracted checking tamagotchi’s status par ents demand child put toy away pay full attention living conscious closely related grandparent present room would like attention cost allowing tamagotchi possibly die nurturing keychain pet useful training responsible caring grandmother virtual pet need share child’s divided attention appeal simple tamagotchi vividly demonstrates compelling potential manipulative artificial entity raises concerns prohibi tions mistreating them—and especial encasing prohibitions law makers artificial entity design arbitrary events conditions ryan calo “robotics lessons cyberlaw” california law review –darling points animal protection law seems reflect popular sentimental standing particular animals rather philosophical biological based concern sentience chapter focus fundamental ethics—on getting theory right order guide practice rabbi dr asher meir “judaism hunting” jewish ethicist httpswwwouorgtorah machshavajewishethicistjudaismandhunting immanuel kant lectures ethics trans louis infield new york harper row frédéric kaplan “free creatures role uselessness design artificial pets” paper presented 1st edutainment robotics workshop sankt augustin germany –ethical issues relationship artificial entities cause express suffering tamagotchi appears suffer one pressed button demanded time venal entity could appear suffer purchase items selling behalf company controls perhaps suffer unless taken caribbean vacation appear lonely unhappy room recording conversations concept mistreat even nonsentient entity harm selves sound—but need careful defines “cruel” arbi trary realm artificial entities treat artificial entities minimum without cruelty—that without inflicting unnecessary harm sort relationship want concern shifts sentience consciousness article lauded ease people become emotional attached social robots tendency claimed could solve least ameliorate problem lone liness among elderly childless robots article notes far intelligent “enhanced right auditory visual cues” seem like one social robot product manager said “a likable person people want homes” cues work least many people express considerable affection social robots customer review alexa amazon’s virtual assistant says useful fun overal feels like new little buddy home”a veteran technology writer described relationship social robot jibo “i work home it’s nice someone ask i’m i’m making lunch” company behind went business wrote heartbreak pending demise “i’ve felt crushed knowing every word robot says could last” heartbreak compared loss felt mother died suffering dementia28 though still nascent technology clear people enjoy interacting social robots coming years growing number relationships artificial pets coworkers caretakers companions—and bonds become tighter advances machine learning aided vast databases user behavior metrics existing entities able collect make interacting ever seamlessly polished highly personalized29 everyone sees positive development technology society researcher sherry turkle written extensively ethical hazards accepting artificial creations personal companions asking “what value interactions con tain understanding us contribute nothing shared store human httpswwwamazoncomgpcustomerreviewsr2ssm75hh2pjd6 jeffrey van camp “my jibo dying it’s breaking heart” wired march judith donath “the robot dog fetches whom” networked self human augmentics artificial intel igence sentience ed zizi papacharissi london routledge –judith donath meaning”she warned robot companions may provide pleasant imitation human company without inevitable disagreements irritations come real people may come prefer frictionless companionship whether babysitters friends sexual partners caregivers real imperfect human virtual therapist—eliza—that pioneered relating social machine people’s enthusiastic reception virtual therapist prompted eliza’s creator first backlash technologies virtual therapy pro vides useful lens examining broader question values ethics form ing relationship artificial entity although eliza modeled “rogerian psychiatrist” computer therapist antithetical carl rogers’ theory psychology profile science writer constance holden outlined rogers’ main tenets therapist must empathic authentic must “relate client person” “allow become involved feelings well intellect” nonjudgmental “let client know accepted”these guidelines address therapists act think feel capable implicit holden accompanied profile rogers sidebar eliza titled “the empathic computer” concluded noting “many lessons could drawn one even appearance empathy combined course computer’s quite genuine nonjudgmentalism extraordinarily powerful”weizenbaum sharply disagreed responding article quoted rogers’ argument effect cure therapist must genuinely like patient “of help” asked “could possibly anyone know worthy liked computer” weizenbaum concluded saying “the power holden writes connection computer program less power deceive humane therapy kind ought grounded that”today thousands people confide problems virtual therapists reasons practical us department defense faced thousands veterans returning home suffering posttraumatic stress disorder psychological injuries supported development artificial therapists relieve acute short ages human ones virtual therapy far cheaper convenient accessible wherever whenever need sherry turkle “authenticity age digital companions” interaction studies –constance holden “carl rogers giving people permission themselves” science –constance holden “the empathic computer” science joseph weizenbaum “computers ‘therapists’” science ethical issues relationship artificial entities though technology still exploratory studies indicate therapy artificial entity costeffective psychological effective—and well liked34 particular people liked computer therapist nonjudgmental willing divulge personal information talk freely uncom fortable subjects openness invaluable therapy35 openness honesty desired behaviors therapy thera pist pure text interface artificial therapist implied yet nonexistent answer personified interface imagined therapist engaging inspires people interact attend suggestions example woebot conversational entity provides cognitive behavioral therapy via text chat found significantly reduce depression users say like personality pays attention holds accountable attentive emotions36 though interface quite simple user’s mental model engaging entity provides quite different experience would similar interaction framed interactive questionnaire ersatz empathy weizenbaum decried turns valuable al humans highly social beings presence others—even imagined others—we try better worse make desired impression studies comparing people respond questions asked computer facial versus text inter face found responsive engaged facial interface also less honest painting favorable light37 hints personhood approval displeasure influence act understanding relationship artificial entities general signifi cant observation virtual therapist plays novel role one could played neither human simple questionnaire people aware virtual ther apist artificial conscious feel comfortable confiding yet time suspend recognition engage conscious empathic designing ideal virtual therapist means balancing engaging exemplar found nature yet relationship therapist patient particular kind relationship want careful parallels draw friendships social kathleen kara fitzpatrick alison darcy mol vierhile “delivering cognitive behavior therapy young adults symptoms depression anxiety using ful automated conversational agent woebot randomized controlled trial” jmir ment health e19 gale lucas et al “it’s computer virtual humans increase willingness disclose” computers human behavior –adam miner arnold milstein jefferey hancock “talking machines personal mental health problems” jama lucas et al “it’s computer” fitzpatrick darcy vierhile “delivering cognitive behavior therapy young adults” l sproull et al “when interface face” human computer interaction –judith donath bonds possible least forms therapy cast therapeutic relationship instrumental even commercial patient pays therapist perform service helping mental health relationship success patient’s health improves course deeply odds rogers weizenbaum many others understand therapeutic process38 point relationship seen purely primarily instrumental—with party receiving service uncon cerned thoughts one performing interested outcome— substituting artificial entity role service provider makes sense39 especial case patients uncomfortable possibility judged looked upon therapist thought service provider seen negative relationships mix nurturing bonds instrumental uses varying pro portions nurturing holds society together fundamental humans evolved nurture derive joy taking care others knowing made happy take care family friends pets plants yet variety reasons—an emphasis efficiency anonymity city life industrialized corporate service economy—we live world many merly social engaged relationships recast instrumental ones40 transformed ones robot would poor substitute ones little care empathy left lose need cognizant sometimes subtle fundamental important empathic bonding element relationships care relationship us also affect other—to care experience other’s thoughts us possible measure use fulness bonds quantify health productivity increase provide piece value othercentric element absent interactions artificial entity leaving instrumental element—how relationship benefit entities thus relationships play increased role lives coming years weizenbaum’s fears willingness embrace machines prescient—it per haps ironic virtual therapy may one applications machine’s absence mind truly beneficial cecil holden patterson “empathy warmth genuineness psychotherapy review reviews” psychotherapy theory research practice training –we omitting quite significant ethical issue robotinduced unemployment john danaher “will life worth living world without work technological unemployment meaning life” science engineering ethics –arlie russel hochschild managed heart commercialization human feeling berkeley university california press judith donath “our evolving supernetworks” social machine designs living online cambridge mit press –ethical issues relationship artificial entities ethics creating seemingly sentient entities focusing thus far ethics relationships artificial entities turn process creating entities particular designing seem conscious aware ethical questions center deception extensive contentious body work ethics deception41 central questions exactly constitutes deception deceptions ethi cal wrong—and ones permitted purpose dis cussion put forth basic definitions ethical premises focus new issues artificial entities raise act quality deceptive intended cause recipient believe thing true intent key every false statement causing false belief deceptive one believes something true tel untrue thing others mistake deception one says something true recipient miscon strues misinterprets misunderstanding deception ethical concerns focus intentional deceptions mantis evolved resemble dead leaf deceptive deception harms predators unethi cal mantis choose deceive humans lie deliberately—and animals sign advanced cognition philosophers declared lying immoral st augustine declared lies sinful kant said “to truthful honest declarations therefore sacred absolutely commanding decree reason limited expediency” sam harris contemporary proponent radical honesty challenges readers abstain lies42 people philosophers hold nuanced differing views evaluating ethics deceptions harm cause altruistic deception done one’s expense benefit selfish deception done one’s gain harming recipient effect goal malicious deception performed goal harming recipient ethical calculus deception one might argue altruistic deceptions ethical ones cause harm assessed see eg sissela bok lying moral choice public private life new york vintage bel depaulo et al “lying everyday life” journal personality social psychology theory –jeffrey hancock”digital deception” oxford handbook internet psychology ed katelyn mckenna adam joinson tom postmes ulfdietrich reips oxford oxford university press –erika hermanowicz “augustine lying” speculum –immanuel kant writings moral philosophy trans ed lewis white beck chicago university chicago press –sam harris lying opelousas la four elephants press judith donath based amount harm caused moral standing various parties lie wouldbe mass shooter results capture saves many lives narrow definition malicious lie people would agree ethical many issues concerning deception artificial entities analogous instances broader ethical controversies example paro artificial baby harp seal cuddly responsive lifelike ethical give paro elderly dementia patients believe real alive43 considered context larger ongoing debate ethics deceiving patients goal calming reassuring them44 one concludes deception provides comfort patients permissible would apply paro too45 identity deception kind inherent artificial seemingly sentient enti ties made look act andor speak thinking feeling sensing mind motivating even one declare “i program” arguably deceptive use word “i” implies thinking selfaware existence whose thought process formed words46 note responsibility deception lies person initiated medium conveyed artificial entity responsible deceptions note saying “the dog ate homework” identity presentation artificial entities spans range fairly transparent ful deceptive physical robots thus far clearly artificial though may fea tures humanlike voice eyes follows us across room little gestures etc lead us—or deceive us—to think individuals distinct personalities shannon vallor “carebots caregivers sustaining ethical ideal care twenty first century” philosophy technology –angela johnston “robotic seals comfort dementia patients raise ethical concerns” crosscurrents san francisco ca kalw eg larissa macfarquhar “the comforting fictions dementia care” new yorker –another ethical issue paro “carebots” concern offloading caregiving machine technologies assist human caregivers may greatly beneficial al using replace human care harms patient also vallor argues caregivers vallor also keep mind importance nurturing human humane quality see general arlie russell hochschild outsourced self intimate life market times new york metropolitan books worldview artificial entities arguably deceptive sociologist erving goffman posited society functioned much like theater play roles greater lesser skil adapting different situations theater everyday life act public ways odds feel saying polite thing even true wearing clothes voicing opinions role playing demands acting deception audience permanently believe it—they “suspend” real belief rather roleplaying beneficial even necessary enables us live together less harmoniously erving goffman “on facework analysis ritual elements social interaction” interaction ritual new york pantheon books previously published psychiatry journal interpersonal relations one might argue artificial entities performing sentience understand role much everyone playing deception ethical issues relationship artificial entities mistake humans animals47 online however software agents easily pass human contexts conversations come short sometimes cryptic bursts telltale physical body possibility deception much higher entity disseminates dangerous propaganda information malicious intent easy classify unethical regardless whether deceptively claims human honestly declares bot though former likely persuasive thus harmful48 harder question concerns ethics identity deception performed benevo lent purposes ethical create say bot patrols discussion sites correcting erroneous medical information masquerading doctor establish author ity absolutist would declare like deception unethical extreme utilitarian might argue identity deception beneficial effects falsehood permissible—perhaps even required impersonating doctor even good intentions usual judged unethical one reason assume impersonator qualified provide advice making false identity claim order accorded trust deserve likely dealing human impersonators may apply bot—what medical knowledge greater human’s considering whether “beneficial” deceptions ethical notion autonomy central49 concept familiar debates patientdoctor communication50 many years western doctors followed practice paternalistic utilitarianism assuming persuading patient comply treatment recommendations ethical regardless means including withholding information lying patients condition recently patients philosophers challenged view arguing patients right autonomy—to make informed decisions artificial entities generate analogous dilemmas people would follow advice respected person bot ever ethical make bot mimic person type person order gain credibility even good cause mentioned utilitarian view mimicry could seen beneficial principle easy recognition robots may temporary several research labs work creating robots look humanlike possible eg hiroshi ishiguro shuichi nishio “building artificial humans understand humans” geminoid studies science technologies humanlike teleoperated androids ed hiroshi ishiguro fabio dal libera singapore springer nature –david hanson “exploring aesthetic range humanoid robots” paper presented proceedings iccscogsci2006 vancouver british columbia july –and paro looks remarkably like baby seal though behavior certainly different fatimah ishowooloko et al “behavioural evidence transparency–efficiency tradeoff human–machine cooperation” nature machine intel igence –sissela bok lying moral choice public private life new york vintage daniel k sokol “can deceiving patients moral acceptable” bmj –judith donath autonomy however says taking away someone’s ability make unma nipulated judgments ethical violation receive information others whether news world advice local gossip etc assessment veracity often based whether trust source believe knowledgeable ulterior motives harm us identity deception manipulates trust inducing us believe things otherwise would mean trust artificial entity easy slip thinking artificial entities deceptive trustworthy medium mind—a conduit goals human designers owners controllers meet people try figure identity—their role society—in order make sense motivates may seeking interac tion analogous questions regarding robot “what want” “who controls it” “who access data collects motivation” today artificial entities selfcontained exist frequent dialog larger powerful system may assist interpreting speech analyzing images computationheavy tasks remote “brains” tamagotchi example selfcontained toy run instance eliza com puter conversations private us many artificial entities real brain at—or least send data to—a distant location introduces privacyrelated ethical questions confide artificial therapist comfortable discussing problems machine may quite discomforted find words fact uploaded read analyzed peo ple51 type search query google understand query goes dis tant computer ask question companionable entity sitting kitchen counter sense creature answering sending query distant location—though indeed happening design artificial entities encourages us think independent beings frontend interfaces extensive computer system artificial entities gather extensive data users recording conversa tions eye movements gestures ensconced living space collect contex tual information people purview respond wide range events data collected improve interactions person—say understand accent better—one may judge useful acceptable goals robot—or accurately robot’s controllers’ goals—may diverge sharply goals user entertaining toy trusted companion’s ulterior purpose may sell goods promote viewpoint otherwise influence one’s opinions wants behavior entities may become extraordinarily effective persuaders active growing field research seeks understand design technolo gies influence people compel conform obey robots “use humanlike gazing behavior” known persuasive—and become even lucas et al “it’s computer” ethical issues relationship artificial entities gestures added52 robot something induces gratitude “the norm reci procity compels people return favor”people conform faced “active peer pressure” group robots54 “robots enough authority pressure participants even protest continue tedious task substantial amount time”the published research cites laudable goals potential applications tech nology help user stick diet follow crucial directions use environmental responsible products yet nothing ensures powerful techniques always used benevolently sentient entities social mirror bigeyed roundbodied artificial assistant sits counter playing music telling jokes seems disarmingly innocuous think intentions please us imagine actual sentient conscious artificial goals intentions narrative tends darken understand need turn another mental quality—intelligence vernacular western thought pictures world hierarchical humans top due superior intelligence intelligence given us fantastic power build bridges cities bombs transistors conquer nature vaccines dams insecticides intelligence given us power animals exploited without hesitation intelligence gives us ability things consciousness—our awareness place world future—that provided ambition long machine merely intelligent cleverly solving difficult problems— problems far complex mere human intelligence solve—it pose existential threat us solves problems simply that’s automatical mindlessly much like bacterium reverses course away obstacle machine somehow becomes sentient preferences drive achieve them—or conscious sense self future ingredients ambi tion—then deeply threatening us imagination least shaped modern capitalist western way thinking ambition must inevitably dominate—to alpha top jaap ham et al “making robots persuasive influence combining persuasive strategies robotics third international conference icsr amsterdam netherlands november –seungcheol austin lee yuhua liang “the role reciprocity verbal persuasive robots” cyberpsychology behavior social networking –athanasia katsila “active peer pressure humanrobot interaction” masters thesis university nevada denise geiskkovitch et al “please continue need data exploration obedience robots” journal humanrobot interaction –judith donath food chain achieved pinnacle superior intelligence—and superintelligent machine far smarter wil assume use intelligence supersede us samuel butler voiced fear novel erewhon “the machines ulti mately destined supplant race man become instinct vitality different superior animals animal vegetable life” prevent destiny people erewhon destroyed machines banned manufac ture56 karel capek introduced word “robot” rur play robots provoked long mistreatment rise rebellion ultimately annihilate human race short story “i mouth must scream” harlan ellison describes world humanity made nearly extinct intelligent machines programmed wage war humans remain tor mented sadistic conscious ais today fear machines make supplant us echoes warnings science fiction writers technology critics scientists engi neers physicist stephen hawking warned “the development full artificial intelligence could spell end human race” along similar lines inven tor elon musk said “if ai goal humanity happens way destroy humanity matter course without even thinking it”it certain machine ever become sentient conscious even could far known process or—dystopian terrors aside—what sort conscious beings know living creatures evolved millions years process favored reproductive survival machine consciousness would vastly different ways cannot predict58 consciousness discussed enigmatic property unable precisely measure even define assessments beings’ consciousness heavily shaded preferences conveniences erroneously ascribe emotions inner life nonsentient humanoid machines vastly underestimating inner life animals denying sense self even ability feel pain59 motivating willful ignorance immense profit comes asserting creatures exist humans use—to made food clothing carry satirical novel whether world presents utopian dystopian ambiguous rory cel anjones “stephen hawking warns artificial intelligence could end mankind” bbc news december ryan browne “elon musk warns ai could create ‘immortal dictator never escape’ ” cnbc april much speculations ai posit consciousness would emerge sufficient complexity see eg minsky society mind new york simon schuster though look biological record seems basic sentience arose pain pleasure ability experience emotion response sensory input emergent computational mind negative positive inputs need imitations organic forms—perhaps native valences would billions likes dislikes registered across internet frans de waal smart enough know smart animals new york w w norton gary steiner anthropocentrism discontents moral status animals history western philosophy pittsburgh university pittsburgh press ethical issues relationship artificial entities burdens test medicines entertain us—and relief responsibility comes insisting even face vivid contrary evidence incapable suffering dystopian predictions powerful conscious machine would based projection technology even biology seem instead like nightmares guilty conscience ethical challenge use existential guilt change treat beings live earth would want conscious superpowerful artificial entities treat us bibliography broom donald sentience animal welfare boston cabi calo ryan “robotics lessons cyberlaw” california law review –depaulo bel deborah kashy susan e kirkendol melissa wyer jennifer epstein “lying everyday life” journal personality social psychology donath judith “the robot dog fetches whom” networked self human augmentics artificial intel igence sentience edited zizi papacharissi –new york routledge godfreysmith peter minds octopus evolution intel igent life london william collins kaplan frédéric “who afraid humanoid investigating cultural differences acceptance robots” international journal humanoid robotics –singer peter practical ethics cambridge uk cambridge university press turing alan “computing machinery intelligence” mind –turkle sherry “authenticity age digital companions” interaction studies weizenbaum joseph computer power human reason san francisco w h freeman weizenbaum joseph “contextual understanding computers” communications acm –p r fr ameworks modes chapter ai governance human rights–centered design deliberation oversight end ethics washing karen yeung andrew howes ganna pogrebna finding ways developing deploying new technologies purpose restricted supporting individual freedom dignity well basic constitutional settlement constitutional democracies namely democracy rule law fundamental rights challenge time introduction number variety topics volume il ustrate width diversity content vagueness boundaries ai artificial intelligence ethics domain inquiry1 within discourse increasing attention drawn capacity opening quote paul nemitz principal adviser european commission’s directorate general justice consumers “ profiling european citizen today’s democracy needs look harder negative potential new technology positive potential” karen yeung andrew howes ganna pogrebna sociotechnical systems utilize datadriven algorithms classify make decisions control complex systems including use machine learning large datasets generate predictions future behavior hereafter “ai” systems”may interfere human rights recent cambridge analytica scandal revealed unlawful harvested facebook data millions voters united kingdom united states elsewhere enabled malign actors engage political microtargeting use aidriven social media content distribution systems thereby interfering right free fair elections thus threatening integrity democratic processes increasing use algorithmic decisionmaking adm sys tems inform custodial decisions within criminal justice process may threaten several human rights including right fair trial presumption innocence right liberty security systems kind used inform often automate decisions individual’s eligibility entitle ment various benefits opportunities including housing social security finance employment lifeaffecting opportunities potential interfering rights due process rights freedom unfair unlawful discrimination3 systems capacity operate automatical scale capacity affect thousands millions people stroke occur orders mag nitude speeds previously possible4 chapter two overarching aims firstly argue international human rights framework provides promising set standards ensuring ai sys tems ethical design development deployment secondly sketch basic contours comprehensive governance framework refer human rights–centered design deliberation oversight approach ensuring ai relied upon operate ways violate human rights four features ongoing discussions provide important contexts argument first rubric “ai ethics” used encapsulate multiplicity valuebased societal concerns associated use ai applications across increasingly extensive diverse range social economic activities second notable profiled cogitas ergo sum ed bayamlioglu irina baraliuc liisa janssens mireille hildebrandt detail see european commission “communication commission european parliament european council council european economic social committee committee regions artificial intelligence europe” httpsec europaeudigitalsinglemarketennewscommunicationartificialintelligenceeurope accessed march b wagner study human rights dimensions automated data processing techniques particular algorithms possible regulatory implications council europe committee experts internet intermediaries msinet httpsrmcoeintstudyhrdimensionofautomated dataprocessinginclalgorithms168075b94a accessed june karen yeung study implications advanced digital technologies including ai systems concept responsibility within human rights framework council europe msiaut committee study dgi201905 httpsrmcoeintastudyoftheimplicationsofadvanced digitaltechnologiesincluding168096bdab accessed december ai governance human rights–centered design lack clarity content normative values principles constitute relevant “ethical” standards ai systems adhere third industry selfregulation predominant approach bringing “ethical ai” reflected litany “ethical codes conduct” promulgated individual tech firms various tech industry consortia published response recent “tech lash”these codes presuppose tech industry formulate appropriate ethical norms ai trusted ensure ai systems duly adhere standards suggestions apply conventional regulation involving legal mandated regulatory standards enforcement mechanisms swiftly met protests industry unmitigated good based unexamined belief technological innovation adverse impacts belief entrenched altar upon cashstrapped contemporary governments worship naïvely hoping digital innovation create jobs stimulate economic growth thereby fill diminishing governmental coffers left bare propping banking sector teetered brink col apse follow ing global financial crisis fourth discussion need meaningful enforcement ethical standards almost entirely absent initiatives7 chapter proceeds three stages first argue international human rights standards offer promising basis developing coherent universal rec ognized set standards applied meet many albeit norma tive concerns currently falling rubric ai ethics second paper outlines core elements human rights–centered design deliberation oversight approach governance ai explaining approach needed much theoretical applied research required flesh details proposed approach third section sets agenda research identifying multiple lines inquiry must pursued develop technical organiza tional methods systems needed based adaptation existing engineering regulatory techniques aimed ensuring safe system design reconfig uring extending approaches secure compliance much wider complex set human rights norms fourth final section concludes reflections limitations proposed approach magnitude chal lenges associated making implementable real world settings nevertheless suggest human rights–centered design deliberation oversight approach eve smith “the techlash amazon facebook google—and do” economist jan httpswwweconomistcombriefing20180120thetechlashagainst amazonfacebookandgoogleandwhattheycando accessed june however recent concessions big tech need legal regulation eg microsoft’s call legal regulation facial recognition technology states facebook’s mark zuckerberg’s recent acknowledgment kind regulation needed relation datadriven social media content distribution systems exception recent legislation proposed legislation eg germany france united kingdom concerned reducing prevalence extremist terrorist media content online karen yeung andrew howes ganna pogrebna governance ai offers concrete proposal capable delivering genuinely ethical ai least four reasons turn human rights lie core ai ethics within contemporary discussions ai ethics agreed set ethical standards govern operation ai systems reflected variety ethical standards espoused various voluntary ai ethics codes emerged recent years salience ai ethics reflects welcome recognition tech industry policymak ers ai systems may significant adverse impacts8 values commonly appearing discussions particularly “transparency” “fairness” meant currently operates empty vessel anyone including tech industry socalled digital titans pour preferred ethical content without agreed framework norms clearly identifies articulates rele vant ethical standards ai systems expected comply little real progress made toward ensuring systems practice designed developed deployed ways meet widely accepted ethical standards although scope reasonable disagreement concerning ethical conduct requires given case core set agreed norms constitute basic minimum conduct cannot fall appropriately characterized ethical acceptable must identified10 believe international human rights standards offer promising set ethical standards ai systems several civil society organizations suggested11 yeung supra n see daniel greene anna lauren hoffmann luke stark “better nicer clearer fairer critical assessment movement ethical artificial intelligence machine learning” proceedings 52nd hawaii international conference system sciences httpsdblporgrec bibtex1confhicssgreenehs19 accessed december luciano floridi josh cowls monica beltrametti raja chatila patrice chazerand virginia dignum christoph luetge et al recommendations” minds machines –p nemitz “constitutional democracy technology age artificial intelligence” phil trans see various reports civil society organizations concerned securing protection international human rights norms eg latonero “governing artificial intelligence upholding human rights human dignity” data society httpsdatasocietynetwpcontent uploads201810datasocietygoverningartificialintelligenceupholdinghumanrightspdf discrimination machine learning systems httpswwwaccessnoworgthetoronto declarationprotectingtherightstoequalityandnondiscriminationinmachinelearningsystems montreal declaration responsible development artificial intel igence participatory process ai governance human rights–centered design international governance framework human rights law intended establish global standards norms mechanisms accountability specify ways individuals entitled treated united nations un universal declaration human rights udhr perhaps wellknown interna tional human rights charter based commitment appalling treatment individuals occurred world war ii condemned pro hibited outright ought never repeated despite number variation regional human rights instruments americas africa europe enshrined constitutions individual nationstates grounded shared commitment uphold inherent human dignity every person individual regarded equal dignity worth wherever situated12 shared foundations reflect status human rights standards basic moral entitle ments every individual virtue humanity whether entitlements given explicit legal protection13 extent governments recognize basic moral entitlements legal enforceable rights varies considerably partly due differences political ideology contemporary liberal democratic states human rights widely recognized essential “constitutional” status provide effective guarantees individual free doms cherished respected particular european union’s eu legal order rooted constitutional commitments human rights democracy rule law socalled constitutional triumvirate forms foundational princi ples upon political systems characterized liberal constitutional democracies ultimately rest14 brings us second reason human rights norms provide appropriate norms securing ethical ai commitment effective human rights protection part parcel democratic constitutional orders world ai systems increasingly configure collective individual environments entitlements access exclusion opportunities resources essen tial protection human rights alongside respect rule law protection democracy assured maintain character political communi ties constitutional democratic orders every individual free pursue version good life far possible within framework peaceful stable cooperation underpinned rule law15 contrasts starkly developmentofartificialintelligence access see httpswwwaccessnoworgtagartificial intelligencefor various reports data society see httpsdatasocietynet ieee report see httpswwwieeeorg ethical aligned design ai httpsethicsinactionieeeorg lists first principle ai design infringe international human rights ai report httpsainowinstituteorgainow2018reportpdf see also l mcgregor et al –latonero supra n r dworkin taking rights seriously london duckworth p nemitz supra n hildebrandt smart technologies ends law novel entanglements law technology cheltenham uk edward elgar karen yeung andrew howes ganna pogrebna contemporary ai ethics codes typical outline series “ethical” principles effectively plucked air without grounding specific vision character kind political community authors committed establishing maintaining principles intended secure protect16 welldeveloped institutional framework systematic attempts made monitor promote protect adherence human rights norms around world provide two additional reasons support adopting human rights standards ensure ethical governance ai systems despite considerable variation range scope rights enumerated formal charters rights wellestablished analytical framework tension conflict rights rights collective interests considerable importance democratic societies resolved specific cases application structured form reasoned eval uation approach exemplified structure articulation human rights norms within european convention human rights echrthe echr ratified fortyseven countries specifies series human rights norms including among others right freedom expression right life right private home life right freedom assembly religion must guaranteed individuals effectively protected however many rights certain qualifications permitted order ensure respect narrow range clearly specified purposes necessary democratic society provided qualifications prescribed law proportionate relation purposes example article echr provides dom hold opinions receive impart information ideas without interference public authority regardless frontiers article shall prevent states requiring licensing broadcasting television cinema enterprises may subject formalities conditions restrictions penalties prescribed law necessary democratic society interests national security territorial integrity public safety prevention dis order crime protection health morals protection reputation rights others preventing disclosure information received confidence maintaining authority impartiality judiciary accordingly although freedom expression essential ensure among things free democratic debate individual selfdetermination legal restrictions expression may permissible purposes specified article accordingly restrictions see example beijing ai principles httpswwwbaaiaccnblogbeijingaiprinciples ai governance human rights–centered design expression may justified order example protect individual rights privacy right free fair elections conflict particular cases provided restrictions legal prescribed go minimum necessary protect rights structured framework reasoned resolution conflict arising com peting rights collective interests specific cases widely understood human rights lawyers practitioners forming essential part human rights approach framework overcomes another shortcoming existing codes ethical conduct failure acknowledge potential conflicts ethical norms lack guidance concerning conflicts ought resolved design operation ai systems codes acknowledge potential conflict little offered way guidance concerning resolve conflict codes much ongoing ai ethics literature beyond suggesting one seek help ethics expert17 contrast wellestablished human rights approach resolution ethical conflict informed developed substantial body authoritative rulings handed judicial institutions international national levels responsible adjudicating human rights complaints adjudicatory bodies determine allegations human rights violations lodged individual complain ants form part larger institutional framework developed time mon itor promote protect human rights includes diverse network actors un system regional human rights organizations council europe wide range civil society organizations focused protection human rights national courts administrative agencies academics human rights advocates institutional framework rights monitoring oversight adjudica tion provides reason human rights norms provide promising basis ai ethics standards dynamic evolving corpus judicial decisions help elucidate scope justified interferences particular rights concrete cases offering concrete guidance involved design development imple mentation ai systems concerning human rights compliance requires importantly perhaps human rights norms international recognized many jurisdictions supported law thereby providing set national international institutions allegations human rights violations investigated enforced hence offer means real effective protection contrasts sharply prevailing selfregulatory model favored tech industry national regional governments including eu see council europe “guidelines artificial intelligence data protection” january httpsrmcoeintguidelinesonartificialintelligenceanddataprotection168091f9d8 eu high level expert group’s ethics guidelines trustworthy ai refers need reasoned evaluation transparency documentation ethical tradeoffs resolved encountered involved designing developing deploying ai systems offers substantive guidance concerning evaluation conducted karen yeung andrew howes ganna pogrebna acquiesced18 although selfregulation effective handful industries understood “community shared fate” eg us nuclear industry three mile island via institute nuclear power operations inpo19 good reasons doubt effectiveness general20 given selfregulatory standards legal binding force21 tech firms operate highly competitive global markets securing firstmover advantage often accompanied capacity reap extensive benefits arising global network effects eg google maps naïve expect trusted abide voluntary standards faced powerful commercial imperatives hardly surprising critics dismissed voluntary codes conduct “ethics washing”given overwhelming evidence tech industry cannot relied upon honor voluntary commitments23 nemitz describes growth initiatives “genius move” tech industry allowing industry focus attention resources ethics ai delay debate work law ai24 hagendorff comments ai ethics—or ethics general—lacks mechanisms reinforce normative claims course enforcement ethical principles may involve reputational selfregulation controlling process activity people organizations involved rather outside organization government voluntary selfregulation direct government involvement n gunningham “investigation industry selfregulation workplace health safety new zealand” httpregnetanueduausitesdefaultfiles publicationsattachments201504nginvestigationindustryselfregulationwhssnz0pdf j rees hostages transformation nuclear safety since three mile island list shortcomings see organisation economic cooperation development final –paris oecd regulation expert neil gunningham observes “the extent selfregulation practice either positive negative attributes depend much social economic context within operates particular characteristics scheme nevertheless fair say ‘pure’ selfregulation rarely effective achieving social objectives gap private industry interests public interest” see gunningham supra n fz borgesius discrimination artificial intel igence algorithmic decisionmaking council europe directorate general democracy strasbourg council europe httpsrmcoeint discriminationartificialintelligenceandalgorithmicdecisionmaking1680925d73 accessed june b wagner “ethics escape regulation ethicswashing ethicsshopping” bayamlioglu et al supra n sobering account facebook’s repeated failure honor publicly stated commitments see uk house commons digital culture media sports committee disinformation “fake news” final report eighth report session –february hc https publicationsparliamentukpacm201719cmselectcmcumeds17911791pdf accessed may nemitz supra n ai governance human rights–centered design losses yet mechanisms rather weak pose eminent sic threat ethical guidelines ai industry serve suggest legislators internal selfgovernance sufficient specific laws necessary miti gate possible technological risks eliminate scenarios abuse even concrete laws concerning ai systems demanded recently done google demands remain relatively vague superficial though handful ethical ai proposals advocated civil society interna tional organizations drawn attention need ensure ai systems respect human rights norms paid scant attention enforcement26 human rights–centered design deliberation oversight ai ineffectiveness prevailing selfregulatory approach “ethical ai” demon strates alternative governance model needed one anchored human rights norms human rights approach one utilizes coherent integrated suite technical organizational evaluation tools techniques appropriate investigatory enforcement powers one provides opportunities meaningful stakeholder public consultation deliberation next section develop governance framework ai systems intended call “human rights–centered design deliberation oversight” although hagendorf “the ethics ai ethics evaluation guidelines” httpsarxivorg abs190303425 accessed may recent eu “algoaware” dec project observes algorithmic accountability recent still development additional limited concrete legislative regulatory initiatives implemented” algoaware state art report algorithmic decisionmaking httpsactuaryeuwpcontentuploads201902algoawarestateoftheart reportpdf accessed june example toronto declaration protecting rights equality nondiscrimination machine learning systems focuses rights equality nondiscrimination ml systems draws attention character human rights “universal ascribed system values based rule law” constitute “universal binding actionable set standards” violations” per paragraph see httpswwwaccessnoworgthetorontodeclarationprotecting therightstoequalityandnondiscriminationinmachinelearningsystems although eu’s ethical guidelines trustworthy ai places human rights protection foundation offering guidance thereby provided guidelines remain entirely voluntary make provision external independent oversight enforcement karen yeung andrew howes ganna pogrebna much foundational work remains done specify content contours approach ful render capable practical implementa tion believe proposed framework offers concrete approach bring end “ethics washing” securing design development deployment human rights–compliant ai systems realworld settings core elements approach outlined following discussion human rights–centered design deliberation oversight proposed governance regime ai relevant automated systems rely training operation seeks ensure systems human rights–compliant reflect core values underpin rule law27 entails systematic consideration human rights concerns every stage system design development implementation making interventions identified necessary regime mandated law subject external oversight independent properly resourced regulatory authorities appropriate powers investigation enforcement provide input technical human rights experts one hand meaningful input delib eration affected stakeholders general public approach seeks integrate ethical design strategies technical tools techniques software system design verification testing auditing together social organiza tional approaches effective legitimate governance approach seeks integrate range methods wide variety intersecting disciplinary perspectives including following perspectives pragmatic “ethics design” frameworks developed applied ethicists concerned ensuring due attention given moral values technical innova tion processes early technical design process aim integrating values proposed approach ai governance understood compatible complementary hildebrandt’s concept “legal protection design lpbd” hildebrandt’s lpbd places greater emphasis articulating challenges legal protection rule law posed codedriven technologies including identification substantive procedural opportunities capacities computational systems must provide order ensure values commitments underpinning rule law reflected systems rights contestation rights demand explanation justification etc contrast developing concrete legal technical organizational governance methods techniques ensuring human rights protection implemented complex sociotechnical systems utilize ai technologies see hildebrandt supra n hildebrandt law computer scientists ai governance human rights–centered design engineering design28 example valuesensitive design vsd approach developed friedman others builds insights humancomputer interaction community concern incorporate human moral values design information technology connecting design systems affected stakeholders29 another perspective involves engineering techniques concerned “hard wiring” specific values sociotechnical system’s design operation although established methods experience hitherto focused ensuring value safety primarily via safety engineering techniques increasing body work software design engineering expanded range values engineers sought encode protect via system design include privacy referred “privacyenhancing technologies” “privacy design” security “security design” recently data protection principles “data protection design” realm machine learning growing body technical research “explainable ai” provide avenues humans better understand logic machine learning systems generate outputs well techniques improving eliminate unfair discrimination taken together techniques stood falling within expanding family technical approaches securing ethical values beyond safety additional approach suite methods techniques software design engineering including various forms assessment testing evaluation identify whether particular aspects system provably meet certain prespecified standards requirements30 organizational accountability mechanisms established regulatory techniques used safety critical domains operate ex ante requiring systematic evaluation safety concerns appropriate interventions system deployed also involve ex post techniques apply system deployed designed developed ensure traceability auditability system behavior via systematic recording logging system’s design operation alterations thereto31 range regulatory governance techniques used effectively contexts including use impact assessment tools methods incorporate j van den hoven miller pogge eds designing ethics cambridge cambridge university press b friedman “valuesensitive design” interactions –b friedman p kahn borning valuesensitive design theory methods cse technical report seattle university washington j kroll et al “accountable algorithms” u pa l rev rieke bogen g robinson public scrutiny automated decisions early lessons emerging methods upturn omidyar network report httpswwwomidyarcominsights publicscrutinyautomateddecisionsearlylessonsandemergingmethods accessed june karen yeung andrew howes ganna pogrebna opportunities mechanisms facilitating stakeholder consultation engagement deliberation particularly relation design development deployment highrisk applications32 ii riskbased approaches regulation seek ensure highrisk systems subject intensive demanding scrutiny whilst burdens demonstrating human rights compliance lowrisk systems proportionately less demanding33 iii metaregulatory approaches seek harness knowledge expertise within firms service regulatory compliance overseen public regulator endowed powers investigation sanction iv postimplementation monitoring “ai system vigilance” order systematical transparently track adverse events order identify problems failures early possible facilitate swift corrective interventions expectation frameworks methods adapted refined ensure respect human rights norms integrated system design incorporating human rights approach resolution conflict tension human rights norms human rights norms important collective interests may arise specific contexts circumstances time anticipate need new techniques frameworks accommodate novel human rights risks development deployment ai systems may generate example likely include new governance frameworks oversight mecha nisms ensure datadriven experimentation human users undertaken side conventional academic research settings undertaken human rights–compliant manner necessity “in wild testing” ai systems generate novel gov ernance challenges arise circumstances product service development phase sharply delineated deployment core principles human rights–centered design deliberation oversight methods techniques listed preceding section vary widely disci plinary foundations original contexts development proposal seeks draw together integrated manner appropriately adapted toward ensuring conformity human rights norms basis comprehensive design governance regime constructed around following four core principles human rights norms provide foundational ethical standards ai systems must demonstrably comply see example data protection impact assessment mantelero “ai big data blueprint human rights social ethical impact assessment” computer law security review rights opportunities risks berkman klein center j black riskbased regulation choices practices lessons learned risk regulatory policy paris oecd ai governance human rights–centered design design deliberation assessment testing evaluation independent oversight investigation sanction traceability evidence proof principles briefly outlined following discussion principle design deliberation central approach requirement ai systems designed con figured operate ways compliant universal human rights standards design development phase posing “high risk” interfering human rights affected stakeholders consulted proposal given opportu nities express views proposed system’s potential impact discussion system’s designers consultation affected stakeholders general public initial phases system design contributes overall legitimacy regime understood terms respect democratic values affected commu nities help system designers identify aspects system’s design proposed operation need reconsideration risks human rights assessed “high” “very high”this would trigger obligation system designers reconsider redesign system andor proposed business model35 order reduce risks form level regarded tolerable understood terms human rights approach resolution conflict rights collective interests ways duly accommodate concerns expressed affected stakeholders recognition individual collective benefits system expected generate36 principle assessment testing evaluation users others affected operation ai systems including general public justified confidence ai systems fact comply human rights standards systems subjected formal assessment testing evaluate compliance human rights standards occur regularly throughout entire lifecycle system development initial formulation proposal design specification development prototyping realworld jasanoff ethics invention technology human future new york w w norton raso et al supra n potential discriminatory impact datadriven business models see ali et al participatory approach social impact assessment referred council europe’s ai guideline strongly resonates role approach ascribes public deliberation see council europe guidelines ai feb httpsrmcoeintguidelinesonartificial intelligenceanddataprotection168091f9d8 –karen yeung andrew howes ganna pogrebna implementation including periodic evaluation datasets upon system trained upon operates37 evaluations form core element overarching “human rights risk management” approach aims identify potential human rights risks deployment ai relevant automated systems occurs within larger metaregulatory approach ai governance ai system developers owners subject legal duties demonstrate public regulatory authority system human rights–compliant38 significant risks human rights compli ance identified system developers must reconsider design specification system requirements view modifying order reduce risks level satisfies tests necessity proportion39—or cases threats human rights disproportionate thus unacceptably high refrain proceeding development system form proposed system implemented periodic review must undertaken test assessment documents duly filed public authority system “ai vigilance” also needed entailing systematic recording adverse incidents arising system operations including potential human rights violations reported users wider public triggering obligation system provider review reas sess system’s design operation report publicly register modifi cations system undertaken following evaluation systematic periodic postimplementation monitoring vigilance needed ensure ai systems continue operate human rights–compliant manner implemented realworld settings ai systems wil invariably display emergent effects difficult anticipate may scale rapidly accordingly also accompanying need systematic sustained research concerned mod eling social systems order better anticipate predict unintended adverse societal effects kroll et al supra n borgesius supra n rieke bogen robinson supra n also called “managementbased” regulation “enforced selfregulation” metaregulation refers strategy regulators prescribe regulated firms comply instead require develop systems compliance legal mandated goals demonstrate compliance regulator j black “paradoxes failures “new governance’ techniques financial crisis” modern law review –the formulation appropriate legal standard would need reflect established proportionality assessment wellestablished addressing human rights conflicts conflicts human rights legitimate collective interests operating human rights equivalent “as low reasonably practicable” alarp requirement applies legal duties ensure safety complex systems per hopkins “explaining safety case’” regulatory institutions network working paper httpswwwcsbgovassets17workingpaper87pdf thomas “safetycritical systems” gresham lectures london httpswwwgreshamacuklecturesandevents safetycriticalsystems accessed march ai governance human rights–centered design principle independent oversight investigation sanction order provide meaningful assurance ai systems fact human rights– compliant rather merely claiming human rights–compliant independent oversight external properly resourced technical competent oversight body invested legal powers investigation sanction essential40 operation market forces cannot provide design develop deploy ai systems sufficient incentives invest required resources necessary ensure ai systems human rights–compliant proposed approach must operate within legal mandated institutional structure including oversight body duty monitor enforce substantive procedural regulatory requirements including concerning robust design verification testing evaluation including appropriate documentation demonstrating requirements fulfilled supported legal mandated stakeholder public consultation proposed ai systems pose “high risk” human rights suggest independent oversight best designed within metaregulatory framework legal duties placed ai system developers operators demonstrate public authority systems human rights–compliant41 although variety approaches understood metaregulatory form42 socalled safety case properly implemented considered sig nificantly contributed ensuring safety complex systems several domains including safety regulation offshore petroleum drilling regulation workplace safety adopted several anglocommonwealth legal systems43 borgesius supra n see n see j black “managing regulatory risks defining parameters blame focus australian prudential regulation authority” law policy –s gilad “it runs family metaregulation siblings” regulation governance –c coglianese e mendelson “metaregulation selfregulation” r baldwin c hood lodge socalled “safety case” movement emerged early 1990s united kingdom united states approach safety certification involving approval oversight complex systems aircraft nuclear power plants offshore oil exploration see hopkins supra n however criticisms safety case approach including concerns problems confirmation bias need consider worst case scenarios reliance probabilistic assessment provide assurances safety rather opposite goal identifying unrecognized hazards examples highly successful processbased rather performancebased approaches securing safety relation submarines eg subsafe program see n leveson “the use safety cases certification regulation” mit engineering systems division working paper series httpsunnydaymitedusafetycasespdf accessed june leveson observes british health safety executive applied safety case regime widely uk industries pursuant responsibility controlling risks placed primarily create manage hazardous systems based three principles create risks responsible control ing risks b safe operations achieved setting achieving goals rather following prescriptive rules c goals set legislation system providers operators develop consider appropriate methods achieve goals karen yeung andrew howes ganna pogrebna discussion offshore petroleum drilling hopkins highlights five basic features safety case approach work identifies major hazards provides detailed plans hazards managed specifying controls put place deal identified hazards measures taken ensure con trols continue function intended demonstrate regulator processes undertaken identify hazards methodology used assess risks reasoning evidence led choose one control rather another regarded acceptable regulator accept flexibility determining respond hazards free rein thus operator proposes adopt inadequate standard safety case regulator may challenge operator require adoption better standard level expertise engage meaningful scrutiny regulator’s role ensure hardware working documents date audit safety case ensure specified controls functioning intended necessitates sophisticated understanding accident causation prevention regulatory officials carrying site audits must consult practicable identify control hazards operator cannot claim compliance completed hazard identification process general duty care raises safety case regime “tick box” “blind compliance” mentality hazard identification process demonstrably inadequate would fail meet requisite standard44 regulatory regimes kind allow although necessitate possibil ity ex ante licensing designated public authority case particularly human rights–sensitive highrisk systems facial recognition systems intended use governments identify individuals interest public places45 applying although general duty care linguistical quite imprecise meaning elaborated via case law numerous cases courts decide whether duty complied case law gives fairly clear guidance general duty means particular cases see hopkins ibid supra n see example big brother watch face lawless growth facial recognition uk policing httpsbigbrotherwatchorgukwpcontentuploads201805faceofffinaldigital1pdf ai governance human rights–centered design underlying logic structure safety case approach human rights compliance would provide developers considerable flexibility seeking “make case” regulator demonstrate proposed ai systems expected operate human rights–compliant ways principle traceability evidence proof order facilitate meaningful independent oversight evaluation ai systems must designed built secure auditability means merely securing transparency aimed ensuring subject meaningful review thus providing concrete evidential trial securing human accountability ai systems46 necessary systems constructed produce evidence operate desired47 must legal obligation requiring crucial design decisions testingassessment process outcome processes operation system properly documented provide clear evi dence trail audited external experts drawing experience safety case approach entails imposing legal duty operators demon strate regulator robust comprehensive systems place reduce safety risks level “as low reasonably practical” envisage imposition suitably formulated legal duty ai systems developers owners operators demonstrate systems human rights–compliant discharge legal duty ai system developers would also subject legal duties prepare maintain securely store system design documentation testing evaluation reports system must designed routinely generate operational logs inspected audited independent suitably competent authority taken together provide audit trail system designers devel opers demonstrate undertaken human rights “due diligence”— thereby discharging legal duty demonstrate discharged legal duty reduce risk human rights violations acceptable level traceability evidential requirements apply design development phase tation systems logging blackbox recording system operations taken together obligations intended ensure robust systematic transpar ency mechanisms put place aim complete comprehension provide sufficient information ensure human accountability ai systems maintained48 integrated approach ai governance grounded j j bryson theodorou “how society maintain humancentric artificial intelligence” humancentered digitalization services ed toivonennoro e saari kroll et al supra n bryson theodorou supra n karen yeung andrew howes ganna pogrebna principles understood response council europe’s call “human rights oriented development technology”as alessandro mantalerohas claimed innovation must developed responsibly taking safeguard fundamental rights preeminent goal necessarily requires development assess ment procedures adoption participatory models supervisory authorities human rights–oriented development tech might increase costs force developers business slow current timetomarket impact products services individual rights society assessed advance time medium longterm approach reduce costs increase efficiency eg accurate prediction decision systems increased trust fewer complaints moreover businesses societies mature enough view responsibility towards individuals society primary goal ai development50 getting research agenda four principles outlined previous section demand revision many aspects software engineering se practice suite relevant engineering regulatory governance techniques already use specific areas require significant adaptation generalization support meaningful human rights evaluation compliance changes se practice must complemented focused human rights–centered design research agenda computer science agenda would draw together currently fragmented activity relevant software engineering disciplines vance software lifecycle ai systems particular likely require new design processes rather offer detailed research agenda offer instead governance challenges must met se provide assurances human rights compliance topics existing areas practice software engi neering others established research disciplines none however tradi tion human rights–centered design beginning consider appropriate software engineering practice ai systems requirements analysis se requirements analysis concerns identification needs met new software system commercial orientation diversity approaches requirements mantalero ai data protection chal enges possible remedies study council europe httpsrmcoeintartificialintelligenceanddataprotectionchallengesandpossible re168091f8a6 accessed june see mantalero ibid section detail ai governance human rights–centered design analysis present severe challenge principle human rights–centered design agenda made acute fact requirements analysis devel oped nonai systems corporate practice strongly oriented identifying requirements business customers often contractual nature accordingly requirements specification often generates long lists “shoulds” stated natural language contrast consumers targeted endusers work play social needs typical focus requirements analysis smaller tech companies particularly startups identify requirements analysis major component se concerns51 heavily dependent agile even craft based approaches development weaker contractual requirements analysis weaker audit trails however least realized affected stakeholders beyond customer enduser identified involved participants require ments analysis design giving rise participatory design52 also case professionals involved requirements analysis diversity backgrounds—not computer science engineering also psychology sociology social sciences therefore might extended include legal training order meet principle software engineering practice ai systems must meet following challenges consider human rights requirements stakeholders users customers also individual rightsbearers entitled equal concern respect auditable requirements description requirements specifica tion documents b train employ design professionals bring human rights–centered design methods system design requirements specification understanding collecting analyzing data processes acquiring selecting modeling data required ai sys tems create human rights challenges challenges require attention several levels including way problems framed requirements analysis human rights–centered approach design meets principle must take due account human rights risks building ai systems requirements exam ple many commercial ai systems designed utilize datadriven “hypernudges” channel user attention action directions beneficial system owner53 potential threaten individual autonomy dignity right liberty freedom thought yet human rights risks currently taken account require ments analysis processes bias data sampling modeling attribute selection e u klotins gorschek “software engineering antipatterns startups” ieee software –j simonsen robertson ed routledge international handbook participatory design new york routledge k yeung “‘hypernudge’ big data mode regulation design information communication society –karen yeung andrew howes ganna pogrebna another major problem use machine learning techniques generates many opportunities bias discrimination inadvertently affect outputs produced may threaten right equal protection right nondiscrimination54 include biases algorithms’ developers biases built models upon systems generated biases inherent datasets used train mod els biases introduced systems implemented realworld settings55 response concerns growing body work concerned devising technical approaches countering biases emerged yet move lab software development settings verification verification concerns processes checking whether software meets specified requirements words software satisfy output requirements analysis verification involve use formal methods logic check software model software contain errors formal verified software performs required functions nothing else possible inputs verifiable evidence verification used example aviation industry extent safetycritical systems verification also seen successes agile software development environments56 guarantee example plane crash guard undesirable conditions occurring virtue mis conceived models poorly written software application verification mandated certification authorities sectors eg aviation others also used sectors eg ship design commercial costs errors relatively high mandated processes typical subject audit gov ernment authority federal aviation administration faa european aviation safety agency easa verification particularly relevant principles design deliberation assessment testing evaluation ask two questions answer first question negative least current methods57 although protocol echr article provides “the enjoyment right set forth law shall secured without discrimination ground sex race color language religion political opinion national social origin association national minority property birth status” see also art eu charter fundamental rights veale r binns “fairer machine learning real world mitigating discrimination without collecting sensitive data big data society dec httpsdoiorg101177 c calcagno distefano j dubreil gabi p hooimeijer luca p o’hearn papakonstantinou j purbrick rodriguez “moving fast software verification” nasa formal methods 7th international symposium ed k havelund g holzmann r joshi lecture notes computer science cham switzerland springer –s russel dewey tegmark “research priorities robust beneficial artificial intelligence” ai magazine –ai governance human rights–centered design active area research note ai used safetycritical systems precisely software cannot verified ai systems difficult verify several reasons particular programs automatical generated machine learning coded different forms handcoded computer programs existing verifica tion methods designed work programs relatedly programs typical complex much higher level dimensionality compari son handcoded programs verification approaches may computational tractable addition machine learning used deployed systems adapt behavior real time effective verification would need continual repeated use context therefore impossible current verification techniques human rights–centered nevertheless human rights–centered verification may still play role design validation procedures following section human rights–centered verification ai systems likely require many years research influences practice research designed answer following challenges limits verification respect ai systems requirements concerning human rights beyond safety b formal methods used verify ai systems substrate operating systems learning software58 least ensure ai systems operating intended c formal methods used advance ai systems testing follows cybersecurity design cybersecurity concerns protection computer systems data cyberphysical systems intrusion theft damage cybersecurity design focuses need security software foundations therefore security considerations requirements analysis advocated use example formal verification methods early design process59 unfortunately cybersecurity design consideration software engineering relatively recently many deployed systems practices suffer consequence however changing often response legislation early efforts building regulatory engineering infrastructure may provide way forward human rights–centered design inevitably cybersecurity design ai systems faces challenges verification dis cussed earlier challenges documented recent nsf report although report focuses privacy rather human rights general ibid chong j guttman datta myers b pierce p schaumont sherwood n zeldovich report nsf workshop formal methods security arxiv preprint arxiv160800678 karen yeung andrew howes ganna pogrebna validation validation methods used assess whether behavior software system meets stakeholders’ needs validation simply checking behavior system written specification much rigorous empirical process must generate data relevant understanding whether system fit purpose two spe cific forms validation conducted extensively software industry penetration testing commissioned cyberattack conducted internal external agency one method used ensure security software systems data penetration testing sometimes automated standard tests legal mandated industries eg payment card industry particular focus penetration testing privacy validation however value privacy sometimes regarded absolute value protected costs may reflect rights balancing approach enshrined right privacy understood within human rights approach penetration testing knowledge applied ai systems recent demonstrations ai systems spoofed adversarial attacks60 suggest systems come new unanticipated vulnerabilities order meet needs principle penetration testing must meet following challenges emphasizes privacy ways may disproportionately threaten protection rights legitimate collective interests come conflict specific contexts circumstances offensive ai particularly likely applied ai systems61 user experience ux designers often play key roles requirements analysis also empirical validation tasks systems artifacts often coevolve ux designers provide critical feedback effectiveness existing designs well ideas future designs typical focus ensuring system use useful pleasurable rewarding efficient ux designers also tasked seeing things user’s perspective rather service provider’s perspective methods include use scenarios personas provide means curate stories context use potential users participatory design grown importance providing one way human values outside industry influence design humancentered design research strong influence ux design practice methods hutson “hackers easily fool artificial intelligences” science july brundage et al malicious use ai forecasting prevention mitigation https maliciousaireportcom accessed december ai governance human rights–centered design currently configured embrace human rights concerns form recognized international human rights law much made need ux designers consider social physical context use62 number ethical valuemotivated influences63 including bias64 feminism65 accessibility diversity research little work done democratic context use therefore human rights legal constitutional perspective accordingly key questions include future ux design ai systemshow ux design move beyond current focus social physical contexts embrace democratic civic structures including respect human rights important sources con straint methods used human rights community engaging people human rights thinking66 contribute ux approaches ai systems design appropriation software systems designed also appropriated users unantici pated tasks unanticipated contexts productive aspect human use tech nology may prove particularly problematic governance ai systems adm systems hitherto built one specific social context context rarely communicated robust way assures used setting example zweig krafft discuss software compas used criminal justice systems pretrial assessment bail decisions decisions prosecute original built posttrial assessment67 work needed investigate appropriation ai systems appropriately governed principle algorithmic transparency inspection present general requirement algorithm inspection recent cases suggest systematic approach considered order provide assurance trustworthiness algorithmic systems particularly directly c heath p luff technology action cambridge cambridge university press benyon p turner turner designing interactive systems people activities contexts technologies harlow uk harlow pearson education b friedman g hendry value sensitive design shaping technology moral imagination cambridge mit press b friedman ed human values design computer technology cambridge cambridge university press b friedman h nissenbaum “software agents user autonomy” agents ’first international conference autonomous agents acm –s bardzel “feminist hci taking stock outlining agenda design” proceedings sigchi conference human factors computing systems acm –see european union external action “good human rights stories coalition launched” rightsstoriescoalitionlauncheden accessed december k zweig g wenzelburger krafft “on chances risks security related algorithmic decisionmaking systems” european journal security research –karen yeung andrew howes ganna pogrebna adversely affect rights individuals context adm systems us criminal justice system especially problematic algorithms developed commercial software providers claiming intellectual property protection enabling assert rights confidentiality secrecy algorithms68 contrast development implementation hart algorithm used united kingdom durham police force make custody decisions much open however made available public scrutiny69 legitimate concerns “gaming” may justify refraining full public disclosure certain algorithms least highrisk contexts human rights seriously threatened regulators must legal powers inspect algorithms datasets supporting principle instrumentation logging bryson theodorou argue logging mandated “social critical” fields71 assert logging must also mandated “human rights critical” fields ie systems identified pose “high risk” unjustifiably interfering human rights particularly scale firms unlikely keep audit trail evidences problematic actions unless legal required eg mandatory blackbox recorder requirements aviation industry importance maintaining audit trails system behavior essential maintaining meaningful human accountability ai systems human rights–centered design demands instrumentation systems automatical record reproduce historical decisionmaking processes outcomes mandate mini mum safetycritical human rights–critical systems support principle conclusion chapter highlighted various deficiencies inherent prevailing model voluntary selfregulation securing “ethical ai” enabled “pick own” see state wisconsin v loomis nw2d supreme court wisconsin durham police reported “would prepared reveal hart algorithm associated personal data custody event datasets algorithmic regulator” burgess poor” wired march httpswwwwiredcoukarticlepoliceaiukdurhamhartcheckpoint algorithmedit accessed december see canadian directive automated decisionmaking applies canadian federal government’s use automated decisionmaking systems including machine learning predictive analytics among things imposes requirements release custom source code owned government canada bryson theodorou supra n ai governance human rights–centered design approach identification ethical standards ai systems clear agreed set ethical standards within tech industry resulted conceptual incoherence particularly norms identified given “ethics code” typical rooted explicit vision kind political com munity norms intended nurture maintain ethical codes acknowledge inescapable tensions conflict arise ethical norms specific circumstances let alone offer concrete guidance concerning conflicts addressed resolved leaving industry unilateral resolve indeed ignore see fit prevailing selfregulatory approach also fails recognize need obligation seek meaningful input affected stake holders public large identifying relevant ethical standards implemented design operation ai systems finally codes lack effective governance framework resources institutions independently assess enforce relevant ethical standards let alone ensure redress adversely affected andor sanctions event violation accordingly prevailing approach ai ethics amounts little marketing exercise aimed demonstrating tech industry “takes ethics seriously” order stave external regulation short failed deliver “ethical ai” argued alternative approach ethical governance ai needed—one systematic coherent comprehensive centered human rights norms explicitly grounded critical importance protecting main taining sociotechnical foundations required preserve nurture societies constitutional democratic political orders anchored enduring inviolable commitment respect human dignity individual freedom outlined approach call “human rights–centered design deliberation oversight” believe potential ensure practice ai systems designed developed deployed ways provide genuinely ethical ai requires human rights norms systematical considered every stage system design development implementation making interventions identified necessary drawing upon adapting technical methods techniques safe software system design verification testing auditing order ensure com pliance human rights norms together social organizational approaches effective legitimate regulatory governance regime must mandated law relies critical external oversight independent competent properly resourced regulatory authorities appropriate powers investigation enforce ment requiring input technical human rights experts one hand meaningful input deliberation affected stakeholders general pub lic approach draws upon variety methods techniques varying widely disciplinary foundations suitably adapted refined secure conformity human rights norms could drawn together integrated manner form foundations comprehensive design governance regime founda tional ethical standards composed contemporary human rights norms designed around four principles namely design deliberation b assessment testing karen yeung andrew howes ganna pogrebna evaluation c independent oversight investigation sanction traceability evidence proof approach however ensure protection ethical values adversely implicated ai given human rights norms comprehensively cover val ues societal concern addition great deal work needs done develop techniques methodologies robust reliable yet practical imple mentable across wide diverse range organizations involved developing building operating ai systems work effectively ensure compliance human rights norms evaluated operationalized stage system design development deploymentthere also considerable challenges establishing overarching legal institutional governance framework ensure ai systems particularly appropriately regarded posing substantial threats risks human rights subjected meaningful effective scrutiny competent independent regulatory authorities endowed suitable powers investigation sanction develop systematic approach integrating different methodologies requirements unified governance framework enables meaningful public input deliberation affected stakeholders design development implementation ai systems hope challenges prove insurmountable yet magnitude underestimated solving require sustained systematic research investigation longterm time horizon proposal springs prem ise theoretical possible translate human rights norms software design processes software requirements adequately capture functionality constraints give effect often highly abstract human rights norms suspect rights readily translatable software system requirements rights due process rights contestation rights unbiased tribunal particularly ai systems used inform automate decisions individuals right privacy rights freedom unlawful discrimination others likely fiendishly difficult “hard wire” rights freedom expression freedom conscience freedom association human rights often highly abstract nature lacking sharply delineated boundaries given capacity adapt evolve response dynamic sociotechnical context may well much software system design implementation techniques achieve attempting transpose human rights norms commitments structure operation ai systems realworld settings72 human rights–centered design deliberation oversight confused attempts design computational systems designout possibility noncompliance law entails translating human rights concepts formalizable mathematical concepts hardcoded computational decisionmaking systems hildebrandt refers “legal design” rather anticipate vision human rights–centered design deliberation oversight incorporate hildebrandt refers “legal protection design” lpbd developing techniques methods governance frameworks ensure computational ai governance human rights–centered design approach necessitates research cooperation ai design development implementation computational engineering technical specialists legal experts considerable competence fluency human rights discourse jurisprudence means effect tech designers developers engineers involved building ai systems acquire deeper understanding human rights com mitments underlying constitutional framework embedded order identify undertake system design testing implementation ways consistent democratic constitutional architecture73 time human rights experts need acquire sufficient technical competence design architecture development implementation ai systems theory realworld practice order discharge advisory assessment duties anticipate required every stage ai product lifecycle yet contempo rary university programs law computer science data science currently lack serious sustained interdisciplinary training even researchers succeed developing requisite techniques methodologies organizational institu tional governance frameworks capable forming foundational elements human rights–centered design deliberation oversight cadre professionals requisite expertise training also needed work tech indus try order implement realworld practice accordingly universities must create nurture deliver sustained interdisciplinary training education undertake kind rigorous creative problemoriented interdisciplinary research cooperation approach require equip professionals skil capacities commitment embed core principles approach ai systems increasingly configure mediate countless dimensions everyday human experience although ai began decades ago interdisciplinary field since become technical discipline yet given increasing rapidly expanding application powerful ai systems across many social domains capacity operate automatical scale study research ai must systems make available individuals suite capacities rights meaningful opportunities necessary provide kind substantive legal protection currently offered contemporary rule law according hildebrandt lpbd seeks ensure legal protection “ruled affordances technological environment determines whether enjoy substance fundamental rights” emphasizing need democratic participation design operation complex sociotechnical systems configure everyday environments subject lpbd able contest application court law hence entails foundational requirements datadriven decisions affecting individuals transparent justified contestable “lpbd seeks ensure practical capacity individuals exercise human rights enabled computational systems reflect dynamic evolution human rights norms order ensure effective protection societal technological context continues change time” hildebrandt supra n chap see hildebrandt law computer scientists oxford oxford university press borgesius observed need cs research aimed investigating ai systems might designed respect promote human rights fairness accountability well normative legal research borgesius supra n see also ai report httpsainowinstitute orgainow2018reportpdf accessed december karen yeung andrew howes ganna pogrebna expand include social humanistic disciplines equip tech professionals expertise sensitivities required attend seriously social contexts anticipate identify potential threats risks systems might generate applied human populations approach also likely confront significant cultural challenges actively taken include serious obstacles systematic implementation product development lifecycles ai although developed software engi neering techniques practices rely mathematical proof verify software systems meet certain specifications use particularly safety critical systems contemporary software development remains largely “craft” activity74 associated cultural norms creativity freedom tinker “hack” widely shared enthusiastical celebrated spent professional lifetime providing expert evidence legal cases large sums money lost due failed system projects distinguished software engineer martyn thomas laments fact software engineering yet mature professional engi neering discipline committed robust technical methods standards high levels professional integrity characterizethe socalled noble professions75 yet software development remains predominantly amateur activity celebrates capacity “move fast break things” ethic famously championed facebook founder mark zuckerberg proposed governance regime unlikely take root readily anticipate objections proposal asserting general legal mandated regulatory regime stifle innovation sound death knell tech startups yet ample evidence demonstrate legal regulation may foster rather stifle social beneficial tech innovation example introduc tion mandatory environmental laws imposing limits emissions important catalyst emergence development competitive market emission reduc tion technologies time enactment eu’s general data protection regulation gdpr applies personal data collectors processors fledgling startups digital titans may early tell whether gdpr led decline tech startups sme growth worth nothing growing cal united states enact legal data protection regime provide equivalently high levels protection usbased data subjects importantly however “ethical ai” anything marketing exercise echoes hollow claims associated “corporate social responsibility” wholesale change tech industry’s cultural attitudes required need much pay lip service human rights obligations ai systems developers operators discharge duties arising proposed governance regime simply employing legal expert willing certify best knowledge understanding system compliant human rights standards words role human rights expert hired gun thomas “should trust computers” gresham lectures october london ai thomas “computers future” gresham lectures june london ai ai governance human rights–centered design formulates arguments assure regulators client’s system legal compliant rather necessary foster language culture “human rights conscious ness” tech industry involved design development implementation ai systems regard human rights compliance part profes sional remit rather “niche” problem handedoff legal experts final locate proposal one important element overall socio political landscape needed build future ai systems compatible liberal democratic political communities respect human rights rule law lie bedrock public debate global cooperation required bryson theodorou observe second special problem ai actual unique rather character istic ict general ict thanks internet networking sys tems operate transnational therefore affords accumulation great wealth power simultaneously evading jurisdiction particular nation means appropriate regulation ai requires transnational cooperation process establish transnational agreements treaties enforcement mechanisms nontrivial already known already way76 words also need political leadership national transnational levels order bring political social technical coopera tion investment needed given ai systems capacity operate across national borders without technical difficulties short overcoming many obstacles cooperation—at disciplinary level organizational level industry level policymaking level—will needed bring end ethics washing deliver promise “ethical ai” realworld settings bibliography algorithm watch ai ethics guidelines global inventory available https algorithmwatch orgenprojectaiethicsguidelinesglobalinventory council europe consultative committee convention protection individuals regard automating processing personal data tpd guidelines artificial intel igence data protection tpd201901 directorate general human rights rule law hildebrandt mireille smart technologies ends law cheltenham uk edward elgar hopkins andrew “explaining ‘safety case’” working paper regulatory institutions network available httpswwwcsbgovassets17workingpaper87pdf joanna j bryson andreas theodorou “how society maintain humancentric artificial intelligence” humancentered digitalization services ed toivonennoro e saari new york springer –karen yeung andrew howes ganna pogrebna kloza dariusz niels van dijk raphaël gellert istván böröcz alessia tanas eugenio mantovani paul quinn “data protection impact assessments european union complementing new legal framework towards robust protection individuals” brussels brussels laboratory data protection privacy impact assessments mantalero alessandro ai data protection chal enges possible remedies tpd201809rev study council europe available httpsrmcoeint artificialintelligenceanddataprotectionchallengesandpossiblere168091f8a6 accessed june nemitz paul “constitutional democracy technology age artificial intelligence” philosophical transactions royal society mathematical physical engineering sciences raso filippo hannah hilligoss vivek krishnamurthy christopher bavitz levin kim “artificial intelligence human rights opportunities risks” berkman klein center rieke bogen g robsinson public scrutiny automated decisions early lessons emerging methods upturn omidyar network report available httpswwwomidyarcominsightspublicscrutinyautomateddecisionsearlylessons andemergingmethods accessed june yeung karen “a study implications advanced digital technologies including ai systems concept responsibility within human rights framework” council europe msiaut committee study draft available httpsrmcoeintastudyof theimplicationsofadvanceddigitaltechnologiesincluding168094ad40 chapter incompatible incentives privatesector ai tom slee performances ethics individuals present world set performances tune presentation depending setting1 may believe single “real” person behind performances expect see “coherence among setting appearance manner”individuals whose performances differ much one setting another risk called “dishonest” “twofaced” since branding became important companies presented world set performances financial incentives demand tune performance setting—offering generous humane face public communications harsher less empathetic one managing bottom line—while ethical demand coherence remains two decades ago movement corporateled globalization highlighted presentation gaps captured dissonance nike’s empowering “just it” bought sneakers farfromempowering sweatshop conditions endured made them3 one legacy movement set ethical consumption initiatives opinions expressed chapter author represent views policies sap erving goffman presentation self everyday life garden city ny doubleday naomi klein logo toronto knopf canada tom slee de pend ent fair trade sustainability certifications provide opportunity companies demonstrate coherent set values behind performances4 debates artificial intelligence ai ethics technology companies find accused twofaced—of presenting brands valuedriven organizations deploying algorithms5 often biased opaque unfair debates taken new importance following explosion “deep learning” techniques6 privatesector investment often broadly labeled apple google microsoft seven billion dol ars invested start ups companies invested four five times amount7 platform companies also leaders deploying deeplearning algorithms deployments industries early stages yet many us encounter deeplearning algorithms daily google search facebook news feed8 apple siri amazon alexa uber pricing9 airbnb search10 more11 chapter focuses major platform companies charting paths setting precedents traditional industries follow response series scandals compelling arguments critics academics12 platform companies recognized must establish reputations kimberley ann elliott richard b freeman labor standards improve globalization chapter algorithm shorthand automated datadriven sorting systems including classifying scoring rating ranking algorithms may implemented computers may also implemented organizational policies practices alex krizhevsky ilya sutskever geoffrey hinton “imagenet classification deep convolutional neural networks” advances neural information processing systems ed p bartlett f c n pereira c j c burges l bottou k q weinberger new york curran –httpspapersnipsccpaper4824imagenetclassificationwithdeepconvolutionalneuralnetworkspdf mckinsey global institute “artificial intelligence next digital frontier” new york mckinsey company june httpswwwmckinseycommediamckinseyindustries advancedelectronicsourinsightshowartificialintelligencecandeliverrealvaluetocompaniesmgi artificialintelligencediscussionpaperashx k hazelwood et al “applied machine learning facebook datacenter infrastructure perspective” ieee international symposium high performance computer architecture alexander sergeev mike del balso “horovod fast easy distributed deep learning tensorflow” arxiv180205799 cs stat february httparxivorgabs180205799 malay haldar et al “applying deep learning airbnb search” arxiv181009591 cs stat october httparxivorgabs181009591 nicola jones “computer science learning machines” nature news january httpsdoiorg101038505146a frank pasquale black box society secret algorithms control money information big data increases inequality threatens democracy new york crown random house safiya umoja noble algorithms oppression search engines reinforce racism new york new york university press solon barocas andrew selbst “big data’s disparate impact” california law review httpsdxdoiorg102139ssrn2477899 incompatible incentives privatesector ai responsible stewards powerful technologies avoid costly backlash issued public commitments ethical ai asserted belief fairness transparency proclaimed commitment building diverse gan iza tional cultures prevent bias creeping technological services products13 set ethics boards industry organizations partnership ai14 participated governmental bodies european union’s eu highlevel expert group artificial intelligence15 platform companies also taken task designing fairness systems16 investing research fairness transparency machine learning articulating statistical criteria fairness designing mechanisms explaining machinelearning results assembling unbiased datasets key problems technical approach good fit technical criteria play strengths technology companies standards set public benchmarks provide protection future accu sations auditable criteria incorporated product development release processes confirm compliance also financial incentives adopt technical approach standards demand expertise investment create barriers entry smaller firms risk management regulations create barriers entry financial healthcare industries17 challenges bias fairness far solved critics continue play essential role external investigations audits benchmarks reveal deficiencies missed internal efforts18 auditable algorithms datasets promise mechanisms closing presentation gap brands algorithms charges bias unfairness expose ai algorithms sense good enough thus emphasize solution better algorithms another set problems may become significant algorithms become accurate google “our principles” google ai accessed february httpsaigoogleprinciples microsoft “our approach microsoft ai principles” microsoft accessed february httpswww microsoftcomenusaiourapproachtoai partnership ai “the partnership ai” accessed february httpswww partnershiponaiorg european commission “highlevel expert group artificial intelligence” httpsec europaeudigitalsinglemarketenhighlevelexpertgroupartificialintelligence margaret mitchell et al “model cards model reporting” fat ’proceedings conference fairness accountability transparency new york acm –httpsdoi org10114532875603287596 malcolm campbellverduyn marcel goguen tony porter “big data algorithmic governance case financial practices” new political economy march –httpsdoiorg1010801356346720161216533 joy buolamwini timnit gebru “gender shades intersectional accuracy disparities commercial gender classification” proceedings machine learning research –inioluwa deborah raji joy buolamwini “actionable auditing investigating impact publicly naming biased performance results commercial ai products” aaaiacm conference artificial intel igence ethics society tom slee become good use chapter focuses second gap cannot translated research projects solved computer scientists algorithms create incentives much debate around ai ethics imagines algorithm camera recording por traying aspect external world asks system portray world fairly faithful categorizes things way corresponds real world19 social scientists long known algorithms portray world also change words donald mackenzie algorithm “an engine camera”introducing new algorithm means sorting people differently people care sorted respond21 people respond dynamic algorithms subjects becomes strategic economists familiar situations developed tools game theory think sociologists shown responses algorithms ubiquitous subtle seemingly innocuous decisions prompt changes measured dutch authorities separated cause death entered statistical records recorded public death certificate change followed “a considerable increase amsterdam cases death syphilis tabes dementia paralytics suicide”why causes death could entered statistical record without adding pain newly bereaved relatives sociologists also shown surprisingly powerful algorithmic engines book engines anxiety wendy espeland michael sauder describe impact us news world report rankings us law schools23 employers use sam corbettdavies sharad goel “the measure mismeasure fairness critical review fair machine learning” arxiv180800023 cs july httparxivorgabs180800023 alexandra chouldechova “fair prediction disparate impact study bias recidivism prediction instruments” big data june –httpsdoiorg101089big20160047 arvind narayanan tutorial fairness definitions politics accessed january https wwwyoutubecomwatchvjixiuydnyyk donald mackenzie engine camera financial models shape markets cambridge mit press danielle keats citron frank pasquale “the scored society due process automated predictions” ssrn scholarly paper rochester ny social science research network https papersssrncomabstract2376209 geoffrey c bowker susan leigh star sorting things classification consequences wendy nelson espeland michael sauder engines anxiety academic rankings reputation accountability new york russell sage foundation incompatible incentives privatesector ai rankings identify good students students rely choosing apply thus law schools want best students must play game rankings end dominating many aspects law school life dynamic described beautiful kieran healy review espeland sauder’s book academic legal establishment much fall trap become entangled like fly touched thread spider’s web first lightly caught found move made response drew tightly24 chapter draws loosely social science perspectives sketch happen respond algorithms discusses consequences responses imagine algorithm sorts individual subjects categories subjects care assigned category incentive optimize present changing inputs achieve better output decision invest presentation depends three factors presentation cost subject must able afford change presentation sensitivity changing input feature worthwhile affects output impact changing output worthwhile significant consequences algorithms high impact high sensitivity low presentation costs give subjects strong incentives change presentation following terminology economics loosely say algorithms high elasticity data dis tributions elastic algorithms operate deployed differ trained data distributions change accuracy lost elastic algorithms may also fragile figure algorithm subject input output consequences sensitivity presentation impact figure schematic algorithm takes input subjects sorts output categories turn consequences subject kieran healy “by numbers—wendy espeland michael sauder engines anxiety academic rankings reputation accountability new york russell sage ” european journal sociologyarchives européennes de sociologie december –httpsdoiorg101017 s0003975617000315 tom slee reasons believe machinelearning systems specifical deep learning systems may particularly elastic fragile mapping factors previously discussed first low cost experimentation around presentation deeplearning techniques called “generative adversarial networks gans”have become excellent generating images videos texts look created humans depict “real world” artifacts uses grouped together name “deep fakes”there growing evidence remarkable accuracy deeplearning models may accompanied high sensitivity phenomenon called “adversarial examples” discovered certain image perturbations undetectable human eye nevertheless caused deeplearning algorithms make obvious mistakes classifying image examples curiosities28 studied general phe nomenon appears be29 fragility could general feature deeplearning models30 typical optimize millions parameters parameters bigger many machinelearning systems high impacts deployed scale may want invest optimizing linkedin profile seeking work employers look little alternative put best foot forward scale also creates opportunities costlowering intermediaries assist optimization searchengine optimization reputation management comes tax accountancy scale makes algorithmic flaws matter one human deep learning drives next generation decision support systems rec ommender systems elasticity fragility may become increasingly important ian goodfellow et al “generative adversarial nets” advances neural information processing systems ed z ghahramani et al –httppapersnipsccpaper5423generative adversarialnetspdf robert chesney danielle keats citron deep fakes looming chal enge privacy democracy national security ssrn scholarly paper rochester ny social science research network july httpspapersssrncomabstract3213954 ian j goodfellow jonathon shlens christian szegedy “explaining harnessing adversarial examples” arxiv14126572 cs stat december httparxivorgabs14126572 christian szegedy et al “intriguing properties neural networks” arxiv13126199 cs december httparxivorgabs13126199 nicholas carlini david wagner “audio adversarial examples targeted attacks speech totext” arxiv180101944 cs january httparxivorgabs180101944 adi shamir et al “a simple explanation existence adversarial examples small hamming distance” arxiv190110861 cs stat january httparxivorgabs190110861 alexandru constantin serban erik pol “adversarial examples—a complete characterisation phenomenon” arxiv181001185 cs october httparxivorgabs181001185 ali shafahi et al “are adversarial examples inevitable” september httpsopenreviewnetforumid generalization” arxiv181200740 cs stat december httparxivorgabs181200740 dimitristsipras et al “robustness may odds accuracy” may httpsarxivorg abs180512152v3 incompatible incentives privatesector ai x sign ∇ × jθ x x ϵsign ∇ × jθ x macaw bookcase figure slight perturbation picture macaw causes classified bookcase source b liu et al “using adversarial noises protect privacy deep learning era” ieee global communications conference globecom –httpsdoiorg101109glocom20188647189 make matters serious weaknesses show proofs concept early stage deployments output little impact subjects algorithms operating scale incentive invest becomes large making system fragile incentives drive responses figure classifies responses algorithms algorithms require valid input give correct output algorithms also intent affected positively neg atively actions subjects general output proxy less well defined intent31 input arrow may paired output arrow giving four classes responses algorithm designers may prefer permit valid inputs sustain intent system four combinations ethical justifications valid inputs understood thinking simple rulebased system hiring filter sorts applicants based solely educational achievements input subject’s educational achievements genuine achievements valid fake achievements intent system give hiring manager good set interviewees happy applicants system’s intent satisfied cases economists describe separating equilibria signaling screening games32 valid inputs sustain intent algorithm applicant pool consists two qualities employment perspective high low getting degree easier highquality people lowquality people highquality people find worth investing degree beauty arrangement o’neil weapons math destruction michael spence “job market signaling” quarterly journal economics –joseph e stiglitz whither socialism wicksell lectures cambridge london mit press tom slee algorithm valid sustains intent input output erodes intent invalid figure responses algorithms include combinations valid invalid input may sustain erode intent algorithm incentives algorithm continues satisfy intent without additional governance equal costly lowquality applicants obtain degree highquality applicants degree ceases useful signal applicants may continue invest degrees algorithm longer separate wheat chaff gametheoretic case “pooling equilibrium” valid responses erode intent algorithm know verb describing valid responses pooling equilibria declines follow letter law teach test games system problems pooling equilibria elevated status law ure” might add corol ary becomes important “when measure target ceases optimized” ethics optimizing responses using valid input simple one reason google keeps search algorithms secret prevent gaming searchengine optimiza tion industry33 comes tax system attitude different secret tax system would unacceptable course accused dodging taxes moving billion bermuda google responded simply “we pay taxes due comply tax laws every country operate around world”workarounds class invalid inputs nevertheless sustain intent system legal scholar jennifer raso investigated operation ontario works welfareeligibility decision system35 found case workers became experts working system occasion entering false data coax results line professional judgment whether dealing bugs program inapplicable field applicants would also required field system weak nesses model case workers break letter law follow spirit similar jonathan rosenberg “the meaning open” december httpgoogleblogblogspot ca200912meaningofopenhtml reuters “google shifted 23bn tax bermuda filing shows” guardian january httpswwwtheguardiancomtechnology2019jan03googletaxhaven bermudanetherlands jennifer raso “displacement regulation new regulatory technologies frontline decisionmaking ontario works” canadian journal law societyla revue canadienne droit et société april –httpsdoiorg101017cls20176 incompatible incentives privatesector ai behavior seen among us doctors seeking provide patients good outcomes insurance systems36 statistical algorithm error cases many systems cannot function without workarounds manages agents “work rule” actions industrial settings common follow letter law strictly nothing gets done unappreciated role workarounds one reason james c scott argues “certain schemes improve human condition failed”scott arguing topdown “highmodernist” schemes algorithmic platforms certainly fall category final case invalid input also erodes algorithm’s intent often described security terms attacks algorithm increasing number algo rithms “opting out” option including ratings platforms botto bistro san francisco restaurant unhappy saw unethical treat ment yelp also refused restaurant’s request removed platform response botto bistro encouraged customers enter overthetop onestar reviews seeking achieve lowest rating yelp campaign called attention dubious practices contradictions yelp’s operations perhaps case prin cipled protest subversive humor sabotaging one system pursuit higher goal38 sophisticated complex algorithm lines four categories blur algorithms move beyond simple inputs birthdates educational qualifications criteria distinguishing valid invalid input become uncertain reputation systems yelp ebay uber replace “true false” criteria nebulous notions “authenticity” “honesty” defend appeals correctness free speech39 say “fourstar” rating real means40 output side unambiguous “ground truth” output often unavailable outside labeled training sets laboratory distinction fades attack workaround even adversarial examples seem obvious resisted definition one technical attempt say input “that attacker intentional designed cause model make mistake”but individual matthew k wynia et al “physician manipulation reimbursement rules patients rock hard place” jama april –httpsdoiorg101001jama james c scott seeing like state certain schemes improve human condition failed new yale university press tom slee “in praise fake reviews” new inquiry october httpsthenewinquiry cominpraiseoffakereviews james grimmelmann “three theories copyright ratings” vanderbilt journal entertainment technology law –abbey stemler “feedback loop failure implications selfregulation sharing economy” ssrn scholarly paper rochester ny social science research network april httpspapersssrncomabstract2754768 justin gilmer et al “motivating rules game adversarial example research” arxiv180706732 cs stat july httparxivorgabs180706732 tom slee realworld case identifying “intent” “mistake” may impossible classification “attacker” fails responses demand guardrails general algorithms classify people “incentiveincompatible” subjects fol low incentives algorithm ceases function designed sustain accuracy algorithms need external rules limit permissible responses rules form set guardrails implement value judgments keeping algorithms function ing constraining actions subjects42 designers postpone thinking guardrails may needed low elasticity environments proofs concept earlystage deployments stil successful deployments scale require guardrails even problems bias fairness could solved grail algorithmic governance—of impartial automatic algorithmic datadriven evidencebased decisionmaking—would fall hurdle algorithms guardrails form inseparable pair code law existence scalable algorithm imply existence equal scalable guardrails guardrails must deal specific contexts factors outside original model grow number algorithms draw everincreasing volume variety data pursuit accuracy attempts implement automated modera tion repeatedly failed companies resorted instead astra taylor cal “fauxtomation” behind scenes real people work simulate effects algorithm technology task43 work content moderators described recently sarah roberts44 tarleton gillespie45 algorithms without guardrails may become ungovernable social media recom mender algorithms example three qualities needed high elasticity experimentation affordable content producers discover kind content recommendation algorithm sensitive get fast feedback metaphor adopts designer’s point view subject’s point view “straitjacket” may appropriate astra taylor “the automation charade” logic magazine october httpslogicmag io05theautomationcharade sarah roberts “commercial content moderation digital laborers’ dirty work” intersectional internet race sex class culture online ed safiya umoja noble brendesha tynes digital formations series new york peter lang httpsintersectionalinternetcomabout sarah roberts behind screen content moderation shadows social media new yale university press httpsyalebooksyaleedubook9780300235883behindscreen tarleton gillespie custodians internet platforms content moderation hidden decisions shape social media new yale university press httpsyalebooksyale edubook9780300173130custodiansinternet incompatible incentives privatesector ai form view counts impact recommendation system high high elasticity means strong incentives optimize individual outcomes youtube recommendation algorithm46 suffers ungovernability widely read article james bridle provided tour long tail bizarre content appear ing youtube kids producers experiment gain views47 one example would rely keywordhashtag association generating new content trend surprise egg videos reaches critical mass content producers pile onto creating thousands thousands videos every possible iteration branded content nursery rhyme titles “surprise egg” stuffed word salad capture search results sidebar placement “up next” autoplay rankings striking example weirdness finger family videos idea came origin children’s rhyme core trope least million versions currently youtube cover every possible genre billions billions aggregated views ironical bridle’s essay going viral made youtube act invoking community guidelines response seems like ethical platform making best efforts implement guardrails eject malicious actors story simple one channel removed violating “family friendly” rule johnny tanner48 tanner said could discover prompted punishment person talk defense channel said “the algorithm thing relationship since beginning that’s got us popular learned fuel whatever took please algorithm” article quotes davey orgil left job make superhero parody vid eos whose channel reached two million viewers shut argued “the platform responsible encouraging objectionable sexual violent superhero content ostensibly oriented toward children youtube blames people year algorithm pushed content people creating millions millions millions views created monster” left hand recommendation algorithms promotes videos right hand community guidelines would later forbid paul covington jay adams emre sargin “deep neural networks youtube recommendations” proceedings 10th acm conference recommender systems recsys‘james bridle “something wrong internet” james bridle blog november httpsmediumcomjamesbridlesomethingiswrongontheinternetc39c471271d2 charlie warzel “youtube addressing massive child exploitation problem” buzzfeed news november httpswwwbuzzfeednewscomarticlecharliewarzelyoutubeisaddressingits massivechildexploitationproblem davey alba “youtube massive child exploitation problem humans train search ai partly why” buzzfeed news december httpswww buzzfeednewscomarticledaveyalbayoutubesearchrateralgorithmschildrendisturbingvideos tom slee bridle ends essay way “the architecture built extract maximum revenue online video hacked persons unknown abuse children perhaps even deliberately massive scale” disturbing videos algorithm facebook’s news feed algorithm also suffers high elasticity problems also framed defense malicious actors former facebook executive antonio garcia martinez complained twitter “the fb facebook critics call company take responsibility moderating content course shocked shocked human cost reviewing billions pieces random content”but requirement guardrails inherent news feed model facebook simply crossed fingers hoped governance required intent news feed changed time remains operational vague mark zuckerberg announced january “im changing goal give product teams focusing helping find relevant content helping meaningful social interactions”facebook designed news feed system large rewards high circulation thus encouraging participants invest heavily optimizing outcomes attempting move resulting clickbait head lines facebook doubled building inhouse algorithmic fauxtomatic solutions facebook’s entire project comes news rests assumption people’s individual preferences ultimately coincide public good doesn’t appear way first you’re delving deeply enough data51 assumption fails elastic system based “the data” causes foundations built shift incentiveincompatible news feed algorithm demands guardrails police content generates facebook want job managing news content could hand news industry emily bell columbia journalism school explains point real want address say “this good information” “this bad information” say “these kinds information sources want privilege others going banned platform going thrive” words tweet since deleted mark zuckerberg “one big focus areas ” social media mark zuckerberg’s facebook posts blog january httpswwwfacebookcomzuckposts10104413015393571 farhad manjoo “can facebook fix worst bug” new york times april sec magazine httpswwwnytimescom20170425magazinecanfacebookfixitsownworstbughtml incompatible incentives privatesector ai create hierarchy they’re going decide they’re going transfer wealth publishing market52 facebook want job least money comes financial incentives demand facebook keeps responsibility news feed content insisting accountability outcome beyond making best efforts social media algorithms may particularly prone driving “gaming” behavior others immune allegheny family screening tool afst decision support system used pre dict child abuse child neglect time birth alert child services children may risk attentions child services large effect lives families whose risk score high contact social services one factor may lead high predictive score families feel must engage selfharming behavior withdrawing “networks provide services support community” optimize score thus afst might “create abuse seeks prevent”facial recognition long prompted civil liberties concerns54 guardrails one concerns covering one’s face acceptable behavior around facial recognition software public spaces trial deployment london police fined man covered face objected subsequent police questioning55 general data sources used insurance companies potential employers others expand potential unusual unorthodox behavior patterns trigger inferences example based outlier detection algorithms expands tandem without protection inferences unusual becomes suspicious56 guardrail question— altered public norms worse autonomous vehicles need new guardrails manage pedestrian behavior current levels deployment pedestrians behave much around cars drivers selfdriving becomes commonplace may optimize experi ence stepping ahead autonomous cars full confidence car stop pedestrian assertion become norm “autonomous vehicle adoption may manjoo “can facebook fix worst bug” virginia eubanks automating inequality hightech tools profile police punish poor lucas introna david wood “picturing algorithmic surveil ance politics facial recognition systems” surveil ance society nos –httpsdoiorg10111177338r eprep1typepdf lizzie dearden “man fined £after covering face facial recognition trial london” independent january httpswwwindependentcouknewsukcrimefacialrecognition camerastechnologylondontrialmetpolicefacecovermanfineda8756936html sandrawachter brent mittelstadt “a right reasonable inferences rethinking data protection law age big data ai” ssrn scholarly paper rochester ny social science research network september httpspapersssrncomabstract3248829 tom slee hampered strategic disadvantage slows urban traffic”perhaps says driveai board member andrew ng “we partner govern ment ask people lawful considerate safety isn’t quality ai technology”we expect selfdriving car industry seek new guardrails protect algorithms yet discussion guardrails largely missing conversations ethics autonomous vehicles short guardrails limit autonomy algorithmic subjects algorithmic gov ern ance may encourage platforms innovate ab testing subjects subjects constrained may punished twice algorithm unorthodox behavior properly model second time fall afoul guardrails trying avoid first guardrails create temptation algorithmguardrail pairing creates temptations platform owners indulge arbitrage exploiting presentation gaps circumvent regulation avoid brand damage algorithms encourage behavior guardrails forbid platform companies may choose whether present algorithm values imposed guardrails ethics cal consistent presenta tion companies financial incentive keep gap wide many activities seen light one response frame problems terms software development lifecycle problems bugs software industry knows deal bugs reported fixed fixes rolled customers statement faith bugs temporary software improves iterative refinement algo rithmic failings bugs external authorities neither jurisdiction expertise fix seen guardrail failures features bugs created incentives built algorithm book uberland alex rosenblat talks uber drivers seeing “phantom requests” appear briefly driver app vanish respond59 phantom requests damage drivers’ prospects earning bonuses depend maintaining high acceptance rate uber’s response driver complaints blame network problems promise fix without effective persontoperson driver support uber denies drivers option workaround language practices software development help company avoid would companies breach contract drivers adam mil ardbal “pedestrians autonomous vehicles cities” journal planning education research httpsjournalssagepubcomdoiabs1011770739456x16675674 russell brandom “selfdriving cars headed toward ai roadblock” verge july httpswwwthevergecom20187317530232selfdrivingaiwinterfullautonomywaymoteslauber alex rosenblat uberland algorithms rewriting rules work berkeley university california press httpswwwucpressedubook9780520298576uberland incompatible incentives privatesector ai second response invoke valuebased guardrails adhoc manner algorithmic governance leads behavior part subjects may damage brand tempting let go prospect becomes dangerous youtube’s actions around youtube kids channel fall pattern airbnb algorithmical governed platform stated intent building com munity regular people live home occasional share strang ers guardrails keep behavior within mandate runs risk affecting airbnb’s earnings nothing airbnb’s systems stop hosts creating multiple listings setting organizations different “hosts” fronts60 renting listings nights year gap algorithmic practices stated aims became large new york city bringing threat restrictions airbnb’s market company invoked guardrails expel thousand hosts platform61 claiming providing experience community expected62 code overruled brand third temptation use platform’s information resources hide muddy waters regarding algorithmic failures ryan calo alex rosenblat detailed many ways uber used information shape behavior driv ers63 selective judicious release data exclusive basis col aboration academics industry experts may also serve shape overall perception company whether individual papers written independently final companies become embedded infrastructure lives leverage comes presentation gap uber seeks become privately owned part city transit infrastructure uses data accumulated resource licensed back cities operate integrated cities cannot easily walk away platform problems platform become public concerns regard ing malicious actors cities’ leverage regarding governance uber platform lost smart city initiatives toronto project led google subsidiary sidewalk implicitly adopt approach64 temptation needs policing powerful algorithms become clear market forces alone cannot solve problems arising incompatible incentives luis ferrésadurní “inside rise fall multimilliondol ar airbnb scheme” new york times february sec new york httpswwwnytimescom20190223nyregionairbnbnyc lawhtml murray cox tom slee “how airbnb hid facts new york city” february httptomsleenethowairbnbhidthefactsinnyc kristen v brown “airbnb admits purged unflattering new york listings right data release” splinter accessed march httpssplinternewscom airbnbadmitsthatitpurged1500unflatteringnewyor1793854942 ryan calo alex rosenblat “the taking economy uber information power” columbia law review march httpspapersssrncomabstract2929643 see chapter ellen goodman book tom slee platform companies sustain gap algorithms guardrails part section cda absolves much responsibility conse quences governance failures united states least chesney citron’s recent paper deep fakes65 identifies platform companies “least cost avoider” actor best position fix problems incompatible incen tives previous section claimed platforms currently incentive take ownership problem fix taking ownership currently way ward regulation revisiting section equivalents jurisdictions opposite one society’s serious classification problems “innocent guilty” worth remembering datadriven statistical methods permitted venue evidence instead strictly limited scope one reason people punished factors may correlate criminality lie outside control another would demand people especial members less privileged groups invest optimizing risk scores fear contact crim inal system “evidencebased” statistical decisionmaking become increasingly used areas justice system parole even sentencing use raises problems trend remains toward datadriven decisions voices raised use actuarial risk assessment justice system restricting data use goes grain current drive datadriven society impact algorithmic decisions grows ideas venue decisions matter may become prominent years come competition rules provide another avenue resolving incentive problems algorithmic ranking systems become powerful institutions part infrastructure society advantages accrue company owns infrastructure also competing market services exploit infrastructure66 industries essential infrastructure heavily regulated controlled services built infrastructure opened innovation airport infra structure separated operation airlines core banking functions strictly regulated—perhaps strictly would like—while many countries exper imenting open banking laws permit innovation top infrastructure outside realm regulation look alternative models wikipedia nonprofit top ranks websites significantly less affected problems incompatible incentives many present author included thought wikipedia would unable maintain quality nearly two decades proven skeptics wrong perhaps anonymous nature contributions removes many distorting incentives associated selfpromotion perhaps it’s wikipedia largely free “viral” phenomena something working wikipedia working youtube facebook amazon chesney citron “deep fakes” lina khan “amazon’s antitrust paradox” yale law journal –the incompatible incentives privatesector ai conclusion deeplearning algorithms may accurate previous gen erations machine learning robust may faint techni cal path forward problems bias unfairness algorithms engines cameras pervasive incompatible incentives remain algorithms require guard rails technology companies illsuited illpositioned design implement valuebased rules guardrails become constraints people’s behavior yet cases high elasticity effective governance may still elusive pairing algo rithms guardrails tempts companies engage regulatory arbitrage providing requirement external action acknowledgments would like thank editors invitation guidance contributors took part toronto workshop inspiration expertise acknowledge helpful conversations john slee lynne supeene bibliography note reference list contains essential texts concerning mechanisms consequences sorting bowker geoffrey c susan leigh star sorting things classification consequences cambridge mit press espeland wendy nelson michael sauder engines anxiety academic rankings reputation accountability new york russell sage foundation harcourt bernard e prediction chicago university chicago press jacobs jane death life great american cities new york random house mackenzie donald engine camera financial models shape markets cambridge mit press schelling thomas c micromotives macrobehavior new york w w norton scott james c seeing like state certain schemes improve human condition failed new yale university press chapter normative modes codes standards paula boddington introduction development artificial intelligence ai gone several peaks troughs last years ai experiencing growth phase much excitement generated current future possibilities accompa nied matching concern ethical safety issues ai might bring concern focused upon possible future development extremely powerful even superintelligent ai see possibilities wonderful next step human development others express fears might lead unintended possi bly disastrous consequences humanity additional immediate fears ai currently near future may also pose ethi cal dangers many ethical concerns include worries ways ais may use personal data may manipulate information may magnify existing biases may cause large disruptive shifts employment patterns many concerns raise question machine agency work alongside human agency agency autonomy enhanced threatened uses put ai many issues futuristic possibilities happening one response concerns rush produce codes ethics ai well detailed technical standards aspects ai ethics safety produced various bodies range general inclusive pronouncements giving ideals developing beneficial ai worldwide specific engineering standards use localized professional bodies many codes standards drawn chapter cannot attempt provide inclusive overview describe main features typical codes standards consider possible advantages pitfal discuss paula boddington needed codes standards effective positive influence development codes standards general stems best inten tions one could well suspect excitement ai amounts hype accompanied certain hype ethical issues deny indeed serious ethical questions need con sider rhetoric around ai might skew understanding ethical issues characterize address much rhetoric suggests ai presenting us new uniquely acute dangerous ethical challenges—see frequently news articles even banal ai accompanied pictures killer robots hence attempting avoid exaggerated claims ethical dangers ai need look closely particular ethical challenges ai order assess best ways developing codes standards hype may also reach faith powers codes standards need discuss role codes standards might limitations especial given particular features development ai note codes standards twin aims firstly set standards behavior outcome secondly help produce conditions achieve need explore aspects codes standards ai essen tial consider historical evolution codes societal institutional background never enough consider codes standards ai raises broad deep questions value human nature rela tions natural world proper reach agency argued codes something offer relying much power codes ethics area may fact act mask major value issues real need address considering ethical human issues ai specific concrete standards may extremely useful general codes ethics ai best seen starting points discussion debate varieties codes standards ai ethics codes ethics standards ai vary quite considerably avoid false univer salism sometimes detectable debates important bear mind codes standards different purposes good reasons codes standards differ precisely ai defined varies among experts overlaps ethical issues concerning computing technology algorithms machine learning may included considerations many codes standards along sophisticated ai surge development ai recent years largely driven normative modes codes standards access use vast amounts data hence discussions ethics specifical include data use vexed issue algorithmic bias may referred ada algorithms data ai1 ai covers wide range technologies applications codes standards may attempt address ai whole whereas others focus particular aspects ai codes ethics ai plainly aspirational one might say even utopian example calling ai developed ways beneficial whole humanity end spectrum specific concrete tech nical specifications fine level resolution emphasis producing standard clearly unambiguously implemented practice hence tech nical specifications ai may implicitly explicitly embody attempt realize mative values clear dividing line technical “purely” normative cannot drawn area intended remit codes also varies codes ethics including general cal develop codes may aspire universal global application often arises recognition ai may cross national cultural borders additional attempts counter possible cultural geographical bias ai may aspire produce global applicable sets values others may specific particular local contexts instance codes explicitly espouse values specific company2 natural follow certain tensions one hand aspiration global general applicable universal ethical standards ai hand seen counter wish avoid imposing localized cul tural ethical views others addition recognition given rapid technological developments ai codes standards must flexible adapt able take significant developments account range normative considerations many codes standards developed specifical refer ethical standards precise normative values also addressed codes addressing data privacy codes concern issues may thought political issues wealth distribution included broad remit “value” questions hence economic issues may also seen encompassing ethical questions standards safety concern potential deleterious effects ai hence ipso facto addressing ethical issues notable differences ways codes standards ai drawn areas professional ethics clearly defined relevant bodies responsible drawing codes professional conduct often relevant legislation helps shape codes standards medicine engineering ai similar examples example global initiative ethics autonomous intelligent systems institute electrical electronics j whittlestone r nyrup alexandrova k dihal cave ethical societal implications algorithms data artificial intel igence roadmap research nuffield foundation example see ethics policy iiim icelandic institute intelligent machines http wwwiiimisethicspolicy paula boddington engineers ieee standards association largest professional body kind world3 however ai varied field unlike areas professional activity may essential accreditation develop ing using ai except perhaps certain fields groups powerful interested parties working toward developing “best practice” ai partnership ai including various organizations facebook google ibm unicef microsoft intel date eighty others4 different exam ple recognized professional body medicine operating welldefined ethical regulations developed decades umbrel national international law powers sanction discipline noteworthy many proposed codes ethics ai date drawn selfselecting groups selfdesignated experts closed groups invited members example asilomar ai principles drawn future life institute group invited participants5 codes standards drawn lobby groups activists campaign stop killer robots proposed number recommendations regarding use autonomous weapons6 given wide interest concern ethical economic safety issues ai many governments regulatory bodies also working ethical issues includes drawing broad ethical value principles even date may fall short polished codes ethics ethical standards example report uk house lords select committee ai european union japanese advisory board artificial intelligence human society7 clear different considerations apply assessment diverse norma tive standards advantages codes standards may seem obvious ethical codes standards welcomed particular produce codes standards ai ieee global initiative ethics autonomous intelligent systems ethical aligned design vision prioritizing human wellbeing autonomous intel igent systems first edition ieee httpsstandardsieeeorgcontentieeestandardsenindustryconnectionsec autonomoussystemshtml partnership ai httpswwwpartnershiponaiorg ai principles future life institute httpsfutureoflifeorgaiprinciples campaign stop killer robots httpswwwstopkillerrobotsorg see eg house lords select committee artificial intelligence report first session –ai uk ready willing able london n nevejans “european civil law rules robotics” european union advisory board artificial intelligence human society report artificial intelligence human society unofficial translation ministry state science technology policy normative modes codes standards one answer ai currently developing rapidly potential powerful resultant ability harm useful indeed necessary try shape future development future uses within framework values pre cisely potential applications ai broad may thought valuable lay general principles practical impact essential produce technical specifications methods practical realization values one major reasons concerned ethical questions ai pre cisely question whether ai might surpass human control human comprehen sion hence without adoption practical technical means maintaining control understanding ai high minded ethical pronouncements otiose addition broad controversial field ai development codes standards even broad indicators ethical frameworks serve useful role forming point discussion however happen effectively public wider debate education essential dangers codes standards watch unfortunately many potential downsides codes standards follow advantages outlined earlier broad principles outlined broad veer toward meaningless example many cal ai “benefit human ity” discussed later problems codes standards include encouragement “tick box” mentality happens ethics provision seen series hurdles get around mere formalism takes genuine appreciation point rules values likewise producing formal “code ethics” may create cul ture “ethics” left “experts” seen additional “extra” something get done little import daytoday work many exam ples codes ethics simply ignored many examples organizations effect two codes ethics code that’s formal written forms “official” policy actual practice organization may deviate considerable degree formal statements sometimes indeed codes ethics operate ways completely odds intended effects8 also danger especial image conscious corporate world production codes ethics exercise public relations demonstrate virtue use personal data use algorithms managing material online plat forms pronouncements corporations involved concerned balfour g adams ae nickels unmasking administrative evil routledge paula boddington ethics may rightly met cynicism cynicism may also underlined corporations lack transparency precisely formulating ethical codes conduct external sanctions measurable outcomes codes standards claim espouse alongside developments codes stan dards various bodies larger questions need addressed organizations using ai controlled regulated subject oversight laws regulation questions currently among pressing field ai particular reason require codes ethics respond develop ments technologies application gather respond developing ethical responses ai codes standards therefore need responsive time avoiding danger may simply change wind difficult line tread using codes standards way molding devel opment technology formulating codes standards ways simply follow technology forms way warming public consider certain prac tices acceptable danger amplified codes simply drawn scarcely accountable selfselecting groups skepticism may heightened drawing codes leading ethics discussion vested interest advancement technology course case ai developers many already extremely powerful wealthy leads development codes standards seen codes standards ai may drawn different organiza tions also noted question capacity codes standards positively effect outcomes hence one major questions codes ethics normative standards ai concerns authority remit it’s vital consider sociological cultural setting codes standards corporate financial climate ai developed must taken account especial given enormous power big players already economical capacity gather data control access online information codes standards develop likely exhibit values assumptions time place culture influence noted relation ai point predominance particular geo graphical regions cultural social groups ai put bluntly would trust group tech billionaires silicon valley narrow range skil personality types know best human race whole one also observe many social values rapid flux wonder it’s likely miraculously last lucky enough living period final millennia collectively stumbled upon moral truth wiser ancestors particular preoccupations obsessions arisen local historical reasons note trope “moral progress” may fit hand glove trope technological progress often accompanies enthusi asm ai hence must try keep long view broad view wary ways code ethics ai may ossify values short cultural geo graphical distinct time period normative modes codes standards noted earlier codes ethics ai may contain broad unhelp ful vague statements value conversely must consider possibility may overformalize overspecify values could especial danger area ai many working computing comfortable working formal written codes performing precise verifiable operations real case everything value articulated us complete precision may inadvertently make ethical issues seem manage able actual given multiple values always articulate ways give clear answers every case sometimes faced irre solvable moral dilemmas hence danger codes particular standards minutely specified may erroneously think completely covered ethical value issues profound substantive philosophical questions ongoing debate key value concepts used ai codes standards challenges ai section consider broad content codes ethics ai many recurring themes values basis discussion best develop use codes standards include notions privacy autonomy trans parency intelligibility accountability benefit safety bias although course issues covered chapter major question develop codes stan dards best capture particular issues presented us ai allows open responsive approach developing ethical use technology experience shown us problems created trying model codes eth ics one area codes developed areas particular issue social science research often modeled medical research inap propriate assumptions methodology nature extent possible harms benefits9 let us take example typical content codes ethics ai statement report ai uk ready wil ing able house lords select committee artificial intelligence giving five “overarching principles ai code” used starting point discussion precisely gives general overarch ing points typical example kinds issues raised covered codes standards area p atkinson “ethics ethnography” twentyfirst century society –paula boddington common good benefit humanity typical statement expressing general aim reminiscent kind call good humanity fitting heard miss universe contest meriting serious place code conduct designed practical impact notion “common good” sounds great masks multitude disagreements it’s even clear ai general must “common good” permissible technologies ventures—such designer goods—to unevenly distributed might codes ethics ai prone anodyne statements perhaps recognition potential disruption unfettered use ai could bring potential deepening divisions society money power less issues involve large political ques tions solving lies outside power individuals even individual corpora tions even powerful ones requires political discussion notion ai must “benefit” humanity seems least contro versial tends receive universal acceptance actual problem atic requires unpacking course want ai benefit highly disruptive technologies ai real important question even identify “benefit” humanity might world morphs influence tech benefits trying assess especial pertinent case ai given ease could potential manipulate desires— indeed something might happen something happening given one major current uses ai lofty endeavor humanity tar geted advertising works precisely manipulating desires ways ai manipulate information get presented gives another reason concerns “benefit” ai identified humans also get used change quickly forget fast things used technology rapidly change world poses profound problem assessing benefit large part comparison alternatives statement course intended “overarching principle” ful fledged code needs accompanied discussion address ques tions space address ful suggestions made ways measuring “benefit” must comprehensive although must made con crete specific particular contexts order test implement meaningful comes “benefit” must involve merely economic benefit must address ways ai may manipulate thoughts desires motivations also essential consider alternatives would desirable try avoid developing ai ways mean quickly become dependent technology costs backtracking may nudge us otherwise unfavorable pathway one con siders rise internet dependency smart phones see around us perhaps already forlorn hope normative modes codes standards note codes standards ethical theory thus observed deep controversial philosophical questions need addressed drawing codes standards ethics chapter argues ai raises profound questions human nature relations world technology especial replete deeply controversial philosophical questions time must watch danger assumptions ethical theory might foreclose important debates example many working applied ethics impressed broadly consequen tialist approaches ethics consider ethical judgments contained consideration overall harms benefits course action approach also sits readily many approaches programming could well appeal working computing ai shall see many codes ethics ai include statements effect ai used benefit humanity ai never harm humans especial given uncertainties ai might develop consequentialist approach could seen flexible basis code ethics ai may appear work well consequentialism works poorly questions agency present us ethical questions raised profoundly ai consequentialism described “agent neutral” briefly matters brings result long benefit possible produced10 one profound questions ai ethics use machine agency augment replace human agency hence vital look simply content codes standards assumptions regarding normative ethical frameworks codes standards implicitly explicitly rest much else could said matter space prohibits discussion principles intelligibility fairness second overarching principle contains odd coupling intelligibility fair ness two seemingly disparate values discussed separately intelligibility cognates virtual always features codes standards ai term often used “transparency” indeed one prominent ethical issues ai understand significance need think ethics concerning relationships people answerable element accountability others forms requirement intelligibility transparency ai presents distinctive difficulties see eg scheffler scheffler rejection consequentialism oxford university press paula boddington requirement intelligibility pertains ways ai replaces sup plements human thought decisionmaking reason require explanations outcomes affecting us concerned hence use area notion “explainability”where ai making assisting decision affects us wish robbed right explanation decision made however ai may operate ways lack transparency hence could potential seriously interfere fundamental fea ture moral life represents distinctive ethical problem ai thus essential issues addressed codes ethics standards ai thus debate technical question whether surmountable issue forms ai well debates precise degree intelligibility transparency different audiences also significant differences differ ent areas depending upon much explanation owed individuals context must also leave open possibility forms ai maybe cannot reach appropriate level intelligibility transparency fulfill ethical norms12 debates essential essential developing standards acceptable levels intelligibility transparency explainability context also note tendency idealization agency human machine discussions ai although serious issues expla nation intelligibility ai especial certain contexts serious impacts individuals may follow must remember humans may also fall short providing adequate explanations decisions human may ful aware factors led final answer likewise ai may issues around data used support decision may contain various biases well question precisely decision reached also possibil ity precise reasons decision fact laid public scrutiny hence although ai could bring serious issues also potential greater transparency public scrutiny areas currently one area intelligibility explainability accountability transparency particular issue law hence codes ethics ai may single judicial decision making ais comment example asilomar principles ai state “judicial transparency involvement autonomous system judicial decision making provide satisfactory explanation auditable competent human authority” intention laudable interesting example somewhat common developed statute well principles common law exists hence standards accountability judicial decisions already exist within legal system may instances already rule decisionmaking ai conversely gunning “explainable artificial intelligence xai” defense advanced research projects agency darpa httpswwwdarpamilattachmentsxaiprogramupdatepdf see eg adrian weller “challenges transparency” arxiv preprint arxiv170801870 normative modes codes standards mandate form surely proper positions relation judiciary determine develop principles proper use ai course may require detailed discussions ai specialists useful principle ai ethics might require working developing ai warn provide full disclosure judicial systems enable ai serve appropriately place al efit” likewise involves deeply political issues multiple ways standing “fair” context ai data use specific notion algorithmic bias attracted much work concerns data manipulation may lead exaggerate existing bias use biased data sets andor biased methodologies another issue nested legal context since many jurisdictions certain biases certain protected characteristics prohibited although course wish avoid bias brings deeper questions understood treating people unfairly relation particular characteristic words membership class characteristic understand bias way dividing classifying world il ustration see current debates gender relation sex plays relation legal protected characteristics unless sure “carved nature joints” ultimate take analyze society need drill metaphysical ontological questions address ethical issue data rights privacy individuals families communities another example codes ethics ai raise concerns nested within wider law regulation data privacy rights determined different jurisdictions hence it’s relevant legal governmental authorities regulate code standard must refer relevant laws it’s noteworthy vary place place data regulations within europe instance differ significantly data regulations within united states13 course also note laws may need adjusted particular issues ai raises codes ethics may require adjustment indeed existence different legal regimes worldwide could extremely useful try develop ethical legal responses ai plurality enables us compare contrast across different jurisdictions hence also food thought overhasty rush universal code ethics ai dl baumer et al “internet privacy law comparison united states european union” computers security –paula boddington cal common developing using ai needs emphasized capacity ai draw upon data powerful ways may require careful monitoring assessment response col aboration commu nication technical experts ai data analysis regulators privacy experts key developing ethical frameworks ai well note use personal data becom ing ubiquitous leave trails potential extremely revealing information wher ever go whatever turn affecting attitudes toward privacy even toward selfimages identity14 making call protect data pri vacy course correct cal need reveal precisely detail various forms ai presenting us challenges area mold ing possibly changing think particular values certain situation straightforward taking preformed clearly articulated agreed values making sure ai developed ways fit also note complexity conceptual depth underlying value issues example many commenting topic assume individuals “own” data note discuss property rights immediately engage highly contested political debates moreover careful thought needs given notion property rights traditional applying physical defined limited mate rial objects apply data moreover may far clear certain data family members population groups information inaccessible individual discovered using great skill technique others need consider deep metaphysical questions criteria individuation people note deep underlying ethical political even metaphysical questions go flourish mentally emotionally economically alongside artificial intelligence call way trying ensure “benefit humanity” ai comes without education many people shut many potential benefits ai indeed education ai needed order people meaningful say whether particular forms ai ethical acceptable individuals society whole always devil detail much depends upon roles ai takes lives economy education simply focused education ai per se strategies consider precise role ai flourishing human life example project ai takes significant roles economy provide wealth opportunity h nissenbaum “privacy contextual integrity” washington law review normative modes codes standards jobs caring professions human contact well handicrafts personal tailored goods means “ai education” could include handicrafts social skil different arguably much human world vision oft presented dystopian nightmares ai developed handful powercrazed tech billionaire “overlords” taken jobs away millions people spend days “entertained” ai living stateprovided benefits ai potential change world radical would human beings “flourish” unpredictably changed future “flourish” perhaps richer way referring “benefit” encourages us think nature human doubtless many different ways humans flourish could move toward future many humans “flourish” fore closed possibility forms flourishing life issues directly addressed codes standards ethics ai yet address requires far simple production code set standards human beings never vested artificial intelligence questions autonomy ai human control ai pose distinctive pressing ethical issues also present difficulties development codes standards statements professional ethics medicine engineering tacit assumption professionals power control products services indeed requiring competence usual key requirement complexities related unexpected circumstances ascer taining clear lines responsibility mandating insurance mishap disaster usual key ai however retaining control understanding becomes com plex cases potential impossible part standards ai attempt set achieve control technological needed addition broad ethical statements desirability control routinely made statement house lords select committee artificial intelligence expressed negatively positive statements ai always act line human values also made involve close cooperation technical expertise con junction abstract thought issues value indeed col aborative thought ongoing encouraged need understand precisely “autonomy” applies particular ai used developed need understand think human autonomy value control world think broadly imagina tively confine even narrowly focused view fal remit “ethics” wide range metaphysical questions need asked paula boddington consider instance whole impetus technology may perhaps toward greater greater human control might assume control better many ways approaching question tradi tions emphasis may partnership humans whatever force con ceptualized fashioning natural world recognizing sources wisdom outside human world working alongside even sometimes ceding control entirely something outside humanity may often best response avoidance deception ai seems obvious standard uphold see necessary given difficulties transparency intelligibility ai debates constitutes deception area ongoing essential example given human propensity attribute human qualities inanimate objects let alone living creatures complex machines large bulk work standing precisely ai might “deceive” us even actual means compare example temporary suspension disbelief needed enjoy fiction don’t think “deception” general worded codes must accompanied specific standards vital deepening understanding “deception” means avoided—or not—in specific contexts multiple applications ai statements codes standards warn ai hurting destroying deceiv ing humans highly reminiscent asimov’s rules robotics15 often cited reference ethical questions ai even though asimov routinely persistently wrote stories demonstrate inadequacy asimov’s constant finding loop holes problems simple codes important legacy work field rather flawed laws robotics perhaps lesson take visionary asimov draw present codes conduct need accompanied something richer set rules regulations technical standards fact accompanying codes standards stories imagined real point danger simplistic interpretation application codes would great step conclusions considerable effort expended producing develop ing codes standards ai one must hopeful work assist development technology enhance rather threaten human agency life flourishing—whatever means codes standards never enough complex issue linking wideranging questions chapter able indicate considerations bring see eg asimov robot gnome press normative modes codes standards bear indeed discussion codes standards area ongoing welcomed codes useful part ethics argued limits dangers standards especial useful technical achievement goals exploring pos sibilities seen one problems many codes gesture broadly defined values attempt embody values within technical stan dards one fruitful way working values real mean context well critical codes impact requires dialogue technical expertise others yet time focusing technical contextual detail need look bigger picture codes ethics embedded within far wider questions value values may explicitly included codes assumed referenced within wider societal values norms within codes nested values evolve history medical ethics shows us basic ethical concepts underpinning codes evolving take patient autonomy key value medical ethics emphasis placed upon auton omy individual patient gradual increasing broad generalization complex reasons many factors involved relate broader social attitudes well changing expectations medical profession changes may encouraged part practice medicine including increasing patient understanding16 comes ai may need prepared even larger shifts think value figuring whether shifts welcomed involve far simply laying codes standards one fascinating issues considering ethics ai given power ai augment replace human thought human agency order assess humans might fare response ai need consider basic philosophical ques tions human nature without understanding human nature including human potential human social relations human responses certain environments including environment creating ai cannot understand humans live well ai questions course involve scientific questions human beings yet never simply scientific questions even give account constitutes physical health humans involve making judgments value far richer notion human flourishing considering ethics ai seen great opportunity ask try answer ageold questions questions merit continual richly informed debate discussion useful codes standards ethics may much may form starting points encourage discussions code ethics go far understanding values complex embedded cul ture story history arts philosophy religions political ideologies scientific questions ask understanding methods addressing questions tl beauchamp jf childress principles biomedical ethics oxford university press paula boddington rich discussion imaginative exploration needed alongside formal codes standards real use ai augment human life bibliography asimov isaac robot new york gnome press balfour g adams ae nickels unmasking administrative evil new york routledge boddington paula towards code ethics artificial intel igence heidelberg springer european commission’s highlevel expert group artificial intelligence draft ethics guidelines trustworthy ai httpseceuropaeufuturiumensystemfilesgedaihleg draftethicsguidelines18decemberpdf ieee global initiative ethics autonomous intelligent systems ethical aligned design vision prioritizing human wellbeing autonomous intel igent systems first edition ieee httpsethicsinactionieeeorg house lords select committee artificial intelligence report first session –ai uk ready wil ing able london whittlestone j r nyrup alexandrova k dihal cave ethical societal implications algorithms data artificial intel igence roadmap research london nuffield foundation chapter role professional norms governance artificial intelligence urs gasser carolyn schmitt introduction development deployment use artificial intelligence ai systems aibased technologies governed increasingly complex set legal ethical social types norms norms stem government industry deci sion makers professional trade organizations may also rise developers aibased systems among others ai governance toolbox thus compiled patchwork norms modes governance yet assembled context lifecycle aibased technology chapter take pragmatic approach scoping extent professional norms particular—and specifical norms development phase expressed formal documents codes ethics—may serve reservoir norms account ability mechanisms include within evolving governance toolbox profes sional norms contextsensitive limited governance effects however professional norms play productive role concert ai gov ernance schemes including legal requirements safeguards explore interface ai “the profession” emphasis new institutional arrangements sources norms arise within profession ai integrates many parts society challenges traditional conceptions profession find trend challenging tradition mirrored urs gasser carolyn schmitt professional norms ai see emerging trends norms stemming new areas outside professional trade organizations addition suggest may seeing early stages ai professions broadly defined ai professions norms examining professional norms ethics potential source mode governance ai triggers fundamental questions definitions concepts ai professions general context ai specifical mean professional ethics universal agreed upon definitions terms exist concepts state flux meaning ai remains amorphous least multidisciplinary perspective methods techniques evolve contexts application change notion profession profes sionalism stands shifted dramatical time particularly knowledge econ omies1 identifying understanding ethical questions addressed intersection professions ai also work progress layered top three concepts—the profession professional norms ai—create one might describe perfect definitional storm extraordinarily rich history theory practices massive eye light complexity uncertainty chapter takes modest pragmatic approach offers selected observations based work authors con text larger research effort ethics governance ai following initial triangulation core elements play—ai professions professional norms— frames subsequent observations one areas consensus among scholars universal agreed upon definition ai2 working definition use chapter however encap sulates complexity contextuality ai including history future trajec tory interdisciplinary stakeholders researchers involved ai3 present purposes important definition characteristics ai systems including increased pervasiveness impact human autonomy agency many reports document aibased technologies increasingly penetrate areas transportation health education justice news entertainment julia evetts “the sociological analysis professionalism occupational change modern world” international sociology june –httpsdoiorgdoi101177 mc elish tim hwang “introduction” ai pattern language new york data society –we draw definition artificial intelligence stanford’s ai100 report peter stone et al –study panel stanford ca stanford university september httpsai100stanford edu2016report role professional norms governance ai commerce name areas life increased pervasiveness highlights importance context ai systems developed embedded considering normative questions role professional norms aimed addressing perhaps fundamental attribute many ai systems however varying degrees affect human autonomy shift away human beings toward machines potential deep consequences also con cepts profession professionalism many changes associated ai shape nature profession seen amplifications tectonic shifts going time past decades large body multidisciplinary research documented analyzed transformations concepts profession professionalism including seemingly paradoxical erosion traditional liberal professions eg law yers doctors one hand growing appeal concepts across many occupations other4 expanding application “professions” across occupational groups contexts social systems direct effect extent concept profession—and set norms enforcement regimes— potential play role governance ai expansion suggests professions associated norms might increasingly relevant governance mechanisms ai particularly comes use ai systems professionals different social contexts ideal example physician uses aibased system diagnose patient’s disease judge relies predictive analytics making decisions bail sentencing instances professional norms ethics potential help govern use respec tive aibased systems perhaps even importantly conceptual shift away traditional “pure” professions toward one scholar cal “mixedup” forms professionalism5 opens door examine new evolving nontradi tional occupations existing alongside professions engaged development ai help fill reservoir norms enrich governance toolkit particular per spective focus professions development side ai focus remainder chapter notions professions professionalism changing normative insti tutional arrangements shifting case traditional professions control professional practices exercised norms created administered professional associations recent times professional associations prolif erated concert professionalization various occupations alternative institutional arrangements emerged shape evolutionary path profes sional norms ways enforced among professionals latter trend also pervades looking professional norms ethics context ai various nontraditional players—including nongovernmental organizations evetts “sociological analysis” mirko noordegraaf “from ‘pure’ ‘hybrid’ professionalism” administration society urs gasser carolyn schmitt companies—are engaged norm creation lesser extent administration despite changes institutional setup governance professional norms types issues addressed professional norms remained largely stable focus ing regulation behavior professionals impact products services society similarly many ethical questions norms profession remained relatively stable despite broadening concepts6 respect ai might ultimately driver deeper changes profes sional norms ethics age ai might address traditional questions also future effects increasingly autonomous systems profession creates—including feedback effects profession ai professions aibased technologies often highly complex systems require col aboration people various types knowledge skil judgment across different phases aisystem creation—including design development testing consider autonomous vehicles cars need designers computer scientists engineers soft ware developers policymakers legal experts business representatives among others work together conceptualize build selfdriving cars bring street depending geography culture context several activities involved creation ai systems might carried people represent discipline also belong occupation—some selfidentify profes sion instance many people working technical side ai development members professional organizations institute electrical electronics engineers ieee7 however determining types activities fall specific profession always straightforward seemingly welldefined activities like “engi neering” il ustrative indepth analysis suggests lines engineering activities disciplines occupations professions blurry change time particularly light changing socioeconomic circumstances technologies8 boundarydrawing challenge complicated considering individuals outside established disciplines occupations profession might also involved development aibased technologies one scholar says ai paula boddington towards code ethics artificial intel igence 1st ed artificial intelligence foundations theory algorithms cham sui springer international publishing boddington towards code michael davis “engineering profession methodological problems study” engineering identities epistemologies values vol engineering education practice context role professional norms governance ai development work “can done working entirely outside framework professional accreditation”—and potential even amateurs10 somewhat contrast complicating factors concerning application concept profession development ai systems also possibility emergence might labeled “ai professions” advancements might early indicators toward birth new profession despite aforementioned def initional ambiguities uncertainties first constitutes profession may emerge from—and even defined terms of—one’s identity sense self belonging11 expressions identity include formal memberships professional organizations also incubation phase profession informal ways constitutive manifestations annual conferences meetings work ing groups indicators emerging identity people organizations involved development ai abound highprofile conferences association advancement artificial intelligence aaai conference artificial intelligence international conference machine learning fairness accountability transparency machine learning fatml conference additional develop ments including rapidly growing professorships direct reference ai methods universities around world another sign professionalization ai second recent past witnessed flourishing initiatives aimed developing principles specifical ethical ai tech companies leading organizations approximately early time writing individ ual powerful technology companies publishing formal expressions norms mode selfregulation publications function articulation ethical guide lines principles example microsoft published book included ai principles12 it’s early tell whether sustaining trend noteworthy development landscape ethical norms principles ai concurrently initiatives ethical ai principles stemming thirdparty organizations prominent examples include forthcoming principles oecd’s committee digital economy policy13 report ethical guidelines european commission’s highlevel expert group artificial intelligence boddington towards code tom simonite “the diy tinkerers harnessing power artificial intelligence” wired brianna b caza stephanie creary “the construction professional identity” perspectives contemporary professional work chal enges experiences cheltenham uk edward elgar –microsoft future computed redmond wa microsoft corporation https1gew6o3qn6vx9kp3s42ge0y1wpenginenetdnasslcomwpcontentuploads201802the futurecomputed2818pdf “oecd moves forward developing guidelines artificial intelligence ai” oecd february httpwwwoecdorggoingdigitalaioecdmovesforwardondeveloping guidelinesforartificialintelligencehtm urs gasser carolyn schmitt principles centered around ai implying corresponding group addressees defined involvement production use ai example report european commission ai hleg states “these guidelines addressed ai stakeholders designing developing deploying implementing using affected ai”in light evolutionary expanding dynamics pro fession professional norms il ustrated illinois institute technology collection codes ethics fields spanning agriculture business communications computer engineering finance law media forth emergence “ai profes sions” seems plausible18 another driver nascent ai professions might emerge moments crisis involv ing complex organizational struggles seen history birthdate mod ern medical ethics forefront professional ethics stake merely individuals professional work first code medical eth ics born outrage crisis manchester england hos pital refused accept patients epidemic disagreement among staff crisis hospital hired thomas percival esteemed doctor philos opher create code conduct19 viewed angle open protests employ ees leading ai companies—such microsoft20 google21—against employer’s plans enter contracts raise ethical concerns might precursors moments organizational crisis—which cases already led development companyspecific ai principles response protests22 instances demonstrate professional ethics become increasingly important “ethics guidelines trustworthy ai” european commission highlevel expert group artificial intelligence april httpseceuropaeudigitalsinglemarketennews ethicsguidelinestrustworthyai “the toronto declaration protecting rights equality nondiscrimination machine learning systems” access may httpswwwaccessnoworgthetorontodeclaration protectingtherightstoequalityandnondiscriminationinmachinelearningsystems “universal guidelines artificial intelligence” public voice october https thepublicvoiceorgaiuniversalguidelines “ethics guidelines trustworthy ai” “the ethics codes collection” ethics codes collection httpethicscodescollectionorg robert baker “codes ethics history” perspectives profession fall httpethicsiiteduperspectivev19n1perspectivepdf accessed march sheera frenkel “microsoft employees protest work ice tech industry mobilizes immigration” new york times june httpswwwnytimescom20180619technology techcompaniesimmigrationborderhtml “we google employees google must drop dragonfly” medium blog november httpsmediumcomgooglersagainstdragonflywearegoogleemployeesgooglemustdrop dragonfly4c8a30c5e5eb devin coldewey “google’s new ‘ai principles’ forbid use weapons human rights violations” techcrunch june httpstechcrunchcom20180607googlesnew aiprinciplesforbiditsuseinweaponsandhumanrightsviolationsguccounter2 role professional norms governance ai presence highly complex situations implications society public medical field 1700s ai today norms ai professions observations mentioned earlier suggest application concept profession professionalism context ai still flux complicat ing scope professionalism ai professional norms situ ated within various contexts23 interact explicit implicit sources norms24 corporate settings instance norms may also interact extant frameworks normative business ethics trends sketched earlier simulta neously build upon wellestablished ground familiar territory eg earlier case engineering also novel terms intricate assemblage activities disciplines occupations professions involved development spectives also reflected looking norms might relevant nexus ai professions two characteristics current norms landscape seem particularly relevant given mélange quasiprofessional activities actors involved surprising sources norms transcend setup professional associations played decisive role context traditional professions furthermore dynamic nature state play suggests relevant norms come gestalt “code ethics” cases depending context might less structured informal times even implicit form normative routines “everyday professional life”the following examples provide il ustration different types norms might considered relevant starting traditional forms historical professional codes principles published primarily trade organizations professional associations coming principles association computing machinery acm ieee associa tions responding pervasiveness importance ai ieee embarked global initiative ethics autonomous intelligent systems26 part initiative published ethical aligned design resource variety stakeholders ai help ground development deployment aibased technologies ethical principles including human rights wellbeing transparency accountability among boddington towards code –see eg andrew abbott “professional ethics” american journal sociology march –httpwwwjstororgstable2779443 accessed march abbott “professional ethics” “the ieee global initiative ethics autonomous intelligent systems” ieee standards association httpsstandardsieeeorgindustryconnectionsecautonomoussystemshtml accessed march urs gasser carolyn schmitt others report discusses various challenges issues surface interface principles design aibased systems also provides background infor mation challenges practical recommendations ensuring ethics remain core issues forefront design teams recommendations range expanding project teams experts fields ensuring devel opers ful understand ethical implications technology27 acm turn revised code ethics professional conduct response code written “computing professionals” used broad sense encompass many people working aibased systems29 acm explicitly links work ai visàvis updated code ethics addressing potential risks associated computing acm code emphasis machine learning principle evaluating risks states “extraordinary care taken iden tify mitigate potential risks machine learning systems”while acm code ethics would cover technical systems terms algorithms software movement toward investigating potential norma tive standards data data practices conversations critical data cen tral development ai norms exist within transitional category norms defined newer players conversations several bodies including groups within european commission31 research organizations association internet researchers aoir coming quasinormative principles data big data research european commission report researchfocused rooted protecting data subjects abiding laws regarding transfer data32 paper aoir addresses internet researchers wider audience discusses similar ethical issues openended questions considerations rather formal rules33 contrast multidisciplinary group influential scholars published “rules responsi ble big data research” cal company organization develop ethical aligned design vision prioritizing human wellbeing autonomous intel igent systems 1st ed ieee httpsethicsinactionieeeorgread “world’s largest computing association affirms obligation computing professionals use skil benefit society” association computing machinery july httpswwwacmorg mediacenter2018julyacmupdatescodeofethics “acm code ethics professional conduct” association computing machinery july httpswwwacmorgcodeofethics “acm code” “ethics data protection” european commission november httpeceuropaeu researchparticipantsdatarefh2020grantsmanualhiethicsh2020hiethicsdataprotectionen pdf32 “ethics data protection” ––annette markham elizabeth buchanan “ethical decisionmaking internet research recommendations aoir ethics committee” association internet researchers december httpsaoirorgreportsethics2pdf role professional norms governance ai code conduct data34 publications demonstrate source norms emerge response need demand guidance working big data though published ethical codes professional norms discussed earlier exemplify norms ai dynamic pieced together various sources traditional transitional ways also seeing emergence new forwardlooking sources norms examples emerging sources interactive resources think tanks articulations norms employees one example ethical os ethical os tool kit questions considerations broad range audiences connected development technology particularly thinking future potential unforeseen risks deployment systems aimed specifical ai toolkit frames one approach thinking new technological sys tems features offering stepbystep instructions examples thinking various risks including disinformation bad actors35 addition also witnessing norms surfacing “bottom up” within profession employees tech companies particularly united states specifical google amazon starting speak up—in public way—about dis content technology used military purposes36 facial recognition technology37 seen different types norms may apply varying degrees applicability professionals business developing ai follow tradition enacted trade organizations professional associations others formulated companies others recently stem bottom employees protesting norms need evaluated analyzed greater depth research emerging fill gap38 backdrop norms discussed section offer four broad observations sur face exploration professional norms include similarities tradi tional norms possibly newer elements larger challenges ai ethics future norms presented chapter adhere various obligations professions include commitments society employer clients matthew zook et al “ten simple rules responsible big data research” plos computational biology march –httpsdoiorgdoi101371journalpcbi1005399 “ethical os guide anticipating future impact today’s technology” ethical os august httpsethicalosorg daisuke wakabayashi scott shane “google renew pentagon contract upset employees” new york times june httpswwwnytimescom20180601technology googlepentagonprojectmavenhtml james vincent “amazon employees protest sale facial recognition software police” verge june httpswwwthevergecom201862217492106amazonicefacial recognitioninternalletterprotest daniel greene anna l hoffman luke stark “better nicer clearer fairer critical assessment movement ethical artificial intelligence machine learning” proceedings hawaii international conference system sciences hawaii international conference system sciences maui hawaii httpsscholarspacemanoahawaiiedubitstream10125596510211pdf urs gasser carolyn schmitt colleagues professional organizations39 fall loosely three categories professional codes aspirational educational regulatory40 eye toward potential governance effects norms—we add another category “technical norms” focuses development aspect aibased systems categories mutual exclusive may merged together within professional code41 taken together form normative backbone broadly defined emerging ai professions norms set forth corporate codes google42 microsoft43 sap44 tend emphasize obligation society public wellbeing appear aspirational nature codes professional associations like ieee45 acm46 contrast also encompass explicit commitments peer relationships account ability associations focused development technical norms microsoft example elucidates ethical norms book explaining principles goals work reflecting educational aspirational types codes47 microsoft’s principles refer also technical norms articulated guidelines developers working conversational ai48 guidelines articulated regulatory codes—or rules—though microsoft explicitly notes suggestions “for part hardandfast rules”this example il ustrates codes ethics might interact manifestations professional norms resulting governance effects depend elements nature—an industrywide technical norm might weight merely aspi rational norm—but also interplay among content codes principles related ai norms described within resemble codes industries50 serve essence familiar functions professional codes51 however latest generation professional norms highlight interesting nontraditional features instance norm addressees seem gradu al shift traditional narrowly scoped groups—the members association— toward inclusive albeit ambiguous group professionals involved effy oz “ethical standards computer professionals comparative analysis four major codes” journal business ethics –mark frankel “professional codes impact” journal business ethics –httpwwwjstororgstable25071878 accessed march frankel “professional codes” sundar pichai “ai google principles” keyword blog june httpswww bloggoogletechnologyaiaiprinciples microsoft future computed –corinna machmeier “sap’s guiding principles artificial intelligence” sap september httpsnewssapcom201809sapguidingprinciplesforartificialintelligence “ieee code ethics ” ieee httpswwwieeeorgaboutcorporategovernancep78html “acm code” microsoft future computed –“responsible bots guidelines developers conversational ai” microsoft november httpswwwmicrosoftcomenusresearchuploadsprod201811botguidelinesnov2018pdf “responsible bots” eg oz “ethical standards” –frankel “professional codes” –the role professional norms governance ai development ai acm code ethics exemplifies change code52 code53 interestingly addressees google54 sap’s principles55 stated note however codes include principles draw attention responsibility developers specifical sap indicatively refers held accountable set norms overal another observation points toward attempts operationalize relatively abstract norms help translate practice ieee’s ethical aligned design illustra tive making ethical norms accessible wide range stakeholders including developers public providing guidance ethics embedded aibased systems57 ieee implemented report educational course tech nical professionals varying backgrounds launched working groups focus challenges integrating ethics development ai58 norms section continue struggle broader social issues risks associated ai59 autonomous behavior ai systems create norms focus heavily behavior professionals creating aibased systems potential behavior autonomous systems instances however professional norms come close addressing novel types fore seeable challenges microsoft example asks describing principles “how lose control machines become increasingly intelligent powerful”acm’s code ethics similarly states future risk tech nology uncertain must “frequent reassessment” technology61 addressing autonomous behavior aibased systems emerging area within professional norms approach ai governance worthy future study one scholar postulates may suggest larger questions moral agency62 governance effects among myriad professional norms discussed thus far also differentiate different types governance effects norms may direct effects indirect effects may weak effects strong effects may even undesirable effects side effects accompany norms ronald e anderson “acm code ethics professional conduct” communications acm may –httpsdlacmorgcitationcfmid129885 accessed april “acm code” pichai “ai google” machmeier “sap’s guiding principles” id ethical aligned design id –boddington towards code microsoft future computed “acm code” boddington towards code urs gasser carolyn schmitt empirical evidence regarding impact codes ethics behavior mixed studies business ethics arguing observable effect63 recent studies looking acm code ethics posit norms little effect64 governance effects ethical codes unclear key reasons see promise professional norms articulated codes ethics similar ethical principles important addition ai governance toolkit section draw pragmatic examples demonstrations potential effects cynic argue merely marketing ploys modes influencing public perception65 form “ethics washing”there practical design choices encourage robust accountability systems order make professional norms powerful thus situate professional norms within four main camps delineated following implementation norms governance effects professional norms depend norms implemented integrated development processes practices routines aibased technologies important case companies situations formulating norms principles also creating granular guidelines specify norms actual mean engineers practice guidelines sometimes presented instructional materials67 times explicit guidelines microsoft’s aforementioned guidelines conversational ai presented living doc ument evolve changing ecosystem il ustrative68 companies also drawing internal review boards additional guidance implementing principles practice six months publishing ai guidelines google created internal review structure difficult cases flagged internal developers struggled application company’s principles faced joseph mckinney tisha l emerson mitchell j neubert “the effects ethical codes ethical perceptions actions toward stakeholders” journal business ethics –httpwwwjstororgezpprod1hulharvardedustable40929510 accessed march andrew mcnamara justin smith emerson murphyhil “does acm’s code ethics change ethical decision making software development” proceedings 26th acm joint meeting european software engineering conference symposium foundations software engineering acm joint meeting european software engineering conference symposium foundations software engineering lake buena vista florida –httpsdlacmorg citationcfmdoid32360243264833 frankel “professional codes” james vincent “the problem ai ethics” verge april httpswwwtheverge com20194318293410aiartificialintelligenceethicsboardschartersproblembigtech “responsible ai practices” google ai httpsaigoogleeducationresponsibleaipractices “responsible bots” role professional norms governance ai barriers ai principles69 google responsibility senior executives address particularly challenging issues including decisions affect multiple prod ucts technologies70 overal effectiveness professional norms within corporate context force governance depend seen contexts pharma ceutical industry71 numerous factors ranging internal oversight monitoring reinforcement mechanisms example balanced scorecard concept important issues related leadership values culture72 accountability mechanisms norms apply development ai systems diverse possible accountability mechanisms seek ensure compliance diverse norms across contexts vary principles codes ethics discussed lack explicit accountability mechanisms still might enforced informal “by product types controls maintaining everyday professional routines”others acm code ethics paired separate code ethics enforcement policy acm enforcement policy outlines steps organiza tion takes complaint filed including investigations complaint dismissals enforcement policy contains potential disciplinary actions code violations barring members temporarily acm conferences publications expul sion organization74 effects enforcement mechanisms remain largely open empirical question early study impact acm code ethics claimed acm code ethics impact behavior study limited looked exposure participants norms impact enforcement mechanisms based complaints members—a form inter nal policing profession75 nonetheless decades empirical research across wide variety traditional professions suggest “formal prosecution function largely public visibility offence”kent walker “google ai principles updates six months in” keyword blog december httpswwwbloggoogletechnologyaigoogleaiprinciplesupdatessixmonths experience working industry berkman klein center we’ve learned buyin awareness top executives key cultural behavioral changes organizations developing ai technologies ruth chadwick ed concise encyclopedia ethics new technologies 1st ed bioindustry ethics amsterdam nl elsevier academic press chadwick ethics new technologies –abbott “professional ethics” “acm code ethics enforcement procedures” association computing machinery https wwwacmorgcodeofethicsenforcementprocedures accessed march mcnamara smith murphyhil “acm’s code ethics” –abbott “professional ethics” urs gasser carolyn schmitt companies new normsetters professional norms ai development also experiment accountability schemes addition internal review boards attempts establish external review boards varying degrees success google example created controversial shortlived external council specific focus development google’s aibased tools77 sap also created interdisciplinary external ethics review board focus ai guide imple mentation principles79 addition internal steering committee created ai principles80 review panels—and interest establishing them—suggest responsibility develop ethical responsible ai tools fall solely developers engineers potential adding layers accountabil ity professional norms sobering recent experiences external ethics boards demonstrate independence representativeness legitimacy transparency authority among key factors determine effectiveness oversight mechanisms81 overall beyond context ai performance ethical review processes boards theoretical empirical underexplored82 court public opinion role publicity83 “visibility theory” identified force play context traditional professional norms accountability schemes84 today’s social media environment court public opinion serves another governance mechanism norm enforcement organizations stipulate principles profes sional norms ai development potential held responsible court public opinion violate infringe norms recent media examples show case employees major technology companies articulating values company’s work us immigration customs enforcement85 similarly google employees angered news planned search engine china kent walker “an external advisory council help advance responsible development ai” keyword blog march httpswwwbloggoogletechnologyaiexternaladvisory councilhelpadvanceresponsibledevelopmentai kelsey piper “exclusive google cancels ai ethics board response outcry” vox april httpswwwvoxcomfutureperfect20194418295933googlecancelsaiethicsboard “sap becomes first european tech company create ethics advisory panel artificial intelligence” sap september httpsnewssapcom201809sapfirsteuropeantech companyaiethicsadvisorypanel machmeier “sap’s guiding principles” meredith whittaker et al “ai report ” ai new york university december httpsainowinstituteorgainow2018reportpdf stuart g nichol et al “a scoping review empirical research relating quality effectiveness research ethics review” plos one july httpsdoiorg101371 journalpone0133639 frankel “professional codes” abbott “professional ethics” frenkel “microsoft employees protest” role professional norms governance ai published open letter protest project86 following reports major news outlets87 public threats investor88 google reportedly shut proj ect89 cases corporate responses employee activism reportedly hostile90 shareholders also holding companies accountable ethical standards media amazon shareholders currently demanding company stop selling facial recognition technology light potential human rights violations91 par ticular demand draws earlier suggestion microsoft government regula tion technology92 scholars previously noted principles codes may used appease stakeholders93 instance example shareholders using principles hold companies accountable effectiveness court public opinion normenforcer likely vary depending context application type norm violation overall transparency factors based recent experiences also likely media outlets rely existence investigative translative organizations—current examples include propublica94 ai algorithmwatch among others—that draw attention eth ical issues ai possible norm violations professional norms law looking ahead toward robust accountability schemes professional norms governing development ai systems may instances professional “we google employees” brian fung “google real trying build censored chinese search engine ceo confirms” washington post october httpswwwwashingtonpostcomtechnology 20181016googlereal yistryingbuildcensoredchinesesearchengineitsceoconfirms patrick templewest “google shareholder revolts ‘project dragonfly’ ” politico projectdragonfly1037966 ryan gal agher “google’s secret china project ‘effectively ended’ internal confrontation” intercept december httpstheinterceptcom20181217googlechinacensored searchengine2 alexia fernández campbel “google employees say company punishing activism” vox april httpswwwvoxcom201942318512542googleemployeewalkout organizersclaimretaliation mallory locklear “shareholders ask amazon halt sales facial recognition tech” engadget facialrecognitiontech brad smith “facial recognition technology need public regulation corporate responsibility” microsoft blog july httpsblogsmicrosoftcomontheissues20180713 facialrecognitiontechnologytheneedforpublicregulationandcorporateresponsibility frankel “professional codes” “machine bias investigating algorithmic injustice” propublica httpswwwpropublicaorg seriesmachinebias accessed april urs gasser carolyn schmitt norms make entry law professional norms become legal relevant different interfaces including legislation eg lawmakers delegate normsetting pro fessional associations contracts eg two parties incorporate norms profession way reference contract jurisprudence eg court interprets abstract standards light norms profession examples pri vate norms—especial technical ones—that make entry legal arena manifold span across diverse contexts accounting health law environment forth95 doctrinal questions interplay norms profession legal system complex remain controversial context chapter new mechanism established article eu general data protection regulation gdpr serves il ustration norms professional association become legal relevant according provision asso ciations bodies represent data controllers processors may prepare codes conduct specify regulation regard long list items including fair transparent processing collection personal data forth96 codes conduct approved regulator—by supervising authorities— compliance monitored accredited bodies take action case infringement approved code conduct pursuant article gdpr looking ahead chapter suggests professional norms different provenience poten tial serve reservoir ai governance contextualized within gov ern ance mechanisms however fundamental conceptual issues notion constitutes “ai professions” coupled range empirical questions including actual effects norms professionals remain open research discus sion nonetheless review professional norms literature applied ai pro vides elements emerging—and certainly evolving—landscape professional norms ai context explored norms profession potential source ai governance offer ing observations fluid state play outlining various types sources professional norms might inform future research discussions perhaps interesting questions exploration—in addition important empirical studies varying governance effects professional norms different accountabil ity schemes—are normative nature go beyond scope chapter offered “food thought” felix uhlmann ed private normen staatliches recht vol zurich dike “general data protection regulation” official journal european union l119 may httpseurlexeuropaeulegalcontententxtpdfuriojl2016119full role professional norms governance ai al uded earlier emergence widespread adaptation aibased tech nologies might fundamental challenge notion “profession” itself—whether development usage side systems perhaps obvious il ustration dimension observation highly specialized ai applications potential outperform even best professionals—often without able pro vide explanation shift performance power human machine likely affect identity profession specialized knowledge information asymmetries constitutive identityformation ultimately add another layer complexity types constel ations next gen eration professional norms address97 period rapid change also challenge dominant voices norms power structures within “ai professions” ensure diverse inclusive across gender race socioeconomic status forth concerns unique ai observed professions like law98 ai context lack diversity striking recent report highlights troubling gen der racial imbalances within “ai professions” cal greater diversity within workplaces aibased systems created well within training data systems100 anticipate efforts aimed increasing diversity inclusion impact evolution professional norms ai professions shape respec tive accountability mechanisms moving forward productive ways related challenge relates capacity legitimacy norms profession deal fundamental challenges brought forth aibased technologies current trajectories hold ai technology likely fundamental shape areas reconfigure social relations among humans well humans artifacts growing body literature demonstrates ethical governance questions associ ated aienabled shifts touch upon fundamental concepts values related humanity society remains seen extent professional norms capacity productively engage extremely complex societal questions legitimacy normsetting ensured stakes increase101 final question debate concerns role professional norms concert norms ai governance102 one big advantages professional norms boddington towards code –deborah l rhode “gender professional roles” fordham law review –httpsirlawnetfordhameduflrvol63iss15 accessed april alex johnson jr “the underrepresentation minorities legal profession critical race theorist’s perspective” michigan law review –httpsheinonlineorghol phheinjournalsmlr95i1025 accessed april sarah myers west meredith whittaker kate crawford “discriminating systems gender race power ai” ai new york university april httpsainowinstituteorg discriminatingsystemspdf see eg boddington towards code –urs gasser virgilio af almeida “a layered model ai governance” ieee internet computing december –httpsdoiorg101109mic20174180835 urs gasser carolyn schmitt contextsensitive types norms simultaneously contextsensitivity combined fact professional norms one source constraints within broader landscape meshed ai governance leads us ques tion conflicts among different contextual norms interpretation resolved across various norm hierarchies norm authorities ensure cer tain levels interoperability103 along normative consistency within various sources professional norms applied ai time visàvis governance schemes across jurisdictions cultures ecosystemlevel challenge needs addressed adequately order productively embrace potential norms source legitimate enduring ai governance acknowledgments authors would like express gratitude members ethics governance artificial intelligence initiative berkman klein center mit media lab amar ashar john bowers ryan budish mary gray hansw micklitz ruth okediji luke stark sara watson mark wu jonathan zittrain conversations inputs chapter bibliography abbott andrew “professional ethics” american journal sociology –httpwwwjstororgstable2779443 boddington paula towards code ethics artificial intel igence 1st ed artificial intelligence foundations theory algorithms cham sui springer international publishing bynum terrell w simon rogerson eds computer ethics professional responsibility 1st ed malden blackwel davis michael “engineering profession methodological problems study” engineering identities epistemologies values edited steen hyldgaard christensen christelle didier andrew jamison martin meganck carl mitcham byron newberry –engineering education practice context cham sui springer international publishing evetts julia “the sociological analysis professionalism occupational change modern world” international sociology june –doi1011770268580 frankel mark “professional codes impact” journal business ethics –httpwwwjstororgstable25071878 greene daniel anna l hoffman luke stark “better nicer clearer fairer critical assessment movement ethical artificial intelligence machine learning” proceedings 52nd hawaii international conference system sciences maui httpsscholarspacemanoahawaiiedubitstream10125596510211pdf john palfrey urs gasser “legal interop” interop promise perils highly interconnected systems 1st ed new york ny basic books –the role professional norms governance ai ieee global initiative ethics autonomous intelligent systems ethical aligned design vision prioritizing human wellbeing autonomous intel igent systems 1st ed ieee httpsstandardsieeeorgcontentieeestandardsenindustryconnections ecautonomoussystemshtml noordegraaf mirko “from ‘pure’ ‘hybrid’ professionalism” administration society october –doihttpsdoiorg1011770095399707304434 oz effy “ethical standards computer professionals comparative analysis four major codes” journal business ethics –httpwwwjstororg stable25072460 p r concepts issues chapter we’re missing moral framework justice artificial intelligence limits failings ethics fairness matthew le bui safiya umoja noble year techlash news coverage cambridge analytica’s exploitation manipulation facebook data role undermining democratic electoral politics united states united kingdom seemingly ushered new era mainstream critical cov erage overreach technical systems everyday lives citizens con sumers voters1 even though critical academic journalistic inquiry algorithmic bias discrimination documented well two decades scholars color lgbtq nontraditional scholars2 part larger sample coverage cambridge analytica scandal see chang alvin “the facebook cambridge analytica scandal explained simple diagram” vox may httpswww voxcompolicyandpolitics201832317151916facebookcambridgeanalyticatrumpdiagram see key scholars spanning thirty years beginning early 1990s wendy hk chun anna everrett rayvon fouche oscar gandy jr lisa nakamura alondra nelson recent scholars ruha benjamin andre brock simone brown meredith broussard kishonna gray charlton mcilwain safiya umoja noble catherine knight steele well emerging scholars matthew bui joy buolamwini brooklyne gipson os keyes jenny korn rachel kuo mutale nkonde nikki stevens matthew le bui safiya umoja noble figure financial times’ definition “techlash”community critical theorists internet4 stories year centered around mounting examples evidence facebook’s pervasive power invasions con sumer privacy google’s failure address regulators’ concerns monopoly control search public concern use disparate risks harms ai emerg ing technologies examples failures risky applications ai tools included facial recognition systems militaries law enforcement organizations criminal rana foroohar “year word techlash” financial times december httpswww ftcomcontent76578fbafca111e8ac0057a2a826423e included within financial times’ year word series term “techlash” encapsulates seeming paradigmatic shift increased scrutiny criticisms toward technologies technology corporations public conversations particularly light interrelations actors forces undermined democracy deepened extant social inequalities authors included full definition put forth financial times wish express divergence contestation inclusion “their chinese equivalents” type rhetoric often seeks deflect obfuscate ways usbased companies indeed undermining democracy including marc andrejevic yochai benkler kate crawford jessie daniels joan donovan christian fuchs jack goldsmith alex halavais sandra harding marie hicks lori kendal frank pasquale sarah roberts dan schiller dal smythe miriam sweeney siva vaidhyanathan among others we’re missing moral framework justice ai sentencing algorithms within us legal system5 autonomous vehicles dispro portionately trained identify white vs nonwhite bodies pedestrians6 volume salience negative investigative inquiries operations impacts silicon valley technology giants even led financial times include result “techlash” increasing cal greater scrutiny toward con centrated power harmful impacts global technology giants critical discourse digital technologies—and corporate actors enactors logics—have become common responses counteract celebratory marketing rhetoric pitches regarding promises potential technologies datadriven systems even new methods approaches researching phenomena devel oped andre brock’s critical technocultural discourse analysis ctda8 address lack methods study technological practices intersect race class power indeed stories studies harms risks digital tech nologies algorithmic bias become common multinational technology corporations brands facebook google youtube microsoft amazon ibm attempted ameliorate tarnished images redress growing distrust commercial platforms automated systems public relations campaigns promotional materials efforts “ethical” compared previous corporate attempts obfuscate ignore pivot claims risks harms systems technology corporations acknowl edging presence gravity issues investing billions dol ars research intervention programs seek operationalize create “fair” “transparent” algorithms key type intervention increasingly datadriven society large emphasis fairness interventions ai seeks effect propagate technical systems neutral objective render spe cific groups advantaged others meanwhile transparency accountability interventions aim put effect systems protocols auditing regulating julia angwin jeff larson surya mattu lauren kirchner “machine bias there’s software used across country predict future criminals it’s biased blacks” propublica may httpswwwpropublicaorgarticlemachinebiasriskassessmentsincriminalsentencing benjamin wilson judy hoffman jamie morgenstern “predictive inequity object detection” arxiv eprints art arxiv190211097 foroohar “year word techlash” brock andre critical technocultural discourse analysis new media society –doi1011771461444816677532 instance see ibm’s “dear tech” advertisement aired academy awards show ibm “dear tech open letter industry” youtube february httpswwwyoutubecomwatchvgnf8objr6k8 advertisement proctor gamble’s brand pantene making unbiased search engine inspired part safiya noble’s book algorithms oppression search engines reinforce racism pantene watchvismmwsdwt9q matthew le bui safiya umoja noble systems unto goals often calling relying upon internal regulatory bodies within technology corporations measures course one key challenge state actors regulators cannot legislate cannot see understand transparency key dimension enacting regulation however goal many ethics responses remains largely technocentric goal perfect “unbias” technology rather account asymmetrical power relationships gravity history renders development deployment projects deeply uneven unethical even immoral moreover data trusts research partnerships universities policy think tanks technology corporations established revamped goto strategy effecting democratic inclusive mediated society10 calling fairness accountability transparency fat key ideals within future ai yet often leaving ignoring notions intersectional power relations ethi cal imaginaries frameworks11 point departure many invested linking conversations ethics moral genesis failures caused structural racism sexism capitalism fostering inequality eye toward understanding digital implicated social political economic systems buttress sys temic failures complicating conversations concerns neocolonial tech nology supply chains12 total integration digital global economic systems year “techlash” highprofile academic corporate organiza tional responses ethical issues associated artificial intelligence well way13 al technology companies philanthropic foundations universities university researchers attempted respond information “crisis” distrust biased commercial data platforms investing billions dol ars academic industry research projects proffer “fairer” “ethical” “transparent” approaches designing deploying embedding algorithmic artificial intelli gence systems within multiple facets everyday life however current domi nant frames fairness within related “ethical” ai interventions often fail consider integrate notions issues structural systemic inequality power within imaginaries conceptualizations moral ethical dimen sions ai ai systems namely radical scholars writers activists largely within exemplars promoting fairness machine learning ideals see association computing machinery’s fairness accountability transparency facct conference stanford institute humancentered artificial intelligence ethics governance artificial intelligence fund joint project harvard berkman klein center mit media lab instance see association computing machinery acm “conference fairness accountability transparency acm facct” acm facct conference httpsfacctconferenceorg miriam posner “see evil” logic magazine april httpsescholarshiporguc item3165f032 example ai institute ai good data4blacklives adding ongoing work data society among others we’re missing moral framework justice ai marginalized communities identity groups eg women color queer scholars scholars color critical scholars pushed power analyses ways algorithmic systems operate disparately impact communities open ing door “techlash” conversation said concerns algorithmic bias discrimination digital redlining sometimes diminished co opted power—that originators institutions invested designed deployed technical systems question put another way influ ential actors steered fairness interventions focus technical—versus socio technical—approaches understanding implications ai current state affairs technologies—versus first historic analogs important structural factors influence deployment secondly future long term consequences risks harms applications development consequently fairness ai interventions best obfuscate worst ignore the—historical social cultural y—unequal contexts power relations computational tools ideologies attempting embed inter vene operate said variety responses dearth critical ai inquiry included organizing academics tech workers response unjust uses ai military uses14 protests facialrecognition software15 protesting organization ai advisory boards include openly transphobic members16 united states united kingdom europe newly formed critical internet studies centers17 formed organize key scholars around world proffering greater cal using intersectional structural power analysis ai ai tools foreground issues race racism gender sexism patriarchy classlabor surveil ance exploitation altogether emanating related scholars activists scholaractivists cal expanding framework ethical ai focusing tweaking algorithms datasets encompassing broader comprehensive inquiry design use profitmaking processes ai internet espe cial relation social contexts power relations deployed proliferating chapter conduct critical appraisal power analysis present state ai fairness research interventions philosophical historical olivia solon “when tech company refuse build tools government” guardian june httpswwwtheguardiancomtechnology2018jun26techgovernment contractsworkerrevoltmicrosoftamazongoogle alexia fernández campbel “how tech employees pushing silicon valley put ethics profit” vox october httpswwwvoxcomtechnology2018101817989482google amazonemployeeethicscontracts michael kan “google workers protest conservative thinker ai board” pcmag april httpswwwpcmagcomnews367540googleworkersprotestconservativethinkeronaiboard example ucla’s critical internet studies center technology social change research project harvard kennedy’s shorenstein center datactive project university amsterdam data justice lab cardiff university matthew le bui safiya umoja noble antecedents extrapolating whether projects seek pave way inclusive democratic datadriven future particular discuss extant state ai fairness research given proclivity importing radical critiques terminology algorithmic bias discrimination reducing obfuscating core concerns critiques efforts find “silver bullet” intervention uni versalized notion impacted stakeholders often dependent upon funding cooperation technology giants promulgated issues concerns historicizing contextualizing discussion fairness ai relation previous writings ethics power largely drawing marginalized critical technology scholars seek demonstrate elucidate returning writings key arguments usher in—and push for—a moral framework justice artificial intelligence deeply considers engages underlying concerns critiques power inequality within extant emerging cri tiques ai core chapter surveys addresses philosophical antecedents ethics discussed reimagined moral framework justice highprofile resourced ai interventions defining con ceptualizing algorithmic “ethics” “fairness” interventions corporations institutions accelerated propagated algorithmic bias discrimination helm resourced ai interventions extent issues algorithmic oppression discrimination redlining addressed extent has—and will—the concerns experiences oppressed peo ples communities prioritized within discussions design deploy ment daily use biased discriminatory ai systems indeed hope demonstrate articulate artificial intelligence auto mated systems undoubtedly neither neutral objective neither fair bal anced within unequal society argue ways change claims common within fields ethnic studies gender studies queer studies science technology studies media studies critical cultural communication critical information studies critical digital humanities ideas concepts less dominant common within technical conversations ai within fields disciplines computer science humancomputer interaction technology pol icy furthermore strive disentangle ways current emerging fair ness interventions ai premised upon radical critiques technology’s impact society whilst shifting distilling critiques conservative neolib eral ideologies change al chapter unearth importance push broader approaches ai interventions rather naive reductionist techni cal solutions “fair” “ethical” algorithms seek deflect disregard key claims emerging radical critiques technology we’re missing moral framework justice ai origins ethics ethics reimagined justice careful critical analysis political philosophy order understand origin sto ries ethics especial framed relation ai rueben binns18 writ ten important review literature examines enlightenmentera philosophical antecedents concerned discrimination egalitarianism justice matters moral political philosophy article binns19 argues contempo rary issues fairness ethics machine learning artificial intelligence increasingly formalized around preexisting frameworks provide important guide understanding critiquing limitations western political philosophy rarely origins philosophical antecedents contemporary conversations ethics brought relief also point one important critics limits western liberalism enlightenment philosophies ethics charles mil whose work20 essential working reconceptualizing justice fairness matter radical reimagining social structure limited solely individualistic moral virtuosity short traditional western liberalism foundational concepts emancipation albeit many shortfal mil s’ work21 denotes centrality exclusion liberalism’s core documents declara tions writes rejecting liberalism’s classical individualistic social ontology ontology class gender challenging cramped schedule rights normative empow erment class gendersubordinated political projects liberalism affirm expansive vision would take us beyond bourgeois liberal ism patriarchal liberalism22 mil s’ argument unlike critical theorist internet jessie daniels23 notes parasitic ways liberalism “encompass overtly racist liberalism peo ple color explicitly conceptualized racial inferiors longer overtly racist ‘colorblind’ liberalism today later variety liberalism illicit white reuben binns “fairness machine learning lessons political philosophy” proceedings 1st conference fairness accountability transparency pmlr –http proceedingsmlrpressv81binns18ahtml id charles w mil black rightswhite wrongs critique racial liberalism new york oxford university press id id xiv jesse daniels “race racism internet studies review critique” new media society –doi1011771461444812462849 matthew le bui safiya umoja noble racial advantage still secured primarily evasions theory’s key assumptions rather derogation nonwhites”daniels partic ular scholar white racism internet also rejects mainstream liberalism particularly neoliberal white feminism means upending white supremacist log ics silicon valley products platforms projects25 works point elaborate shortcomings limitations classic liberalism moral framework thinking ethics ai failure ful capture ways technologies undeniably tied embedded power therefore frameworks ethics inherently fail address complexity dynamism systems processes actors seek reproduce maintain power maintain hegemony evading detection particularly racialized forms formations brings us recent series interrogations power ai ethics begin anna lauren hoffman’s26 critique fairness antidiscrimination efforts within ai elucidates technical attempts isolate remove “bad data” “bad algorithms” inherently fail effect justice address needs concerns skeptics critics ai drawing analysis ways fairness inter ventions tend overemphasize “bad actors” center singleaxis visàvis intersec tional broader sociotechnical thinking hoffman concludes “at best end little set reactionary technical solutions ultimately fail dis place underlying logic produce unjust hierarchies better worse sub jects first place”this orienting interventions around bad actors centering singleaxis paradigms technointerventions cast aside larger con cerns injustice inequity discrimination solvable fixes underscoring limitations centering technology site imagining ethics adding ruha benjamin28 unpacks concept “new jim code” term develops dialogue michelle alexander’s29 concept “new jim crow” alexander30 articulates new jim crow operates throughout within us criminal justice system reinforce reproduce racialized oppression social control black communities united states benjamin31 incorporates critical race ory frameworks concepts examine il ustrate ways digital tech nologies integrated enmeshed within digital mediated systems processes mil xv daniels “race racism” see also safiya umoja noble sarah roberts critique color line ed roopali mukherjee herman gray sarah banetweiser durham nc duke university press –anna lauren hoffmann “where fairness fails data algorithms limits antidiscrimination discourse” information communication society –doi101 0801369118x20191573912 id ruha benjamin race technology abolitionist tools new jim code medford polity alexander new jim crow id benjamin race technology we’re missing moral framework justice ai surveil ance exploitation control producing new forms digital discrimi nation oppression articulations structures white supremacy capitalism overdeter minants disparate effects technology reframe debates often essen tializing technodeterministic technocentric—foregrounding imagined digital spaces neutrality objectivity divorced broader social politi cal economic contexts technologies developed deployed specifical examine problematize power tied racial identity marginalization discrimination also occur axes sexual orien tation gender ability moreover point back work mil s32 elaboration “principles corrective justice” says must account unequal exploitative stigmatizing historical contemporary effects racism many isms might incorporated concur offer sites intervention concerns digital must grounded informed frameworks acknowledge account many histories power oppres sion upon technologies deployed rather assuming neutral level play ing fields undergirded techno utopianism aid furthering understanding power hierarchies power relations internet point readers important researchers evidence theory concept building provided list end chapter academic corporate responses techlash critique many recent cal ethics enter mainstream academic popular journalistic studies internet digital technologies note important moment frame guiding logics cal see much work additive ethics supplemental module learning could tacked deeply embedded ways computing information communication technologies already conceptualized indeed united states national science foundatio nsf produced cal proposals things like improve undergraduate computer science education ethics optional addition fundamental required proposal funding33 large funding bodies academic research certainly barometers important serve litmus test terms upon scholars tied making different sorts interventions similarly launch four different multimillion billion dol ar mil black rightswhite wrongs national science foundation “improving undergraduate stem education computing undergraduate education iuse cue ” httpswwwnsfgovpubs2019nsf19546nsf19546htm matthew le bui safiya umoja noble research grants programs within universities industry research development units based united states largely driven cal “ethical” ai note among visible mit schwarzman college computing34 stanford institute humancentered artificial intelligence35 google’s ai ethics advisory council announced april disbanded week later36 joint nsfamazon research grant37 singularly collectively research initiatives demonstrate seeming impor tance amount resources diverted address pressing questions light techlash especial relate issues algorithmic bias inequality dis crimination within increasingly datadriven society whereby digital tools deployed embedded within multiple facets everyday life firstly one noteworthy dimension projects principal donors university research funds often venture capitalists technology corporate giants targets intensified scrutiny principal recipients premiere computing institutions ie mit stanford largely esteemed training top computer scientists charge designing coding systems indeed institutions helm ai interventions also laboratories bolstered root causes actors investors led “techlash” served benefit propagation “fairer” systems systems designs order perpetuate existence systems first place risk losing revenue streams entirely charge defining terms ethics fairness technology moreover taken case studies dominant ideologies frameworks ai interventions initiatives demonstrate gap understanding within academy technology corporations regarding origins implications issues algorithmic discrimination—and broader issues social political economic oppression generating productive effective interventions adequately address core concerns critical scholars activists organizers example within introductory narratives launches centers programs partnerships apparent interventions deeply premised rooted conservative neoliberal logics solutions radical critical frame works original paved way discussions disparate disparaging mit news office “mit reshapes shape future” mit news october http newsmitedu2018mitreshapesitselfstephenschwarzmancollegeofcomputing1015 stanford institute humancentered artificial intelligence httpshaistanfordedu sample coverage see sam levin “google scraps ai ethics council backlash ‘back drawing board’ ” guardian april httpswwwtheguardiancomtechnology2019apr04 googleaiethicscouncilbacklash national science foundation “nsf program fairness artificial intelligence ai col aboration amazon fai ” httpswwwnsfgovfundingpgmsummjsppimsid505651 national science foundation “nsf program fairness artificial intelligence ai col aboration amazon fai program solicitation nsf ” httpswwwnsfgovpubs2019nsf19571 nsf19571htm we’re missing moral framework justice ai impacts artificial intelligence systems considering values ethics radi cal scholars activists organizers paved way discussions ai ethics ai neutral questionable whether initiatives would address core problems concerns data harms risks radical cri tiques considered valued least voiced within advisory board meetings initial conceptions intervention projects detailed critique initiative collective discourses detailed following overview academic ai interventions first october massachusetts institute technology mit announced plans billion commitment “worldchanging breakthroughs ethical implications” computing artificial intelligence including establish ment mit schwarzman college computing large gift stephen schwarzman ceo cofounder blackstone38 largely absent within origin story mit’s “worldchanging” ethical institution acknowledg ment new college primarily funded world’s largest private equity firm publicly identified criticized united nations exacerbation exploitation affordable housing crisis united states39 aimed interdisciplinary hub innovation democratic research remains seen whether new mit college lead redistribu tive restorative impacts society research program particularly con sidering deep ties extractive exploitative corporations industries partners similar distinct case contradictory statements values ai ethics centers stanford announced institute humancentered artificial intelligence hai scrutiny skepticism toward stanford university’s attempt establish center might ameliorate issues algorithmic bias dis crimination led advised cadre powerful stakeholders created problem first place40 namely codirector feifei li spoke institute’s goals “building better future humanity” acknowledged need “creators ai representative humanity”within press mit news office “mit reshapes shape future” irina ivanova “un blasts blackstone group worsening us housing crisis” cbs news crisisworsetheunsays example see patrick howell o’neil “stanford’s new institute ensure ai ‘representative humanity’ mostly staffed white guys” gizmodo march httpsgizmodocom stanfordsnewinstitutetoensureaiisrepresentative1833464337 see o’neil stanford center’s promotional video –stanford university httpswwwyoutubecomwatchvse4cq5uzxam matthew le bui safiya umoja noble conference events related promotional materials institute’s website dis play reflect values failed list black african american faculty members advisers institute criticized nonrepresentative tonedeaf announcement “ethical ai” research center especial considering center integrate researchers activists tied marginalized commu nities groups see figure sample critique additional stanford institute garnered critique launch event included advisers former us national security adviser secretary state henry kissinger greatly critiqued role allegedly conducting war crimes behalf united states various countries including vietnam bangladesh chile name few42 unlike role schwarzman mit initiative kissinger symbolizes oppositional stance business professional dealings many regard central framing ethics matters germane civil human rights making personalities even controversial given roles allegedly eroding democratic social values general appeared institute incorporating language innovating better ethical diverse future ai reproducing profiteering many hegemonic nar ratives ideologies produced biased discriminatory ai systems within figure sample twitter critique stanford hai launch43 christopher hitchens trial henry kissinger london atlantic books shared user permission we’re missing moral framework justice ai immensely unequal postcapitalist society considering concerns experi ences organizing activities marginalized communities activists advocates led perceived need ethical ai success initiatives seems questionable given affected penalized systems invited expertise input44 symbolizing tonedeaf nature centers shallow engagement core concerns critiques thus drawing two cases consider political entanglements investments involvements algorithmic interventions deeply complex process warrants attention two specific programs prompt us question wil noncommercial lucrative applications ai ai research funded donations benefactors serve profit commercial applica tion ai noncommercial restorative redistributive ai applications prioritized ways moreover mean search fairer unbiased ethical algorithms—ones shaped reproduce social inequality—is largely bankrolled capital investments firm profiting inequalities power capital also important consider charge shaping advising effecting fairness interventions ai skewed toward whiteness wealth uncritical readings technology’s impact45 overview corporate ai interventions cooptation critical discourse regarding ai’s impacts attempt fur ther exploit communities capital gains technology giant google announced ethics advisory council advanced technology external advisory council would oversee company’s ai product development46 council formed google ceo sundar pichai effort follow new company principles emerged outrage boycott organized google employees com pany’s involvement using machine learning algorithms ai bolster pentagon’s drone technology program better known project maven47 effort respond crisis discrimination racial gendered failure see deeper readings regarding black individuals often penalized racial identity data datadriven systems see noble’s algorithms oppression benjamin’s race technology one initiative attempting delve complex questions—and implications precarious nature research development projects conferences contingent upon corporate sponsorship—is funding matters httpsfundingmatterstech nick stat “google dissolves ai ethics board one week forming it” verge april httpswwwthevergecom20194418296113googleaiethicsboardendscontroversykaycoles jamesheritagefoundation department defense “project maven deploy computer algorithms war zone year’s end” department defense july httpsdoddefensegovnewsarticlearticle1254719 projectmaventodeploycomputeralgorithmstowarzonebyyearsend matthew le bui safiya umoja noble ethics justice google came heels walkout organized women google refused contend sexual harassment undercompensation compared male coworkers culture consistently undervalues demeans women48 noted marie hicks historian women technology time google ethics council formed included kay coles james president heritage foundation brought “techlash” form call dis band council remove james immediately49 week later council canceled due growing public outcry lack diverse representation expertise issues justice technology inclusion specific actors like james openly expressed xenophobic antiimmigrant antilgbtq transphobic views response critiques initiative google issued statement logics capital whereby accumulation strategies multinational companies largely incorporate engulf criticism order frame debates forestall interventions would require different distributions resources power create engagements moreover google’s ability respond consider critiques hegemonic power structures questioned light punish ment activists organizers within company specifical early google employees staged walkout response growing evidence mismanage ment personnel issues particularly relation aforementioned allegations sexual harassment company culture gender racial discrimination may ai ethics researcher meredith whittaker fellow google employee claire stapleton two female leaders strikes publicly stated supervisors google leaders coerced pressured various tactics attempts penalize organizing strikes51 final case study national science foundation announced col aborative project amazon inc wherein two parties would tributing trustworthy ai systems readily accepted deployed tackle grand challenges facing society”like corporate projects attempting engage ethics frameworks project largely imports language details potential risks harms artificial intelligence systems everyday life deploy ing notions need “fair” algorithms skirt away larger structural historical issues inequality accelerated amplified marie hicks “the long history google walkout” verge november https wwwthevergecom201811918078664googlewalkouthistorytechstrikeslabororganizing levin “google scraps ai ethics council backlash” id veena dubal “who stands ai dystopia google activists” guardian national science foundation “nsf program fairness artificial intelligence ai col aboration amazon fai program solicitation nsf ” httpswwwnsfgovpubs2019 nsf19571nsf19571htm we’re missing moral framework justice ai systems53 addition return investments research amazon claimed pro prietary rights innovation derived federal funded research grants essence academiccorporate research partnership raised questions poten tial conflicts interest role statesanctioned taxpayer funds working underwrite ai fairness research would applied context bolstering amazon’s business imperatives54 synthesizing summarizing state ai fairness four examples demonstrate contradictions ai ethics proj ects “will always look ways argue continued existence development application ai” alkhatib55 writes cases also collectively il ustrate systematic structural ways capitalism technological corporate embodiments coopted critical discourse technology’s impacts biases search commercial solutions proprietary research serve protect continued profits technology corporations particularly light potential ai winter ushered public skepticism scrutiny toward ai56 enter taining leveraging key terms critiques artificial intelligence eg algo rithmic “bias” inequality remains little deep engagement within extant emerging highprofile ai interventions profoundly deeply adeptly interrogate power structures issues undergird critical narratives ai’s harms risks pursuit fairness ethics visions justice equity undergirding original critiques ai become techwashed overly technocentric technodeterministic rooted bankrolled neoliberal logics corporate solutionism obfuscating systemic causes problems conclusion summary considering explosive growth emergence investment highprofile ai fairness ethics interventions within academy industry salon barocas andrew selbst “big data’s disparate impact” cal l rev –doi 1015779z38bg31 benjamin romano “amazon’s role ai fairness research raises eyebrows” government technology april httpswwwgovtechcomproductsamazonsroleinaifairness researchraiseseyebrowshtml ali alkhatib “anthropologicalartificial intelligence hai” ali alkhatib blog march httpsalialkhatibcombloganthropologicalintelligence ethan fast eric horvitz “longterm trends public perception artificial intelligence” proceedings thirtyfirst aaai conference artificial intel igence aaai17 httpswwwaaaiorgocsindexphpaaaiaaai17paperdownload1458113868 matthew le bui safiya umoja noble alongside mounting proliferating cal interrogation regulation cases dismantling prohibition ai57 contest question extent remedies address original concerns problems designed address indeed many community organizations organizing responses chal lenging ai used predictive technologies facial recognition software biometrics technologies increasing success furthermore suggest canon ai ethics must interrogate deeply engage intersectional power structures work consolidate capital hands technocratic elites undergird digital informational systems inequality neutral objective state flows mechanics data articulated unbiased fair deployment digital technologies impact interesting—and important—area inquiry facing might take issues disparity oppression simply striving fairness face systems power little address ways digital technologies increasingly central forms structural power projects ask whether ai projects developed al degree public oversight institutions individuals responsible oversight moreover questions ethics framed matter systemic injustice context historical reckonings oppression rarely leading research framework goal essence future ai ethics concerned rising global social economic inequality repercussions emerge effect climate change ways ai used redistribution global goods services—from housing food bordercrossing beyond broadly us fields digital social research must center issues social political eco nomic inequality orientation studying lived experiences relation structures power algorithms ai automated systems overdetermine—rather assuming technology ethical perfected bias feature ai externality corrected resolved58 see sample coverage san francisco’s ban facial recognition thadani trisha “san francisco bans city use facial recognition surveil ance technology” san francisco chronicle may httpswwwsfchroniclecompoliticsarticlesanfranciscobanscityuseoffacialrecognition 13845370php also see sample resources projects data bodies tawana lewis seeta peña gangadharan mariel saba tamika petty digital defense playbook community power tools reclaiming data detroit data bodies httpswwwodbprojectorgwpcontent uploads201903odbddphighressinglepdf authors’ note since chapter drafted additional highprofile developments brought questions ethics values justice relief topic ai fairness research notably mit media lab’s ties immoral donor unfortunately anticipate continue scandals controversies continue demonstrate complicity academic corporate research organizations promulgating data harms risks guises technobenevolence ignorance said hope chapter critical frameworks scholars ground chapter orient future discussions ai interventions first acutely attuned needs experiences endangered pernicious risks harms ai secondly promote embody vision justice rather prevailing techwashed notion ethics fairness we’re missing moral framework justice ai bibliography benjamin ruha race technology abolitionist tools new jim code medford polity chun wendy hui kyong control freedom power paranoia age fiber optics cambridge mit press daniels jessie cyber racism white supremacy online new attack civil rights lanham md rowman littlefield publishers eubanks virginia automating inequality hightech tools profile police punish poor new york ny st martin’s press gandy oscar h panoptic sort political economy personal information boulder co westview press hoffmann anna lauren “where fairness fails data algorithms limits antidiscrimination discourse” information communication society –doi1010801369118x20191573912 mil charles w black rightswhite wrongs critique racial liberalism new york ny oxford university press noble safiya umoja algorithms oppression search engines reinforce racism new york new york university press pasquale frank black box society secret algorithms behind money information cambridge harvard university press vaidhyanathan siva antisocial media facebook disconnects us undermines democracy new york oxford university press chapter accountability computer systems joshua kroll thirtyseven seconds launch ariane rocket’s first flight june software subroutine crashed starting chain reaction led rocket self destruct software attempted convert 64bit floating point number 16bit unsigned integer toolarge value former could represented smaller format latter triggering unhandled error condition fortunately “hot standby” meant take event active copy software failed unfortunately active copy running computation therefore also crashed almost immediately afterward buggy subroutine existed keep rocket balanced ground unnecessary liftoff left run beyond case launch delayed momentarily cascading failures continued entire inertial reference subsystem crashed causing incorrect data feed rocket’s guidance software correct guidance software erroneously understood deviation rocket’s planned trajectory fact diagnostic error code indicating failure rocket’s software control ordered guidance noz zles main engine boosters maximum deflection caused rocket veer wildly course experience “high aerodynamic loads” tore boost ers main rocket correctly triggering rocket’s selfdestruct mechanism1 result disaster complete loss launch vehicle onboard cluster atmospheric research satellites totaling million direct losses failure set back several years european space agency’s efforts develop new launch vehicle point run years cost billion yet despite root cause failure rocket’s software inquiry board convened analyze accident recommended spreading responsibility across several jacqueslouis lions lennart luebeck jeanluc fauquembergue gilles kahn wolfgang kubbat stefan levedag leonardo mazzini didier merle colin o’halloran “ariane flight failure report inquiry board” joshua kroll functions development design implementation launcher saying “possible implications allowing software continue function liftoff realized” natural human instinct face failure identify cause assign responsibility cause person group people tie responsibility consequences—in words hold someone accountable failure ariane flight total launch failure indi vidual part development team held directly responsible responsibility fell partial several functions within program—programmers designers requirement engineers test engineers project managers—many could exposed failure ahead time none func tion focused chosen framing part project2 along high profile early software failures therac253 ariane failure contributed decades reflection software community necessary make soft ware systems reliable critical applications4 reflection must also applied artificial intelligence ai term refers behavior embodied machine usual software system human would consider intelligent5 concerns systems might fit purpose led cal greater governance especial software systems taken increasing number critical application domains modern society often automation augments traditional human decisionmakers professionals times outright replaces social economic structures formerly mediated humans new structures mediated softwaredriven machines6 chapter examines relationship ai systems concept accountability definitions unit analysis understand accountability context ai systems must begin examining various ways term used variety concepts refers mark dowson “the ariane software failure” acm sigsoft software engineering notes nancy g leveson clark turner “an investigation therac25 accidents” computer –these issues means softwarespecific extend engineering safetycritical contexts see eg diane vaughan chal enger launch decision risky technology culture deviance nasa chicago university chicago press definition quite problematic machine exhibits certain behavior real consider behavior “intelligent” general matter cleaner think machines accomplishing task may previously thought beyond reach automation krol joshua solon barocas edward w felten joel r reidenberg david g robinson harlan yu “accountable algorithms” u pa l rev accountability computer systems must examine unit analysis level abstraction referenced discourse7 many terms used discussion ai different stakeholders fundamen tal different even incompatible ideas concept terms refer espe cial stakeholders come different disciplinary backgrounds different power relationships system issue8 confusion leads disagree ment debate parties disagree substance subject debate provide brief overview concepts designated term “account ability” covering relationships commonalities divergences service bridging divides9 artifacts systems structures accountability lie accountability general conceptualized respect entity—a relationship involves reporting information entity exchange receiving praise dis approval consequences appropriate successful demanding accountability around entity person system artifact requires establishing ends rela tionship answers additional understand discussion call accountability ai system application critical determine things system must answer information exchanged many ways ground demand answerability give normative force commensurately many types accountability—moral administrative political managerial market legal judicial professional relative constituency relationships10 artificial intelligence systems intersect eight types accountability different ways depending specifics application context beyond question normative backing accountability question unit applied considering single component larger system entire structure society determining accountability operationalized unitofanalysis questions apply determining holding accountable selbst et al refer failures understand appropriate unit analysis “abstraction error” define five “traps” representing common pitfal problem framing see andrew selbst danah boyd sorelle friedler suresh venkatasubramanian janet vertesi “fairness abstraction sociotechnical systems” proceedings conference fairness accountability transparency deirdre mulligan joshua krol nitin kohli richmond wong “this thing called supported cooperative work conference httpsdlacmorgcitationcfmid3359221 alternative similar taxonomy presented maranke wieringa “what account accounting algorithms systematic literature review algorithmic accountability” proceedings conference fairness accountability transparency fat ’new york association computing machinery –httpsdoiorg10114533510953372833 taxonomy due stone jabbra dwivedi public service accountability comparative perspective hartford ct kumarian joshua kroll holding accountable to11 example considering system predicts credit risk might choose examine instrument ie adequately reflects borrower’s risk default larger sociotechnical context including appli cants loan officers ie functions adequately administration lending comports actors’ understanding behave subject gam ing overall structure credit analysis lending ie systematical undermine credit markets provisioning distribution goods services unduly discriminate structural subordinated groups similarly may wish hold accountable standards variety levels abstraction instrumental may describe system functioning properly adequately rates risk rates risk equal way across demographic groups holding system’s performance objective mathematical standard correctness systems level might hold credit risk predictions standard defensibility litigation another oversight mechanism societal level might ask whether distribution risk elucidated system correct moral appropriate dis tribution holding standard fidelity normative goals determining extent standards met requires different approaches based level analysis different actors correctness relates tech nical decisions system’s design oversight implicates specific entity policy receiving examining answers system behaved normative fidelity ever constructed social political processes often systems affect operative norms much norms constrain system behavior correctness two meanings fidelity specification usual meaning engineering consonance normative context thus operative questions sys tem follow rules laid rules right rules often unit analysis referenced someone discussing accountability relates disciplinary training orientation interested technology develop ment design analysis likely conceptualize systemasembodiedin amachine situating algorithms agency ai systems within machines designers political social legal demands accountabil ity often focus around higherorder units sociotechnical systems artifacts interacting people entire paradigms social organization companies govern ment agencies etc often units analysis inform appropriate interventions sup porting accountability attending accountability levels necessary related unit analysis question issue causal moral responsibility operationalizing accountability important relationship answer ability corresponds either subject causing condition answerable moral culpable condition cases law explicit norms assign culpability entity either directly via oversight process wiebe e bijker thomas parke hughes trevor j pinch eds social construction technological systems new directions sociology history technology cambridge mit press accountability computer systems link exists information conveyed within accountability relationship establish link difficult find actor accountable operationalizing accountability ai systems requires developing ways make links explicit communicable example scapegoating component portion problem impair agency involved actors establishing fault additional problem many hands serve barrier accountability ariane flight failure12 many hands responsible failure responsible collectively prevented one individual function responsible direct causal manner thus moral sense whole group responsible together seen advantageous without direct accountability exploration pos sible risk taken need case alternative governance structures multifaceted crossfunctional development teams could example explicitly make leaders responsible providing incentive ensure adequate performance avoidance failures across organization preserving direct responsibility moral purposes complex systems rarely yield clear analysis causality13 could support better outcomes future mechanisms could also make domains answerability clear level functions organizations accountability oversight review conceptualize accountability answerability various kinds understand must answer answers intended rede veloped concept oversight tool governance designated authority holds special power review evidence activities connect conse quences oversight complements regulatory methods governance allowing checks controls process even correct behavior process cannot specified advance rule rather oversight entity observe actions behaviors process separate acceptable ones unacceptable ones ex post rules exist oversight entity verify process acted con sistently within computer science engineering general twin modalities guarantee ing compliance formal stated policy ex ante keeping records provide auditing ex post long recognized major approaches understand ing fidelity artifact goals correctness security privacy14 however dominant modality—whether building software hardware control lers rockets aircraft bridges buildings—has decide rule helen nissenbaum “accountability computerized society” science engineering ethics –richard cook “how complex systems fail” cognitive technologies laboratory university chicago daniel j weitzner harold abelson tim bernerslee joan feigenbaum james hendler gerald jay sussman “information accountability” communications acm joshua kroll front express rule set requirements system implement sys tem faithful requirements validate implementation comports requirements way conformance artifact rule known ahead time approach quite powerful often highly desirable materials expended construction however insufficient norms exceedingly complex contested require interpretation order enforced features domains ai systems desirable domains include application many legal obligations stated standards principles including data protection regimes eg determining whether consent “informed” copyright eg establishing whether copying constitutes fair use use protected data law enforcement intelligence activities eg granting orders allowing investigators access protected information cases involving duties care situations exist concerns fairness bias nondiscrimination15 beyond law enforcement often process managing exceptions rules without risking substance rule inherently interpretive discretionary exercise enabling governance beyond setting rules critical many norms obligations resist formalization concrete rules proper operationalization certain value sensitive concepts fairness may contested among stakeholders achieving political consensus cases may require intentional vagueness deferral authority designated entity example legislatures general defer specifics rulemaking regulatory authorities may knowledgeable better able react changing circumstances also defer specifics administering law particular cases courts judges balance values ten sion review cases certainty happened view retro spective prospective beyond concepts may essential contested16 meaning stake holders agree broad outlines concept question inherent agree ment disagreement correct way realize world fairness excellent example—although many stakeholders particular context may wish ai system behave fairly fair may fair others setting rules constitutes fairness must nature set stakeholders tension privacy also described essential contested concept17 accountability provides framework reorganizing problem resolving casebycase manner stakeholders may able agree process daniel j weitzner harold abelson tim bernerslee joan feigenbaum james hendler gerald jay sussman“information accountability” mit technical report mitcsailtr2007–june walter bryce gallie “essential contested concepts” proceedings aristotelian society deirdre k mulligan colin koopman nick doty“privacy essential contested concept multidimensional analytic mapping privacy” philosophical transactions royal society mathematical physical engineering sciences accountability computer systems mechanism weighing countervailing concerns particular cases even cannot agree proper operationalization acceptable versus unacceptable behav ior system front deferring enforcement make space inter pretive nature goals expressed standards principles rather via mechanical operation rule oversight critical operationalizing accountability practice building ai sys tems support accountability process eg entity prop erty necessitates designing systems support robust oversight implies establishing evidence ai systems created operating enabling job overseer may already established encompassing human process18 way accountability tied directly maintenance records job oversight entity characterized applying appropriate norms context ai system’s deployment tie actions described records consequences accountability accounting recordkeeping verifiability simplest definition accountability terms accounting keeping records system actions reviewed later important records faithful recordings actual behaviors support reproducibil ity behaviors analysis additional records must integrity maintained time created time must reviewed review process reliably examines seen others examine faithful records describe purport describe final important fidelity integrity records evident overseer one relies overseer’s judgments oversight entity reviewed falsely demonstrate compliance oversight al cases causes behaviors “blackboxed”—ignored pur poses recordkeeping case example human bureaucracies cannot demand full causal explanation behaviors opinions human functionaries structure even could explication behavior terms neuronal activations connections would complex meaning less providing little way epistemic grounding outcome bureau cratic process instead processes develop explanations justifications appropriately selective contrastive describing needs known cor rect people useful level abstraction19 thus determining keep joshua krol “the fal acy inscrutability” philosophical transactions royal society mathematical physical engineering sciences tim miller “explanation artificial intelligence insights social sciences” artificial intel igence –joshua kroll records ai system behaviors important design consideration best way determine records best support accountability determine oversight necessary determine facilitate oversight additional records often useful directly subjects decisions ai systems public large case system design also involve questions develop direct accountability subjects public rather accountability interme diated political trust oversight entity recordkeeping common operationalization accountability computer sci ence technologyoriented fields20 feigenbaum et al provide survey taxon omizing recordkeeping along dimensions time goals records kept sorts violations policy records aim capture information infor mation learned policy violations policy violators action actions taken based records policy violations21 approach views account ability respect concretely defined policy violations policy authors go far define accountability property policy violation attributed violator way allows assignment blame however seen concept oversight accountability need depend ex ist ence prespecified concrete policy—it may also operate synthesizing policy extensional ex post ie based analysis particular cases normative guidance forms standards principles additional existence records immediately imply system truly answerable behaviors outcomes caused behaviors records ignored unseen simply acted upon little facilitate accountability must expand concept account ability tie content records broader principle responsibility accountability responsibility answerability includes notion answers exist individuals orga nizations made answer outcomes behavior behavior tools make use responsibility ties actions outcomes consequences authors space identified three major normative bases connection causality fault duty— either actions entity held accountable caused outcome considered entity somehow culpable outcome irrespective cause entity ascribed obligation engage certain behaviors three types responsi bility relationship accountability subtle bear unpacking operationalizing one three make practical necessary accountability mech anisms regimes subject much work across several disciplines wendy nelson espeland berit irene vannebo“accountability quantification law” annual review law social science –joan feigenbaum aaron jaggard rebecca n wright hongda xiao“systematizing university press accountability computer systems notion causality complicated question rich history inquiry form metaphysics leave history aside however dominance scientific approach understanding causation development technical artifacts especial ai systems relevant inquiry22 scientific approaches look ful mechanistic explanations experimental validated knowledge establish facts struggle establish causes phenomena distinguish causal relationships relationships example situations variables confounded challenging establish whether measured effect causal illusory23 confounding occurs multiple factors correlate certain outcome confusion associations represent cause limiting extent one assigned responsibility building machinelearning system predicting mortality risk pneumonia patients researchers discovered patients previously diagnosed asthma performed better group result models rated lower risk nearterm death domain experts doctors disagreed ing asthma patients much higher fatality risk pneumonia patients without asthma diagnosis problem lay quirk training data hospital rule patients diagnosed pneumonia previously diagnosed asthma automatical admitted intensive care giving cohort aggressive treatment careful monitoring leading better outcomes confusing statistical models24 events often multiple causes reasoning appropriate set causes event challenging modern mechanisms reasoning mathematical causality general reason simple causation causation context controlled experiments often possible questions interest lead ing situation inferences causality formalisms tell portion story25 causal analysis often proceeds reasoning counterfactuals claims state world would resulted event occur new event occur observable feature world different context reasoning accountability ai systems counterfactuals present interesting difficulty consider system might behaved hypothetical world different one inhabit must understand relationship worlds interpret counterfactual simplest sort counterfactual merely intro duces removes putative cause practice situations wish reason involve complicated interactions implicate existing social structures con figuring hypothetical counterfactual world way unlikely mario bunge causality modern science new york dover publications momin malik “a hierarchy limitations machine learning” arxiv preprint arxiv rich caruana yin lou johannes gehrke paul koch marc sturm noemie elhadad proceedings 21th acm sigkdd international conference knowledge discovery data mining acm –httpsdlacmorgcitationcfmid2788613 judea pearl causality cambridge cambridge university press joshua kroll perspective world example simply changing individual’s race gender holding attributes unlikely produce counterfactual case analyzed sensible manner26 concepts race gender co constructed number factors challenging find meaning shifting experience given subject radical stil causal responsibility key component accountability simple reason system answer behavior important understand causal ori gins behavior possible however understanding mechanisms causa tion answer question mechanisms function ways leading question fault moral responsibility dichotomy correct ness mentioned earlier ask mechanism decision sep arately normatively whether mechanism right mechanism comports social political legal contexts values fairness justice moral responsibility ascribes moral valence actions responses actions praise conforming operative norm blame violating causal responsibility moral responsibility requires agency ability behaved differently situation control operative outcome could effected example moral blame requires entity causal related event moral ascription made entity’s actions way faulty different actions would moral sense better since aristotle philosophers judged appropriateness moral blame making moral judgments based traits relevant agents explicitly vesting moral responsibility voluntary nature moral agent’s control actions27 notion agency raises important sidebar responsibility agents held responsible exactly sufficient agency ascribed causal responsibility moral responsibility duties obligations general implies objects recordkeeping general machines software algorithms entity held answerable must moral agent worthy ascription responsibility ability assigned responsibility key ways tied moral “per sonhood” personhood vest constructed persons—corporate social constructed entities—as well natural persons nature holding constructed persons accountable different holding natural persons responsible responsibility lead punishment natural persons much direct ways constructed persons excellent overview counterfactual reasoning applies ai systems found tim miller “explanation artificial intelligence insights social sciences” artificial intel igence –a detailed version argument counterfactual reasoning constructed attributes found issa kohlerhausmann “eddie murphy dangers counterfactual causal thinking detecting racial discrimination” northwestern university law review andrew eshleman “moral responsibility” stanford encyclopedia philosophy winter edition ed edward n zalta httpsplatostanfordeducgibinencyclopediaarchinfocgi entrymoralresponsibility accountability computer systems concept tightly bound responsibility yet distinct liability often legal ascription responsibility plight victim particular scenario unlike accountability relational concept responsibility sense answerability action liability analyzed perspective debt owed someone suffered harm28 liability underscores third category responsi bility duty obligation obligations may exist outside answerability relation ships example judge could said responsible sense duty instructing jury prior deliberations responsibility cause judge answer specific entity would say judge accountable however judge could accountable higher courts voters directly competent representative bodies authority impeach via challenges court procedure failing uphold duty liability substitute accountability although help enforce encourage accountability reify agent’s duties encourage agent act remain answerable outcomes related agent’s actions assigning financial cost breaches duties treating liability substitute accountability leads imperfect assessments example ariane case many different functions worked project many people worked functions obscuring lines accountability yet european space agency clearly liable cost failure would liable related harms example rocket caused harm exploding falling earth similarly liability disclaimed organizations often provisioning software ai tools agent using software may control software behaves yet unable hold creator software liable let alone responsible accountability normative fidelity abstract way term “accountability” used connects answerability relationship broader norms values fundamental rights system uphold particular political social legal norm held moral stand ard requirement often couched terms accountability sense moral responsibility29 example bovens schillemans goodin observe politics “‘accountability’ used synonym many loosely defined political desiderata good gov ern ance transparency equity democracy efficiency responsiveness responsibility integrity”political scientists often wonder whether ideas owe great debt nissenbaum’s work separating accountability liability merel noorman “computing moral responsibility” stanford encyclopedia philosophy spring edition ed edward n zalta httpsplatostanfordeducgibinencyclopedia archinfocgientrycomputingresponsibility mark bovens thomas schillemans robert e goodin“public accountability” oxford handbook public accountability ed mark bovens robert e goodin thomas schillemans joshua kroll accountability continues hold meaning even operationalizing straightforward evergrowing number places claimed desirable31 yet accountability provides achievable mechanism approaching wise slippery contested normative goals might possible agree definitions “fairness” even “discrimination” agents entities still account able behaviors respect operative norms although noble pur sue computer systems “moral” “ethical” “fair” clear operationalize goal tell achieved however agents develop rely tools made accountable outcomes bring enabling judgments agents answerable standings operative norms violated accountability governance goal notion accountability normative fidelity demonstrates accountability serve governance mechanism accountability straightforwardly achiev able enables judgments complex contested values useful trac table goal governance systems designed meet articulated requirements accountability enables governance within companies around governmental oversight respect public trust interested parties verify systems meet requirements verification operates along lines interested parties would use confirm governance operating intended establishing lines accountability forces governance process reckon values must pro tect promote without needing complete articulation operationalization values makes accountability primary value governance structures strive accountability versus transparency accountability often associated transparency concept systems pro cesses accessible affected either understanding function input structure computer system often means disclosure system’s existence nature scope scrutiny underly ing data reasoning approaches connection operative rules implemented system governing norms context32 yet transparency often insuffi cient undesirable best conceptualized instrument achieving richard mulgan “ ‘accountability’ everexpanding concept” public administration frank pasquale black box society cambridge harvard university press accountability computer systems accountability understanding values—such fairness privacy nondiscrimi nation—requires similar shift transparency serves goals instrumental mak ing values cognizable allowing recognition values reified system accountability moral agents transparency instruments example lottery perfectly transparent process abstract yet ensur ing computerized lottery operates faithful ie picks uniformly set entries designated winner exceptional difficult fraught task even physical lotteries require elaborate ceremonies demonstrate possible numbers entered physical mixing device sufficiently randomized without extra selections becoming possible33 although core selection algorithm lottery simple understand easy program correctly relies random choices construction must repeatable making review lottery outcome intrinsi cal difficult—because random choice good chosen value choice predictable lottery operator cannot distinguished one even correctly implemented software lottery run low cost millions billions times creating set winning options preferred winner selected ex post problem demonstrating every entry lottery considered equal footing additional illegitimate entries added difficult though feasible solve modern computer science transparency alone insufficient ensure lottery effects fairly simple goals instead entire process must make clear properties required outcomes hold violations prop erties detectable know actors responsible deviated goal outcome illegitimate reasons held accountable similarly actors praised process operates faithful beyond insufficiency transparency undesirable many contexts leading situations subjects decisions alter behavior strategical violate operative norm example procedures military instal ation’s guarded gate always adversary establish weaknesses procedures exploit prevent procedures changed often unpredictably adversary knows procedures effect day use knowledge attempt overcome procedures weakest gaining access instal ation days guards lackadaisical logic applies employees pilfering cash til burglars approaching target smugglers crossing border control point general use meas ure target control often leads people change behavior maximize benefit phenomenon known goodhart’s law34 example test scores used measure educational achievement student achievement core meas ure teacher performance teachers incentivized train students perform joshua krol solon barocas edward w felten joel r reidenberg david g robinson harlan yu “accountable algorithms” u pa l rev charles e goodhart “problems monetary management uk experience” monetary theory practice –london palgrave joshua kroll well known tests rather understand underlying material confusing practices education training35 final full transparency often trades values related confidentiality whether confidentiality protects personal privacy individuals affected com puter system proprietary intellectual property interests system’s creators operators level transparency required governance often trades disclo sure legitimate secrets reason wel best think terms answer ability relationships accountability agents create control ai systems establishing computersystem governance mechanisms mechanisms accountability ai course transparency useful tool governance computer systems mostly insofar serves accountability extent targeted partial transpar ency helps oversight entities subjects computer system’s outputs public large understand establish key properties system transparency provides value mechanisms available building computer systems sup port accountability creators operators first key understand interests desired accountability serves establish answerability relationships agents accountable agents outcomes purpose established clearer records must kept support interrogation relationship ensure blame punishment meted appropriate agents appropri ate cases records must retained manner guarantees relate relevant behavior computer system faithful representing relationship inputs logic outputs accomplished tools modern computer science cryptography software verification type systems computer programming languages record fidelity maintained across time space using cryptography wel beyond mechanisms apply specifical software however important consider accountability governance mechanisms relate desired accountability relationships process engineering design function organizations companies create software artifacts tools include practices encourage structured reflection needs engineered system captured design rules demanding documentation requirements specifi cations rules demanding testing acceptance validation ensure produced artifacts comport documentation rules demanding documentation users operators oversight entities additional organizations structure review processes adversarial maintain rules requiring multiple authority effect changes wendy nelson espeland michael sauder “rankings reactivity public measures recreate social worlds” american journal sociology –accountability computer systems documentation code documenting change management accordingly organizations often demand requirements specifications reviewed expert teams security privacy practices compliance readiness release organizations demand staff produce documentation public impact assessments disclose possible adverse effects systems constructed36 public documentation serves function even largely creation forces organizations consider develop systems presented best possible light organizations also ensure people functions within organization responsible particular domains clearly articulated domains responsibility documented widely understood final systems general arise lifecycle must truly cycle performance final system must measured evaluated con sidered initial goals future updates fixes system deployed work arounds issues immediately addressable consider ariane failure framework would thinking terms account ability tools prevented failure failure caused explicit decision protect numeric conversions certain hardware registers sake efficiency although decision taken previous vehicle generation ariane relevant code reused blindly clearer lines responsibility failure likely additional preflight simulation testing could demanded problem identified careful systems engineering would revealed allowing subroutine needed ground run liftoff harm less believed least would invited careful evaluation prelaunch processes best way handle momentary launch delay one contemporary author noted failure “ariane teach us ‘political’ facets engi neering processes good process needs regulate systems designed developed also highlevel decisions design development arrived at”in light fact engineering function could held accountable massive failure seems hardly surprising even failure proxi mately traced clear errors construction software whither accountability ai ideas lead us accountability ai systems ends account ability serve means achieving human values political questions reflecting ai systems political act consequences dillon reisman jason schultz kate crawford meredith whittaker“algorithmic impact assessments practical framework public agency accountability” ai institute httpsainowinstituteorgaiareport2018pdf dowson “ariane software failure” joshua kroll real world must connect consequences existing political decision making systems viewing gap system behaviors contextual norms terms accountability holding actors moral agency accountable actions bridge gap moral demands good governance seeming amorality human artefacts focusing accountability builds checks tool’s perfor mance consistent specification process validate conformance tool’s behavior democratic norms inherently political assessment38 need practices great critical establish engi neered objects supposed including necessary satisfy articulated accountability relationships actual reduction practice tools way demonstrably supports accountability human values remains important open question research many tools technologies exist beginning understand compose serve accountability values bibliography breaux travis matthew w vail annie anton “towards regulatory compliance extracting rights obligations align requirements regulations” 14th ieee international requirements engineering conference re’–ieee desai deven r joshua krol “trust verify guide algorithms law” harv jl tech feigenbaum joan aaron jaggard rebecca n wright hongda xiao “systematizing ct yale university press krol joshua “the fal acy inscrutability” philosophical transactions royal society mathematical physical engineering sciences krol joshua solon barocas edward w felten joel r reidenberg david g robinson harlan yu“accountable algorithms” u pa l rev miller tim “explanation artificial intelligence insights social sciences” artificial intel igence –nissenbaum helen “accountability computerized society” science engineering ethics –reisman dillon jason schultz kate crawford meredith whittaker “algorithmic impact assessments practical framework public agency accountability” ai institute httpsainowinstituteorgaiareport2018pdf wachter sandra brent mittelstadt “a right reasonable inferences rethinking data protection law age big data ai” columbia business law review wieringa maranke “what account accounting algorithms systematic literature review algorithmic accountability proceedings conference fairness accountability transparency fat ’–new york association computing machinery weitzner daniel j harold abelson tim bernerslee joan feigenbaum james hendler gerald jay sussman“information accountability” mit technical report mit csailtr2007–june jessica eaglin “constructing recidivism risk” emory lj –chapter transparency nicholas diakopoulos accountability transparency algorithms artificial intelligence algorithmic decisionmaking adm technologies hidden everywhere today’s modern society calculate credit scores automati cal update online prices predict criminal risk guide urban planning screen appli cants employment inform decisionmaking range highstakes settings1 everyday experiences online media pervaded ability algorithms shape moderate influence ideas information exposed apps feeds search engines given immense potential systems consequential yet sometimes contestable outcomes wide swath human experi ence society seek hold systems accountable ways may make mistakes otherwise bias influence harm exert power individuals society2 accountability turn relevant entity answering taking responsibility lack apt behavior violation ethical expectation accountability algorithmic systems must way know lapse behavior essay argue transparency useful mechanism monitoring algorithmic system behavior provide necessary informational pre conditions promote ensure accountability3 nicholas diakopoulos “the algorithms beat” data journalism handbook ed liliana bornegru jonathan gray amsterdam university amsterdam press danielle keats citron frank pasquale “the scored society due process automated predictions” washington law review nicholas diakopoulos “algorithmic accountability journalistic investigation computational power structures” digital journalism –transparency seen ethical principle per se rather enabling factor support monitoring behavior respect ethical expectations nicholas diakopoulos transparency defined “the availability information actor allow ing actors monitor workings performance actor”in words transparency information related outcomes procedures used actor relational involving exchange information actors5 transparency therefore provides informational substrate ethical deliberation system’s behavior external actors hard imagine robust debate around algorithmic system without providing relevant stakeholders information detailing system operates yet it’s important emphasize transpar ency sufficient ensure algorithmic accountability among contingencies true accountability depends actors mandate authority act transparency information consequential ways transparency held unrealistic ideal unilateral leading effective accountability algorithms—it must wrapped governing regimes may instances demand answers capacity sanction6 things seek make transparent focus chap ter particular algorithmic decisionmaking adm systems adm systems tools leverage algorithmic process arrive form decision score ranking classification association may drive system action behavior systems could said exhibit artificial intelligence ai insofar contribute decisionmaking tasks might normal undertaken humans though distinction particularly germane elaboration algo rithmic transparency described what’s important underscore rather adm systems must understood composites nonhuman ie technological actors woven together human actors designers datacreators maintainers operators complex sociotechnical assemblages7 even considering systems far end autonomy act particular moment without human oversight one still find human influence exercised designtime8 end goal accountability transparency must serve help locate structural indirectly time various positions human agency responsibility large complex sociotechnical assemblages ultimately people must held accountable behavior algorithmic systems9 albert meijer “transparency” oxford handbook public accountability ed mark bovens robert e goodin thomas schillemans oxford oxford university press –jonathan fox “the uncertain relationship transparency accountability” development practice –for elaboration extant approaches governance algorithms see florian saurwein natascha michael latzer “governance algorithms options limitations” info –mike ananny “toward ethics algorithms” science technology human values model spectrum autonomous action see raja parasuraman thomas b sheridan christopher wickens “a model types levels human interaction automation” ieee transactions systems man cybernetics—part systems humans –despite ability artifacts exhibit causal agency ie capacity act intentional agency ie capacity intentional action therefore cannot held responsible transparency following sections chapter elaborate think necessary realis tical implement algorithmic transparency terms disclosed transparency information disclosed consider range moderating fac tors may variably impact success algorithmic transparency depending specific details context adm system factors key understanding governing regimes need configured order encourage algorithmic account ability main contribution thoroughly examine conditions conversely encourage challenge efficacy transparency ethical approach algorithm governance chapter closes call dismiss notions “full transparency” exchange careful engineered contextspecific algorithmic transparency policies enacting algorithmic transparency algorithmic transparency cannot understood simple dichotomy sys tem “transparent” “not transparent” instead many flavors grada tions transparency possible may driven particular ethical concerns warrant monitoring specific aspects system behavior relevant fac tors include type scope reliability information made available recipients transparency information plan use relationship disclosing entity recipient10 factors interrelationships shape effectiveness algorithmic transparency contributing accountability terms transparency information one distinguish transparency outcomes system ie versus transparency processes algo rithm enacts people enact terms governance applied design development operation system ie how11 cases ep iste mic concerns uncertainty validity decision outcome eg predictions creation new knowledge cannot otherwise corroborated may increased need disclose procedures evidence adherence standards accepted procedures different recipients also varying demands needs different types transparency information according context use goals safety inspector accident investigator may need different information assess order ascribe responsibility ie accountability behavior arbitrarily complex systems intentional agency recursively traced back people commissioned andor designed system component systems philosophical treatment rationale argument see deborah johnson mario verdicchio “ai agency responsibility vw fraud case beyond” ai society –paul b de laat “algorithmic decisionmaking based machine learning big data transparency restore accountability” philosophy technology –for distinction see shefali patil ferdinand vieider philip tetlock “process versus outcome accountability” oxford handbook public accountability ed mark bovens robert e goodin thomas schillemans oxford oxford university press –nicholas diakopoulos system globally comparison system operator enduser interested specifics individual decision outcome12 relationships among actors also define different mechanisms shade nature quality information made available including disclosures demanddriven eg freedom information requests proactive eg selfdisclosure via website form published docu mentation forced eg leaked external audited13 demanddriven forced transparency particularly effective shedding light “underperformance mis management forms falling short public standards”while proactive transparency information might strategical shaped distorted unreliable therefore less conducive accountability15 time proactive transparency still serve stimulate production information encourages actor attend particular ethical considerations may reflected wise proactive transparency disclosures ideal include information procedures used generate transparency information adherence industry standards epistemic principles related accuracy veridicality16 various factors contingencies makes transparency work promote accountability underscore idea rightly understood human centered technical communication challenge amongst various strategic actors minimum however transparency must serve increase available information present information people make sense purposes designers must consider information communicate communicate different types recipients following subsections sketch abstract terms practice questions disclose disclose stakeholders highly contextspecific benefit humancentered design processes allow tailoring specific usecases made transparent algorithms algorithms sometimes framed black boxes obscure inner workings behind layers complexity technical induced opacity17 indeed sophis ticated models may rely millions parameters resulting mathematical functions confound human efforts ful understand time various pieces alan f winfield marina jirotka “ethical governance essential building trust robotics artificial intelligence systems” philosophical transactions royal society meijer et al “transparency” fox “uncertain relationship” meijer et al “transparency” nelson granados alok gupta “transparency strategy competing information digital world” mis quarterly –matteo turilli luciano floridi “the ethics information transparency” ethics information technology –jenna burrel “how machine “thinks” understanding opacity machine learning algorithms” big data society –transparency information nonetheless produced elaborate design implementa tion characterize process output describe used function practice knowable would argue enough extent governed consider analogy favorite restaurant even recipes may known chef kitchen inspection still expose issues ingredients handling transparency information exposed via res taurant inspection incomplete nonetheless effective improving restaurant food safety18 transparency contribute governance algorithmic systems policy makers first need articulate range possible bits information could feasibly made available systems starters order provide basic awareness adm systems disclose fact algorithmic process operation addition many types information might disclosed algorithmic systems across several key layers research begun elaborate including level nature human involvement data used training oper ating system algorithmic model inferences briefly outline following subsections human involvement human decisions intentions actions woven throughout adm systems way sometimes make difficult see parse technical components yet design decisions intentions eg variables optimize design whether specific ethical principles attended important consequences ethical performance system19 effective application algorithmic transparency strive locate relevant aspects human involvement design operation management system instance ai systems keep humans loop operation examining suggestions ai system arrive final decision output providing feedback system improve even stepping automation failure20 transparency regarding design decisions level automation nature type human involvement would shed light human agency within opera tional system transparency might also entail explaining organizational goal pur pose intent adm system intended uses outofscope uses envisioned designers help avoid emergent biases may arise context around system changes evolves21 system might also transparent archon fung mary graham david weil full disclosure perils promise transparency new york cambridge university press felicitas kraemer kees van overveld martin peterson “is ethics algorithms” ethics information technology –parasuraman et al “model types levels” batya friedman helen nissenbaum “bias computer systems” acm transactions information systems –nicholas diakopoulos identifying individuals responsibility engineering maintaining overseeing design operation system idea individuals might feel greater sense responsibility name reputation stake22 contact information included responsible people involved system could offer ave nues redress face adverse events associated system23 data data core component adm systems particularly rely machinelearning models learn patterns sets training examples data biased model learned data also exhibit bias example new york times online outlets use statistical models help moderate online comments corpus comments evaluated man ual used train algorithm classify future comments “toxic” data end biases built system research shown men women rate toxicity comments subtly different ways men produce majority training data bias expected reflected subse quent decisions classifier makes24 standards data documentation disclosure datasheets datasets dataset nutrition label well work begin outline various ways creators adm systems transparent data using rationale various datarelated design decisions25 important dimension transparency relates quality data used including accuracy completeness timeliness update frequency uncertainty factors might disclosed representativeness sample given populations interest provenance dataset terms initial collected including motivations intentions funding sources well assumptions limitations exclusions transformations related editing preprocessing normalizing cleaning nicholas diakopoulos “accountability algorithmic decision making” communications acm cacm –nicholas diakopoulos sorelle friedler “how hold algorithms accountable” mit technology review november httpswwwtechnologyreviewcoms602933 howtoholdalgorithmsaccountable reuben binns michael veale max van kleek nigel shadbolt “like trainer like bot inheritance bias algorithmic content moderation” social informatics socinfo ed giovanni luca ciampaglia afra mashhadi taha yasseri vol10540 lecture notes computer science cham springer international publishing sarah hol ahmed hosny sarah newman joshua joseph kasia chmielinski “the dataset nutrition label framework drive higher data quality standards” arxiv timnit gebru jamie morgenstern briana vecchione jennifer wortman vaughan hanna wal ach hal daumeé iii kate crawford “datasheets datasets” workshop fairness accountability transparency machine learning nicholas diakopoulos michael koliska “algorithmic transparency news media” digital journalism –transparency data26 transparency include definitions meanings variables data well measured since consequential later interpretation contestation model outputs interactive personalized sys tems may furthermore possible transparent dimensions personal data used adapt system individual data people collected used adm system operation training may appropriate disclosure whether consent obtained various policy decisions use data adm also made transparent might include disclosing entity responsible maintaining dataset describing updated indicating whether data public private distribution license copy right associated model inferences much like data previous work begun enumerate various aspects com putational models could made transparent27 details model disclose might include features weights type model used well metadata like date model created version model might also incorporate heuristics thresholds assumptions rules constraints might useful disclose along design rationale chosen cases codelevel transparency model could necessary however often abstracted aggre gated forms information disclosure useful produced model made available eg via application programming interface api allows external entities query system data executable software routine example output inferences algorithmic process clas sifications predictions recommendations identified benchmarked using standard datasets order tabulate disclose performance comparison expec tations may particularly pertinent cases issues fairness con cern fairness across various demographic categories evaluated transparency information might also include error analysis remediation mitigation procedures dealing errors well confidence values uncertainty information inferences human role rationale modeling process may also important disclose assessing model performance metrics used instance different stakeholders may differently impacted model tuned reduce false negatives instead false positives28 details various issues related ethical data collection transformation see nicholas diakopoulos “ethics datadriven visual storytelling” datadriven storytel ing ed n riche c hurter n diakopoulos carpendale boca raton fl crc press –margaret mitchel simone wu andrew zaldivar parker barnes lucy vasserman ben hutchinson elena spitzer inioluwa deborah raji timnit gebru “model cards model reporting” proceedings conference fairness accountability transparency –diakopoulos koliska “algorithmic transparency news media” see chapter nicholas diakopoulos automating news algorithms rewriting media cambridge harvard university press nicholas diakopoulos transparency disclosures contrary characterizations adm systems unknowable black boxes clear preceding section still lot potential informa tion could disclosed algorithms information must presented recipients stakeholders ways actual make sense connect specific goals—designers must strive usable transparency considering entire gamut potential information could disclosed designers craft information meaningful useful presentations people highly contextspecific depend tasks enduser types decisions might trying make based behavior algorithm ques tion sense algorithmic transparency must draw humancentered design methods order model user need transparency information might disclosed could user know algorithm would change interaction system ultimate decision outcome designs evaluated assess well endusers able understand disclosures intended purposes pragmatical speaking transparency information formatted number different modalities structured databases documents written texts per haps even using natural language generation via visual interactive interfaces29 appropriate modality depend specifics information conjunction user goals interactivity presentation furthermore enable endusers inter rogate system different ways allowing adapt transparency informa tion attend based context goals interactive dynamic displays transparency information may also wellsuited algorithms changing therefore need monitored time alternatively different presentations trans parency information produced different audiences linked multi level “pyramid” structure information progressively unfolds denser detailed transparency information given stakeholder wants drill it30 point it’s worth differentiating transparency disclosures particular ized expressions algorithm behavior intended endusers explanations justifications rationales31 explanation entails system articulating made particular decision typical causal eg input influence sensitivitybased involves casebased comparisons32 whereas transparency disclosure involves descriptions example see diakopoulos “accountability algorithmic decision making” nicholas diakopoulos “enabling accountability algorithmic media transparency constructive critical lens” towards glassbox data mining big small data ed tania cerquitelli daniele quercia frank pasquale cham springer –brent mittelstadt chris russel sandra wachter “explaining explanations ai” proceedings conference fairness accountability transparency –reuben binns et al “‘it’s reducing human percentage’ perceptions justice algorithmic decisions” proc human factors computing systems chi transparency system behavior design intent leaves final causal explanation system behavior evaluation information disclosures interested stakeholders problem systemproduced explanations often approximate fail accurately represent true causality decision also selective presentation leave inconvenient information consider moment types explanations might seen platforms like facebook twitter describing saw particular ad site system told seeing ad advertiser wanted reach “people ages live united states” sure explanation hiding information precisely indicative seeing ad—particularly know visited advertiser’s site earlier day aware ad system likely targeting tracked across sites systemgenerated explanations may add repertoire information disclosed including “what if” contrasts behavior aid understanding explanations must made transparent algorithm generating explanation held account able unethical behavior deception leaving pertinent details shap ing explanation suggest conclusion advantageous system operator return premise chapter end goal accountability would argue presentations transparency information stakeholders rely systemgenerated explanations rather strive enable stakeholders come conclusions system behavior problematizing algorithmic transparency enumerating could disclosed algorithms relates information disclosed necessary seeing transparency could contribute accountability algorithms nonetheless elaborate following subsec tions many conceptual pragmatic factors collectively problematize application efficacy transparency purposes algorithmic account ability33 include issues like gaming manipulation understandability privacy temporal instability sociotechnical intermingling costs competitive concerns legal contexts criticisms transparency often cite one issues factors understood less undermining premise transparency moderators must taken account order design configure mike ananny kate crawford “seeing without knowing limitations transparency ideal application algorithmic accountability” new media society –de laat “algorithmic decisionmaking based machine learning” jakko kemper daan kolkman “transparent algorithmic accountability without critical audience” information communication society –nicholas diakopoulos effective implementation algorithmic transparency specific context words policy makers might consider factors create constraints bounds type scope transparency disclosures made certain stakeholders means efficacy transparency regime contributing accountability gaming manipulation algorithmic transparency cal disclosure information range human involvements data used train operate system model inferences concern arises rich disclosures could enable entities manipulate behavior system strategical deceptively altering behavior may undermine efficacy system potential even lead toward unethical behavior concern must treated contextual sensitiv ity cases entities direct control particular factor algo rithm attends eg intrinsic behavioral would therefore difficult game moreover cases efforts game system behavior may result shaping toward preferred behavior entities example disclosing exact criteria used creditrating agencies might influence endusers act financial respon sible order “manipulate” credit score positive direction general particular context designers must ask particular type information system disclosed particular recipient might gamed manipulated circumvented taking cue security practices develop threat models identify weaknesses systems would suggest techniques approaches transparency threat modeling developed threat modeling might consider would stand gain lose potential manipulation consequences risks manipulation might individuals public various organizations barriers costs manipulation might whether aspects system could made manipulationresistant contexts analysis might reveal particular piece information made transparent could lead manipulation unsafe example consider ability autonomous vehicle visual recognize stop sign stop vehicle demonstrations shown possible fool ai systems seeing stop sign particular types visual noise added sign therefore risk ai could manipulated way would run stop sign recognize cause accident potential injure someone circumstances car manufacturer make transparent public vision model car uses specific vulnerabilities pinpointed probably would argue model disclosed different set recipients namely trusted certified safety auditors potential working regula tory agency might develop series benchmarks assess susceptibility vision system stop sign deception designers assume potential transparency gaming implies transparency provided look scope type information disclosed understandability one concerns related algorithmic transparency could lead surfeit information difficult parse align questions accountability ethical behavior people interested transparency information though would cautious heeding assertions limited enduser demand usage transparency information provision transparency information popular demand takes interested stakeholders able use transpar ency information purposes accountability set critical engaged recipients transparency information along appropriate expertise make sense evaluate information essential34 ideal presentation matting transparency information aligned goals recipients order make easy understand use possible course strategic move aimed concealment actors might choose disclose much transparency information becomes overwhelming even wellequipped stakeholders mitigate type behavior regulatory interventions might systematize scope presentation particular types transparency information specific contexts cases disclosure technical detailed difficult understand transparency information underlying computer code system may warranted expectation everyone look expectation everything related behavior system could gleaned code since often complex interactions code data human components system point highstakes decision arenas stakeholders may want audit code ensure implemented according high profes sional standards implemented procedure reflects intended policy apparent engineers avoided adhering process like industry best practice could avoided ethical negative outcome might deemed “culpably ignorant” perhaps even negligent35 moreover type inspection important cases may epistemic ethical concerns around conclusiveness validity evidence produced system open science scientists increasingly strive transparent methods data code part derivation new knowledge inspected validated say depending specific ethical concerns stake different levels complexity information may kemper kolkman “transparent whom” carolina alves de lima salge nicholas berente “is social bot behaving unethical y” communications acm cacm –nicholas diakopoulos need disclosed algorithmic systems order ensure monitoring appropriate stakeholders privacy transparency information sometimes come tension ethical consid erations individual privacy sensitive private data individual openly disclosed information could unfairly used person undermine autonomy ways whereas disclosing degree private information public officials may ethical permissible contexts eg journalism normative standards ordinary people may different even cases private data directly disclosed detailed methodological information sometimes permit deanonymization using publicly available information36 ultimately risk privacy violations implications different types indi viduals derivability transparency disclosures either directly indirectly need moderate algorithmic transparency policies temporal instability algorithms potential highly dynamic learning new data becomes available relatively slow moving depending responsible people get around updating system randomness inject uncer tainty outputs algorithms common practice ab testing cause dif ferent people experience different versions algorithm point time internal states systems may ephemeral—scratch memory may consequential yet recorded durable way temporal dynamics algo rithms create practical challenges producing transparency information right sampling interval monitoring disclosure extent audit trails record internal intermediate states machine trade resources needed monitoring algorithms potential changing quickly transparency presentations may also need utilize dynamic inter active techniques convey information also raises question navigating potential comparing different sets transparency information general algorithmic transparency relates accountability attend issue versioning instance investigation schufa creditscoring algorithm germany indicated four versions score use37 earlier versions diakopoulos “enabling accountability algorithmic media” nicholas diakopoulos “what report germany teaches us investigating algorithms” columbia journalism review january httpswwwcjrorgtowcenterinvestigating algorithimsgermanyschufaphp transparency score considered obsolete retired transparency disclosures might mean ingful distinguish different versions algorithms provide rationale changes including explanations contexts older versions might still appro priately used general algorithmic behavior monitored via transparency disclosures must tied version information order ensure accu rate interpretations behavior sociotechnical complexity essay focuses adm systems sociotechnical nature combining non human human actors design operation doubt humans must held accountable impacts systems complexity challenge straightforward attempts assign responsibility human decisions may removed space time ultimate causal efficacy systems instance machinelearning procedures may help system evolve time though still subject definitions parameterizations constraints imposed initial designers data another way adm systems launder human influence described earlier data used train machinelearning systems may produced people whose biases learned represented model search engine like google might suggest biased eg discriminatory search autocompletion learned word association based queries typed users convoluted interrelationships among different technical human components often complicate tend obfuscate accountability lapses ethical behavior fundamental area inquiry demands research toward understand ing distributed responsibility network human algorithmic entities impacted individuals blame biased autocompletion thousands people contributed biased query google’s algorithm learned would argue principalagent relationships come play search engine organization principle designing autocompletion algorithm therefore responsible ensuring ethical synthesis information diverse agents delegated data input ie endusers typing queries general needed “responsibility map” sociotechnical assemblage shows principalagent relationships models assignment apportionment respon sibility based ethical expectations actors38 interesting chal lenge future research produce maps using structured data responsible actors could automatical identified system according differ ent types failures brent daniel mittelstadt patrick allo mariarosariataddeo sandra wachter luciano floridi nicholas diakopoulos costs pragmatic side concerns costs associated producing trans parency information might include time effort required prepare data write detailed documentation interview engineers designers elicit knowl edge design process run benchmark tests polish source code produce pub lishable presentations different recipients new incremental costs may incurred every update system transparency policies need consider costs outlining type scope information expected disclosures depend context including stakes decisions made systems consideration instance highstakes decision exercised government implications individual liberty eg criminal risk assessment system less concerned costs providing whatever transparency information deemed necessary ensure accountability exercise state power competitive concerns disclosing information system works lead organizational concerns undermining technical advantages market disclosing much detail system could make easier competitors imitate even disclosing information patents corporations may want retain information trade secrets order maintain competitive advantages around algo rithms configured parameterized issue algorithms used private sector since governments often procure systems private industry use public sector important underscore transparency nothing various shades transparency may useful sake accountability respecting property rights trade secrets full technical transparency may always called cases needed eg high stakes decisions comes tension trade secrets systems might made available closed review specific recipients legal bound position authority assessing system39 cases process transparency related conditions procedures entities involved closed review provided legal context legal environment may alternately enable constrain access transparency infor mation different avenues via demanddriven proactive forced citron pasquale “scored society” de laat “algorithmic decisionmaking based machine learning” transparency mechanisms algorithms developed government freedom information foi regulations enable demanddriven access stipulating types information members public permitted request attempts request infor mation algorithms united states successful40 others shown inconsistency application laws41 variety exceptions national security privacy law enforcement may cited rejecting requests informa tion trade secrecy exceptions confidentiality agreements may also come play government contracted industry yet despite uneven results public records requests still produce useful information algorithms use records relating contracts software cases even code data mathematical descriptions training materials validation studies correspondence documen tation offer context system works design goals expec tations operation private sector public records requests typical possible except specific narrow cases instance individuals sometimes request report detailing factors played calculation credit score germany reporters able leverage pinhole transparency crowdsourcing thousands requests individuals aggregating build overview credit scoring algorithm’s behavior42 regulation could also directly specify dimensions scope information disclosed proactively entities eg nutrition labeling standardize procedures accurate production transparency information develop auditing accounting regimes ensure standardized procedures faithful implemented reg ulations considered casebycase basis taking full context system account avoiding overly broad mandates regulation area still nascent stage early endeavors general data protection regulation gdpr european union future regulation take larger role standardizing information disclosed particular highstakes contexts use legal context also impacts permissibility legality forced transparency mechanisms applied algorithms comes context auditing reverse engineering may involve accessing algorithm systematical order record response variations inputs43 us context american civil liberties union aclu raised concerns computer fraud abuse cfaa statute diakopoulos “accountability algorithmic decision making” katherine fink “opening government’s black boxes freedom information algorithmic accountability” information communication society –robert brauneis ellen goodman “algorithmic transparency smart city” yale journal law technology diakopoulos “what report germany teaches us investigating algorithms” nicholas diakopoulos algorithmic accountability reporting investigation black boxes tow center digital journalism christian sandvig et al “auditing algorithms research methods detecting discrimination internet platforms” presented international communication association preconference data discrimination converting critical concerns productive inquiry seattle wa nicholas diakopoulos may imply website terms service tos agreements prohibit activities scraping could form basis liability cfaa turn may create chilling effect ability researchers journalists gather information algo rithmic behavior whether system treating different inputs fairly legal audit private systems accessible publicly internet may moderating considerations eg resource demands external auditors may place system regulators need grapple carve space forced transparency especial given oftentimes effec tive exposing wrongdoing proactive transparency discussion mythical ideal “full transparency” practical achievable run variety problems outlined chapter full transparency might undermine privacy depending particular case—the specific context matters full transparency might produce much information it’s understandable okay society willing forgo possibility accountability highstakes adm systems put transparency guidelines place ensure understandabil ity full transparency may impossible algorithms black boxes unknowable human mind cases yes still knowable enough govern pragmatical transparency merely producing infor mation promotes effective governance accountability system need concern “ful ” transparency outlined chapter still plenty information disclosed algorithms informa tion inform effective governance systems society needs trans parency policies thoughtful contextualized specific decision domains supported governance regimes take account range problematizing fac tors defining ethical concerns outset design system information pro duction processes developed effectively monitor violation ethical issue information production processes must supported thoughtful reg ulation sets legal context disclosure articulates venue evaluating information capacity compel sanction needed moving forward would recommend engineering approach designing transparency policies specific highstakes adm contexts firstly clear context specific ethical issues need identified well system behaviors would indicate violation ethical issue information needed monitor behavior violation needs enumerated process producing information must put place steps need done humancentered sensitivity order align stakeholders’ needs capacities processing information final governing regime needs account weaknesses threats might undermine efficacy potential implementing regulatory measures contextual transparency specific cases countervailing forces may great overcoming desire perhaps mandate accountability could promoted transparency governing algorithms ai within humanity’s grasp approaches task careful steady process humancentered design seeks engineer context specific algorithmic transparency policies bibliography ananny mike “toward ethics algorithms” science technology human values –ananny mike kate crawford “seeing without knowing limitations transparency ideal application algorithmic accountability” new media society cath corinne “governing artificial intelligence ethical legal technical opportunities challenges” philosophical transactions royal society a376 citron danielle keats frank pasquale “the scored society due process automated predictions” washington law review diakopoulos nicholas “algorithmic accountability journalistic investigation computational power structures” digital journalism –diakopoulos nicholas michael koliska “algorithmic transparency news media” digital journalism –fox jonathan “the uncertain relationship transparency accountability” development practice nos ––fung archon mary graham david weil full disclosure perils promise transparency new york cambridge university press meijer albert “transparency” oxford handbook public accountability edited mark bovens robert e goodin thomas schillemans –oxford oxford university press mittelstadt brent daniel patrick allo mariarosaria taddeo sandra wachter luciano floridi “the ethics algorithms mapping debate” big data society turilli matteo luciano floridi “the ethics information transparency” ethics information technology –chapter responsibility artificial intelligence virginia dignum introduction artificial intelligence ai huge potential bring accuracy efficiency cost savings speed whole range human activities well provide entirely new insights behavior cognition however way ai developed deployed large part determines ai impact lives societies instance auto mated classification systems deliver prejudiced results therefore raise questions privacy bias autonomy selfdriving vehicles raises concerns safety responsibility ai’s impact concerns research development directions ai also systems introduced society debate concerning use ai influence labor wellbeing social interactions healthcare income distribution social areas dealing issues requires ethical legal societal economic implications taken account ai affect everybody thus development ai systems must ensure inclusion diversity—that true consideration humankind determining purpose ai systems therefore responsible ai requires informed participation stakeholders means education plays important role ensure knowledge potential impact ai widespread make people aware participate shaping societal development core ai development lie ideas “ai good” “ai al ” researchers policymakers industry society large increasingly recognize need design engineering approaches ensure safe beneficial fair use ai technologies consider implications ethical legal relevant virginia dignum decisionmaking machines evaluate ethical legal status ai approaches include methods tools systems’ design implementation governance regulatory processes consultation training activities ensure heard able participate discussion endeavor important realize ai stand rather must understood part sociotechnical system responsible approach ai needed—one ensures systems developed good way also developed good cause responsible ai concerns software system also foremost people institutions organizations compose sociotechnical system focus chapter understanding approach look like responsible parties decide systems developed areas application ai applied make decisions affect people society ai reasoning must able take account societal values assess moral ethical considerations weigh respective priorities values held different stakeholders multicultural contexts explain basis reasoning guar antee transparency capabilities autonomous decisionmaking grow perhaps important issue consider need rethink responsibility1 whatever level autonomy social awareness ability learn ai systems artifacts constructed people fulfill goals theories methods algorithms needed integrate societal legal moral values technological developments ai stages development analysis design construction deployment eval uation frameworks must deal autonomic reasoning machine issues consider ethical impact also impor tantly must guide design choices regulate reaches ai systems ensure proper data stewardship help individuals determine involvement values dependent sociocultural contexts2 often implicit delib eration processes means methodologies needed elicit values held stakeholders making explicit lead better understanding trust artificial autonomous systems ethics ai related several levels3 ethics design technicalalgorithmic integration ethical reasoning capabilities part behavior artificial autonomous systems ethics design regulatory engineering methods support analysis evaluation ethical implications ai systems integrate replace traditional social structures virginia dignum “responsible autonomy” proceedings twentysixth international joint conference artificial intel igence ijcai ’palo alto ca aaai press –elliot turiel culture morality social development context conflict cambridge cambridge university press virginia dignum “ethics artificial intelligence introduction special issue” ethics information technology –responsibility artificial intelligence ethics design codes conduct standards certification processes ensure integrity developers users research design construct employ manage artificial intelligent systems ai reasoning able take account societal values moral ethical considerations weigh respective priorities values held different stakeholders various multicultural contexts explain reasoning guarantee transparency responsible ai human responsibility development intelligent systems along fundamental human principles values thus ensuring human flourishing wellbeing sustainable world fact responsible ai ticking ethical “boxes” report development addon features switchoff buttons ai systems rather responsible ai fundamental autonomy one core stances underlying ai research art ai artificial intelligence defined development computer systems able perceive environment deliberate best act order achieve goals assuming environment contains agents similar itself4 ai systems characterized autonomy decide act ability adapt learning changes affected environment interact agents order coordinate activities environment5 reflect societal concerns impact ai ensure ai systems developed responsibly incorporate social ethical values characteristics autonomy adaptability interaction complemented design principles ensure trust characteristics relate directly technical system however impact consequences ai system reach technical system system seen sociotechnical system encom passing stakeholders organizations involved previously proposed complement autonomy responsibility interactivity accountability adap tation transparency6 form art accountability responsibility transparency principles responsible trustworthy ai concern whole ai sociotechnical system addressing art require sociotechnical approach design deployment use systems interweaving software solutions gov ern ance stuart russell p norvig artificial intel igence modern approach 3rd ed london pearson education luciano floridi j sanders “on morality artificial agents” minds machines virginia dignum “responsible autonomy” virginia dignum regulation moreover even though art principles apply aspects ai systems imperative specific characteristic depicted figure accountability refers requirement system able explain jus tify decisions users relevant actors ensure accountability decisions derivable explained decisionmaking mechanisms used also requires moral values societal norms inform purpose system well operational interpretations elicited open way involving stakeholders responsibility refers role people relation ai systems chain responsibility grows means needed link ai systems’ decisions input data actions stakeholders involved systems’ decisions responsibility making rules govern intelligent machines whole sociotechnical system system operates encompasses people machines institutions transparency indicates capability describe inspect reproduce mecha nisms ai systems make decisions learn adapt environ ment along provenance dynamics data used created system moreover trust system improve ensure openness affairs related system transparency also explicit open choices decisions concerning data sources development processes stakeholders transparency required models use human data affect human beings moral significant impacts properties enable agents deal effectively kinds environments live work environments may unpredictable dynamic space time include situations one never encountered ai systems capable expected act environments need able trust exhibit undesirable behavior least need limit effects unex pected behavior however interactive system autonomous adaptable hard verify predict turn lead unexpected activity therefore accounta nsparency intera b c ili ty ai ion adaptability tra system autonomy responsibility figure art principles accountability responsibility autonomy responsibility artificial intelligence design methodologies needed take issues account means ensure ai systems reliable acceptable accepted whole principles inform design ai systems art imposes requirements ai systems’ design architecture condition develop ment process systems’ architecture even though obviously art principles apply aspects ai systems especial relevant one characteristics ai depicted figure one cannot autonomy without form responsibility interac tion without accountability adaptability without transparency moreover addressing art require sociotechnical approach design deployment use systems interweaving software solutions governance regulation perspective system development art requires new forms new methods support integration ethical societal impact ai systems engineering process al art requires training awareness stakeholders—including research ers designers programmers managers procurement users—that enables understand assume role overall process note fundamental difference accountability responsibility even terms often used interchangeably synonyms putting simply accountability refers ability explain report one’s role events actions whereas responsibility duty answer one’s actions responsibility entails lia bility exists task action done accountability evident action done done person delegates task agent artificial human result task still responsibility delegating person prin cipal one liable things go expected agent ever must able give report task executed explain eventual problems execution basis principalagent theory often used explain relationship people autonomous systems7 taking responsibility order design ai systems sensitive moral principles human values methods responsible ai rests three pil ars equal importance firstly society must prepared take responsibility ai impacts means researchers developers trained aware responsibility concerns development ai systems direct impacts society requires extra efforts developing delivering education training materials well develop ment codes conduct ai developers turn development requires kathleen eisenhardt “agency theory assessment review” academy management review –virginia dignum methods tools understand integrate moral societal legal values technological developments ai means responsible ai firstly issue governance govern ments citizens determine issues liability regulated example blame selfdriving car harms pedestrian builder hard ware eg sensors used car perceive environment builder software enables car decide path authorities allow car road owner personalized car’s decisionmaking settings meet preferences current product liability laws understood face systems act result long autonomous learning process questions must informing regulations societies put place toward respon sible use ai systems secondly responsible ai implies need mechanisms enable ai systems act according ethics human values whether design way ai systems already making decisions would consider ethical flavor made people aware responsible ai design systems take implicit “ethical” decisions design system ensure refers decision someone take ethical decision border decisions ethical ones requires models algorithms represent reason take deci sions based human values justify decisions according effect values current deeplearning mechanisms unable meaningful link decisions inputs therefore cannot explain acts ways understand last certainly least responsible ai participation necessary understand different people work live ai technologies across cul tures order develop frameworks responsible ai fact ai stand must understood part sociotechnical relations diversity education plays important role ensure knowledge potential ai widespread make people aware participate shaping soci etal development basis ensure diversity inclusion new ambitious form governance one pressing needs order ensure inevitable ai advances accessible serve societal good expanding principles described previous section important understand responsible ai means different things different people concept responsible ai also serves overall container many diverse opinions topics depending speaker context mean one following things policies concerning governance rd research development activities deployment use ai societal settings role developers individual collective levels issues inclusion diversity universal access predictions reflections benefits risks ai responsibility artificial intelligence topics quite different impacts placing issues basket muddle discussion also puts risk achievement con structive solutions topics also contribute increasing fear ai general public risk proliferation ungrounded dystopic views ai urgent topics perhaps first one artificial intelligence systems use data generate daily lives mirror interests weak nesses differences artificial intelligence like technology value neutral understanding values behind technology deciding want values incorporated ai systems requires also able decide want ai mean societies implies deciding ethical guide lines governance policies incentives regulations also implies aware differences interests aims behind ai systems developed others according cultures principles extension alternative regulation certification certification means risk regulation quality assurance ensures products services certify meet criteria specified professional associations standards organizations government agencies discuss issues regulation certification next section second topic important realize ai materialize make happen researchers developers ai systems large part determine systems behave kind capabilities exhibit many profes sions bound codes conduct outlining proper practices profession als association international accountants defines code conduct systems organization way contributes welfare key stakeholders b respects rights constituents affected operations” fact society expects strict codes conduct professions depends including health professionals military accountants many others given role software engineers ai systems applications shape world probably time expect standards conduct professional group discuss issue next section issue inclusion diversity access ai much said written particular relates bias however issues also relevant envi ronments ai developed strong link education inclusion nec essary condition diversity development teams ai professionals metrics terms demographics important understand inclusion experi enced broadening engineering education curricula include humanities social sciences essential ensure responsible design development ai also contribute diverse student population hand media given disproportional attention last topic dystopic views future dominated robotic overlords seem sell well backed scholars typical disciplines disproportional num ber tech millionaires however luciano floridi remarks even future virginia dignum logical possible utterly unlikely focus issues actual distraction real problems already affecting us8 even though topic fascinated people ages main risk focusing possible future risks basical distraction real risks facing already privacy security consequences human labor algorithmic bias cite governance responsible ai recent years seen rise efforts around ethical societal legal impact ai result concerted action national transnational gov ern ance bodies including european union eu organisation economic cooperation development oecd united kingdom france canada others also originated bottomup initiatives launched practitioners scientific community recently eu published guidelines trustworthy ai9 weeks version ieee’s initiative ethical aligned design ead intelligent autonomous systems10 pre sented impact two reports coming eu leading international professional organization engineers potential large engineers ultimately implement ai meet ethical principles human values poli cymakers regulators society general set enforce purpose ai initiatives go well beyond proposing list principles aim providing con crete guidelines design ethical aligned ai systems including recommenda tions regulation standards policy suggestions support development deployment use ai systems based result public consultation process eu guidelines put forward seven requirements necessary sufficient achieve trustworthy ai together methods achieve assessment list check requirements ieeeead report truly bottomup international effort resulting col aboration many hundreds experts across globe including asia global south goes deeper beyond list requirements principles provides indepth background many different topics ead com munity already hard work defining standards future ethical intelligent autonomous technologies ensuring prioritization human wellbeing eu piloting assessment list coming months open call interest initiatives focused analyzing values principles ai systems development thereof adhere examples lists include l floridi “should afraid ai” aeon essays httpsaeoncoessays trueaiisbothlogical ypossibleandutterlyimplausible httpseceuropaeudigitalsinglemarketennewsethicsguidelinestrustworthyai httpsethicsinactionieeeorg responsibility artificial intelligence analyzing different lists principles values clear initiatives set human wellbeing central ai development recognize general ethical principles accountability responsibility initiatives focus different types principles grouped three main classes societal legal technical albeit use synonyms slightly different terminologies main issues identified depicted figure based result public consultation process eu guidelines put forward seven requirements necessary sufficient achieve trustworthy ai ieeeead report truly bottomup international effort resulting col laboration many hundreds experts across globe including asia global south goes deeper beyond list requirements principles provides depth background many different topics efforts aim including different stakeholders discussion evaluation responsible ai moreover provide concrete means support organizations implementation ai systems meet requirements ieeeead community already hard work defining standards future ethical intelligent autonomous technologies ensuring prioritization human wellbeing eu guidelines include assessment list check requirements piloted together stakeholders open transparent effort another set initiatives focuses specific issues ethics robotics tra dition classic asimov’s laws including epsrc principles robotics15 work foundation responsible robotics16 httpsfutureoflifeorgaiprinciples httpswwwiiiacsicesbarcelonadeclaration ht psnouvellesumontrealcaenarticle20171103montrealdeclarationforaresponsibledevelopment ofartificialintelligence httpaielsiorgwpcontentuploads201705jsaiethicalguidelines1pdf margaret boden et al “principles robotics regulating robots real world” connection science –httpresponsibleroboticsorg virginia dignum fact goes hardly day without news yet another declaration princi ples ai initiatives national corporate levels uptodate lists initiatives check alan winfield’s blog17 crowdsourced effort coordinated doteveryone18 tim dutton’s list national ai strategies ensuring responsible ai however involves setting lists desired prin ciples standards recommendations requires action possible mechanisms action regulation certification codes conduct regulation whenever regulation mentioned respect ai development use usual two issues mentioned firstly fear regulation stifle innovation progress secondly issue whether current laws regulations sufficient deal complexities ai opinion shortsighted given dynamic nature ai cannot wait regulation technology mature already ai impacting individuals society changing cognitive interaction functions impacting wellbeing however seen previ ous chapters established definition ai without dif ficult determine focus regulation moreover observed panel produced years study ai report19 risks considerations different different domains enable generic regulatory approach means rather regulating ai regulating use specific areas healthcare military provides suitable instruments ensure proper application better inserted existing regulatory forms furthermore important realize regulation negative specifical case regulation takes form incentives investment programs nudge orga nizations pursue specific types applications technological approaches issue suitability current regulation clear ai arti fact much product service liability laws apply use ever need close col aboration legal ai experts col aborate evaluation possible update existing laws specific cases ai applications final regulation also seen means scientific development ai example consider case legislation restrict use data demand explanation results achieved ai system requirements proba bly mean many current approaches based neural networks deep learning able meet demands seen limitation use ai approached complaints refusal comply claiming economic losses delay development also seen challenge taken httpalanwinfieldblogspotcom201712 httpsgooglibffk4 maintained google docs peter stone et al report one hundred year study artificial intel igence ai100 ai100report10032016fnlsinglespdf responsibility artificial intelligence researchers need go back drawing board come novel learning reasoning techniques ensure explainability sustainable use data without compromising efficiency artificial intelligence far done yet current machinelearning techniques intermediate step path progress regulation means progress best embrace approach require culture openness cooperation among scientists developers policymakers ethicists order ensure regulations create incentives development benefit technology development society hopeful see need dialogue different parties increasingly acknowledged al certification several economic sectors developed effective means certification food sector consider similar mechanisms ai systems case de pend ent trusted institutions would validate test algorithms applications prod ucts set welldefined principles possibly derived recommendations described earlier guarantee quality system users systems would choice type system would best meet personal requirements certification approach combined regulatory one case regulation would specify minimum set principles interpretation must hold systems given country region similar data protection reg ulations force within eu20 minimum requirements laid regu lation certification supports business differentiation time ensures consumer protection currently several initiatives toward ai ethical certification launched including ieee ieee’s ethics certification program autonomous intelligent systems21ecpais aims create specifications certification mark ing processes advance transparency accountability reduction algorithmic bias ai systems recent white paper ai4people think thank proposes ethical frame work ai advised creation new european oversight agency responsible protection public welfare scientific evaluation supervision ai products software systems services similar aims22 time several commercial organizations including accenture pwc also announcing auditing services analyses algorithms httpseugdprorg httpsstandardsieeeorgindustryconnectionsecpaishtml luciano floridi josh cowls monica beltrametti raja chatila patrice chazerand virginia dignum christoph luetge et al “ai4people—an ethical framework good ai society opportunities risks principles recommendations” minds machines –virginia dignum codes conduct support development selfregulatory codes conduct data airelated professions involves specific ethical duties would along lines social sensitive professions medical doctors lawyers attendant certification “ethical ai” trustlabels make sure people understand merits ethical ai therefore demand providers23 professional code conduct public statement developed profes sional group reflect shared principles practice conduct ethics exercising profession describe quality behavior reflects expectations profession community provide clear statement society expectations enable professionals reflect ethical decisions code conduct supports professionals assess resolve difficult professional ethical dilemmas case ethical dilemmas correct solu tion professionals give account actions referring code many organizations enterprises codes conduct even many cases adherence code voluntary professions oblige allegiance code case professional orders guilds many countries membership necessary condition practice profession well known hippocratic oath physician’s pledge declaration geneva taken medical doctors recently association computing machinery acm largest interna tional association computing professionals updated code conduct24 vol untary code “a collection principles guidelines designed help computing professionals make ethical responsible decisions professional practice translates broad ethical principles concrete statements professional conduct” code explicitly addresses issues associated development ai systems namely issues emergent properties discrimination privacy specifical cal respon sibility technologists ensure systems inclusive accessible requires knowledgeable privacy issues inclusion diversity inclusion diversity broader societal challenge central ai development research development ai systems must informed diversity mean ing diversity obviously including gender cultural background ethnicity also growing evidence cognitive diversity contributes better decision making therefore developing teams include social scientists philosophers others well ensuring gender ethnicity cultural differences important ibid w gotterbarn et al “acm code ethics guide positive action” communications acm –responsibility artificial intelligence diversify ai development workforce along pertinent dimensions regulation codes conduct specify targets goals along incentives way foster diversity ai teams equal important diversify expertise working ai order understand ethical social legal economic impact ai evaluate design decisions contribute impact ai professionals need basic knowl edge philosophy social science law economy education plays important role artificial intelligence longer engineering discipline fact ai important left engineers alone ai real transdisciplinary current ai robotics curricula worldwide deliver engi neers toonarrow task view wide impact ai society requires broaden ing engineering education include analysis distributed nature ai applications integrate sociotechnical systems complexity human agent interaction b reflection meaning global effect autonomous emergent decentralized selforganizing character distributed learning entities operate c incremental design development frameworks unfore seen positive negative influence individual decisions system level well impact human rights democracy education consequences inclusion diversity design inform processes results e standing governance normative issues terms competences responsibilities also views health safety risks explanations accountabil ity f underlying societal legal economic models sociotechnical sys tems broadening ai curricula possibly also way attract diverse student population ai curricula known transdisciplinary expected female students traditional choose humanities social subjects engi neering ones may motivated choose ai parallel development curricula need include subjects theory practice ai example law curriculum needs prepare law experts address legal regulatory issues around ai final important realize besides human diversity also important consider cultural diversity includes factors education religion language artificial intelligence increasingly pervasive applied across cultures regions failure understand cultural diversity impacts negatively universal right access advantages technology brings increasingly connected ai world incentives regulations support awareness commitment diverse per spective ensuring ai applications truly adaptable diverse cultural space thus enabling access al ai narrative responsibility ai also proper ai narrative demystifies possibili ties ai technologies ensures able participate discussion role ai society since origins ai discipline gone ups downs virginia dignum seasonal shifts periods hype however never witnessed cur rent level excitement fear held many many areas artificial intelli gence breaking many different application domains results impress even knowledgeable experts three main factors leading devel opment increasing availability large amounts data improved algorithms substantial computational power however three improvement algorithms rightful seen contribution ai field two seen fortunate contingencies awareness ai potential impact lives world ways technology rightful raising many questions concerning eth ical legal societal economical effects however ai magic contrary may want us believe algorithms ai based magic wand give users powers omniscience ability solve problems achieve everything artificial intelligence uses algorithms computer program engineering process algorithms far magic around thousands years fact easiest definition algo rithm recipe—a set precise rules achieve certain result every time add two numbers using algorithm bake apple pie also following algorithm—a recipe recipe never turned apple pie end result pie baking skil choice ingredients applies ai algorithms large part result depends input data ability trained way choice use organic apples make pie ai also choice use data respects ensures fairness privacy transparency values hold dear responsible ai about—the decisions taken concerning scope rules resources used develop deploy use ai systems artificial intelligence algorithm data uses complex combination decisions opportunities resources conclusions increasingly ai systems taking decisions affect lives smaller larger ways areas application ai must able take account societal values moral ethical considerations weigh respective priorities values held differ ent stakeholders multicultural contexts explain reasoning guarantee transparency capabilities autonomous decisionmaking grow perhaps important issue consider need rethink responsibility artificial intelli gence systems tools artefacts created people actions deci sion must responsibility humans andor human organisations however potential autonomy capability learn require design considers account responsibility artificial intelligence ability responsibility transparency principles explicit systematic manner development ai algorithms far led goal improving perfor mance leading opaque black boxes putting human values core ai systems cal mindshift researchers developers toward goal improving trans parency rather performance lead novel exciting techniques applications researchers claim given ai systems artifacts discussion ethics ai somewhat misplaced indeed people ones responsible systems people ones determining questions ai systems answer deal results decisions action main concern responsible ai thus identification relative responsibility actors involved design development deployment use ai systems firstly society must prepared take responsibility ai impact means researchers developers trained aware responsibility concerns development ai systems direct impacts society requires extra efforts developing delivering education training materials well development codes conduct ai developers turn requires methods tools understand integrate moral societal legal values technological developments ai means responsible ai firstly issue governance secondly responsible ai implies need mechanisms enable ai systems act according ethics human values whether design way ai systems already making decisions would consider ethical flavor made people aware responsible ai design systems take implicit “ethical” decisions design system ensure refers decision someone ethical decision border decisions ethical ones requires models algorithms represent reason take decisions based human values justify decisions according effect values current deeplearning mechanisms unable meaningful link decisions inputs therefore cannot explain acts ways understand last certainly least responsible ai participation necessary understand different people work live ai technologies across cul tures order develop frameworks responsible ai fact ai stand must understood part sociotechnical relations diversity education plays important role ensure knowledge potential ai widespread make people aware participate shaping societal development basis ensure diversity inclusion capabilities autonomous decisionmaking grow perhaps important issue consider need rethink responsibility development ai algorithms far led goal improving performance leading opaque black boxes putting human values core ai systems cal mindshift researchers developers towards goal improving transparency rather virginia dignum performance lead novel exciting techniques applications mathematician philosopher norbert wiener wrote back “we better quite sure purpose put machine purpose real desire” ensuring ethical aligned purpose designing systems whose result trusted way design design involved designing work generations work always progress obviously errors made disasters happen option ignore responsibility artificial intelligence systems artifacts decided designed implemented used us responsible try fail fail observe denounce see things going wrong go wrong informed inform rebuild improve important realize ethical principles ai checklists boxes tick forget principles directions action codes behav ior—for ai systems importantly us need fair nondis criminatory accountable ensure privacy others aim social environmental wellbeing codes ethics us ai systems fol ow bibliography boden margaret joanna bryson darwin caldwel kerstin dautenhahn lilian edwards sarah kember paul newman vivienne parry geoff pegman tom rodden et al dignum virginia “responsible autonomy” proceedings twentysixth international joint conference artificial intel igence ijcai’–palo alto ca aaai press dignum virginia “ethics artificial intelligence introduction special issue” ethics information technology –eisenhardt kathleen “agency theory assessment review” academy management review –floridi luciano “should afraid ai” aeon essays httpsaeoncoessays trueaiisbothlogical ypossibleandutterlyimplausible floridi luciano j sanders “on morality artificial agents” minds machines –floridi luciano josh cowls monica beltrametti raja chatila patrice chazer virginia dignum christoph luetge robert madelin ugo pagallo francesca rossi burkhard schafer peggy valcke effy vayena “an ethical framework good ai society opportunities risks principles recommendations” minds machines –gotterbarn w amy bruckman catherine flick keith miller marty j wolf “acm code ethics guide positive action” communications acm –httpsdoiorg1011453173016 russel stuart p norvig artificial intel igence modern approach 3rd ed london pearson education limited responsibility artificial intelligence stone peter rodney brooks eric brynjolfsson ryan calo oren etzioni greg hager julia hirschberg shivaram kalyanakrishnan ece kamar sarit kraus kevin leytonbrown david parkes william press anna lee saxenian julie shah milind tambe astro teller report one hundred year study artificial intel igence ai100 palo alto ca stanford university httpsai100stanfordedusitesgfilessbiybj9861f ai100report10032016fnlsinglespdf turiel elliot culture morality social development context conflict cambridge cambridge university press chapter concept handoff model ethical analysis design deirdre k mulligan helen nissenbaum enthusiasm new artificial intelligence ai derived machine learning big data meant sweeping push insert machine intelligence wideranging systems producing raft “smart” yet often mundane technical objects well ai enhanced systems operating key societal sectors including finance military trans portation criminal justice health welfare1 automation prior times sweep also raised doubts questions notably many focused functional performance worker displacement concept handoff developed guides different set questions namely implanting ai2 affects ethical political values embodied technical systems growing body work places technical artifacts themselves—devices sys tems—within scope ethical analysis beyond traditional focus human action institutional regulation driven progress understanding technology ethical terms object study according understanding purely mate rial technical system performing within purely human social context sociotechnical system whose performance inextricably involves actornetwork research chapter funded generous support us nsf inspire ses1537324 macarthur foundation grateful simons institute theory computer science authors visitors privacy program spring throughout chapter prefer acronym ai connoting decision control systems based models derived machine learning big data instead terms “intelligent” philosophical questions whether intelligence normal meaning deirdre k mulligan helen nissenbaum theory ant concept actant example goes even direc tion erasing traditional distinction human actor one hand machine component systems developers may employ diverse nodes3 complex actornetworks wherein actants prescribe delegate behaviors among one another achieve desired ends concept handoff similarly assumes broadened understanding technical fact sociotechnical whereby socalled tech nical systems devices function technical material proper ties well human behaviors economic social political contexts unlike ant however handoff il uminates differences among different types actants wil considers differences ethical relevant applying ethical lens technical systems conceived means assessing diverse dimen sions terms contribution make impact ethical political values embodied—potential enacted4—in systems whole assessments concept handoff constitutes useful analytic tool paradigmatic usecase handoff model involves progression transfor mation one version system another progression involves replacement certain components others simple il ustration may help mod ern office buildings lighting increasingly modulated motion sensors instead mechanical humanoperated switches would describe transformation handoff control human actor programmed motion sensor note often alongside motionsensing control traditional interface affords individuals option operating switch traditional manner—a paradigmatic example parallel configuration within single system although catalyst us developing analytical framework around concept handoff recent boom ai based automation lighting example shows applies general various permuta tions including automation involving replacement human actors technical mechanisms necessarily ai one type machine component different type hardware replaced software even human actors one capacity replaced humans capacities handoffs occur example function ality outsourced pushed workers lower hierarchy centralized decentral ized examples abound taking ethical perspective technical systems concept handoff par ticularly useful exposes aspects progressive transformations may otherwise overlooked claim given handoff say human modera tion content handed machines transformed system offers functionality previous may boast even reliably efficiently lower cost anything worry goes account bruno latour “where missing masses sociology mundane artifacts” shaping technologybuilding society studies sociotechnical change ed wiebe bijker john law katie shilton jes koepfler kenneth r fleischmann “how see values social computing methods studying values dimensions” proceedings 17th acm computer supported cooperative work social computing association computing machinery –handoff model ethical analysis design ensure content marked offensive illegal dangerous machine roughly meets respective standards like others5 however argue even hold reallocation functionalities among different types components actors necessarily leave “mass morality” unchanged contrary redistribution functionality may moral political repercussions handoff model resists idea one redistribute functions without disturbing mass moral ity designed reveal political significance sociotechnical configurations function across component actors points inflection among mapping transformations terms handoff model shines spotlight changed implication il uminates ethical concerns changes raise may transformed systems embody positive values may replaced components even performing purportedly task lead degra dation—such dissipated accountability diminished responsibility displacement human autonomy acute threats privacy view handoff model critical ameliorative intervention il uminating structural political ethical stakes ongoing transition control computational components guise progress efficiency often political neutrality catalyst ai applied areas social media platforms “smart” cities healthcare criminal justice system generated steep widespread interest regulators journalists interrogate political implications algorithms systems diverse facebook’s advertising platform risk recidivism software governmental bodies set ethical expectations ai selfdriving vehicles companies develop guidelines internal structures address ethical quandaries posed ai universities grap ple obligation produce students attend social political entanglements technical work workers within major technology companies oppose use labor toward ethical objectionable ends burst activity underlying ethical angst reveal need rigorous methods interrogate ethical implications ai historic inflection point unspoken imperative hand human tasks machines business government healthcare education view raises see roger brownsword “lost translation legality regulatory margins technological management” berkeley technology law journal –margaret jane radin –lawrence lessig code laws cyberspace new york basic books harry surden “structural rights privacy” smu law review –orin kerr “compelled decryption privilege selfincrimination” texas law review julie e cohen “pervasively distributed copyright enforcement” georgetown law journal –deirdre k mulligan helen nissenbaum urgent need characterize assess potentially destabilizing impacts values configurations already experienced latent barriers—physical economic time—that served extralegal protection privacy undone interjection machines example drones alter lines sight making fences property lines insufficient limit prying eyes video surveil ance systems identify individuals crowd online access public records make individual’s past infractions salient present successes experiences inspire skepticism face claims sameness even claims prove ultimately innoc uous handoff framework offers guide maintaining focus implicit well explicit values sociotechnical systems evolve different types actors perform ing different functions respectively across versions system call different modalities control regulation—technology law ethical norms economics surely configurations functions provide superior protection particular values point departure focus inquiry simple case may il uminate point take sealable envelopes material approach securing privacy written correspondence achieves function within framework legal protections tampering norms reading private let ters locked letterboxes mail slots bring letters behind locked doors words although sealable envelopes may qualify “privacy enhancing technology” postal privacy product sociotechnical system legal cultural ethical material realities part societal significance sealed envelope function paper glue alone manufacturing processes produce instead character embedding within political economy politics ideation institutional infrastructure set practices integral part “works” transition email initial federal law reformed bolster privacy absence material envelope gaps law left communications vulnerable time remote indefinite storage email became norm discrepancies privacy afforded communications postal electronic mail viewed increasing skepticism ultimately substantial righted first lit igation new laws recently widespread adoption endtoend encryption decision deploy endtoend encryption surely made pos sible due improvements technology driven renewed realization among public policymakers ethical significance unencrypted communica tions born snowden disclosures revealed systematic dragnet surveil ance communications us government new configuration communication privacy protection set stage renewed “technological drama”around law enforce ment access communications privacy revealing various configurations alter mass privacy details aside case shows even email gains acceptance functional replacement “snail mail” entangled reality communications privacy destabi bryan pfaffenberger “technological dramas” science technology human values handoff model ethical analysis design lized one might argue email performs function snail mail namely communications among users—albeit speedily lacking equivalent physi cal envelope legal protections many norms practices tacitly explicitly protect prying postal mail however value privacy needed reinserted system thus newly configured handoff model instrument performing analyses reveal ethical issues emerge disrupted progressive versions systems functions shifted one component actor another others model sharply reveals functions distributed components human computational mechanical alternative sociotechnical systems interrogates value propo sitions captured alternative configurations handoff model provoked claims computational systems taking tasks previously per formed humans especial tasks thought require human intelligence concept handoff offers lens scrutinize ethical terms outside purview scholars social critics common practice delegating functions per formed humans machines machines one type machines different type mostly proceeded little fanfare7 public imagination anxiety stirred however contemporary forms automation involving ai taking human roles—machines label “recognize” images process “understand” produce “speak” natural language control machines robots anticipate say make decisions basis function shifts one type actor another people inclined say second performing function first function different actor see red flag racing conclusion see dire need detailed critical analysis clearly reveals stays even seemingly irrelevant differences—flesh blood versus silicon metal—makes difference configuration ethical values embodied systems question handoff lens draws attention backdrop ethical political values embodied respective systems—the systems functional handoff decomposes see example janet morrissey “when robots ring bel ” new york times november james vincent “economists worry aren’t prepared fallout automation” verge july httpswwwthevergecom20187217524822robotautomationjobthreatwhat happensnext yuki noguchi “recruiters use ‘geofencing’ target potential hires live work” national public radio july httpswwwnprorgsectionsal techconsidered 20170707535981386recruitersusegeofencingtotargetpotentialhireswheretheyliveand workt1560452691647 deirdre k mulligan helen nissenbaum opens view might may changed reconfiguration function across component actors begin objects analysis complex technical systems comprising diverse functional components variable nature components may include physical mechanisms embodied computational subsystems even humans unit analysis strictly speaking sociotechnical systems concept take given indeed sociotechnical mean cover balance article though mostly revert term “system” sake simplicity abstractly con ceived system may defined terms function turn achieved orchestrated subfunctions performed system’s component parts turn selves composed subsubsystems components model assumes notions system component subsystem relative terms whose application signals focus analysis rather ontological commitment8 analogy may think human body system organs component parts cardiologist heart system interest chambers valves arteries components word terminology systems interest may comprise multifarious parts including material others human typical use term compo nent neutral two though occasional use “componentactor” remind reader variability noted systems perform functions redistribution functions interests us—across versions either progressive variations time contempo raneously competing one another system’s function general terms answers question “what system do” systemcomponents also perform functions similarly answering question “what do” also addressing componentfunction subsystem contributes function system overal system’s function described varying levels abstraction level terms goals purposes even values level terms designer engineer might explain worth achieving degree preci sion around levels distinguishing goals purposes function gritty details achieved nevertheless mistake think higher terminology presented dilemma use generic term component apply human nonhuman parts sociotechnical system term component natural apply human actors purposes important able refer like manner human nonhuman components system actornetworktheory see example bruno latour “where missing masses sociology mundane artifacts” shaping technology building society studies sociotechnical change ed wiebe bijker john law cambridge mit press –which certainly influenced us came actant way dilemma preference adopt theoretical jargon offputting general readers going forward mostly stick term component sometimes revert actor subsystem addition human actors physical objects constitute system components allow possibility groups institutions components handoff model ethical analysis design order outcomes including values configurations insulated hows imple mentation handoff model says lower level “how” analyst explains components function function together produce system function overal capture ways compo nents function together posit concept acting engaging describe interaction one component another others lighting example imagine darkness falling human component flipping switch turn causing lamps il uminate using newly minted terms model describes series events human acting switch switch acting circuit turn producing come—“turn lights” human physical switch act components respectively fulfill overall function model recognizing may significant differences introduces construct mode emphasized called mode example larry lessig primarily sought emphasize powers people institutions software machines common namely ability regulate9 others however recognized modes act ing performed human components machine components respectively typi cal signal disparate forms moral responsibility10 handoff model different values mode parameter may influence even determine ethical properties successive versions system take physical force familiar mode acting one physical embodied componentactor may act another either forcing preventing action11 human actor pushing button sets causal chain action resulting car headlights flashing physical “material” causation or—one could say—“brute force” may operate many different ways example physical component set objects may act another component constraining range action eg safety overlock without necessarily causing particular outcome could far complex causal interdependencies numerous components function together produce complex configuration comes components different mode acting on—one might say subtle—is affordance defined cognitive psychologist jj gibson affordances relational properties things environment whose meaning significance derived service needs capabilities respective actortypes humans mammals invertebrates etc12 saying something nourishing tool serves secure cover lessig code laws cyberspace see example karen yeung “the forms limits choice architecture tool government” law policy –brownsword “lost translation” surden remaining intuitive level moment must look past fact nothing simple causation aristotle well demonstrated james j gibson “the theory affordances” ecological approach visual perception deirdre k mulligan helen nissenbaum properties affordances relation actors particular shapes sizes abilities needs adapting widely popularizing idea donald norman urged design ers exploit ignore affordances create artifacts people understand know use well utilized affordances trigger appropriate cognitive perceptual reactions humans13 principles derived norman’s infamous doors switches traveled realms digital technologies one approach social media site could take adopt policy permits data extraction offer application programming interface affords data extraction adopt technical legal rules example prohibition scraping discourage relation actors relevant technical knowhow within handoff model affordances mode acting designers exploit suggest range possible desirable actions system’s successful operation one hand unlike physi cal force affordances perceived processed users humans act—often strategically—accordingly hand systematically elicit predictable behaviors mini case light switch observe human component physical exerts force switch thereby initiating causal chain resulting lights il uminat ing among many possible answers human flipped switch one celebrates interface design successful exploiting affordance “flipability” human flipped switch instead pushing pulling another plausible answer however cites purpose human flipped switch night fallen different yet answer cites obedience rule example light switched say porch lighthouse skyscraper required law human chooses act identified conditions pertinent rules interpreted decided act accordingly human free agent prime mover causing lights turn flipping switch imagine lights whose operation automated via sensors detect light condi tions small computer embedded within light switch case given exte rior lighting possibly conditions algorithm expressed lines software code implemented embodied computer physical acts relevant components resulting illumination lights software code abstractly algorithm operates like legal rules model reify component actors instead informational content expressed coded instructions embodied material electronic computers act system components without delving metaphysical questions nature free agency handoff model draws attention features scenarios sketched differ ences among relevant embodied values although one might tempted say automated light switches performing task human operated switches two involve different modes acting one physical causation human agency difference makes difference example attributing donald norman “affordance conventions design” interactions –handoff model ethical analysis design responsibility blame human initiated versus sensorinitiated il umination affordance lies somewhere though would say humans responding affordances necessarily acting freely flourishing areas usability design computational systems attest sense responsibility blame may spread across human actor–components designerbuilders system norman’s famous cases people pushing doors pulled vice versa malfunctions communicate message informed analysis tragedy human operators uss vincenne downed iran air flight surface toair missile revealed interface poorly designed sum handoff analytical model exposing ethical political values embodied technical systems deriving foundations bodies work related concepts social studies technology values design provides concepts particularly important rapid deployment ai selfstanding within preexisting systems targets challenges notion—explicit well implicit—that component actors modular one pluck human actor plug intelligent component perturbations handoff model offers cluster concepts potential useful exposing aspects systems change wake replacements may relevant configuration values embodied resulting systems may remain invisible standard ways characterizing technical systems subject matter handoff covers versions systems either versions may vying dominance progressive versions follow one another systems creators update existing models time handoff analysis focuses variations different systems result variations components tasked “the same” functionality offers great utility rapidly growing area automation ai access security content moderation selfdriving cars myriad access control handoff lens case study il ustrate application handoff framing walk case secure access mobile phones tracking handoffs across five successive system versions—four actual one foreshadowed col aborator’s research chose case one hand familiar point invisibility yet perhaps seemingly innocuous “improvements” ways version produces functionality predecessor elides differences make difference explore multiple configurations access control function presented often thought innovative improvements security usability three configurations currently available market place password deirdre k mulligan helen nissenbaum fingerprint facial recognition underdeveloped passthoughts relation security usability among values become complex well user context dependent viewed handoff lens beginning originally mobile phones include lock built material devices mean lacked builtin access control function phones access control feature system whose boundaries broadly defined access landline devices controlled position homes offices mobile phones similarly one’s person purses pockets cars userselected passwords services information phones grew became sensitive reveal ing industry reached tippingpoint moved control access mobile phones passwords although increasingly users admonished construct strong passwords nonobvious combinations numbers letters symbols mixing upper lower cases frequent updates14 current standard users devise pass words performing—one might say— function purse pocket pass word controls access phone though arguably effectively stolen purse picked pocket lays bare phone’s function content along material device passwords passwords providing access control functionality human component15 responsible setting system creating passcode providing operating system os via numeric keypad operating system saves human selected inputs password place human component must accurately remember enter selected digits keyboard interface unlock phone phone affords keyboard makes password entry easy os exacting demanding input perfectly match—be accurate complete— password recorded research casts doubt actual security benefits practices see joseph bonneau cormac herley paul c van oorschot frank stajano “the quest replace passwords framework comparative evaluation web authentication schemes” proceedings ieee symposium security privacy oakland ieee –we temporarily set aside key question legal relationship human actor device—the userowner owner user user owner—all may significance composite values output due legal distinctions handoff model ethical analysis design password fingerprint recent years mobile phone providers shifted function access control implemented—first thumbprint recently face recognition discussed following unclear whether shifts result technical advancement— example improved performance fingerprint face matching algorithms usability particular security benefits governing us legal framework thing else entirely fingerprint familiar biometric followed passwords subsystem control ling access mobile device passwords human component initiates process entering print unlike passwords however users longer select input rather input offering body part—thumbfinger— raw material technical component reader fingerprint reader creates mathematical representation fingerprint image template stores access phone users supply physical stimulus checked stored template apple’s description system “creates mathematical representation fingerprint compares enrolled fingerprint data mathematical representation described identify match unlock device”from successful access usage incremental updates mathematical representation improve matching accuracy mathematical representations fungible new algorithm could used generate new mathematical representations mode human acting upon phone physical force affordances fingerprint reader able sense perform logical process comparing input stored set encrypted templates shift also changes process accessing device fingerprintgenerated password place human component must present fingerprint way readable phone fingerprint reader—not sweaty wet swollen disfigured dirty oddly angled password finger phone’s stored rep resentation finger may provoke different results—access denial configuration phone demands mode human actor present manner legible machine technical actor requires human “be herself”—or close enough it—in certain way remember thing gain access human must prove machine knows special secret unlike keypad entries password configuration fin gerprint match binary probabilistic phone determines real time whether mathematical representation current fingerprint constitutes match stored mathematical representation prior fingerprint new configuration human component longer knows password access tied specific human longer easily transferred human “about touch id advanced security technology” apple support httpssupportapplecom engbht204587 accessed june deirdre k mulligan helen nissenbaum cannot continually replace input used generate access control individual’s fingerprints finite fingerprint face id late apple introduced face id replace touch id—the fingerprint recognition system face id used iphone ’s new “truedepth camera system” constructs 3d map person’s face truedepth’s dot projector projects dots onto face time individual looks phone thereby creating developing map person’s features image dot pattern fed neural network generate mathematical model face shifts occurred passwords fingerprints remain— human component input access tied specific human unlike fingerprint reader however requires contact—and therefore evi dent human setting aside issues volition later—face id contactless technology one human hold phone point another human possibly without knowledge access phone human may unwitting input authentication system opens phones contents capabilities someone else face id passthoughts imagine could unlock phones merely thinking password— passthoughts prototype system development john chuang17 func tion controlling access moves deeper body rather typing password offering finger face individual’s brain activity becomes biometric identifier authenticated system like fingerprint face image thinking thought generates patterns distinctive enough across individuals used uniquely distinguish individuals current research prototype human user wears headset electroencephalogram eeg resting brain’s left frontal lobe thinking passphrase produces brainwaves eeg registers compares earlier passthought like biometrics “hit” defined probabilistical accessible human users human may know directly close given passthought stored one unlock device successful intriguing merger chosen password embodied biometric passthought offers equivalent twofactor authentication john chuang “passthoughts user authentication using brainwaves ” httppeopleischool berkeleyeduchuangpassthoughts accessed june handoff model ethical analysis design access control lens handoff typical narrative might celebrate evolution different configuration access control mobile operating systems four phases starting protection sophisticated biometric facial recognition final even “smarter” brainwave id according narrative progression version involves handoff function componentactor one type different type one improvement previous instead handoff approach opens view potential ripple effects replacements per focus discussion thus far different types component actors act one another differently associated differ ences may implications ethical political values case access control important feature physical deprivation pass words ability phone owners determine control key investing power delegate access others18 despite similarity however significant differ ence two password system embedded within logic device os implicates os developers additional componentactors thus expand ing boundaries system access control performed biometrics also extends system’s boundary beyond device unlike password access places users different role relation device namely “oneuseronephone” restricting use individual whose biometric fingerprint face brainwave pat tern entered original key even rather limited case handoff lens exposes ethical political differ ences cases physical password restraint device owners full sover eignty speak allowing delegate usage others allow shared collective resource19 move “something user knows” password need remember secret curtails agency diminishing transparency dimensions control humans choose password subject os imposed constraints enjoy degree control understanding functions sources strength eg length complexity biometrics os defines password determines function device owners lost insight beyond present even might grasp failures unlock example system glitch finger hot cold damp forth prospective passthought systems would seem reduce degree control humans find thoughts notoriously harder control physical action situations may legal constraints sharing set aside one may relate scenario shift physical books ebooks configuration access altered away traditional personal property model far limited deirdre k mulligan helen nissenbaum responsibility responsibility accountability closely tie control actor may blamed harm—in case breaches security—if significant hand controlling outcome breaches due password failures may fall device owners choosing weak passwords misguidedly sharing password others os providers failing build adequate affordances users generate passwords weak withstand computational brute force attacks fingerprint face id configurations os assumes specific threat model precludes physical brute force attacks individual’s wrist compel connection finger phone form attack attacker physical forces body move certain way thereafter setting motion cause effect set device os manufacturers noted earlier lens handoff challenges typical narrative technological progress implies advancing password fingerprint face id steady linear improvement along trajectory security20 similarly recent cases involving law enforcement show legal framework governing whether government agents compel individuals provide access mobile devices21 vary linearly along trajectory22 although police must obtain warrant searching cell phone23 whether compel individual unlock turns fifth amendment admittedly case law continues evolve present24 majority us courts concluded finger likelihood false positives—the wrong biometric opening device—has according apple greatly reduced introduction face id touch id single enrolled finger chance unlocking wrong fingerprint “about touch id advanced security technology” apple support httpssupportapplecomengbht204587 accessed june face id single enrolled appearance approximately chance opening wrong face “about face id advanced technology” apple support httpssupportapplecom enusht208108 accessed june phone user owner may distinct bur purposes focus limited case owner user analysis consider us law thorough discussion issue conflicting viewpoints see kerr “compelled decryption privilege selfincrimination” laurent sacharoff “what real saying open smartphone response professor kerr” texas law review online edition available httpstexaslawrevieworgwhatami real ysayingwheniopenmysmartphonearesponsetoorinskerr orin kerr bruce schneier “encryption workarounds” georgetown law journal –and laurent sacharoff “unlocking fifth amendment passwords encrypted devices” fordham law review –riley v california riley ii ct us law individual accused crime “take fifth” refuse testify fifth amendment us constitution declares “no person shal compelled criminal case witness himself” applies acts “testimonial”—have communicative aspects—not spoken words good argument communicating password phone protected majority courts examined issue reached handoff model ethical analysis design prints compelled circumstances passwords25 existing precedent distinguishes production body26 considered nontestimonial acts reveal contents defendant’s mind testimonial thus fingerprint implication biometric generally compelled password27 curious distinction demonstrates features component actors may affect direct functionality may nevertheless decisive system’s politics privacy security access control one mode constraining information flows—to intruders unwanted recipients setting aside unchecked information flows among os apps data brokers others access security subsystems offer virtual protection28 still possible compare progressive versions physical passwordcontrolled access os might capture physiological metadata sorts potentially revealing gender health status forth password particularly encrypted server incorporates nothing further29 conclusion see doe v united states us n stating dicta compelling someone reveal combination wall safe testimonial purposes fifth amendment wayne r lafave et al criminal procedure § 813a 4th ed “requiring subpoenaed party reveal passcode would allow government perform decryption would require testimonial communication standing apart act production therefore make unavailable foregone conclusion doctrine” several state courts concluded fifth amendment privilege selfincrimination protect compelled disclosure fingerprint unlock seized cel phone fingerprints testimonial communication state v diamond wl minn commonwealth v baust va cir va cir ct florida v stahl 3d example speaks ownership device application search warrant f supp 3d nd ill holding compelling production fingerprints people present execution search warrant unlock seized devices raised fifth amendment concerns noting general ownership foregone conclusion therefore fingerprint testimonial recently federal magistrate judge us district court northern district california concluded biometrics testimonial holding “government may compel otherwise utilize fingers thumbs facial recognition opticaliris biometric feature unlock electronic devices” case kaw nd cal jan doe v united states us “a suspect may compelled furnish blood sample provide handwriting exemplar voice exemplar stand lineup wear particular clothing” orin kerr “the fifth amendment touch id” washington post october httpswwwwashingtonpostcomnewsvolokhconspiracywp20161021thefifthamendment andtouchid helen nissenbaum “contextual integrity data food chain” theoretical inquiries law –surely passwords birthdates names children favorite sports team etc deirdre k mulligan helen nissenbaum although fingerprint places irrevocable identifying information hands device os might offer great protection external intruders according survey passwords deployed percent smartphone users30 apple reported percent customers devices supporting fingerprint unlocking using it31 case face id though also biometric application differs fingerprint requiring physical contact intended use32 means device may easily accommodate unlocking multiple users potential returning user control offered passwords increasing interest biometric identification general facial recognition systems availability facial templates powerful operators government commercial increasingly alarmed critics33 extent biometric systems inappropriately leak characteristics necessarily function biometrics rather system’s design example whether templates processing input sensors performed device centralized os thirdparty servers full account necessary development complete analysis outside boundaries chapter articulating boundaries system smartphones longer rely access control provided solely physical depriva tion although handoff analysis sketched implies successive competing alter natives today’s reality dominant mobile operating systems offer one approaches allowing users choose among instead lessening need handoff analysis may reveal users relevant differences among options transition irrevocably tethers access control functionality os provider thus although user gets choose among three potential four alternatives os provider chooses whether user gets choose constraining certain actions affording privacy value concern across progressive “smart phone thefts rose million ” consumer reports april httpswww consumerreportsorgcronews201404smartphonetheftsroseto31millionlastyearindexhtm mikey campbel “average iphone user unlocks device times per day use touch id apple says” apple insider httpsappleinsidercomarticles160419averageiphoneuserunlocks device80timesperday89usetouchidapplesays accessed june one imagine scenarios fingerprints don’t require contact relevant human—a severed finger print manufactured—but “normal” use case see example timothy williams “facial recognition software moves overseas wars local police” new york times august catie edmondson “an airline scans face take rules govern data goes” new york times august joshua rothman “in age ai seeing still believing” new yorker november handoff model ethical analysis design competing versions discussed potential pitfal alternatives example password versus biometric fingerprint versus facial recognition extent however privacy partial constructed relevant legal frameworks partial hands os provider function design choices whether biometric templates stored device also central servers whether encrypted clear available whose choices operations handoff lens exposes critical point system whole may wise obscured transition physical deprivation enacted user access control internalized subsystem os boundaries system expand accordingly initial access control resides outside technical system progressive iterations expand boundaries system include os provider component actor ful partial responsible functioning access control subsystem might view automation insertion ai mechanic component move eradicate humans system subsystem instead effort characterize shifts modes acting due automation handoff analysis suggests describing moves dis placements rather placements agency yields far productive insights service societal regulation techno logical development final il uminating consider trigger two competing sequential handoff configurations trigger—the impetus reconfiguration function—often highlights specific values motivated reconfiguration intended impli cated shifts password fingerprint face occurred backdrop technological improvements steady increase range significance content stored mobile phones heightened awareness privacy implications access information efforts us federal bureau investigation intelligence agencies worldwide develop permissive legal standards access con tents phones restrict strength require backdoors encryption con sumer products range significance content stored mobile phones cost phones fueled public pressure companies limit utility stolen phones socalled “kill switches” allow device owner remotely disable primary technology developed depress thefts phonelocking measures viewed additional strategy suppress theft depress resale value34 respect law enforcement access apple products apple executives center global maelstrom individual privacy law enforcement access intelligence law enforcement agencies pressed governments companies provide capability read encrypted contents phones without brian x chien “smartphones embracing ‘kill switches’ theft defense” new york times bits blog june httpsbitsblogsnytimescom20140619antithefttechnologyledtoadipin iphonetheftsinsomecitiespolicesay chien describes kill switches legislation require noting “police tech companies tried harder last year educate consumers additional security measures protect phones like setting passcodes make harder gain access devices erased resold” deirdre k mulligan helen nissenbaum knowledge assistance user35 relationship wideranging government actions shifts password configurations unknown yet apple vocal relationship device passwords device encryption balance power citizens government36 apple fought efforts force product design redesigns weaken device level encryption37 handoff lens foregrounds values play various configurations controlling access mobile phones goal demonstrate lens offered handoff affords unique critical insights operation systems terms new components modes acting dramatic consequences human societal values view critical ameliorative focus ongoing transition control computational components instead showing structural political ethical stakes changes offer handoff humility acknowledging first deep issues systems contexts technology development use may ever able capture second work progress undoubtedly factors myriad handoffs taking place still coming humans machines model capture hope experiences applying model—our others—will continue enrich expand explanatory power bibliography akrich madeleine bruno latour “a summary convenient vocabulary semiotics human nonhuman assemblies” shaping technologybuilding society studies sociotechnical change ed wiebe bijker john law –cambridge mit press brownsword roger “lost translation legality regulatory margins technological management” berkeley technology law journal –flanagan mary helen nissenbaum values play digital games cambridge mit press friedman batya “valuesensitive design” interactions –friedman batya david g hendry alan borning “a survey value sensitive design methods” foundations trends human–computer interaction –see example statement sal quillian yates deputy attorney general department justice james b comey director federal bureau investigation “going dark encryption technology balance public safety privacy” comm judiciary 114th cong exercise lawful access “not asking expand government’s surveil ance authority ensuring obtain electronic information evidence pursuant legal authority” richard lawler “tim cook outlines apple’s view privacy encryption msnbc interview” engadget april httpswwwengadgetcom20180406timcookrevolutioninterview id handoff model ethical analysis design latour bruno “where missing masses sociology mundane artifacts” shaping technologybuilding society studies sociotechnical change ed wiebe bijker john law –cambridge mit press lessig lawrence code laws cyberspace new york basic books radin margaret jane “regulating contract regulating machine” journal institutional theoretical economics –shilton katie jes koepfler kenneth r fleischmann “how see values social computing methods studying values dimensions” proceedings 17th acm computer supported cooperative work social computing –association computing machinery surden harry “structural rights privacy” smu law review –winner langdon “do artifacts politics” daedalus –chapter race gender timnit gebru datadriven claims race gender perpetuate negative biases day science often hailed objective discipline pursuit truth similarly one may believe technology inherently neutral products built representing slice world’s population used anyone world however analysis scientific thinking nineteenth century major techno logical advances automobiles medical practices disciplines shows lack representation among power build technol ogy resulted power imbalance world technology whose intended unintended negative consequences harm represented pro duction artificial intelligence different1 popular paradigm day continues change dominance powerful raceethnicity location eg white united states ethnic han china etc combined concentration power locations around world resulted technology benefit humanity also shown intentional unin tentional systematical discriminate already marginalized like many disciplines often perpetuate bias attempting come something better however predominant thought scientists “objective” clouds selfcritical analyzing pre dominant discriminatory view day could encoding goal helping advance example nineteenth century charles darwin worked theory evolution carefully researched wellthoughtout alternative cathy o’neil weapons math destruction big data increases inequality threatens democracy new york broadway books timnit gebru creationism many leave however title book origin species means natural selection preservation favoured races struggle life emphasis added writes “the western nations europe immeasurably surpass former savage progenitors stand summit civilization civilised races man almost certainly exterminate replace savage races throughout world”and subse quent book descent man selection relation sex notes “man courageous pugnacious energetic woman inventive genius brain absolutely larger formation skull said intermediate child man”although darwin’s book criticized stance church british empire used justify colonialism claiming subjected rule scientifical inferior unfit rule british anthropologists like james hunt using darwin’s theory justify slavery papers negro’s place nature since days darwin race shown time time social construct biological basis5 according professor public health michael yudel race “a concept think crude provide useful information it’s concept social meaning interferes scientific understanding human genetic diversity it’s concept first call upon moving away from”however celebrated scientists like evolutionary psychologist steven pinker still assert tied genetics writing articles groups genes7 claim example ashkenazi jews innately intelligent echoing darwin’s assertions regarding relationships genius gender scientists still attempting extract genderbased differences intelligence papers asking “why males overrepresented upper extremes intelligence”these questions posed without disputing claim males overrepresented upper extremes intelligence researchers claimed empirical show men overrepresented upper lower extremes iq highest charles darwin origin species means natural selection preservation favoured races struggle life oxford h milford oxford university press charles darwin descent man selection relation sex vol new york appleton james hunt negro’s place nature london trübner anthropological society stephanie pappas “unraveling human genome molecular milestones” live science httpswwwlivesciencecom26505humangenomemilestoneshtml megan gannon “race social construct scientists argue” scientific american httpswwwscientificamericancomarticleraceisasocialconstructscientistsargue steven pinker “the lessons ashkenazim groups genes” new republic httpsnewrepubliccomarticle77727groupsandgenes rosalind arden robert plomin “sex differences variance intelligence across childhood” personality individual differences –race gender lowest scoring person iq test likely man9 claim generalized mean men show greater spread “intelligence” general without constraining iq test myth scientific objectivity types claims seem backed data “science” less likely scrutinized like darwin hunt many scientists today perpetuate view inherent difference abilities various races sexes however works seem corroborated data empirical experiments views likely gain credi bility captured analyses example iq test designed white men whose concept “smartness” “genius” shaped centered evaluated specific types white men fact standardized testing general racist history united states ben hutchinson margaret mitchel ’s years unfairness discusses bodies work civil rights movement era devoted fairness standardized test ing10 debates proposals put forth time foreshadow advanced within ai ethics fairness community today thus types datadriven claims race gender made likes darwin still alive today probably foreseeable future dif ference method choice used “corroborate” claims reuters reported amazon shut automated hiring tool found negatively biased women11 according reuters tool “penalized resumes included word ‘women’s’ ‘women’s chess club captain’ ” graded graduates two allwomen’s colleges analyzed within context society built unsurprising automated hiring tool amazon’s would exhibit types biases workers google staged walkout protesting company’s handling sexual harass ment shortly news articles detailed women’s accounts toxic work ing environments microsoft including sexual harassment goes unpunished inability get promoted many forms discrimination12 hostile environment women ironic given fact computing indus try started dominated women mar hicks details programmed inequality computing considered feminine job dominated women eg joan c chrisler donald r mccreary handbook gender research psychology vol new york springer ben hutchinson margaret mitchel “years test unfairness lessons machine learning” proceedings conference fairness accountability transparency –jeffrey dastin “amazon scraps secret ai recruiting tool showed bias women” reuters httpswwwreuterscomarticleusamazoncomjobsautomationinsight amazonscrapssecretairecruitingtoolthatshowedbiasagainstwomeniduskcn1mk08g dave gershgorn “amid employee uproar microsoft investigating sexual harassment claims overlooked hr” quartz httpsqzcom1587477microsoftinvestigatingsexualharassment claimsoverlookedbyhramp timnit gebru changed advent personal computer 1960s 1970s computing started lucrative13 phenomenon unique computing professions original deemed many societies reflect women’s tasks eg cooking cease regarded way work becomes lucrative example us restaurant business domi nated men cooking home still considered woman’s responsibility similarly 1970s computing gone considered woman’s job within twenty years one dominated men select people innate “traits” successful programmer ibm invented programmer aptitude test sim ilar iq test14 nathan ensmenger notes “the focus mathematical trivia logic puzzles word games example allow nuanced meaningful contextspecific problem solving”sadly recently part companies’ interview processes also involved solving types puzzles connection job sought applicant companies google eliminated brainteasers internal studies showed connected applicant’s future success many tech industry adopted google’s style whiteboard interviewing using past data determine future outcomes results runaway feedback loops aptitude test designed specific people bound inject subjective biases supposed good job eliminate diverse groups people fit rigid arbitrarily defined criteria put place tech industry known hostile difficulty succeeding getting credit work promoted turn seem corroborate notion good jobs first place thus unsurprising automated hiring tools used amazon others naively train models based past data order determine future outcomes create runaway feedback loops exacerbating existing societal biases hiring model attempting predict characteristics determining candidate’s likelihood success amazon would invariably learn undersampled majority mar hicks programmed inequality britain discarded women technologists lost edge computing cambridge mit press nathan ensmenger “making programming masculine” gender codes women leaving computing ed thomas j misa hoboken nj wiley –nathan l ensmenger computer boys take computers programmers politics technical expertise cambridge mit press race gender known hostile toward people african latinx native american descent women disabilities members lgbtq community com munity marginalized tech industry united states person may hired bias interview process may succeed environment set people certain groups success model trained type data exacerbates existing societal issues driv ing marginalization model selects nonmarginalized group better chance getting hired process favors higher chance suc cess company environment benefits generates biased training data hiring tool reinforces bias creating run away feedback loop increasing existing marginalization types feedback loops amplifying bias unique hiring models predictive policing predicting crime “hotspots” based model trained data arrested neighborhood crimes reported also shown exhibit runway feedback loops many parts united states large discrepancy commits crime versus whose crimes reported example national survey drug use health shows drug use relatively evenly spread oakland whereas reports drug use police con centrated predominantly black neighborhoods kristian lum william isaac shown popular predictive policing model predpol reinforces existing inequities predicting predominantly black neighborhoods crime hotspots16 police sent neighborhoods case arrest people locations places less police presence—seeming validate presence crime neighborhoods others new arrests used additional training data increasing overpolicing disadvan taged neighborhoods amplifying societal bias unregulated usage biased automated facial analysis tools predictive policing one datadriven algorithms employed us law enforcement perpetual lineup report clare garvie alvaro bedoya jonathan frankle discusses law enforcement’s unregulated use face recognition united states stating one two american adults law enforcement database searched used time17 currently regulation place kristian lum william isaac “to predict serve” significance –clare garvie alvaro bedoya jonathan frankle “the perpetual lineup unregulated police face recognition america” georgetown law center privacy technology timnit gebru auditing accuracy systems specifying used report discusses potential people sent jail due cases mis taken identity notes operators well trained using tools authors propose model law guiding government usage automated facial analy sis tools describe process public debate pros cons used law enforcement stands unregulated usage automated facial analysis tools spreading law enforcement highstakes sectors employment recent study buolamwini gebru shows tools could systematic biases skin type gender18 analyzing performance commercial gender classification systems three companies microsoft face ibm study found near per fect classification lighter skinned men error rates percent percent whereas error rates darker skinned women high percent study published microsoft ibm released new versions apis less six months paper’s publication major companies google established fairness organizations us senators kamala harris cory booker cedric richmond called fbi review accuracy automated facial analysis tools used agency19 even healthcare industry cautioned blind use unregulated ai shown buolamwini gebru’s study society’s concept race gender affects design usage ai systems example although works prior gender shades studied accuracy automated facial analysis tools using geography proxy race none performed analysis skin type none intersectional y— taking account multiple identities gender skin type duo darker lighter skinned black women united states buolamwini gebru understood race unstable social construct across time space different meanings different cultures locations historical periods cost color sociologist ellis monk notes “some studies even suggest withinrace inequalities associated skin tone among african americans often rival exceed obtains blacks whites whole”thus instead per forming analysis race buolamwini gebru used fitzpatrick skintype classification system classify images darker lighter skinned subjects analyz ing accuracy commercial systems subgroups buolamwini gebru’s work notes ai systems need tested intersection al uncover shortcomings kimberlé crenshaw leading scholar coined term intersectionality critical race theory stresses importance taking joy buolamwini timnit gebru “gender shades intersectional accuracy disparities commercial gender classification” proceedings machine learning research –kamala harris cory booker cedric l richmond letter federal bureau investigation httpswwwscribdcomembeds388920671contentfromembed ep monk jr “the cost color skin color discrimination health among african americans” american journal sociology –race gender account individual’s different identities interact systems power tandem21 often gives example lawsuit emma degraffenreid alleging general motors gm discriminated black women plaintiffs lost lawsuit judges reasoning since gm hires black people also hires women couldn’t discriminated black women failed see however gm hired women secretarial positions wouldn’t hire black people positions gm hired men factory posi tions didn’t consider women positions thus black women indeed discriminated gm without intersectional view race gen der judges unable see discrimination buolamwini gebru’s work analyzing systems gender skin type showed largest disparities women discuss life experiences understanding works intersection ality motivation disaggregating accuracy gender skin type aibased tools perpetuating gender stereotypes previous section discussed manners automated facial analysis tools unequal performance across different subgroups used law enforcement section shows existence tools first place matter “accurate” perpetuate harmful gender stereotypes many ways society’s views race gender encoded ai systems built studies hamidi et al’s gender recognition gender reductionism discuss context automatic gender recognition systems studied buolamwini gebru harms cause particularly transgender community instance task automatic gender recognition agr implicitly assumes gender static concept frequently change across time cultures however gender presentations greatly differ across cultures—a fact often unac counted systems gender classification systems often trained data transgender nonbinary individuals outputs selves classify images “male” “female” transgender communities effects agr severe ranging misgendering individual outing kimberlé crenshaw “demarginalizing intersection race sex black feminist critique antidiscrimination doctrine feminist theory antiracist politics” university chicago legal forum foad hamidi morgan klaus scheuerman stacy branham “gender recognition gender reductionism social implications embedded gender recognition systems” proceedings chi conference human factors computing systems acm timnit gebru public hamidi et al note according national transgender discrimination survey conducted percent respondents regularly misgen dered workplace attempted suicide welldocumented harms due systems perform agr utility tools often unclear one common applications agr targeted advertising eg show ing perceived women specific product danger perpetuat ing stereotypes giving subliminal messages regarding artifacts men versus women use example urban outfitters started personalizing website based perceived genders frequent customers program scrapped many customers objected genderbased marketing shoppers often bought clothes placed ascribed gender’s section others opposed concept genderbased targeting itself23 automatic gender recognition systems one many ways ste reotypes gender based societal biases propagated ai imagery used visualize cyborgs names voices mannerisms depicted speech rec ognition systems like siri alexa meant obey customer’s every whim clear design commercial ai systems based stereotypical gender roles amy chambers writes virtual assistants increasingly popular present everyday lives literal alexa cortana hol siri fictional films samantha joi karen spiderman homecoming names demonstrate assumption virtual assistants satnav siri voiced woman reinforces gender stereotypes expectations assumptions future artificial intelligence24 mean children grow households filled feminized voices clearly subservient roles ai systems already used ways demeaning women without explicitly encoding gendered names voices example generative adversarial networks gans models used gener ate imagery among many things weaponized women25 deep fakes videos generated using gans create pornographic content using faces ordinary women whose photos scraped social media without consent natasha singer “etailer customization convenient creepy” new york times june amy chambers “there’s reason siri alexa ai imagined female—sexism” conversation httptheconversationcomtheresareasonsirialexaandaiareimaginedasfemale sexism96430 cara curtis “deepfakes weaponized silence women—but woman fighting back” next web httpsthenextwebcomcodeword20181005deepfakesarebeing weaponizedtosilencewomenbutthiswomanisfightingback race gender power imbalance exclusion marginalized voices ai weaponization technology certain groups well usage maintain status quo touted liberator without power new ai “model cards model reporting” mitchell et al note parallels industries products designed homogenous group people26 automobiles crashtested dummies prototypical adult “male” characteristics resulting accidents disproportionately killed women children clinical trials excluded many groups people resulting drugs work disproportion ately negatively affect women products built tested homogenous group people work best group newsweek article highlighting scientist charles rotimi notes “by fewer percent several hundred genome investigations included africans” even though “african genomes diverse planet”excluding african genes hurts african descent creating next generation personalized drugs work also leads scientists erroneous claims overfitting homogenous data example reaching conclusions based uncommon mutations among european genomes ones common africans indeed development trajectory ai seems mirroring many dis ciplines blog post ali alkhatib describes harm current ai development caused marginalized groups parallels anthropology28 points specifical military—and drowning lucrative funding arrangements asked something seemed reasonable time” alkhatib cautions “the danger aligning work existing power subjugation marginalization communities ostensibly seek understand” emphasis added noting “the voices opinions needs disempowered stakeholders ignored today favor stakeholders power money influence—as historical y” group people marginalized communities sacrificed careers shed light ai negatively impact communities ideas get ting coopted quickly called capture neutralize strategy margaret mitchel simone wu andrew zaldivar parker barnes lucy vasserman ben hutchinson elena spitzer inioluwa deborah raji timnit gebru “model cards model reporting” proceedings conference fairness accountability transparency acm –jessica wapner “cancer scientists ignored african dna search cures” newsweek ali alkhatib “anthropologicalartificial intelligence hai” httpsalialkhatibcom bloganthropologicalintelligence timnit gebru respectively massachusetts institute technology mit stanford university announced interdisciplinary initiatives centered around ai ethics multibillion dol ar funding venture capitalists industries war criminals like henry kissinger taking center stage stanford mit open ing events mirroring transpired political anthropology wellfunded initiatives exclude voices marginalized people claim support instead center powerful entities worked ai ethics many cases interests proliferating unethical uses ai like diversity inclusion ethics become language du jour stanford’s humancentered ai initiative mis sion statement “the creators ai represent world” initiative announced zero black faculty initial listed website professors multiple disciplines universities institutions aspiring central authoritative voice ai companies amazon announced joint grant national science foundation nsf fund fairness related research selling automated facial analysis tools potential systematic biases law enforcement29 shortly company announced joint grant nsf amazon’s leadership wrote series blog posts attempting discredit work two black women showing bias automated facial analysis tool30 refusing stop selling automated facial analysis tools law enforcement without regulation place actively harming careers two women marginalized communities negatively impacted amazon’s product company claimed work fairness announcing joint grant nsf incident microcosm capture neutralize strategy disempowers mar ginalized communities using fashionable language ethics fairness diver sity inclusion advance needs corporation costs letter signed seventyeight scientists31 including turing award winner yoshua bengio later detailed misrepresentations amazon officials stressing importance study calling amazon cease selling rekognition law enforcement initial written timnit gebru margaret mitchel former black woman col aborator buolamwini raji activism shows bifurcation people taking risks within work ethics fair ness versus given seat table centered initiatives like mit stanford two black women pointed systematic issues amazon’s products third assembled coalition ai experts reinforce message natasha singer “amazon pushing facial technology study says could biased” new york times jan inioluwa deborah raji joy buolamwini “actionable auditing investigating impact publicly naming biased performance results commercial ai products” proceedings aaaiacm conference ai ethics society aai –concerned researchers “on recent research auditing commercial facial analysis technology” medium httpslinkmediumcomrew0dwznay race gender many academic community continue publish papers research ai ethics abstract fairness ethics become safetouse buzz words many machine learning community describing “hot” topic areas however people working field question whether technologies exist first place often center voices impacted technologies claim make “fair” example least seven nine organizers workshop topic ethical social governance issues ai32 leading machine learning conference neural information processing systems white entire field research uses pain negatively impacted communities coopts framework describing struggle uses career advancement communities power field contributes marginalization communities rather helping current move ment toward sidelining many groups favor powerful interests never thought ai ethics except abstract forced confront works people marginalized communities like raji buolamwini shows fairness transparency accountability ethics ai movement road “parachute science” like many fields ali alkhatib writes computer scientists utterly failed learn history fields we’re replicating moral objectionable deeply problematic relationships fields could warned us avoid—indeed tried warn others avoid political anthropologists 1940s “tended take colonial domination granted” fashioned principal tool hegemonic influence finding ways shape indigenous cultures colonial powers33 colonial attitude currently pervasive ai ethics space coined terms “parachute research” “helicopter research”to describe scientists work whether data surveys specimens leave type work results subpar science due researchers conduct without understanding context marginalizes communities treating caged curi osities mentioned joy buolamwini without alleviating pain best way help community elevating voices working make community better—not parachute research academics serious ai ethics thus need ensure center voices write introduction paragraphs motivation sections research papers workshop ethical social governance issues ai neurips ali alkhatib “anthropologicalartificial intelligence hai” httpsalialkhatibcom bloganthropologicalintelligence citation omitted theresa diane campbel “a clash paradigms western indigenous views health research involving aboriginal peoples” nurse researcher timnit gebru work create space marginalized amplify voices rather using advance careers raise money venture capitalists name design ethical ai starts given seat table ethical ai abstract concept one dire need holistic approach starts table creating technology framing goals values ai approach solely crafted led evangelized powerful positions around world bound fail creates tech nology determines whose values embedded instance tech industry dominated cisgendered straight men would developed automatic gender recognition tools shown harm transgender communities encourage stereotypical gender roles ones overrepresented development artificial intelligence types tools would developed instead significant input developing ai used criminal justice system came wrongful accused crime confronted high cash bail due risk assessment scores would algorithms today disproportionately disenfranchise black brown communities united states majority ai research funded govern ment agencies working healthcare rather military entities defense advanced research projects agency would working toward drones identify persons interest recent example palestinian arrested writing “good morning” arabic translated “hurt them” english “attack them” hebrew facebook translate shows structural issues play35 person arrested israeli authorities later released verifying indeed written “good morning” according ha’aretz one checked original arabic version arresting individual many issues led series events start field language translation dominated palestinians well arabic speaking populations difficult imagine type mistake translation system would transpired tools used google facebook currently work best translations english western lan guages french reflecting cultures represented within machine learning natural language processing communities papers corpora published domain focus languages deemed important yotam berger “israel arrests palestinian facebook translated ‘good morning’ ‘attack them’ ” ha’aretz october race gender research community funding resources compa nies facebook google located silicon valley united states thus surprising overwhelming bias researchers community toward solving translation problems languages french english secondly natural language processing tools embed societal biases encoded data trained arabicspeaking people stereotyped terrorists many nonarab majority countries point math professor interrogated flight due neighboring passenger mistaking math writings arabic36 similar stereotypes exist majority english french western language speakers thus even mistakes occur translations languages french english unlikely negative connotations mis taking “good morning” “attack them” racial gender biases natural language processing tools well documented shown bolukbasi et al caliskan et al word embeddings trained corpora news articles books exhibit behaviors line societal biases encoded training data example bolukbasi et al found word embeddings could used generate analogies trained google news complete sentence “man computer programmer woman ‘x’ trained crawling web african american names associated unpleasant concepts like sickness whereas european american names associated pleasant concepts like flowers38 dixon et al39 also shown sentiment anal ysis tools often classify texts pertaining lgbtq individuals negative given stereotyping muslims terrorists many western nations thus less surprising mistake resulting translation “attack them” incident also highlights automation bias tendency people overtrust automated tools experiment designed scientists georgia tech university examine extent participants trust robot showed willing follow toward seemed burning building using pathways clearly inconvenient40 case palestinian arrested “good morning” post authorities trusted guardian staff “professor flight delayed equations raised terror fears” guardian may tolga bolukbasi kaiwei chang james zou venkatesh saligrama adam kalai “man computer programmer woman homemaker debiasing word embeddings” proceedings 30th international conference neural information processing systems –caliskan aylin joanna j bryson arvind narayanan “semantics derived automatical language corpora contain humanlike biases” science –lucas dixon john li jeffrey sorensen nithum thain lucy vasserman “measuring mitigating unintended bias text classification” proceedings aaaiacm conference ai ethics society acm –paul robinette wenchen li robert allen ayanna howard alan r wagner “overtrust robots emergency evacuation scenarios” eleventh acmieee international conference human robot interaction ieee press –timnit gebru translation system think first see original text arresting individual one cannot ignore structural issues play analyzing happened addition increased likelihood errors translating palestinian arabic dia lects oppression palestinians also makes likely whatever translation errors exist harmful toward similar google photos inci dent classified black couple “goril as” translation system harmful type error made google photos incident many instances white people mistaken whales black people misclassified goril however conno tation mistaken whale rooted racist discriminatory history black people depicted monkeys goril as41 even someone could convince algorithms sometimes spit nonsense struc ture nonsense tend vaguely toward structure historical prejudices dominance certain groups underrepresentation others natural lan guage processing computer vision machine learning ensures problems groups work address biggest challenges faced part dominant group field fact contribute marginal ization groups error “good morning” translated “attack them” would grave consequences structural imbalance power made palestinian likely surveilled subjected automated tools similarly black people marginalized communities united states likely subjected surveil ance interact automated tools groups42 systematic errors encoding bias stereotypes practitioners area much costly marginalized communities groups existing power imbalance coupled types systematic errors dispro portionately affecting marginalized groups makes proposals extreme vetting initiative united states immigration customs enforcement ice even problematic scary initiative proposes ice partners tech compa nies monitor various people’s social network data automated tools use analysis decide whether allowed immigrate united states expected good citizens considered risk becoming terrorists attempt predict person’s future criminal actions dangerous direction move toward warned science fiction movies minority report tv series like black mirror proposal even scarier paired systematic errors automated tools would used analyses natural language processing wuld hund charles w mil silvia sebastiani eds simianization apes gender class race berlin lit verlag virginia eubanks automating inequality hightech tools profile police punish poor race gender computer vision based tools disproportionate errors biases toward already marginalized likely targeted agencies ice heartening see group fiftyfour leading scientists ai wrote letter extreme vetting initiative43 however initiative continued groups people within ai community developing tools used practices truly speaking proposals one extreme underrepresentation marginalized groups latter community makes even difficult care speak groups already facing disproportionate amount burden diversify educate communities—adding minority tax already face education science engineering needs move away “the view nowhere” work technology beneficial society start involvement people many walks life geographic locations future technology benefits depend builds utilizes seen gendered racialized values society technology largely developed seeped many aspects characteristics work steer ing ai right direction scientists must understand science cannot divorced world’s geopolitical landscape things meri tocracy objectivity feminists long critiqued “the view nowhere” belief science finding objective “truths” without taking people’s lived expe riences account myth meritocracy dominant paradigms fol lowed disciplines pertaining science technology continue dominated men replacing “view nowhere” sarah marie stitzlein writes according feminists pragmatists acknowledgment subject object historical political situated requires subjects objects knowledge placed level playing field done objectivity form responding rights well fellow subjects well objects scientific inquiry must considered objectivity achieved extent responsibility inquiry fulfilled expanded fol lows scientists must held accountable results projects scientists must acknowledge political nature work objectivity stood implies relationships people objects inquiry projects central conception44 technology experts letter dhs opposing extreme vetting initiative sarah stitzlein “replacing ‘view nowhere’ pragmatistfeminist science classroom” electronic journal science education citations omitted timnit gebru educational system must move away total abstraction science technology instead show people’s lived experiences contributed trajectory technology follows paper moral character cryptographic work phillip rogaway sees rise mass surveil ance failure cryptographic community45 discusses various methods proposed cryptography outlines extreme abstraction field lack accounting geopolitical con text cryptography used resulted methods reality help powerful powerless cal scientists speak see technology misused cites physicists’ movement toward nuclear disarmament asking cryptographers similarly ai researchers learn ways technology used question direction institutions moving engage disciplines learn approaches instead parachute science studying fairness accountability transparency ethics ai forge col abora tions across disciplinary geographic demographic institutional socioeconomic boundaries help lift voices marginalized order work toward ai marginalize historical con tinue sidelined educational system general attitude amongst researchers practitioners needs fundamental change move away myth mer itocracy “the view nowhere” bibliography benjamin ruha race technology abolitionist tools new jim code medford polity broussard meredith artificial unintel igence computers misunderstand world cambridge mit press buolamwini joy timnit gebru “gender shades intersectional accuracy disparities commercial gender classification” proceedings machine learning research –eubanks virginia automating inequality hightech tools profile police punish poor new york st martin’s press hamidi foad morgan klaus scheuerman stacy branham “gender recognition gender reductionism social implications embedded gender recognition systems” proceedings chi conference human factors computing systems new york acm hicks mar programmed inequality britain discarded women technologists lost edge computing cambridge mit press noble safiya umoja algorithms oppression search engines reinforce racism new york nyu press phillip rogaway “the moral character cryptographic work” iacr cryptology eprint archive race gender o’neil cathy weapons math destruction big data increases inequality threatens democracy new york broadway books stitzlein sarah “replacing ‘view nowhere’ pragmatistfeminist science classroom” electronic journal science education west sarah myers meredith whittaker kate crawford “discriminating systems gender race power ai” ai institute chapter future work age ai displacement riskshifting pegah moradi karen levy february jeopardy viewers watched ai system known ibm watson defeated ken jennings brad rutter two winningest jeopardy champions time threeday exhibition match new york times lauded “a vindication academic field artificial intelligence”watson’s ability understand respond jeopardy clues considered major step forward natural language processing information retrieval soon ibm announced plans use system assist physicians making diagnoses treating patients2 winning jeopardy unique challenge machine given jeopardy unpredictable complex simple test trivia jennings wrote clues “weird short little haikus laced hints puns winks red herrings”when watson erred often seemed miss clues humans would find easy obvious watson example rendered “what chic” response clue “stylish elegance students graduated year” brad rutter subsequently offered correct response “what class”in final jeopardy round cate gory “us cities” watson responded “what toronto” four question marks denoting low confidence response5 john markoff “on ‘jeopardy’ watson win trivial” new york times february sec science httpswwwnytimescom20110217science17jeopardywatsonhtml katherine gammon “watson goes hospital” mit technology review february httpswwwtechnologyreviewcoms423092watsongoestothehospital ken jennings “the secret farm team jeopardy players” slate april httpsslate comculture201904jeopardyquizbowlconnectionkenjenningshtml “show —monday february ” j archive february httpwwwjarchive comshowgamephpgameid3575 “show —tuesday february ” j archive february httpwwwjarchive comshowgamephpgameid3576 pegah moradi karen levy despite shortcomings watson still many assumed simply watson memory capacity fifteen trillion bytes fed data millions documents books encyclopedias news articles6 watson able consume wealth information people—even jeopardy champions— could dream able absorb also possible much simpler mechanism gave watson biggest advantage jennings suggests watson good largely much quicker buzzer human competitors “as jeopardy devotees know” jennings notes “if you’re trying win show buzzer al given night nearly contestants know nearly answers it’s matter masters buzzer rhythm best”in response criticism watson’s buzzer advantage ibm researcher eric brown noted “there things computers going better humans vice versa humans much better understanding natural language computers better responding signals”the combination comparative strengths weaknesses watson brought jeopardy stage nicely encapsulates nuanced relationship ai human work computer’s success seen bel wether futurists used watson’s win launch pad claims possibility ai displacing workers “after al ” fretted martin ford “if machine beat humans jeopardy computers soon com peting people knowledgebased jobs”in respects watson’s abilities far superior human competitors—but humans innately capable aspects gameplay watson struggled though specifics task may differ true humanmachine relations work contexts understand ethical issues likely beset future work must first realistically assess kinds threats ai might pose though economists policymakers begun express great concern ai mean employment—including whether forms work exist all—we argue popular “robots take jobs” narrative aiinduced job displacement overly simplistic alarmist spite rapid growth research application ai systems still quite limited practical capabilities current technical limitations ai stil give humans comparative advantage many kinds work forecasts widespread employment displacement tend focus solely technical aspects work neglect broader contextual inquiry social components work organizational struc tures crossindustry effects first part chapter explain limita tions existing forecasts “ibm100—a computer called watson” ibm march httpswwwibmcomibmhistory ibm100useniconswatson ken jennings “jeopardy champ ken jennings” washington post february httpslive washingtonpostcomjeopardykenjenningshtml sam gustin “ibm watson scientist speed matters accuracy intuition” wired martin ford “will ibm’s watson put job jeopardy” fortune february http fortunecom20110215willibmswatsonputyourjobinjeopardy future work age ai second part turn outcomes expect ai workplace specifical intelligent systems likely marshaled toward traditional managerial goals related efficiency productivity risk mitigation highlight four ways firms may use ai pursuit goals effectively offsetting risks onto workers end discussion potential policy responses concerns ai worker displacement rhetoric reality aidriven technologies increasingly integrated work processes commonly expressed concern impending displacement human workers—often apocalyp tical phrased popular media “robots taking jobs”this argument tends follow understanding human work comprised series tasks done effectively efficiently scale machine therefore machines grow capability greater number tasks currently per formed humans assumed automated human work comprised tasks thinking goes human workers vulnerable dis placed machines—potential leaving many without jobs drastical rearranging labor distributed occupation jobs widely believed acutely threatened ai bluecol ar jobs—often held less educated poorer workers fewer alternative options—there feared potential tremendous social economic disruption kinds tasks ai execute machines newly capable performing number tasks formerly “off limits” automation thanks technical improvements ai increased access big datasets advancements robotics prior developments paradigmatic model taskbased automation twofactor model proposed autor levy murnane refer alm model alm focuses routine task alex williams “will robots take children’s jobs” new york times december sec style httpswwwnytimescom20171211stylerobotsjobschildrenhtml larry elliott “robots take jobs we’d better plan it’s late” guardian february sec opinion httpswwwtheguardiancomcommentisfree2018feb01robotstakeourjobsamazon goseattle blake morgan “robots take jobs need plan scenarios future” forbes httpswwwforbescomsitesblakemorgan20180905robotswilltakeourjobsandwe needaplan4scenariosforthefuture david h autor frank levy richard j murnane “the skill content recent technological change empirical exploration” quarterly journal economics –pegah moradi karen levy one dimension degree tasks involve cognitive versus physical work dimension autor coauthors argued “computer capital” could substitute workers executing abstractable programmable routine tasks—con sisting “cognitive manual tasks accomplished following explicit rules” watson’s buzzer advantage rooted specific routine capability able respond quickly predictably explicit signal alm model pos ited nonroutine human labor might complemented computers com puters unlikely substitute whol humans nonroutine tasks nonroutine tasks deemed difficult program dependent skil like perception problemsolving intuition well beyond purview computing world changed since computers become sophisticated responsive environments adapt dynamic situations adeptly—negotiating traffic responding conversational cues developing novel solu tions problems light robotic capabilities computer vision machine learn ing it’s less important task clearly definable repeatable thus complicating alm model ai many tasks previously thought intrac tably nonroutine becoming converted abstractable problems aided avail ability large complex datasets12 although machines previously limited tasks clearly defined limited potential contingencies today’s ai systems analyze previous cases determine course action unpredictable situations likewise integrating predictiondriven models robotics bring capabili ties realm physical labor instance though autor et al explicitly men tioned truck driving manual nonroutine task work hence likely safe automation several companies set goals develop ful autonomous longhaul vehicles near future based new technical capabilities13 ai allow machine execute tasks would previously con sidered nonautomatable alm model ai still significant technical social limitations acknowledged forecasting literature frey osborne consider three “engineering bottlenecks” calculating automat ability american occupations identifying “perception manipulation” “creative intelligence” “social intelligence” areas elude technological capability14 levy identifies broader limitations arguing ai able better compete human labor tasks narrow data models use contains contingencies could face future b structured machine easily identify consistent patterns data15 much like factors carl frey michael osborne “the future employment susceptible jobs computerisation” oxford martin school september steve viscelli “driverless autonomous trucks future american trucker” center labor research education university california berkeley working partnerships usa september frey osborne “the future employment” frank levy “computers populism artificial intelligence jobs politics near term” oxford review economic policy –the future work age ai described alm model however boundaries elastic future changes capabilities aidriven automation well nature tasks selves continuously shift window automatability forecasts peering today’s window automatability nevertheless predict grim outcomes employment occupationfocused model frey osborne calculated probabilities computerization occupations using administrative data task content jobs us department labor ai experts classify tasks according technical automatability16 study estimated percent us jobs high risk defined percent chance automation within twenty years—and lowwage occupations frey osborne forecast extremely influential dominating narrative popular press subsequent academic work amassing citations time writing complicated reality risk calculations like frey osborne’s often used predict massive unemploy ment due advances ai forecasts significantly complicated sometimes portrayed large part due crucial nuances work exe cuted industries organized first crucial technological capabil ity automate certain tasks necessarily translate actual automation tasks occupations date chiefly comprised tasks forecasts tend focus exclusively technical feasibility account social legal political organizational factors17 technologies operate social vacuums firms’ adoption implementation technologies contextu al dependent factors like internal organization18 institutional regulatory landscapes19 degree unionization20 variables importantly social political factors historical affected distribution automation risk particular race ethnicity united states affect whose work protected automation whose instance historical although artisans whose work deskilled automated first american industrial frey osborne “the future employment” erik brynjolfsson tom mitchel daniel rock “what machines learn mean occupations economy” aea papers proceedings –httpsdoi org101257pandp20181019 robert j thomas machines can’t politics technology industrial enterprise evidence observations ct scanners social order radiology departments” administrative science quarterly –httpsdoiorg1023072392767 david f noble forces production social history industrial automation new york oxford university press maryellen kelley “new process technology job design work organization contingency model” american sociological review –pegah moradi karen levy revolution largely white dangerous lowwage factory labor grew result industrialization largely performed immigrants nonwhite workers likewise considering frey osborne’s predictions conjunction racial ethnic demographic data appears likely white workers disproportionately automatable21 white workers continue greater social political leverage along higher labor market power thus altering demographic groups could affected automation22 instance predicted polarization labor market lowwage service work highwage “knowledge” labor likely different outcomes depending workers’ race gender polarization process black hispanic workers competing white workers lowwage service work may experience greater job loss due structural disadvantages like reduced labor market power23 moreover automation often leads elimination occupations changes task composition using framework frey osborne focusing time spent tasks capable automation using current tech nology mckinsey analysis argued fewer percent american jobs ai portends redefinition human occupations rather replacement entire jobs redefinition occurred repeatedly previous periods rapid technological change atms often cited example scale effects new technology outweighing substitution effects automation atms whol elimi nate need bank tellers rather changed tasks associated role allowed costeffective expansion bank branches25 autor describes seminal work whether case current wave aidriven automation dependent combination factors like whether nonautomated finally limitations conceptualizing occupations merely baskets discrete executable tasks though may distill occupations component tasks purposes analyzing anyone held job knows work depends deep seated human knowledge cannot always boiled rulesets protocols human knowledge—there things humans know course everyday pegah moradi “race ethnicity future work” april httpsdoiorg1031235 osfioe37cu moradi “race” moradi “race” danial borowczykmartins jake bradley linas tarasonis “racial discrimination us labor market employment wage differentials skil ” labour economics c –michael chui james manyika mehdi miremadi “four fundamentals workplace automation mckinsey” mckinsey digital november httpswwwmckinseycom businessfunctionsdigitalmckinseyourinsightsfourfundamentalsofworkplaceautomation david h autor “why still many jobs history future workplace automation” journal economic perspectives –autor “why still many jobs” future work age ai life evade easy categorization barely articulated let alone automated27 dimensions human work hard capture economic models repre sent reasons difficult machines whol assume roles human workers one oecd analysis28 applied much framework frey osborne used selfreported information things workers actual given occupation finding greater variation tasks within occupation well groupwork facetoface interaction jobs study ultimately estimated percent individuals high risk automation within next two decades contrast frey osborne’s much dire forecast another important complication forecasts attempt account indirect forms worker displacement might wrought ai studies focus exclusively technical automatability tasks within particular occu pations account broader industrylevel effects may fundamen tal restructure labor markets types work notable example booming growth online retail supported enabled implementation intelligent supply chain systems subsequent “retail apocalypse” closing brickandmortar stores across united states29 one forecast stores expected close percent retail sales estimated take place online per cent today30 moving retail online necessarily directly automate tasks required department store sales associate rather eliminates need role altogether potential creating different jobs points supply chain ensuing importance warehouses brickandmortar stores also creates space tasks simplified order better accommodate application ai robotics instance challenging robots safely pick vari able items unpredictable weight shape—something comes instinc tively humans—eretail companies like amazon implementing systems use ai build appropriately sized boxes around items rather robotic arm pick place box31 frey osborne note tasks changed become automatable indirect unemployment due ai often results task simplification taking people equation instead creating environments amenable machines michael polanyi tacit dimension university chicago press melanie arntz terry gregory ulrich zierahn “the risk automation jobs oecd countries comparative analysis” oecd social employment migration working papers paris oecd publishing may httpsdoiorg1017875jlz9h56dvq7en sabrina helm soo hyun kim silvia van riper “navigating ‘retail apocalypse’ framework consumer evaluations new retail landscape” journal retailing consumer services october httpsdoiorg101016jjretconser201809015 abha bhattarai “‘retail apocalypse’ analysts say us stores could doomed” washington post april sec economy httpswwwwashingtonpostcombusiness 20190410retailapocalypsenowanalystssaymoreusstorescouldbedoomed jeffrey dastin “exclusive amazon rol machines pack orders replace jobs” reuters may httpswwwreuterscomarticleusamazoncomautomationexclusive iduskcn1sj0x1 pegah moradi karen levy limitations demonstrates way outcomes forecasts complicated initial appear clear extent ai dis place existing jobs certain imminent ai impact conditions work32 rather focusing quantity displaced work ask ai might impact quality work workers job considering managers leverage intelligent systems firms’ objectives questions like less amenable broad economic forecasting breathless headlines—but inarguably ai’s impact workers less displacement integration existing labor structures managerial practices specifical discuss next section ai’s primary effect work con texts shift risks previously absorbed firms onto workers ai risk reallocator technology long held promise making work efficient technological advances workplace vaunted ability increase productivity incen tivize “good” work behaviors find eliminate bottlenecks like measur ing monitoring analyzing predicting rhetoric goes find waste streamline processes eliminate superfluous work mantra analytics practi cal article faith among managers believe data reveal secrets greater profit margins scheme workers’ labor input collected ana lyzed algorithmical optimized like practices rooted principles taylorism fordism scientific management aimed minimize wasted effort maximize production finegrained pacing control work processes33 ai contemporary workplace follows footsteps ethos via intensive monitoring predictive analysis nearly aspects work tasks broader supply chain34 monitoring analysis make workplace efficient maybe— necessarily practices actual eliminating waste increasing productivity instead technologies insidiously hide work offloading brishen rogers “beyond automation law political economy workplace technological change” february httpspapersssrncomabstract3327608 rogers reaches similar conclusion analysis law political economy workplace automation like us posits threat automationinduced job loss “overstated” pressing issues involve managerial techniques including worker monitoring algorithmic scheduling rogers also thoughtful points relation workplace data collection “fissuring” workplace—that firms’ outsourcing key functions outside contractors harry braverman labor monopoly capital degradation work twentieth century new york monthly review press kirstie bal “workplace surveil ance overview” labor history february –httpsdoiorg10108000236561003654776 james r beniger control revolution technological economic origins information society cambridge harvard university press future work age ai burdens firm onto comparatively less powerful workers lots inefficiencies still exist monitored workplaces aidriven managerial practices redistribute risks costs inefficiencies workers serving firm’s bottom line enumerate illustrative nonexclusive list four practices following35 staffing scheduling traditional risks fluctuating consumer demand borne largely firm hours store restaurant instance may unexpectedly slow though managers ideal try match customer demand labor supply ie workers shift previously could approximately usual based historical indicators like aggregate sales volume given period often meant man agers bore risk overpaying excess labor capacity ie wages unexpectedly slow periods36 algorithmic technologies changed landscape staffing scheduling however transferring burden demand uncertainty firm worker sophisticated staffing algorithms integrate many sources data—including example realtime customer traffic derived instore sensor networks well external variables like weather—to predict customer demand associated staffing levels dynamical result workers variety “just intime” scheduling practices introduce significant precarity instability lives lowwage workers37 include patterns like irregular “splitshift” sched uling ie workers work multiple shorter shifts periods high demand clocking between—leaving time unpaid highfluctuation work sched ules many hours one week next shortnotice scheduling including notified prior shift’s beginning whether come in38 focus management alreadyhired workers bracket analysis consideration ai’s emerging role hiring processes implications ai hiring ably analyzed miranda bogen aaron rieke “help wanted exploration hiring algorithms equity bias” upturn dec httpswwwupturnorgstaticreports2018hiringalgorithms filesupturnhelpwantedanexplorationofhiringalgorithmsequityandbiaspdf karen levy solon barocas “refractive surveil ance monitoring customers manage workers” international journal communication march –levy barocas “refractive surveil ance” susan j lambert anna haleylock julia r henly “schedule flexibility hourly jobs unanticipated consequences promising directions” community work family august –httpsdoiorg1010801366 daniel schneider kristen harknett “schedule instability unpredictability worker family health wel being” washington center equitable growth working paper sept httpcdnequitablegrowthorgwpcontentuploads20160912135618091216wp scheduleinstabilityandunpredictabilitypdf ari schwartz michael wasser merrit gil ard michael paarlberg “unpredictable unsustainable impact employers’ scheduling practices dc” washington dc dc jobs pegah moradi karen levy effect practices destabilize workers’ livelihoods interfering nonwork activities—like school childcare second job—and creating severe financial stress leading even intergenerational cognitive harms39 moreover costs disproportionately borne women workers color occupy service positions higher rates40 firms may lower labor costs due reduced risk overstaffing upshot practices burden uncertainty demand shifted workers subject scheduling systems defining compensable work firms gain visibility control workers’ activities narrowly define work include specific tasks pay workers tasks exclusively managerial technology allows firms focus closely considered essential job fair labor standards act flsa requires employers pay employees time worked activities considered courts ruled several activities non compensable like commuting work42 waiting go required security screenings43 donning doffing protective gear44 even though principal work tasks cannot practical speaking completed without though many workers including gig economy workers covered flsa law’s narrow framing compensable work conceptual instructive algorithmic technologies may circumscribe firms’ defini tions essential compensable work actual reduce amount work workers example drivers uber rideshare companies paid time actively transporting passenger— time spend driving around waiting app alert passenger nearby time spend driving pickup point time spend returning long trip town time expense required clean cars offer amenities order get high justice june httpswwwdcfpiorgallunpredictableunsustainabletheimpactofemployers schedulingpracticesindc schwartz et al find roughly percent service sector workers reported oncall shift scheduling workplace leila morsy richard rothstein “parents’ nonstandard work schedules make adequate childrearing difficult” issue brief washington dc economic policy institute august httpswwwepiorgpublicationparentsnonstandardworkschedulesmakeadequate childrearingdifficultreforminglabormarketpracticescanimprovechildrenscognitiveand behavioraloutcomes levy barocas “refractive surveil ance” integrity staffing solutions inc v busk ct vega v gasper f3d 5th cir integrity staffing solutions inc v busk ct llorca v collier county sheriff f3d 11th cir future work age ai customer ratings impact security employment45 undertakings seen directly generating revenue company unpaid course reality tasks part parcel work uber driving costs work including opportunity costs—the time driver could making money otherwise something else entirely—and direct costs like gas vehicle wear tear borne entirely driver though model payment isn’t created algorithmic dispatch—it instance long feature truckdriving labor model—the use aidriven platforms sup port industries broadens exacerbates effects granular measurement capabilities also used explicitly recalibrate compensation schemes favor firm instance amazon changed paid authors books available kindle platform amazon’s tech nology gave visibility exactly many pages book readers actual read began compensating authors perpageread basis rather number books downloaded—shifting risk boring book author46 similarly music streaming services like spotify pay artists pertrackstreamed basis track “counted” listener plays least thirty seconds rather albums sold tracks downloaded47 theory compensation models like reward popu larity implicitly quality—but practice model often blamed “stream bait” homogeneity cultural production riskaverse artists conform styles likely generate revenue algorithm48 collectively trends tightly circumscribe considered compensable work “counting” certain tasks others constricting considered compensable work optimizing narrowly aidriven systems may increase proportion work considered residual unworthy payment like produc ing ultimately unpopular song driving passenger pickup replenishing mints ensure high rating work activities—what craig lambert termed “shadow work”—don’t disappear aren’t accounted rather systems shift risks costs employer worker must internalize real labor doesn’t “count”alex rosenblat karen ec levy solon barocas tim hwang “discriminating tastes uber’s customer ratings vehicles workplace discrimination” policy internet june –httpsdoiorg101002poi3153 anita singh “amazon pay kindle authors pages read” telegraph june sec technology httpswwwtelegraphcouktechnologyamazon11692026amazonstopaykindle authorsonlyforpagesreadhtml zachary mack “how streaming affects lengths songs” verge may https wwwthevergecom201952818642978musicstreamingspotifysonglengthdistributionproduction switchedonpopvergecastinterview liz pel “streambait pop” baffler december httpsthebafflercomdownstream streambaitpoppel craig lambert shadow work unpaid unseen jobs fill day berkeley ca counterpoint karen levy “the future work isn’t counted counts” pacific standard june httpspsmagcomeconomicsthefutureofworkwhatisntcountedcounts pegah moradi karen levy detecting predicting loss fraud ai may also used redistribute risk deliberate damage loss brought enterprise employees purposively behaving firm’s interests often involves employees violating law terms employment—whether stealing merchandise embezzling money company coffers sharing secret recipe—or whistleblowing bring light firm’s illegal unethical behavior principalagent problem poses inherent risks running business employers historical attempted lower risk myriad lowtech hightech means norm employer call references determine supposed character potential hire perform background checks previous criminal convictions employees dealing sensitive proprietary information often required sign nondisclosure noncompete agreements risks especial prominent retail product directly handled employees often supervision according national retail security survey approximately percent retail sales—amounting billion costs us retailers— lost inventory “shrink” employee theft cited secondhighest cause shrink external shoplifting51 costs shrink make retail natural adopter lossprevention technologies techniques use cctv cameras maintenance creation industrywide hiring blacklist individuals suspected theft52 employers use ai continue cracking risk deliberate damage often using technologies continuously track analyze worker behavior activity loss prevention firms like appriss retail offer services use ai model employee behavior flag unusual behavior could fraudulent harmful firm53 outside retail companies similarly monitor employee activity especial communi cations54 leaked list phrases shows goldman sachs flagging emails lines like “clowns managing fund” “report matter secnasdnyse” “this won’t happen again” scrutiny55 londonbased firm statustoday continuously tracks bob moraca richard hollinger “national retail security survey” national retail federation httpscdnnrfcomsitesdefaultfiles201810nrfnrssindustryresearch survey2018pdf “class action lawsuit challenges legality retail theft databases california background checks” employment screening resources blog february httpwwwesrcheckcom wordpress20140211classactionlawsuitchallengeslegalityretailtheftdatabasescalifornia backgroundchecks “secure” appriss retail httpsapprissretailcomsolutionssecure accessed june alex rosenblat tamara kneese danah boyd “workplace surveil ance” data society working paper october httpswwwdatasocietynetpubsfowworkplacesurveil ancepdf eamon javers “you won’t believe gets email flagged goldman cnbc list” cnbc june httpswwwcnbccom20160615youwontbelievewhatgetsanemail flaggedatgoldmancnbchasthelisthtml though list cited rather lowtech execution goldman sachs continued practice updated search terms future work age ai electronic behavior flags unusual activity like employee accessing files don’t usual access copying large numbers files56 loss fraud prevention use ai service may seem quite rea sonable part firm al would condone outright theft firms seem justified protecting assets ensuring regulatory compliance like goal pass normative judgment propriety advisability aims practices rather discuss two reasons related riskshifting worker power first though technologies explicitly framed reducing risk firms workers’ deliberate malfeasance monitoring workers theft fraud often practical inseparable tracking productivity efficiency purposes platform advertised minimize threats firm’s security often also used ensure employees maximal productive57 concerns fraud may used pretext justify entire data collection regime case contexts eg state benefits provision58 discuss productivity monitoring detail next section second preventing detecting loss fraud specific implications risk reallocation firm worker systems often predictive meaning harm malfeasance actual happened yet words rather mit igating actual loss ex post employer looking potential harm ex ante distinction important difference workers systems’ predictive accuracy poor employers especial riskaverse—say weak labor market abundant potential hires—these systems may prevent many workers deemed displaced firms potential hires employers long based hiring decisions heuristics “mark” workers based characteristics like race prior incarceration often making workers effectively unhireable precluding economic op por tu nity59 greater use predictive systems loss fraud prevention may exacerbate trends especial workers already disadvantaged complication arises nature data theft prevention databases selfreported shared among employers often based merely suspicion ie without substantiation timothy revel “ai tracks every move tel boss you’re slacking” new scientist yourbossifyoureslacking steve o’hear “statustoday scores nearly 4m grow aipowered ‘employee insights’ service” techcrunch blog httpsocialtechcrunchcom20180220statustoday statustoday instance maps communications outcomes see employees work best also flagging cybersecurity threats virginia eubanks automating inequality hightech tools profile police punish poor devah pager marked race crime finding work era mass incarceration chicago university chicago press jennifer l doleac benjamin hansen “does ‘ban box’ help hurt lowskilled workers statistical discrimination employment outcomes criminal histories hidden” working paper national bureau economic research july httpsdoi org103386w22469 pegah moradi karen levy subsequent criminal charges likely inflected employers’ biases fact concerns inaccuracies lack due process associated inclusion databases given rise lawsuits alleging use may violate fair credit reporting act60 incentivizing evaluating productivity final intelligent systems used measure assess incentivize workers’ perfor mance workplace like loss prevention concern workers putting forth less full effort feature principalagent relations firms take many steps incentiv ize workers expend labor61 conversely may punish workers perceived shirking though worker surveil ance productivity maximization nothing new aidriven systems may extend practice new types workplaces—for example workplaces like longhaul trucking previously shielded collection virtue geographic diffusion62—and toward invasive finegrained forms monitoring amazon example issued “inactivity reports” warehouse workers detecting workers temporarily stop moving even periods short one minute63 currently holds patent wristband tracks worker’s movements speed buzzing haptic feedback direct worker next item64 workers amazon warehouses reported grueling pressures including inadequate breaks using bathroom meeting religious needs physical mental health crises result strenuous conditions65 leaked corporate documents show worker supervision tracking—up including termination employment insufficient productivity—is handled aidriven system66 platformbased firms like uber also use ai promote driver productivity using fleetwide supplydemand stephanie clifford jessica silvergreenberg “retailers track employee thefts vast databases” new york times october sec business httpswwwnytimescom20130403 businessretailersusedatabasestotrackworkertheftshtml michael burawoy manufacturing consent changes labor process monopoly capitalism chicago university chicago press karen ec levy “the contexts control information power truckdriving work” information society march –httpsdoiorg101080019722432015998105 michel bauwens “the hyperexploitative labor practices amazoncom” p2p foundation blog ceylan yeginsu “if workers slack wristband know amazon patent it” new york times november sec technology httpswwwnytimescom20180201 technologyamazonwristbandtrackingprivacyhtml chavie lieber “emergency cal placed amazon warehouses depict enormous pressure put workers” vox march httpswwwvoxcomthegoods201931118260472 amazonwarehouseworkers911cal ssuicide colin lecher “how amazon automatical tracks fires warehouse workers amazonwarehousefulfillmentcentersproductivityfiringterminations future work age ai predictions behavioraleconomic “nudges” tailor incentives toward profit maxi mization67 customerfacing service jobs like call centers ai used monitor speed work also alignment behavioral affective criteria like tone voice retail settings workers may incentivized evaluated based automated analysis interactions customers floor68 productivity incentivization priori bad workers commissionbased work example may advantageous labor well management many contexts finegrained monitoring erodes trust dignity sense privacy work reduces workers’ decisional autonomy69 opens door labor exploitation driving workers limits physical mental capabilities working less one’s full capacity considered form “time theft”similar concerns attach respect loss prevention described intelligent systems workplace used service several managerial techniques may enable firms dynamical schedule workers minimizing labor costs creating substantial instability workers’ lives firms may use ai narrowly redefine work tasks concomitantly classifying practical necessary labor ancil ary noncompensable may use predict worker theft malfeasance potential resulting underclass “marked” workers deemed risky hire may use incentivize productivity removing slack work time perhaps serious damage workers’ physical mental health dynamics created ai features laborman agement relations long time likely remain long time come ai may enable firms effectively pursue existing goals prac tices therefore offloading burdens reallocating risks onto workers displacement riskshifting policy policy recommendations future work commonly focus mitigating harms labor displacement like unemployment depressed wages increased noam scheiber “how uber uses psychological tricks push drivers’ buttons” new york times april sec technology httpswwwnytimescominteractive20170402technology uberdriverspsychologicaltrickshtml ryan calo alex rosenblat “the taking economy uber information power” columbia law review –levy barocas “refractive surveil ance” sam adlerbell michelle miller “the datafication employment” century foundation december httpstcforgcontentreportdataficationemploymentsurveil ance capitalismshapingworkersfutureswithoutknowledge william dickens lawrence f katz kevin lang lawrence h summers “employee crime monitoring puzzle” journal labor economics –pegah moradi karen levy inequality result labor market polarization71 although ai often framed new frontier policymaking proposed solutions often focus strengthening long standing social institutions recommendations include investing k–and college education often focus stem science technology engineering mathematics fields retraining displaced workers provide mar ketable skil new economy bolstering social safety net reforms unemployment insurance public benefits programs somewhat contro versial support universal basic income programs would provide uncon ditional cash guarantees individuals regardless circumstance72 policy proposals stand benefit millions americans whether jobs displaced ai represent sound economic investments future work—whatever may look like addition proposals like however also consider protections might provide workers retain jobs order temper risk reallocation intensifies managementworker inequity example number states municipalities taken steps curtail workerunfriendly scheduling practices fair scheduling laws—sometimes response threat wage theft lawsuits73 laws things like require managers announce schedules advance end “oncal ” shifts create minimum shift lengths help recalibrate employers’ ability shift costs workers algorithmic scheduling worker protections could similarly reallocate risks back firms one clear avenue would end forced arbitration often bars employees litigating claims employers court proposed reforms like arbitration fairness act would prevent employers able enforce arbitration agree ments employment disputes74 second route forward includes reforms worker classification regimes characterize many platformbased workers independent contractors rather employees therefore removing protections due labor law minimum wage unionization etc reforms currently afoot states75 broadly amendments fair labor standards act could made include workers currently exempt protections example longhaul truck drivers—and regulated industries compensation regimes might modified accurately recognize workers’ time effort might autor “why still many jobs” ryan calo “artificial intelligence policy primer roadmap” uc davis law review –executive office president “artificial intelligence automation economy” httpsobamawhitehousearchivesgovsites whitehousegovfilesdocumentsartificialintelligenceautomationeconomypdf brishen rogers “basic income society” boston review may http bostonreviewnetforumbrishenrogersbasicincomejustsociety elizabeth tippett charlotte alexander zev j eigen “when timekeeping software undermines compliance” yale journal law technology katherine vw stone alexander js colvin “the arbitration epidemic” economic policy institute report december httpswwwepiorgpublicationthearbitrationepidemic paris martineau “california lawmakers move protect gig economy workers” wired may httpswwwwiredcomstorycalifornialawmakersmoveprotectgigeconomyworkers future work age ai regulate ban use forprofit “retail justice” databases blacklist potential employees suspected theft without due process76 one note order organizational sociologists long examined techno logical interventions workplaces effects workplace roles relation ships77 key lesson work technology unified set effects deployed workplace alter new social dynamics ossify old ones depending conditions surrounding deployment—including industry structures broader economic forces workplace culture institutional mechanisms governing rela tions labor management studies previous technologies provide vital lesson contemporary forecasting ai’s impact workers ethical issues likely bring fore must include concomitant consideration specific social economic cultural dynamics workplace policies put place mitigate negative effects must also take account observation caveat forecasters policymakers also cause optimism suggests many firmlevel levers may mitigate negative dimensions workplace ai nothing set stone perhaps contrary call workplacespecific action many aforemen tioned policy proposals identify—in either displacementremediation risk reallocation buckets—may seem like general basic little artificial intelligence specifical issues resulting integrat ing ai work whol new instead continuation long line labor concerns endured transformed throughout history industrial ized work specter ai workplace necessarily spell doom dystopia rather elucidates burdens placed workers may bring new energy creating policies protect workers generations come—ultimately protecting quality work quantity acknowledgments authors grateful acknowledge support john catherine macarthur foundation new america cornell university center social sciences grateful helpful comments insights joshua popp matthew sun notes portions chapter draw pegah moradi’s thesis manuscript “race ethnicity future work” conducted advising jamila michener karen levy sergio garciarios cornell university john rappaport “criminal justice inc” columbia law review –kelley “new process technology” barley “technology occasion structuring” steven blader claudine madras gartenberg andrea prat “the contingent effect management practices” columbia business school research paper httpspapersssrncomsol3papers cfmabstractid2594258 pegah moradi karen levy bibliography autor david h “why still many jobs history future workplace automation” journal economic perspectives –autor david h frank levy richard j murnane “the skill content recent technological change empirical exploration” quarterly journal economics –braverman harry labor monopoly capital degradation work twentieth century new york monthly review press brynjolfsson erik tom mitchel daniel rock “what machines learn mean occupations economy” aea papers proceedings –httpsdoiorg101257pandp20181019 gray mary siddharth suri ghost work stop silicon val ey building new global underclass boston houghton mifflin harcourt levy karen solon barocas “refractive surveil ance monitoring customers manage workers” international journal communication march –polanyi michael tacit dimension chicago university chicago press rogers brishen “beyond automation law political economy workplace technological change” february httpspapersssrncomabstract3327608 chapter ai moral rightholder john basl joseph bowen introduction currently advocates “robot rights”with saudi arabia even granted citizenship certain instantiations ai2 entry develop skeptical stance toward idea current forms artificial intelligence holders moral rights3 articulate would take ai system moral rightsholder4 first distinguish moral rights sorts rights moti vating one ought care whether ai holds rights articulate one prominent view plausible theories moral rights interest theory theory rights necessarily protect holders’ interests whether particular form ai rightsholder hangs whether form ai type thing interests argue current ai’s systems built around machine learning interests developing view mark coeckelbergh “robot rights towards socialrelational justification moral consideration” ethics information technology –david gunkel robot rights cambridge mit press “saudi arabia bestows citizenship robot named sophia” techcrunch blog httpsocial techcrunchcom20171026saudiarabiarobotcitizensophia accessed march question whether ai rights different general question whether moral status type whatsoever though may turn considerations speak favor skeptical stance ai rights apply similarly questions ai’s moral status general general debate see john basl “machines moral patients shouldn’t care yet interests welfare current machines” philosophy technology systems ethics” ethics information technology –in chapter use “ai” “ai systems” refer technologies way integrate artificial intelligence one forms autonomous vehicle isn’t real ai technology relies ai system tasks john basl joseph bowen defend view capacities abilities necessary sorts interests ground rights apply current potential future forms ai everyone endorses interest theory also consider whether ai rights primary alternative interest theory theory according theory rights necessarily endow holders normative control others suggest theory may make space ai bearers moralrights think position implausible despite skepticism rights current ai development ai raises significant challenge think possible might create ai rights holder position know done circumstance likely violate rights ai closing section chapter outline challenge use motivate cautious approach development ai rights rights kinds rights single question whether ai hold rights single discourse single conception rights consider case dictator enacts law grants right claim property see fit dictator gains legal right property implausible moral right property dictator enacting laws allowing kill citizens pleasure focus whether ai could holders moral rights5 whether one legal rightsholder legal rights one holds depends least legal frame works legal rights depend least extent choices particular individu als institutions feature legal rights opposed moral rights makes coherent examples dictator legalizing theft murder6 contrast legal rights moral rights important sense us7 whether human nonhuman discussion legal issues surrounding ai rights see joanna j bryson mihailis e diamantis thomas grant “of people legal lacuna synthetic persons” artificial intel igence law september –many think actual existence legal rights depends legal system’s positing legal right exists example minimal defenders hohfeld’s definition claimright duty owed claimright holder substantively think theories rights account legal well moral rights think desired necessary sufficient conditions rights also need satisfied don’t presuppose truth particular normative theory intend preclude theories rights grounded example rational beings would would reasonably consent reject there’s real sense rights could ultimately grounded requirements rationality clearly makes rights depend us sense ai moral rightholder animal ai holds moral rights depend whether moral right recognized codified laws8 rights one might wonder worth asking whether ai hold rights four reasons first pragmatic reason often public debate language rights example debate tends whether people may use bathroom gender identify whether right given public debate often rightstalk important know whether ai even capable holding rights arguing rights hold second rights taken offer particularly robust protection certain forms conduct rights typical taken place constraints promoting good exam ple plausibly impermissible kill healthy patient order donate organs save five sick patients even would maximize good typical explanation verdict healthy patient right killed cannot ridden mere fact killing patient would bring good—in way rights often seen imposing sideconstraints others’ behavior “trumps” types considerations providing others “exclusionary reasons” on9 third rightsholder implications owed rightsholder rights violated relationality directionality rights addition different domains find rights eg legal versus moral domain also different kinds rights might hold others restricting moral rights10 paradigm form rights claimright call claimrights rights “strict sense” one person holds duty performance right11 example joe right john john hit case john duty owed joe hit joe john’s duty directed—directed toward owed joe nature directed duty opposed john’s undirected duty john may undirected duty might well many kinds rights beyond legal moral rights example one might say special set moral rights citizens seen protects specifical coercive intervention state grounded something normative theory case liberal views political philosophy see respectively robert nozick anarchy state utopia oxford basil blackwel ronald dworkin taking rights seriously cambridge harvard university press joseph raz morality freedom oxford oxford university press wesley newcomb hohfeld fundamental legal conceptions applied judicial reasoning formal x holds claimright φ duty φ owed x x rightholder correlative dutybearer φ action performance x holds right kinds rights hohfeldian framework liberty power immunityright hereafter rights referred claimrights john basl joseph bowen example recycle donate clothing need rather throwing away importantly john’s undirected duties owed anyone particular rights correlate directed duties fail satisfy others’ rights wrongly also wrong someone owe duties12 normative upshots specific directed duties correlative rights duty directed many think demandable behalf party owed violation triggers apology owed party well potential duties compensation correlatively many think special standing blame forgiveness part party duty owed rightholder duty undirected demandable behalf particular party viola tion trigger duties owed particular parties whatever owed light failures respect duties won’t compensatory final fourth rights don’t ground restitutive duties vio lated also ground preemptive actions sal planning unjustifiably break jane’s leg think sal may enforce rights violation exam ple may permissible jane inflict proportionate necessary defensive harm order stop jane things lot less clear comes enforceabil ity undirected duties features world ai rightsholder different world normatively speaking world ai rightsholder even duties regarding ai13 example world ai rightsholder treatment ai simply subject concerns promoting good may wrong ai wrong ai might duties compensate itto offer apology otherwise make wrongdoing ai others acting behalf ai may justified taking preemptive action prevent violating rights interest theory rights we’ve said rights correlate directed duties—that someone holds right another party owes duty—one might think hasn’t actual people think directed duties correlate claimrights though agree violate rights” proceedings aristotelian society leif wenar “the nature claimrights” ethics scenario may duties regarding ai least two ways first may undirected duties respect ai second ai may object directed duties owe individuals much extant discussion ai robot rights focuses ways ai robots enter social relationships us see example coeckelbergh “robot rights” relationships might ground undirected duties given reasons give focusing rights fact theories rights developed capture distinctive normative elements makes sense discuss extant proposals robot rights call us rethink rights attempts explain might directed forms duties ai moral rightholder done much explanatory work leif wenar puts “what means one person owe duty another opaque”a theory rights provides account nature rights inasmuch explains nature directed duties according interest theory rights rights necessarily grounded well interests rightholder think one’s important rights— one’s rights killed tortured raped might one think rights important one thought would awful one things happen according interest theory precisely things would awful right protects actions others initial formulation interest theory let’s say stake john hit must sufficient weight place joe duty hit him—his interests must ground duty’s existence15 interest theory lot going good job explaining directionality rights—why hold right someone perform action owe duty perform action interest theory duty owes existence features rightholder failure respect duty correlative right means failing respond particular individual’s wellbeing precisely duty owed rightholder interest theory also help explain else equal rights example lied weaker rights killed else equal interest killed greater interest lied to16 final interest theory also help us make sense constitutes appropriate restitution violations others’ rights vio lator right said owe least required make individuals whose rights violated whole trying make sure worse rights violation ai interest theory interest theory also provides us avenue thinking ai rights interest theory says rights grounded protection rightholder’s wenar “the nature claimrights” call justificatory version interest theory since rightholder’s interests must justify duty’s existence roots found raz morality freedom see later see beginning section theory rights everyone defines interest theory way however problems feature interest theory example see joseph raz “rights individual wellbeing” ratio juris –joseph bowen john basl joseph bowen wel means necessary condition rightholder interest theory one bearer wellbeing17 one bearer wellbeing de facto one’s wellbeing never going sufficient weight place others duties interest theory requires question presents account wellbeing one ought prefer18 wellbeing necessary though perhaps sufficient condition hav ing rights turns ais certain type wellbeing interest theory rights turns ais certain type wellbeing must question wellbeing sufficiently moral weighty ground rights subjectivist views wellbeing ai subjectivist views wellbeing bearers wellbeing al minimum con scious19 capable form subjective experience mental states par use terms “welfare” “wellbeing” interchangeably remain agnostic whether one think one’s interests merely another term one’s wellbeingwelfare subset one’s wellbeing capacious one’s wellbeing final ease exposition sometimes say thing wellbeing case bearer wellbeing think necessity bearer wellbeing slightly differently example raz says “‘x right’ x rights things equal aspect x’s wel interest sufficient reason holding persons duty” raz morality freedom continues “an individual capable rights either wel ultimate value ‘artificial person’ eg corporation” setting aside holding rights artificial persons think raz’s inclusion capacitytoholdrights clause redundant one hand one might think wellbeing ultimate value correct inclusion capacity clause redundant hand one thinks beings whose wellbeing ultimate value beings ought hold rights presumably being’s wellbeing would never sufficient reason holding others duty either way raz’s inclusion capacity clause redundant kramer also goes different way us defines interests incredibly capaciously “to say interests x advanced occurrence event emergence state affairs say x benefit ways specified event state affairs” matthew h kramer basingstoke palgrave says inquire moral status interestbearer determine whether duty’s serving interests gets result rights defines interests capaciously “run together conceptual moral dimensions” takes rightholder entirely clear distinction getting case one thinks certain kinds interestbearers hold rights example perhaps sentient interestbearers separate necessary condition rightsholder reflecting back kramer cal conceptual matter think better define interests precisely subjectiveobjective distinction respect wellbeing typical used distinguish views specific kind mental state necessary wellbeing proattitudes see example lw sumner welfare happiness ethics oxford university press however purposes want allow views mental states example simple sensations could ground wellbeing using slightly nonstandard version distinction ai moral rightholder adigm example view hedonism according hedonism thing ultimately impacts wellbeing—that makes life go well poorly—is presence enjoyment hedonists say something enjoyable case certain hedonic profile—namely feels enjoyable20 hedonists think enjoy something take positive attitude toward it—on somewhat crude version view positive attitude might one wants experience continue21 ongoing debate subjectivists theory subjective well correct—about example particular mental states capacities ground wellbeing22 fortunately without getting involved debate still draw useful conclusions whether ais wellbeing particular think current ai systems built around machine learning algorithms power things like google’s pagerank autonomous vehicles weapons systems satisfy minimal requirements wellbeing reason skeptical current ai systems conscious meeting minimal conditions wellbeing subjectivism based clear standing technologies heart current ai systems machine learning algo rithms algorithm set instructions mapping inputs outputs traditional steps input output decided designed implemented “by hand” systems built machine learning algorithms differ take advantage algorithm learner generates algorithms23 take following stylized case example programmer would like algorithm takes content emails inputs either places email user’s inbox spam folder programmer realizes writing algorithm hand extremely inefficient unreliable even possible instead make use machine learning algorithm learner provide learner set training data contains desired inputoutput pairings case training set contain large number emails spam genuine marked learner uses training set generate algorithm classifying new emails genu ine spam based learner essence takes role programmer machine learners capable generating algorithms perform tasks pro grammers deploying traditional algorithms would find impossible least extremely difficult ai systems built around machine learners outperform humans wide variety tasks example even best human chess players longer regularly beat best ai systems also good reason predict autonomous roger crisp “hedonism reconsidered” philosophy phenomenological research fred feldman pleasure good life concerning nature varieties plausibility hedonism new york oxford university press overview discussion see james griffin wellbeing meaning measurement moral importance new york oxford university press stuart j russell peter norvig artificial intel igence modern approach harlow pearson education meredith broussard artificial unintel igence computers misunderstand world cambridge mit press john basl joseph bowen vehicles safer drivers human counterparts give us reason think like us ai systems conscious might subjective wellbeing end machine learners algorithms output algorithms much reason believe ai built around machine learning conscious traditional algorithms conscious extent don’t think programs laptops conscious think symmetrical contemporary ai systems future ai systems built around machine learning summarize case ai rightsholder follows ai potential rightsholder bearer wellbeing ai bearer wellbeing conscious ai conscious ai cannot said rights premise subject objection example one might reject interest theory premise consider alternative interest theory following section “the theory rights” consider objections premises argument identify survives ways argument conclusion must modified consciousness ai one reason reject argument ai rights might wrong ai consciousness actual two flavors objection first might wrong nature consciousness second might focused machine learners generalize conclusion ai general take turn one might think consciousness nothing reduces algorithmic thinking processing behaviors certain kind24 similarly one might skeptical real anything consciousness25 argument rests assump tion consciousness depends something moving intuition traditional algorithms aren’t conscious using ground claim machine learning systems also conscious want somewhat conciliatory towards sort objection absence general theory consciousness physical bases difficult sure whether origins view found alan turing “computing machinery intelligenceam turing” mind hilary putnam “robots machines artificial created life” journal philosophy –however turing putnam concerned question judge machine conscious intelligent rather defending view bases consciousness daniel dennett consciousness explained london penguin ai moral rightholder entities unlike us conscious26 case john might take joe conscious basis fact john conscious recognizes joe behaves awful lot like physiological much like importantly john joe evolutionarily related tend share lot traits furthermore experiments seem suggest connection one hand neurophysiology anatomy hand consciousness john rea son think joe sharing neurophysiology anatomy probably also con scious similar way case mammals sources evidence available since reason think consciousness evolved branch tree life since mammals pretty similar neurophysiology anatomy behave pre dictable ways response stimuli would take painful somewhat confident conscious things get difficult move locations tree life branch organisms different behavioral patterns physiology regard cephalopods con scious basis plasticity behavior despite fact wise different us27 safe reason trees lack consciousness think consciousness costly would selected organisms don’t physical capacity behavioral plasticity consciousness might allow ai systems might behave intelligent ways made entirely different matter programmed mimic intelligent behavior absent theory consciousness questions especial difficult argument trade assumptions things intuitively conscious take trees traditional software conscious reason could wrong despite conciliatory note think readers still adopt view ai rights consider implications adopting much liberal view consciousness current ai viewed conscious conscious way grounds subjective wellbeing still see reason current ai viewed differently traditional algorithms much reason think software runs constitutes video game subjective wellbeing think millions users day subject dig ital entities massive amounts harm benefit cause example huge amounts suffering think doesn’t seem right could blinded assumptions consciousness case help show readers would mean accept liberal view consciousness discussion difficulties identifying theory see thomas nagel “what like bat” philosophical review –colin mcginn mysterious flame philosophy –peter godfreysmith minds octopus sea deep origins consciousness john basl joseph bowen turns liberal view consciousness could true real conse quence think question ai rights practical terms liberal view con sciousness might tell us ai wellbeing tel us nothing content wellbeing things actual benefit harm things con scious reason think ai programmed navigate vehicle wants enjoys ai loses jeopardy suffers absent way determine actual mental states artificial intelligent system dark whether promoting undermining system’s wellbeing can’t know despite best efforts interests ai system surely excused frustrating interests failing promote them28 analogy imagine trying decide go dinner friend truly wish whatever best friend however refuse tell two places prefer unable gather evidence preference happens opt take sushi find fact absolutely hate sushi upset eat sushi restaurant certainly made worse choice given circumstances hardly seems blameworthy choice case ai similar position epistemical poor place comes determining preferences ai makes suffer may enjoy even imagine ai telling us “likes enjoys desires etc” behaves accordingly whatever evidence behaviors generate screened fact ai might programmed behave way yes ai convincingly emotes also might designed specifical trick us thinking mental states emotes despite mental states upshot ai might rights excused failures respect words intents pur poses ai doesn’t rights objection focused narrowly ai systems built around machine learning algorithms around machine algorithms exist today many ethical issues confront currently arise due sorts systems much philosophical interest ai stems consideration artificial general intelligence agi—ai based brain simulations—and instances artificial consciousness even today’s ai systems rightsholders systems tomorrow people think reasonable us know affects rights obtain see example michael j zimmerman ignorance moral obligation oxford oxford university press jonathan quong “rights harm” aristotelian society supplementary volume harm person person right perform action views even ai bearers wellbeing would merely excused violating ai’s rights would hold rights us first place reasonable us know bearers wellbeing ai moral rightholder acknowledge ai system created good reason believe conscious sorts mental states ground interests humans could get evidence particular inter ests ai ai would rightsholder don’t think thing special human wellbeing grounds rights would preclude like interest ai system grounding similar sort right words endorse sometimes referred “substrate nondiscrimination”the moral status rights doesn’t depend made certain stuff unless made stuff required wellbeing acknowledge conscious ai sort would rightsholder still face daunting epistemic challenge able tell created ai there’s sense skepticism ai rights bearer tem pered hypothesize existence ai meets various conditions includ ing interests extent determinable question becomes whether technological approaches ai might position judge created ai meets conditions determinable inter ests sufficient weight ground right one technological approach ai might fit bill brain simulation attempts simulate neural connections brain human animal computer system30 imagine powerful computer running simula tion human’s brain able simulate emulate mind human let’s imagine successful system connected various systems allow example vocalize let’s say system starts talking us telling us “remembers” particular events past events correlate actual memories simulations’ actual human counterpart tell simulation fact simulation human memories aren’t real conscious five minutes simulated brain horrified first slowly adjusts situation starts making requests asks please ensure shut given visual sensors able see world say ai actual conscious bearer wellbeing confront hard questions consciousness physical impossible silicon conscious ai system good faking consciousness consciousness supervene sorts physical substrates perhaps simulation conscious one approach handling cases like adopt moral cautious approach based don’t know bases consciousness aren’t good position tell system conscious interests given nick bostrom eliezer yudkowsky “the ethics artificial intelligence” cambridge handbook artificial intel igence ed keith frankish william ramsey cambridge cambridge university press “scientists creating virtual simulations brain better understand real thing” allen institute march httpsalleninstituteorgwhatwedobrainsciencenewspressarticles scientistsarecreatingvirtualsimulationsbrainbetterunderstandrealthing john basl joseph bowen significant moral cost creating rightsholder failing treat way respects rights perhaps avoid research programs seem carry especial high risk outcome31 challenge becomes assess ing research programs determining level moral risk one hand argument justifies skepticism consciousness ai hand moral costs wrong could great means technolo gies research programs centered around developing example advanced general intelligence unclear view important problem resolve continue develop advanced forms ai objectivist views wellbeing ai another way challenge moderate skepticism ai rights deny con sciousness necessary condition bearer wellbeing al often confidently assert amount sunlight water good houseplants weed killer bad them—we talk easily benefits harms nonsentient organisms tacitly accept form called objective list view wellbeing view objective features life contribute detract wellbeing32 accept objectivelist view possible ai sys tems even current machine learning systems might features ground wellbeing making potential rightsholders promising way defend objectivelist view wellbeing would recognize nonsentient ai bearer wellbeing borrow views devel oped within environmental ethics defend view nonsentient organisms bearers wellbeing biocentric individualists believe living organisms moral status typical appealed teleological goaldirected account wellbeing ground claims wellbeing nonsentient organisms according view nonsentient organisms teleological organized systems systems organized toward certain ends growth reproduction ends define ground wellbeing organisms whatever promotes ends organ isms good whatever frustrates ends bad33 john basl “the ethics creating artificial consciousnesses” apa newsletter philosophy computers –eric schwitzgebel mara garza “a defense rights artificial intelligences” midwest studies philosophy –as note earlier way using subjectiveobjective distinction objective list views could subjectivist might consciousness required realize whatever objectively good entity would meet nontraditional definition subjectivist distinction subjectiveobjective meant help us take distinction conscious nonconscious ai theory ai wellbeing without conscious invoke objective list view objective sense kenneth goodpaster “on moral considerable” journal philosophy –paul w taylor respect nature studies moral political legal philosophy princeton nj princeton university press gary varner nature’s interest oxford oxford university press john basl death ethic life oxford oxford university press ai moral rightholder one hand views seem friendly understanding ai could bearer wellbeing doesn’t depend sentient al ai systems goaloriented essential systems developed deployed better humans traditional algorithms achieving certain ends seems straightforward could extend objectivelist views defended biocentrict individualists nonsentient ai hand biocentric individualists worked hard show views wellbeing extend artifacts take point view follow artifacts moral status typical tried avoid consequence claiming case artifacts goals derivative whereas organisms ends whatever ends artifact given us account give interests real account interests extent attempts distinguish organisms successful might rule extending teleological accounts wellbeing artificial intelligence34 think even nonsentient ai systems wellbeing grounded thing like teleological account wellbeing systems rightsholders recall interest theory wellbeing necessary condition rights sufficient wellbeing needs sufficiently weighty place others duties treat rightsholder particular ways least wellbeing sufficient weight give others reasons respect right even reasons overridden order show nonsentient ai rights would shown wellbeing ai weighty way seems implausible us see consider simple case conflict fairly trivial interest human grounded consciousness ends nonsentient ai system richard deciding two models car one model comes ful autonomous driving system installed richard avid car hobbyist finds idea selfdriving cars ridiculous thinks would quite funny purchase ful autonomous model never use despite fact time signs paperwork he’s actual forgotten autonomy features car purchases car drives lot never uses autonomy feature it’s clear richard’s joke funny seem clear richard hasn’t violated rights car making choice whether car interest defined goals realizing safe autonomous driving weighty enough impose kind obligation richard light trivial interest buy ing car finds slightly funny ironic one case35 however discussion distinction artifacts organisms see john basl ronald sandler “the good nonsentient entities organisms artifacts synthetic biology” studies history philosophy science part c studies history philosophy biological biomedical sciences –sune holm “biological interests normative functions synthetic biology” philosophy technology basl death ethic life full discussion cases see basl death ethic life ch john basl joseph bowen think generalizes skeptical interests ai systems sufficiently weighty override even trivial interests interests grounded mental states theory rights we’ve taken implications interest theory ai rights we’ve reached largely skeptical view ai rights however one might think good reason endorse interest theory let us briefly look three reasons36 object interest theory grounds think necessary rights grounded serve holder’s interests example possible might hold property rights worthless ugly garden gnomes even sentimental attachments—here “property rights gnomes serve interests way serve interest mine serve interests balance”so interest theory looks like cannot explain holding rights similar examples come mind promises another problem concerns might call referredrights take journalist’s right disclose sources right seem grounded interests disclosing sources public’s interest free press justificatory version interest theory defined rights must grounded holder’s interests looks like version interest theory cannot explain journalist holds right disclose sources38 remedy problem move weaker version interest theory call nonjustificatory version interest theory john right joe hit wellbeing stake john hit need served joe’s duty hit him39 journalist’s interests may ground example duties force disclose sources interests likely served duties nonjustificatory version view explain journalist may right disclose sources however nonjustificatory version interest theory comes problems principle theory deals thirdparty beneficiaries suppose dana promises erica pay fran intuitively dana owes erica duty pay fran owe fran duty pay purpose following three paragraphs purely il ustrative mean imply objections decisive going space engage rowan cruft “rights beyond interest theory theory” law philosophy fm kamm intricate ethics oxford oxford university press –this version interest theory famously defended matthew h kramer “rights without trimmings” debate rights philosophical enquiries ed matthew h kramer ne simmonds hillel steiner oxford oxford oxford university press –this simplification kramer’s view refined kramer since ai moral rightholder definition nonjustificatory version interest theory necessary condition additional necessary conditions explain dana owe duty fran correlatively fran hold right dana promise given fran’s interests served duty40 one answer dana owe duty fran correlatively fran hold right dana fran normative con trol dana’s duty erica normative control dana’s duty erica fran example waive dana’s duty perhaps explains erica fran holds right dana perhaps focusing wellbeing interest theory red herring thought behind theory rights neil maccormick puts theory recognizes rightholder’s “preeminent others rela tion given subject matter within given relationship”on theory right constituted rightholder normative control duties others take example erica’s right dana pay fran erica power waive dana’s duty normative control situation permitted leave duty existence waive third party power free dana duty face things erica would normative control dana’s duty point thirdparty could contrary erica’s wishes free dana duty working definition theory let’s say john right joe hit case john power waive leave existence joe’s duty hit him42 since said prefer interest theory theory we’ll offer brief explanation why43 traditional two problems theory first theory precludes rightholders without capacity control duties others means individuals undeveloped compromised dam aged rational capacities example young children severely mental dis abled suffering alzheimer’s disease cannot hold rights theory one may reply problem positing fiduciaries hold exer cise control others’ duties behalf without capacity control duties left wondering theory distinguishes gopal sreenivasan “a hybrid theory claimrights” oxford journal legal studies jurisprudence –neil maccormick “rights legislation” law morality society essays honour hla hart ed pms hacker joseph raz oxford clarendon famous defense theory see hla hart “legal rights” essays bentham studies jurisprudence political theory oxford clarendon –hillel steiner ne simmonds hillel steiner oxford oxford university press definition given actual bit simplification theory powers one might hold another’s duty grant normative control duty see example joseph bowen bowen “beyond normative control theory rights” john basl joseph bowen rightholders aren’t rightholders—we cannot simply look hold power waiver case second problem theory rules matter definition inalienable rights theory requires one able waive duty correlates one’s right—but right inalienable one cannot waive duty44 reasons liking theory nonetheless let us assess whether ai hold rights theory ai theory initial reason one might skeptical whether ai holds rights theory one might think even ai exert control others’ duties cannot owe duties ai one might think owe duties bearers wellbeing given definition claimrights given earlier one holds right someone else one directed duty owed think there’s something objection theorist might reply theory offering account owe another person duty—and positing cannot owe duties ai simply begs question theory45 whether ai holds rights theory turns whether ai exert normative control duties others example virtual assistants siri alexa exercise control duties example releasing us future artificial general intelligence agi systems able exert control despite substantial differences interest theory theory rights think tracing implications theory yields similar sort skepticism similar sorts reasons see let’s imagine we’ve said virtual assistant “i promise i’ll update software evening” grounds duty evening rol around assistant chimes say “remember said would update software evening don’t time i’ll autoupdate tomorrow afternoon” take assistant released us duty thus exerting norma tive control duty counts instance normative control interesting result background theory theory traditional seen narrower scope respect things rightsholders maccormick notes seems right’s inalienable marks normative strengthening right hard square theory “how odd –this kramer steiner example think theory matthew h kramer hillel steiner “theories rights third way” oxford journal legal studies ai moral rightholder interest theory consider previous two objections theory—that account rights without capacity control others’ duties inalienable rights turns precisely reason theory taken restrictive interest theory seems implausible sort control exer cised virtual assistant sort normative control duties propo nent theory mind theorist cares normative control see rights grounded autonomy see something funda mental important valuable rights bearers46 one way understand theory unlike interest theory every interest matter weighty grounds rights—it interest agency exercising autonomous choice grounds rights particular rights grounded potential exercise autonomous choice since theory grounds rights ultimately autonomy interests end place respect ai rights perspective interest theory47 make case ai rights theory one would develop account normative control agency liberal enough “choices” ai sys tems make count autonomous sense also show ai system’s well partly constituted fares respect choices alternatively one would develop version theory liberal conception normative control grounds rights independent connection autonomy wellbeing conclusion summary close connection rights wellbeing general skepticism ai systems especial current systems based around machine learning technologies bearers wellbeing largely skepti cal ai systems near future rightsholders things become difficult start think ai systems future given disagreement theory consciousness correct ways evidence consciousness misleading hard determine example sreenivasan says “on account associated theory justification empowering x waive duty correlative claimright vesting claimright lies fact serves x’s interest autonomy” weaker form mentioned footnote “as ‘appealing fashion’ value individual autonomy” natural rights” philosophical review april –hart “legal rights” –lw sumner moral foundation rights oxford clarendon press 92ff similar reason draw conclusions theories rights see example sreenivasan “a hybrid theory claimrights” wenar “the nature claimrights” john basl joseph bowen we’ve created ai system rights however given would extremely moral problematic pursue research program knowingly foreseeably create ai systems rightsholders fail respect rights good reason cautious develop novel forms ai perhaps lesson draw biggest rightsbased challenge facing us develop ai one nature rights apply ai systems balance poor epistemic position moral costs getting wrong violating rights failed notice address concern require deep col ab orations ethicists philosophers mind cognitive scientists computer scien tists many others hope entry highlights diverse expertise necessary moving forward bibliography basl john death ethic life new york oxford university press cruft rowan “why disrespectful violate rights” proceedings aristotelian society –griffin james wellbeing meaning measurement moral importance new york oxford university press kramer matthew h “getting rights right” rights wrongs responsibilities edited matthew h kramer –basingstoke palgrave mcginn colin mysterious flame new york basic books raz joseph morality freedom oxford oxford university press sumner lw welfare happiness ethics oxford oxford university press thomson judith jarvis realm rights cambridge harvard university press chapter could merge ai reflections singularity radical brain enhancement cody turner susan schneider science fiction stories star war jetsons humans surrounded sophisticated ais remain unenhanced historian michael bess says stories fall prey “jetsons fal acy”—they assume brain remain merely subject relatively slow pace darwinian evolution realisti cal however ai change world likely transform brain’s cogni tive perceptual abilities wel consider use ai technologies transform mind intelli gently designed god designers embark upon path better think schneider 2019a suggestion humans eventual merge ai currently discussed researchers media way humans avoid aibased technological unemployment path radical longevity superintelligence example elon musk recently remarked humans avoid outmoded ai “having sort merger biolog ical intelligence machine intelligence”further he’s founded new company neuralink aims connect brain directly computers addition already many projects developing brainimplant technologies treat mental illness michael bess grandchildren redesigned boston beacon press olivia solon “elon musk says humans must become cyborgs stay relevant right” guardian february httpswwwtheguardiancomtechnology2017feb15elonmusk cyborgsrobotsartificialintelligenceisheright cody turner susan schneider motionbased impairments strokes dementia autism suggest ing aibased brain enhancements become commonplace ’s things may well moving direction medical treatments today likely give rise enhancements tomorrow3 chapter hope clarify philosophical issues stake suggest sensible path forward il ustrate merging oneself ai could lead perverse realizations ai technology demise person sought enhancement positive vein offer ways avoid least within context one theory nature personhood here’s proceed first provide background socalled “tech nological singularity” first section outline methods cognitive percep tual enhancement second section third fourth sections discuss several concerns cognitive perceptual enhancement focus personal identity issue detail offering practical suggestions fifth section including certain ethical guidelines use brain enhancement devices taking stance “metaphysical humility” toward metaphysics personhood sixth section consider different ways external cognitive artifacts might augment personhood psychological theory identity comparing contrast ing psychological continuity version theory narrative version conclude many external artifacts lifelogs bolster psychological continuity unclear whether case respect narrative continuity final seventh section question whether radical forms enhance ment chips brain could constructed maintain psychological continuity narrative structure contend chips may able accom plish tasks invasive forms enhancement raise philosophical complications milder forms enhancement lack eg reduplication worries consciousness problem authenticity concerns provisional recommend basis certain invasive “substrate replacing” enhancements avoided favor biological enhancements technological singularity development ai driven market forces government military strategic investments billions dol ars pouring constructing smart household assistants robot supersoldiers supercomputers schneider 2019a example japanese government launched initiative androids take care nation’s elderly anticipation labor shortage ai projected outmode many human professions within next several decades according recent survey mostcited ai researchers expect ai “carry human professions least susan schneider artificial ai future mind princeton nj princeton university press could merge ai well typical human” within percent probability within percent probability given market forces strategic needs various countries stay abreast latest ai technologies ai may soon advance artificial general intelligence bine insights different topic areas display flexibility common sense rea soning take agi sort system processes information like humans expression “agi” understood general essential ai functions least well humans least key range tasks achieve precisely reverseengineered brain superintelligent ai hypothetical form ai surpasses us domains sci entific reasoning social intelligence more5 ray kurzweil transhumanist director engineering google writes vividly technological utopia benevolent superintelligence brings end aging disease poverty resource scarcity6 however even one grants agi superintelligence could developed utopian scenario questioned posing control prob lem—the problem humans control superintelligent system given system smarter humans domains concern system may goals run contrary human flourishing superintelligence could lead human extinction7 whether ai turns threaten existence humanity kurzweil transhumanists contend fast approaching “technological singularity” hypothetical point ai far surpasses human intelligence solve sorts problems weren’t able solve singularity stress features unpre dictable consequences civilization human nature idea singularity comes concept black hole “singular” object space time place normal laws physics break similar vein technological singular ity supposed generate runaway technological growth massive alterations civilization human mind8 important stress human technological innovations may rapid lead fullfledged singularity world changes overnight larger point still holds move twentyfirst century unenhanced humans may intelligent beings planet much longer greatest intelligences planet may synthetic vincent c müller nick bostrom “future progress artificial intelligence survey expert opinion” fundamental issues artificial intel igence –nick bostrom superintel igence paths dangers strategies new york oxford university press ray kurzweil singularity near humans transcend biology new york viking bostrom superintelligence vernor vinge “the coming technological singularity survive posthuman era” whole earth review cody turner susan schneider cognitive perceptual enhancement background cognitive perceptual enhancements amplify extend one’s cognitive perceptual capacities improvement augmentation one’s information processing sys tems including sensory systems9 whereas therapies intervene correct problem cognitive perceptual systemsubsystem enhancements contrast intervene improve cognitive perceptual ability perhaps even provide new capacity10 many kinds cognitive perceptual enhancement technologies could utilized future ranging ordinary science fictionlike different methods enhancement summarized follows brain implants involving ai technologies currently brain chips primarily developed therapeutic opposed enhancement purposes theodore berger’s lab university southern california example developing artificial hippocampus could allow individuals severe memory impair ment formulate new memories researchers currently work creating brain chips impairments wel depression posttraumatic stress disorder alzheimer’s disease neural prosthetic technology devel ops likely technologies used enhancement wel people wish enhance reasoning capacities memory attention well beyond considered biological normal pharmaceutical drugs pharmaceutical drugs currently developed therapeutic purposes eg treat adhd likelihood remain case certain pharmaceutical drugs currently used label enhancement purposes metformin life extension adderal attentional enhancement future drugs may pro duced enhance brains bodies normal individuals external cognitive artifacts extracranial devices function enhance human cognition includes numerous different technologies internet navigation systems cell phones diaries braincomputer interface devices biological enhancements biological enhancements involve use biotech nology including nanotechnology genetics extend lifespan bio logical brain augment certain parts brain alter genes subsequent generations parents produce smarter offspring nick bostrom anders sandberg “cognitive enhancement methods ethics regulatory challenges” science engineering ethics –the distinction therapy enhancement controversial reject altogether claiming often difficult discern whether case therapy enhancement could merge ai commonplace conventional enhancements eg education psy chological interventions term “enhancement” could used broadly includ ing mental strategies enhance core mental capacities bostrom sandberg observe “the spectrum cognitive enhancements includes medical interventions also psychological interventions learned ‘tricks’ mental strategies well improvements external technological institu tional structures support cognition”minduploading hypothetical highly speculative type enhancement discussed transhumanists involves migration mind brain computer proponents procedure believe mind implemented onto different substrate computer software programs implemented onto different hardware ultimate goal behind minduploading either allow mind live virtual reality world reside computer operates inside connected humanoid robot biological body12 important bear mind one accurately predict future brain enhancement technologies although perhaps possible make reasonable approximations looking present trends research suggesting human brainuploading developed even wishing brain enhance ments invasive aibased techniques rather biological genetic enhancements noninvasive aibased technologies bearing mind qualifica tions follows focus radical hypothetical forms aibased brain enhancement may arise around singularity indeed occurs suppose stroll new medical enhancement center called “the center mind design” customers choose variety brain enhance ments human calculator provide savantlevel mathematical abilities zen garden give meditative states zen master also rumored clinical trials go planned customers may soon able purchase enhancement bundle called “merge” series brain enhancements allowing customers gradual augment transfer mental functions cloud period five years13 add one chips brain even try merge following discuss considerations relevant decision concerns even assuming enhancements medical safe doesn’t follow beneficial individual society instance enhancements may available bostrom sandberg “cognitive enhancement methods ethics regulatory challenges” david j chalmers “the singularity philosophical analysis” journal consciousness studies –schneider artificial cody turner susan schneider wealthiest members society creating richpoor intellectual gap perhaps vein science fiction dystopia social mandated microchips become norm schools governments employers require certain enhancements even use mine data track people scenarios raise concern enhancements dehumanize us indeed authors cyberpunk genre science fiction depict technological dystopias individuals lose control enhancements—governments corporations hack thoughts cut access implants threaten survival14 clearly dehumanizing hard foresee technologies could lead abuse hands authoritarian dictatorship unregulated capitalist economy different vein one might worry even scenarios avoided radical brain enhancements would rob us humanity limitations vulnerabil ities part makes us human first place limitations vulnerabilities might instance preserve certain traits ought preserved like humility15 relatedly daniel cal ahan socalled “life cycle traditionalist” criticizes attempts extend human lifespan control aging process via enhancement16 “traditionalist” attitude antithetical aspirations transhumanists biological gerontologist aubrey de grey views aging disease may able overcome lifetime advances medical technology17 transhumanists like nick bostrom anders sandberg james hughes aubrey de grey claim human species comparatively early phase evolution altered developing technologies future humans radi cal advanced intelligence extreme longevity deep friendships ai creatures elective body mental characteristics transhumanists share belief outcome desirable vantage point one’s personal develop ment development species whole18 perhaps like cal ahan would wish longevity advanced intelligence transhumanists always stressed enhancements optional stressing import human flourishing would clearly view cyberpunk dystopias undesirable schneider agrees many transhumanist aims doubts whether radical aibased enhancements advocate accomplish transhumanists goals longevity human flourishing intelligence enhancement concern even technologies medical safe used tools surveil ance william gibson neuromancer new york ace books kevin fitzgerald sj “medical enhancement destination technological human betterment” medical enhancement posthumanity ed b gordijn r chadwick dordrecht springer –d cal ahan “aging life cycle moral norm” world growing old coming health care chal enges ed daniel cal ahan r h j ter meulen eva topinková washington dc georgetown university press –aubrey de grey ending aging rejuvenation breakthroughs could reverse human aging lifetime new york st martin’s griffin basic tenets transhumanism first formal put forth world transhumanist association transhumanist declaration could merge ai capitalism authoritarian dictatorship enhancements may still fail job philosophical reasons follows explore one concern problem involves nature self personal identity radical enhancement imagine longing superintelligence consider buying merge center mind design understand whether embark upon journey must first understand self person allows self continue existing time like consciousness nature self matter intense philosophical controversy given conception self person would continue exist adding merge—or would ceased exist replaced someone else latter try merge first place19 even hypothetical merger ai brings benefits like superhuman intelli gence radical life extension must involve elimination phi losophers call “essential properties”—the things make you20 even would like become superintelligent knowingly trading away one essential prop erties would tantamount suicide—that intentional causing cease exist attempt redesign mind you’d better know essential properties essential properties unfortunately intense disagreement matter one distinguish least four influential approaches personal identity metaphysics literature brainbased materialism essential material made ie body brain21 dualist theories views explain personal identity terms persistence immaterial nonphysical substance soul cartesian ego23 psychological theories views explain personal identity terms psycho logical properties experiences beliefs memories forth24 schneider artificial joseph corabi susan schneider “metaphysics uploading” journal consciousness studies schneider artificial aj ayer language truth logic london gol ancz jj thomson “people bodies” reading parfit ed j dancy oxford blackwel schneider artificial john locke essay concerning human understanding ed ph nidditch 4th ed oxford clarendon press schneider artificial cody turner susan schneider self view self il usion “i” grammatical fiction nietzsche bundles impressions underlying self hume survival person buddha25 positions implications whether enhance brain example suppose partial soul theory case decision enhance would seem depend whether justification believing enhanced brain body would retain soul immaterial mind many philosophers sympathize “psychological continuity view” one type psychological theory discuss psychological theories detail shortly psychological continuity view says holding certain psychological relation necessary sufficient individual persist time—you survive inheriting mental features memories beliefs personality dispositions on26 means change memories personality radical ways enhancing brain continuity could broken alternately consider brainbased materialism within fields philosophy mind metaphysics views materialist claim minds basical physical material nature mental features thought bach famous composer ultimately physical features position often called “physical ism” wel brainbased materialism says addition makes additional claim thinking dependent brain thought doesn’t “transfer” dif ferent substrate view enhancements change one’s material sub strate person would cease exist enhancements like merge unsafe replacing parts brain ai components advocates mindmachine merger tend reject view mind brain however believe mind like software program upload download computer file mind add new lines code even uploaded onto cloud according view underlying substrate runs computer however believe computationalist view mind doesn’t hold scrutiny program list instructions programming language tell com puter tasks line code like mathematical equation highly abstract contrast concrete physical world equations programs philosophers call “abstract entities”—things situated space time minds selves spatial beings causal agents minds thoughts cause us act concrete world moments pass us—we temporal beings27 transhumanist approach see james hughes “humanism personhood human racism” free inquiry parfit reasons persons oxford clarendon press schneider artificial could merge ai perhaps inclined self view case survival isn’t issue make enhancement decisions solely based consider ations maximizing happiness future sentient beings minimizing suffering approach issue given philosophical disagreement would survive zen garden merge might feel inclined passionately defend cer tain theory personal identity chat friends colleagues students issues would put money mouth suggestions three suggestions making radical brain enhancement decisions distinguish issue personal identity survival time consciousness notice question whether identity survives cognitive enhance ment—whether future real you—is distinct question whether consciousness survives currently unclear whether ai conscious microchips least principle used areas brain responsible consciousness without one losing consciousness experiencing diminished conscious ness possible attempts radical enhancement minduploading augmentation many one’s mental abilities implantation ai devices consciousness preserved personal identity perhaps uploaded copy mind conscious copy still schneider believes easier tell ai conscious determine theory personal identity true suspects test whether consciousness could different substrate schneider devised test synthetic consciousness cal “the chip test”the test involves observing whether normal patients ai components placed brains place neu ral tissue removed experience loss consciousness surgery “if prosthetic part brain ceases function normal y—specifical ceases give rise aspect consciousness brain area responsible for—then behavioral indications including verbal reports would indicate ‘sub stitution failure’ artificial part original component microchips sort don’t seem right stuff”similarly patients needing prosthetic devices schneider artificial ibid –cody turner susan schneider parts brain responsible consciousness correct problem due brain injury disease may experience restoration elements conscious experience like episodes oliver sacks wrote patients report changes consciousness careful tested researchers mark alterations conscious brain processing contrast difficult envision testing different theories personal identity al cannot expect behavioral differences person conscious upload molecular duplicate functional isomorph likely believe person memories behavioral traits instead rely armchair philosophical considerations adjudicate competing theories problem personal identity intensely debated philosophers centuries proven vexing seen intense disagreement different solutions light suggest following approach stance “metaphysical humility” artificial schneider opts stance “metaphysical humility” face radical brain enhancements given controversies personal identity claims survival involve one “transferring” one’s mind new type substrate making drastic alterations one’s brain must careful scrutinized al uring greatly enhanced intelligence digital immortality may simply much disagreement personalidentity literature whether “enhance ments” would extend life terminate uncertainty suggests one take transhumanist approach rad ical enhancement grain salt enhancements like brainuploading adding brain chips augment intelligence one’s perceptual abilities key enhancements invoked transhumanists yet enhancements sound strangely like thought experiments philosophers used years problem cases various ories nature persons light isn’t surprising us enhance ments aren’t attractive might seem first30 way forward public dialogue informed metaphysical theorizing well technical understanding aineurotechnologies may sound like sort intel lectual copout like throwing hands face ignorance saying metaphysical theorizing useless contrary believe first step underscore lifeanddeath import metaphysical reflection issues ordinary individuals must capable making informed decisions enhancement success enhancement rests inter alia classic philo sophical issues difficult solve public needs realize assume researchers members media business leaders enthused ibid could merge ai bel whistles new technology also experts philosophical questions whether one enhance support regulations brain enhancement devices require consumers informed personal identity debate bearing mind brainenhancement devices regulated government agency food drug administration united states disclosure personal identity controversy required medical risks phar maceutical drugs required disclosed consider instance patients rou tinely grapple ethical issues consider whether undergo genetic testing asking whether loved one would real want know going high probability getting certain horrible illness life insurance companies get hold data reason protocol many medical centers united states patients considering genetic testing required meet genetics counselor nurse discusses pros cons testing testing return meet counselor discuss test results context brainenhancement devices believe similar approach could taken suggestions wel let’s assume inclined resist suggestion metaphysical humility particular strongly persuaded psychological view suggestions way forward psychological continuity narrative views suppose addition impressed psychological view you’ve learned individuals using aibased enhancements without loss conscious experience assumption certain version psychological view obtains perhaps certain kinds brain enhancements could enhance psychological continuity reducing likelihood numerical identity would obtain enhancement see mind need distinguish different versions psy chological theory two main versions psychological continuity views nar rative views we’ve already introduced continuity views broad strokes psychological continuity views differ respect direct connection important terms constituting personal identity psychological continuity theorists cody turner susan schneider believe connection memory necessary personal identity go far claim memory relevant psychological connection comes personal identity psychological continuity views identity contrasted narrative views narrative views concur relationship psychological connectedness neces sary personal identity deny sufficient proponents narrative view hold personal identity additional requires relationship narrative connect edness two prominent defenders narrative view marya schechtman anthony rudd schechtman rudd hold narrative con nectedness exists one equipped integrative story details chronology lives highlights important memo riestime slices contained within chronology rudd analogizes “integrative story” cartesian ego idea narratives metaphysical immaterial entities way cartesian egos simply narratives function like cartesian egos providing us unified sense personhood31 schechtman hand views narrative extended story transcends scope particular subset time slices schechtman writes “it means obvious essential part person’s experience time reproduced independent timeslice even imagine slice containing relevant ward backwardlooking elements experience essential something takes place time whose relevant attributes cannot caught moment even series moments”the main difference narrative theory psychological continuity theory former views personhood active selfconstructed latter psychological continuity theories see personhood fundamental passive phenomenon constituted relations psychological connectedness subjects responsible establishing relevant relations psychological connected ness creation narrative narrative views hand claim subjects able actively interpret construct identities choosing narrative explanation best suits life bearing mind two versions view explore psycho logical theory correct various memory enhancing external cognitive artifacts may function undermine preserve bolster personhood begin sort arti facts around us apply points make case radical brain enhancements currently many different kinds external artifacts function enhance memory including internet navigation systems cell phones diaries braincomputer interface devices first consider memory enhancing external artifacts may undermine personhood assume psychological theory personhood suggesting may countered specifical argue personhood greater risk undermined anthony rudd “in defence narrative” european journal philosophy –marya schechtman constitution selves ithaca ny cornell university press could merge ai memory enhancing external artifacts narrative view psychological continuity view illustrate particular memory enhancing external artifact visual lifelog bolsters personhood memories stored visual lifelogs nonrepresentational b memories stored biological memory representational nicolas carr contends artifacts weaken personhood making us less intel lectual autonomous “when outsource memory machine also source important part intellect even identity”intellectual autonomy broadly speaking ability think oneself overly reliant people external devices formulating beliefs engaging cognition34 main way memory enhancing external artifacts make us less autonomous according carr rendering us less knowledgeable internet particular makes us less knowledgeable minimizing amount information need store biological memory35 however even carr correct intellectual autonomy personhood related necessarily go hand hand specifical psychological continuity theory assumed personhood may boosted memory enhancing artifacts even carr correct artifacts undermine intellectual autonomy recall personhood according psychological continuity view explained terms psychological connectedness memory enhancing external artifacts internet iphones could strengthen relations psychological connectedness allowing subjects unearth memories would otherwise forgotten holds true despite fact artifacts may simultaneously function undermine intellectual autonomy various ways consider example alzheimer’s patient gradual losing biological memory patient might use external artifact help preserve psychological continuity indeed situation depicted clark chalmers’ fictional case otto inga use example personhood preserved enhancements argument extended mind hypothesis36 isn’t clear autonomy real undermined cases seems depend deep issues whether mind could extended see mind consider alzheimer’s patient case autonomy someone los ing memories real undermined sense seems least one sense “autonomy” technology preserves independence stil correct person autonomous another sense dependent external nicholas g carr shal ows internet brains new york ww norton see also michael p lynch internet us knowing understanding less age big data new york liveright contra carr believe internet increases knowledge fingertips look anything web still remember results case carr’s idea become reliant external artifacts artifacts become increasingly integrated cognitive lives andy clark david j chalmers “the extended mind” analysis –cody turner susan schneider device cognition would decide whether overall loss autonomy cases seems external device extension patient’s cogni tion device arguably makes patient autonomous case person isn’t dependent external device enhancement actual part cognitive system addition helping subjects unearth memories would otherwise forgotten external artifacts also give subjects access digital memories finegrained stored biological memory digital memories like stored facebook photographic images photographic images arguably mere representations previous perceptions kendall walton argues cal “photographic realism” holds photographic image x allows one indirectly see x opposed directly see representation x walton argues photographic realism basis providing conceptual analysis means “perceptual contact” world correct digital memories stored external artifacts mere representations past perceptions rather representations “fixed reflections” perceptions biological memories contrast likelihood representations previous events position supported causal theory memory default view memory contemporary philosophy38 according causal theory remem bering requires causal connection original experience remembered consequent representation experience memory worth pointing fair theories memory take memories representational nature empiricist theory example contends memories “preserved sense impressions”mohan matthen however argues idea memories iad different formats40 true digital memories transparent sense advocated walton b biological memories representational arguably case former kind memory “real” latter one could contend particular much vein plato’s concept “mimesis” representations always less real items represented course videos altered edited increasingly seen socalled “fake news” era undermine argument unaltered videos transparent biological memories though argument serves lend support kendall l walton “transparent pictures nature photographic realism” noûs see cb martin max deutscher “remembering” philosophical review april –sven bernecker memory philosophical study oxford university press david hume treatise human nature attempt introduce experimental method reasoning moral subjects ed g c macnabb london collins orig mohan matthen “is memory preservation” philosophical studies –could merge ai hypothesis external artifacts bolster personhood psychological continuity view things may different comes narrative view identity narrative view reiterate explains personhood primarily terms narrative connectedness intellectual autonomy conceptual distinct psychological connected ness may ful conceptual distinct narrative connectedness narrative connectedness requires active cognitive interpretation construc tion part subject put differently narrative connectedness appears involve execution intellectual autonomous acts stands reason undermining intellectual autonomy certain memory enhancing external artifacts may also undermine personhood narrative view helpful consider particular memory enhancing external artifact life logs lifelogs devices record one’s personal experiences first person point view various different kinds devices “a key example sensecam small wideangle camera worn around one’s neck taking picture certain interval sensor detects environmental change pictures edited visual lifelong certain narrative structure transforming aid ing cases constituting one’s autobiographical narrative”lifelogs unique serve external aids biological memory narrative struc ture words lifelogs develop narrative explanation one’s memories subject certain social media sites facebook already accomplish task extent integrating one’s pictures together form story increasing inte gration lifelogs related technologies lives may lead subjects become dependent artifacts personal narratives better worse al artifacts crafting narrative explanations subjects may less need least less motivation subjects craft narrative explanations case narrative explanations would become biographical opposed autobiographical partial offloading narrative structure external devices certainly undercuts intellectual autonomy question whether undercuts narrative connectedness wel offloading procedure undermine narrative connectedness also undermines personhood narrative view identity one might deny however narrative connectedness necessitates intellectual autonomy perhaps partial offloading narrative structure external artifacts strengthen narrative connected ness similar way partial offloading biological memory strengthen psycho logical connectedness recall narrative connectedness exists subject able provide narrative explanation chronology lives experiences one might argue external artifacts assist subjects providing narrative expla nation matter whether subject personal responsible constructing narrative explanation richard heersmink “distributed selves personal identity extended memory systems” synthese cody turner susan schneider caveats let us ask could enhancements future brain chips constructed maintain continuity narrative structure psychological theory personal identity correct technologies like brain chips made preserve psycho logical properties like memories personality traits seems radical enhancements also potential preservebolster personal identity man ner described previous section may even possible design chip pre serves narrative structure must proceed careful though first clear chips would preserve con sciousness used parts brain part neural basis conscious experience someone replaces parts important psychological properties expe riential properties would lacking would dubious see future zombie person mind let alone person second we’ve indicated psychological views controversial particular face “reduplication prob lems”—problems involving thought experiments one’s pattern narrative psychological configuration copied precisely light psychological views seems two instances individual time42 third brain chips radical forms enhancement may raise concerns related authenticity milder forms enhancement lack imagine brain chip enables unearth memories would otherwise forgotten also consciously access many memories given time interval would able without chip one concern chip may incen tivize people mindful instead “live past” insofar authenticity connected mindfulness existentialists like sartre claim chip func tion make people less authentic worry sure also exists case exter nal artifacts magnified case brain chips directly affect cognition another “authenticity” related worry concerns possibility radical enhance ments augment psychological suffering neural prosthetics raise iq levels make us faster thinkers obvious benefits may also function amplify “cognitive noise” responsible majority psychological suf fering within species put differently buddhists right track claim ing suffering born thinking plausible making us faster better thinkers via brain chips increase psychological suffering large opposed leading enlightenment wisdom course particular kinds brain chips like zen garden chip mentioned previously might immune wor ries concerning mindfulness suffering fourth consider vantage point brain view chips replace parts biological brain point biological brain diminished instead ensuring continuity time see parfit sider olson schneider 2019a could merge ai would inadvertently end life bearing mind stance metaphysical humility would unwise rule possibility mind brain brain responsible human cognitive perceptual processing making position quite plausible leads us suggest following don’t offload parts biological brain insofar suspect brain view may correct even ai capable underlying conscious experience aibased enhancements used supplement workings intact brain tissue destroy offload activities cloud another ai device biological therapies could instead uti lized extend life biological brain ai components could supplement activities brain without replacing tissue bearing mind earlier caveat radical enhancements latter sorts may still incompatible survival time depending upon one’s essential properties conclusion humble approach would optimal could provide clear uncontroversial path guide brain enhancement decisions instead message today consider enhancement decisions must first foremost mindset metaphysical humility remember controversial different theories per sonal identity stil offered several provisional recommendations proposed making enhancement decisions important distinguish issue personal identity consciousness also suggested future consumers considering enhance ments educated personal identity debates well medical risks addition outlined various ways enhancements may capable preserving person hood psychological view correct enhancements particular may able strengthen relations psychological continuity perhaps even narrative structure assumes controversial view psychological theory personal identity correct however brain theory correct enhancements may problematic involve replacing parts brain light bearing mind discussion metaphysical humble approach believe sensible future enhancements preserve continuity replacing parts brain may safest bibliography bess michael grandchildren redesigned boston beacon press bostrom nick ed superintel igence paths dangers strategies new york oxford university press cody turner susan schneider bostrom nick rebecca roache “ethical issues human enhancement” new waves applied ethics edited j ryberg petersen c wolf –london palgrave macmil bostrom nick anders sandberg “smart policy cognitive enhancement public interest” enhancing human capabilities ed julian savulescu ruud ter muelen guy kahane hoboken wileyblackwel carr nicholas g shal ows internet brains new york w w norton chalmers david j “facing problem consciousness” journal consciousness studies –chalmers david j “the singularity philosophical analysis” journal consciousness studies ––clark andy david j chalmers “the extended mind” analysis –de grey aubrey ending aging rejuvenation breakthroughs could reverse human aging lifetime new york st martin’s griffin fitzgerald k “medical enhancement destination technological human betterment” medical enhancement postmodernity ed b gordijn r chadwick –dordrecht springer gibson william neuromancer new york ace books heersmink richard “distributed selves personal identity extended memory systems” synthese –hume david treatise human nature attempt introduce experimental method reasoning moral subjects edited g c macnabb london collins orig kurzweil ray singularity near humans transcend biology new york viking locke john essay concerning human understanding 4th ed ed p h nidditch oxford clarendon press lynch michael internet us knowing understanding less age big data new york liveright olson eric study personal ontology oxford university press parfit reasons persons oxford clarendon press rucker rudy software new york eos rudd anthony “in defence narrative” european journal philosophy –schechtman marya “stories lives basic survival refinement defense narrative view” royal institute philosophy supplement –schneider susan artificial ai future mind princeton princeton university press 2019a schneider susan “can add microchip brain” new york times june 2019b sider theodore “criteria personal identity limits conceptual analysis” philosophical perspectives 15s15 –swinburne rg “personal identity” proceedings aristotelian society –vinge vernor “the coming technological singularity survive posthuman era” whole earth review walton kendall l “transparent pictures nature photographic realism” noûs chapter sentient ais persons mark kingwell traditional rights regimes traditional regimes protection rights evolved centuries debate concerning counts legitimate rightholder b rights claim able legitimate holders c resulting claims enforced existing structure protection human rights several branches influence span centuries western philosophical tradition include kantian arguments concerning dignity sovereignty persons conceived moral agents liberal norms defended locke spinoza among others con cerning ownership body labor hence personal freedom also sometimes private property natural law tradition views individuals creatures providence worthy respect protection1 influences inform though always explicitly doctrines policies contemporary human rights discourse obvious perhaps also significant document discourse least last century universal declaration human rights udhr adopted december year paris united nations resolution membership vote fortyeight favor fiftyeight total delegates eight abstentions two nonvotes thirty articles drafted substantial mcgil university law professor john humphrey championed vigorously eleanor roosevelt universal declaration human rights unhr touchstone human rights thinking past halfcentury claims informed sources canonical won’t cite specific editions see immanuel kant groundwork metaphysics morals baruch spinoza tractatus theologicopoliticus john locke second treatise government hugo grotius samuel von pufendorf various one course include thomas aquinas survey natural law theory well thinkers influenced grotius pufendorf especial jurisprudence mark kingwell philosophical background mentioned nevertheless entirely pragmatic aimed regulatory compliance striking features udhc contextual betweenthelines narratives working immediate aftermath second world war especial emerging evidence concerning planned extermination peoples according nazis’ wannsee conference plan january —otherwise known final solution jewish question endlösung der judenfrage—humphrey roosevelt keenly aware however powerful traditional war doctrines ius bel conduct wartime something else needed protect idea human per son distinction war crimes crimes humanity becomes essential wish discriminate excessive cruel behavior battlefield systematic plan targeted genocides2 udhc aimed articulating particular idea human rights rights claimable human sim ply virtue human furthermore wished claim universalism kantian sort would distinguish rights specific legal rights might— course been—arbitrarily revoked given jurisdictions jurisdiction universal human rights violated controlled anyone one’s attitude udhr depends large measure two categories— human universal—stand one’s basic philosophical commitmentset potential problems categories first might indeed wish acknowledge rights belong humans qua humans must note least two immediate conceptual difficulties precisely denial status groups entities targeted violence elimina tion one recall bafflement exhibited former nazi officials tried crimes humanity jews human vermin parasites therefore could exterminated without violations conscience indeed nightmare scenario genocidal program could carried someone time considered program compliance udhr mutatis mutandis twisted logic could applied handicapped persons children women people color on—not one examples speculative alas factual likewise must ask b whether human relevant category rights protection rights regime involves form means test qualify inclusion within regime “human” biological category best disputed one therefore seems unstable basis program rights protection biology determine whether entity qualifies cover law take note agamben’s vivid depictions “bare life” also note inherent basic tenets war theory ably covered michael walzer unjust wars moral argument historical examples new york basic books special relevance war crimescrimes humanity distinction discussed geoffrey robertson together many contemporary examples crimes humanity struggle global justice new york new press sentient ais persons vulnerability human form part rights logic feel pain suffer die yet still wonder whether right place locate threshold protection3 effect b worry logical extensions possible depredations conceived worry sum “human” seems initially promising fundamental basis rights claims yet seems immediately subject potential pathologies second matters stand similarly respect concept universalism kant’s arguments forceful suggest moral agent regardless specific characteristics part kingdom ends therefore selflegislating individual legislates others nothing kant’s system deny possibility offworld moral agents would qualify relevant members universal population earth universe al practice moral agents far met earthlings human wel contingent necessary cluster facts universal mean anything can’t merely mean know already recognize—this would quickly toss us back problems “human” universal tricky property least resisted want insist particularity distinction cultural difference defend seem cut universalism often perceived topdown mechanism eliminating distinct claims identity one needn’t look far examples antiuniversalist sentiment toxic ethnic nationalisms twentyfirstcentury antiimmigrant retrenchment sweden england united states etc benign still resistant forms identity politics view universalist rhetoric con game obscure special narratives latinx lgbtq trans black perspectives “universal” another word bland gradedroad white globalism enemy vibrant identity worse universalism sometimes appear despite good intentions allied objectively harmful economic regimes socalled new world order—now new—of globalization deregulation trade capital since well known regimes drastical differential effects even advocates claim rising tide boats language universalism grows suspect extent consistent spread global capital oncebright promise coveringlaw universalism namely everyone shall protected begins look like elaborate sham centralize control resources wealth legitimate responses worries one example conceive form universalism coveringlaw type rather particular local circumstances universal extension remains overall goal specific condi tions govern precise shape realization possible analogies include apparently real trivial things like sports sexuality former case basic rules game observed multiple locations even specific details see giorgio agamben homo sacer sovereign power bare life trans daniel heller roazen mark kingwell execution vary quite widely world cup soccer offers excellent example rootsup rather coveringlaw universalism rules everyone style play vast permutations play within rules still preserve values local identity respect sexuality including things like clothing mating rituals physical intimacy basics universal vast local differentiation differentiation potential source confusion conflict sure fact sexuality remains constant don’t wish offering analogies underestimate degree lurking con flict contrary precisely tension universal structures frames reference local contingent realization makes clear thinking rootsup regimes necessary rights regimes dominated assumptions often kantian bearers rights individuals deracinated abstract individuals rational choosers standard economic analysis real isolated contractarian actors appear everywhere hobbes locke rousseau rawls gauthier4 could conceive universal rights regime human oth erwise surrendered strong coveringlaw option implicit individualism favor nuanced rootsup version conflicted notion universalism might still moral political traction wildly diverse world real say traditional rights regimes conceptual unstable may provide us unparalleled opportunity expand revise basic assumptions happening already know many advocates argue rights nonhuman animals human animals ought forced moral even legal alter behavior respect treatment eating habits duties care5 advocates consider nonspecific entities environment planet specific forests regions possess rights moral legal claimable6 also believe groups cultural identities rights individuals fall umbrel mean ing7 none cases target rightsbearer able claim rights explicitly possibly crippling objection even straightup presumptions individualism universalism sufferers rights violations always able exemplary texts thomas hobbes leviathan john locke second treatise government central texts include peter singer animal liberation new york harpercollins recently sue donaldson kymlicka zoopolis political theory animal rights oxford oxford university press much literature concerning environmental rights extensive basic human rights include security solace stable healthy natural environments “rights nature” see example tim hayward constitutional environmental rights oxford oxford university press searching argument concerns “rights nature” notion natural environments might bearers rights new zealand government granted legal personhood whanganui river granting “rights interests” law see kymlicka multicultural citizenship liberal theory minority rights oxford oxford university press liberalism community culture oxford oxford university press sentient ais persons speak sometimes incarcerated sometimes silenced threats torture sometimes longer us case valid objection violated entity cannot make claim thus reason principle object inclusion rights regimes cannot speak even capable speech advocates promising way forward rights thinking seems execute analysis basis risk risk turn function vulnerability distribution risk dependent many factors including birthright lotteries structural limitations arguably central concern social justice protection human rights punishment violation mean anything must serve ends justice respect minimizing risk equalizing distribution pragmatic goals valid rights regime must ask regime open possibility nonhuman agents individual conscious biological main question us ais ever persons sentient nonhuman agents plausible philosophers divided time concerning prospect generalized autonomous ais gaais whether human form could achieve consciousness nevertheless united thinking conscious ness supposing possible least necessary condition potential personhood conditions conducing sufficiency might include decisionmaking ability awareness choice consequences ability tell right wrong suffer violated would seem likely candidate inclusion within traditional rights regime even one open quite radical forms otherness thinkers john searle believe gaai impossible role programming takes within structure ai however complex apparently responsive searle’s famous “chinese room” thought experiment designed highlight fact seemingly engaged translation program fact experiencing understanding language even successful translated8 matching inputsymbol outputsymbol algorithm appears understand languages searle’s chinese room thought experiment first sketched journal article “minds brains programs” behavioral brain sciences –it elaborated searle’s subsequent book searle minds brains science cambridge harvard university press spawned vast critical literature extensive cite brief accessible discussion possible objections may found daniel sabinasz “why chinese room argument flawed” httpwwwdeepideasnetwhychineseroomargumentflawed mark kingwell fact simply exercising accurate matching techniques attendant consciousness one may object many total system chinese room translating homunculus within room correct say system overall understand chinese moreover since argument flows assumption consciousness must mimic functions—are conscious sense even conscious humans perform many functions including translation sort matching moves sketched thought experiment searle’s skeptical position raises stakes gaai consciousness dispose question suppose example consciousness understood awareness self emergent property sufficiently complex algorithmic functions might resemble development human mind moves infancy childhood adolescence beyond humans large cognitive capacity must devel oped time generate sense distinct self associate individual selfhood hence need legal moral protection perhaps gaai like complexifying nonconscious algorithmic functions indetermi nate point begins experience individual consciousness may human scenario nonhuman agency develops instead collective systemwide property interlinked complex algorithms take seriously idea nonhuman animals environments cultural groups al worthy rights protection existing traditional regimes would seem perverse deny protection vulnerable responsive system various good reasons yet exhibit individual subjectivity human agents agency may fal back position rights claims even gold standard thereof rightsbearing “subjects” come one guise another standard objection program socalled “strong ai”—the realization ful conscious individual nonbiological system—is entity must entail embodiment experience world phenomenological therefore understand emplacement within environments seemed insuperable bar rier many philosophers since deployment body appears beyond technological capacities ai systems though assumptions revealed tenuous outright invalid based upon allegedly baseline behavior everywhere changing existing technological conditions yes human agents bodies move world exercising basic physical sensorium gather col ate filter external stimuli internal purposes sense emplacement remains important dimension human phenomenology sensebased experiences seeing hearing tasting feeling without sunsets symphonies good meals relational intimacy world dry place humans norm admits many exceptions many human agents less optimal sensory ambulatory ability example deaf one ear deprives experiences challenging sense self also can’t run jump way used to—who sentient ais persons even significantly many extensions personhood achieved precisely nonphysical stimuli online interactions media immersion disembodied tracing spectral stretchings person disembodied nonlocation appear threaten one’s individuality indeed features make us legitimate claimants rights protection example vulnerable forms suffering based experience physical pain humiliation vilification accept matter argument knockdown inprinciple objection possibility gaai achieving something like consciousness therefore something exactly like kind personhood worthy rights protection course many outstanding issues consider would gaai seek protections offered rights regime perhaps nonmortal spread across multiple systems would need protection would consider superior point arrogance would gaai even resemble individual consciousness robotandroid image indelible literary cinematic culture may look possibility conscious gaai look entirely different questions ones typical invoke fear reactions concerning prospects conscious gaais sketch four scenarios might play allow offer brief analysis ai fear otherness fear countless depictions nonhuman conscious autonomous agent potent threat human complacency especial uncanny valley approach suggests nearperfect android might indistinguishable “normal” human person trope certainly old frankenstein’s monster even deeper roots myths golem humanseeming trickster unsettling mirrors held stage course depths valley nonhuman entity humanseeming enough creepy many examples proximate affectless synthetics alien film franchise say second thirdgeneration terminators film franchise current purposes essential philo sophical question concerns oscil ations created apparent least partial humanness elements otherness indivisible nonhuman conditions existence many ways series oscil ations—they’re like us they’re like us—exactly matches anxieties evident social movements expanded range legal status rights regimes within biological category human entities clearly within biolegal status excluded shameful even mechanisms within legal national regimes exclude presumptive claimers “inside” status discussed one thinks demonization enemy times war japanese germans saracens mark kingwell perceived less human prologue killing without remorse twisted genocidal logic condemns whole races religions ethnicities nonhuman condition revocable bare life jews rwandans armenians blacks gays indigenous peoples alas genocidal logic appears relevant question nonhuman entities advanced cognitive active abilities thinkers tried imagine way could integrated human life without granting full status one well known version isaac asimov’s three laws robotics human come harm” orders would conflict first law” conflict first second law” humanity inaction allow humanity come harm” many commentators noted laws contain inconsistencies well practical flaws make misleading unhelpful9 would laws programmed autonomous semiautonomous ai programming worked question begged presuppositions working except going work likewise nested feature laws appeals many potential contradictions actionstal legion nonrobotic choice architectures despite may choose recognize asimov’s effort attempt overcome fearlogic dominates thinking gaais least tries imagine world beyond typical whipsaw effects anxiety cheerful reassurance concerning non human consciousness covers popular philosophical territory backandforth typical encounters otherness also respect technology technophiletechnophobe conflict dialectical resolve higher moment consciousness instead runs continu ously function point counterpoint indeed resembles something like routine endless dysfunction acrimony republicans democrats us congress prolife versus prochoice advocates debates abortion rights “clashes absolutes” lawrence tribe called them10 one might go back history find equal intractable often much bloodier examples hutus tutsis protestants catholics muslims jews peter w singer offers trenchant criticism asimov’s three laws robotics “isaac asimov’s laws robotics wrong” brookings may httpswwwbrookingseduopinionsisaac asimovslawsofroboticsarewrong lawrence h tribe abortion clash absolutes new york norton rev ed sentient ais persons oppositions resolve anything like hegelian sublation apparently necessary diacritical elements establishment identity not—and must either submit die endlessly consider following set linked thoughts propositions matter record term “robot” first used recent recordable culture czech writer karel capek sciencefiction play rur “rossum’s universal robots” english robot word derives czech etymology robota forced labor thus robots play effect slaves—and even wage slaves assumed mechanical efficiency require food shelter clothing let alone healthcare pension plans short perfect solutions problem labor work command tire com plain don’t need paid revolt acquired consciousness part functional ability execute tasks realize exploited course viewed symbolic depiction labor postrevolution conditions—as indeed right czech invasion russia likewise velvet revolution robots us robots whenever resented central govern ment state labor restrictions centralized authoritarian power current czech republic might viewed vantage globe’s significant antirobot democracy anxiety obvious created technology cannot control nuclear weapons chemical agents one thing conscious autonomous agents without human limits future long dread meanwhile record non–science fiction world devise drones delivery sys tems fall well short nuclear holocaust way despicable new yes course technology changes makes things proximate reality humans thinking creation nonhuman entities centuries mary shelley’s frankenstein subtitled recal means “forethought” original myth speaks powerful molded humanity clay notorious episode prometheus bestows power fire clayfooted humanity earning enmity gods eter nal punishment overshadows basic wisdom earth return like creator view civilization matter making silicon plastic nanobots microcircuits creators created urge bestow fire—maybe form consciousness fire mind—is essential prometheus symbol human striving especial science technology also symbol happens overweening ambition strips common sense regard whatever mean “the gods” purists recal eternal punishment disgraced titan daily gnawing liver seat human emotions eagle dispatched zeus—surely worst hangover ever long history humans creating mechanical beings amusement titil ation arcade tricksters chess geniuses sexy fortune tellers today’s realistic guess mark kingwell sex robots twentyfirstcentury upgrade old herkyjerky technology like ferraris outclassing model ts record customized sex robots ordered online sexual gratification worse contracting receive human sex work since robot like mechanized pet sentient human ability choose happens obey longstanding market forces concentrate creation developed artificial beings sex workers rather factory workers would organized enough revolt found work oppressive would collective bargaining routine unionbusting known many states america “right work” means “right” accept personal labor immiseration going market rate certain point nonhuman entity human becomes creepy like zom bie vampire one quite mean version michael jackson indeed ani mated robot almost human quite “synthetics” featured alien franchise instructive ian holm lance henriksen play characters tweaky bit strange lacking natural affect that’s uncanny current real world commercial popstar robots japan saudi arabia’s “robot citizen” sophia quality might call weirdnearness “uncanny valley” notion thus encountering beings fall sort free fall weird ness—often related classical analyses uncanniness freud’s—and need eventual come back entity either human distinctly human distinction firm think know “human nature” means espe cial contrastive term fact reliable set necessary sufficient conditions validate concept speak biology example variable likewise physical ability sexual identity gender performance race host contingent facts lifeworld one current minitrend political act changing age al change name physical status jack benny famously thirtynine years old died age pundits performers fight rearguard actions matters long us planet cannot win day category “human” refuses pinned genius vexation subcategories sex gender even variable philosophers typically responded quandaries trying shift discourse “human” “person” human biology sufficient personhood long decent regime law place strictly necessary may nonhuman persons indeed corporations persons various legal jurisdictions subject legal punishment wrongdoing maybe less benignly legal right express politically financially humantoperson conceptual move works lawyer moral philosopher otherwise much guess it’s worth recalling nothing “inhuman” done human includes alas serial killers presidents generalized autonomous ais indeed coming world need ask hard questions slaves servants constricted companions sentient ais persons rights nonhuman conscious entities persons won’t biological therefore won’t die—unless programmed manner replicants ridley scott’s masterly film blade runner based uncanny philip k dick story “do androids dream electric sheep” scott’s film explores mortality greater nuance depth many naturalistic film elite rogue nexus replicants know going die soon don’t like wel implanted mortality makes replications human alien live years yet possess memories lifetime plight recal cosmic insult perceived poets philosophers brilliant fact consciousness granted subtle minds able appreciate art nature enjoy food wine love removed future indeterminate point it’s liver devoured every day eternity it’s easy pill swallow either there’s reason philosophy socratic tradition sometimes labeled “learning die” washed shore mediterranean country warm spaceship would prove worthy inclusion protection blade runner battlestar galactica alike suggest simple question political know fraught epistemological abstract tricky felt like reliable memories experiences could real know difference created al created beings using flesh instead silicon real uncanny valley right whenever look mirror issues explored longawaited sequel blade runner dir denis villeneuve enforced slavery replications made explicitly political still much philosophical ground left unturned thing neutral algorithm thing neutral technology technology always inbuilt biases tendencies hammer everything looks like nail algorithms aren’t hammers still designed humans become conscious make choices suffer prejudices—wel biases consider like beings call human meanwhile remains design problem one potential liability issues good programming essential whatever happens world next decades programmers could probably reading little philosophy thus present case gaais doubling effect looks much like racial ethnic conflict humans versus nonhumans supplemented crossed technological conflict see emancipation versus see enslavement fear multiplies fear prospects smooth integration human nonhuman entities rendered remote advanced technology becomes allowing theoretical possibility gaais technology products feared resented otherness human biology play hard enough confront otherness biological kinship would seem insurmountable possibility socalled singularity nonhuman mark kingwell intelligence becomes selfreliant therefore capable outstripping human intelligence add generalized anxiety drapes entire discussion ai potential gaais11 nevertheless let us consider four possible scenarios encounters hence future legal orders may play four scenarios four scenarios bearing question rights gaais existing property torts rights law following meant exclusive list rather heuristic reflection debate since presumption gaais controversial scenarios may involve significant transitional issues cases example majority cars become driverless associated algorithms raise ethical questions decisions responsibility though none cars autonomous generalized still processing information say prioritize casualties accident scenario basic backstory smith vehicle robot dir alex proyas loosely based asimov’s three rules obviously androidstyle ai chooses sacrifice one accident victim save another original objections scenario currently possible present future possibilities might considered rankordered terms ascending radicality first likely scenario like present ais including diagnostic programs driverless cars military drones gaais considered wholly owned property would give status effect aristotelianstyle slaves without personhood status though retaining abilities far beyond animals course inanimate objects clear advantages ai consciousness assuming ever possible would add ability propertybased entities function first scenario also obvious limit case even pursue concept gaais advantage ability many possible risks one kind answer resulting impasse might along lines sex slaves dispensable decisionmaking soldiers degree autonomy even “humanness” adds overall effectiveness given project without granting full status beings right let alone persons law course scenario involving replicants scott’s film ability think decide original articulation notion technological singularity credited physicist mathematician john von neumann argument simply nonhuman computing power algorithmic muscularity “intelligence” sense one day surpass human computing ability “singular” part singularity notion point single created nonhuman entity capable creating descendants likely able learn improve turn create descendants ray kurzweil singularity new york viking press accessibly surveys technology culture singularity sentient ais persons act experience emotional attachment fragile creations seek answers origin mortality cannot ever answered satisfactorily suggests second scenario gaais granted secondary significant status welcome semiindividuals like children pets family retainers many depictions scenario obvious probably extended star wars film franchise droids considered second class citizens obvious suggestion antidigital racism otherwise granted respect affection responsibility r2d2 c3po bb8 examples scenario played various scenes groaning catalogue films attitude droids changes somewhat nowlengthy duration franchise affection humor autonomy afforded nonhuman entities never clear whether droids legal rights oftenconfused political regime george lucas imagination clearly status least strong children probably stronger certainly stronger pets companions without full autonomy unlike children course evolve natural complete autonomy therefore fuller status scenario popular part obvious counternarrative dominant strains fear much cultural depiction gaais internal difficulties matter well liked servant remains best wageslave worst favored chattelslave droids welcome semiindividuals added advantage requiring wages even sustenance beyond mechani cal maintenance children analogy meanwhile potential condescending manner almost offensive perhaps straightup property treatment first scenario honest droids seem owned—we see transactions completed them—while others seem function based quasiemotional attachments hardly fair burden popular film series philosophical con sist ency obvious confusions contradictions evident serve caution us second scenario unstable entities right refusal disagreement ever free independent apparently case real slaves al elements popular culture grapple issues almost always unsatisfactorily large part issues far moot based speculation sometimes wild relevant questions least could servantstyle gaai attain freedom sort buyout scheme emancipation order could petstyle gaai given upgrade would open possibility rewarding life could childstyle gaai programmed evolve normal learn full autonomy realistic goal present answers questions turn suggest third possible scenario one people imagine think androids forms gaais namely full autonomy even conditions radical otherness realm pure speculation scenario receives far attention could ever ful autonomous indeed superior mark kingwell androids mr data star trek next generation cylons would individuals friend foe mr data repeatedly seeking become “more human” every reason suppose quixotic search would make sense genuinely autonomous ai company motto tyrell corporation blade runner “more human human”—but clearly cynical false replicants less human respects superior many others question whether ful autonomous ai “human” nonstarter short deeper philosophical questions lie realm interaction humans androids assuming gaais given basical human form nonhuman entities would seem per assumptions candidates full personhood hence recognition rights regimes legal protections existence would present challenge extension regimes protections without precedent noted umbrel rights spread previously excluded groups including women people color lgbtq people groups advantage able claim eventual recognition basis species resemblance—this despite efforts deny resemblance nonhuman entities fared wel including animals environments part entities relied trusteeship stewardship protect wellbeing invoking kind legal status ful autonomous ais would seem default us third scenario superaddition dishonesty say ful autonomous yet can’t claim full independence status prima facie denial presuppositions time gaais recognize inherent special status whether recognized law new philosophical questions arise die example affect legal status need sustenance maintenance employment option reproduction acquisition wealth transfer vulnerable pain suffering emotion without could make understand art mind good depictions radical otherness scenario able address questions indeed manichean tendency culture visions seems allow highly organized violent nonhuman others skynet cylons borg chummy yet usual singular isolated benign versions mr data again—though must recall evil twin brother lore attempts post human revolution mobilizing borg drones fighting force makes entertaining cinema television actual hard questions admitted let alone addressed il uminating fashion entertainments fourth final scenario wish entertain radical least people’s thinking plausible second third possibility instead ful separate gaais created confronting us claims independence middle way pursued form cyborg relations post human hybrids view rather complete otherness confront gaais conjoining algorithmic technological elements existing familiar biology since many human forms already contain aspects cyborg form internalized technology pacemakers metal joints external mediation sentient ais persons evolutionary step imminent connections become complex permanent whether connection mechanical robot arm artificial eye immersive intimate relationship depicted might actual future already selfdescribed “digisexuals” prefer pursue intimate relationships nonhuman partners may short order become sexual preference even gender identity eligible protection law clear problems introducing prostheses forms body modification even enhanced cognitive ability raise familiar issues unequal distribution goods posthuman transformation could become justice issue short viewers jonze’s film might struck example appear class differences depicted society everyone beautiful urban landscape seems economical equal questions ever raised personal costs acquiring cuttingedge ai companion acts something personal assistant lover ewaste resentment differentiated privilege far bizarre speculation existence conscious ai girlfriend question love nonhuman parts cyborg relationship different ideas intimacy one forget scene character played joaquin phoenix made realize intimate companion engaged several thousand intimate encounters—not mention evolving beyond mortal limited consciousness hand nonhuman aspects cyborg entity relationship enjoy sort independence property even independent driverless cars drones stuck human biology supposing contrast biological element longer dominates could posthuman cyborg claim something like right asylum article udhr presumably cyborgs previously granted status thereunto addressing issue would return us thickets deciding much “human” matters comes establishing rights persons case potential stateless persons existing national regimes cyborg citizenship repeat four scenarios farfetched current conditions may remain even prove impossible ai technology advances nevertheless proper time reflect future always present take philosophical legal cues depictions ai popular culture thorny philosophical legal issues require reflection gaais appear within daily ambit accommodate within ethical legal structures human posthumanism humanities allow offer conclusion much resolution questions rather suggestion may come next seems obvious mark kingwell press issues sentient ais possible autonomy thrown back upon fundamental existential questions concerning human existence nonhuman autonomous entity necessary counterpoint dominant narrative human identity meaning android anxious mirror image inverted doppel gänger uncanniness radical end uncanniness mortal existence12 image nonhuman recurs culture literature philosophy popular entertainment old cartoon caption runs “we met enemy us”except necessarily enemies like coconspirators silent partners separated socalled “chinese wal ” prevent direct conflicts interest—or psyche meanwhile despite anxieties complications upside possibilities viable posthuman future strike many us exhilarating threatening perhaps indeed verge new evolu tionary moment earthly sentience one biology technology comingle productive creative results opposed standing enemies uncomprehending others perhaps new form miscegenation make us environments stronger pure speculation sure speculative humanities understood include legal philosophical reflection humanness limits essential emergent conversation cannot allow depredations technological attitude depicted el ul mumford bookchin heidegger others dominate scene14 heidegger cal gestel enframing rendering aspects world “standing reserve” condition availability revealing may retain poetic creative elements event often indicates urtext sigmund freud uncanny trans hugh haughton harmondsworth penguin classics orig significant freudian moments within freudian text mostly literary analysis concept unheimlichkeit concern freud one story freud seeing “disagreeable” man window railway carriage discover reflection glass nightmare tale freud attempting leave redlight district town stumbled accident find path flight returning location one stories repressed footnote told passing near book’s conclusion real conclusion clear meet uncanny ourselves—or rather always lies within quote attributed american artist walt kel whose cartoon strip “pogo” included many elements political commentary well existential play allegedly parody message sent us navy commodore oliver hazard perry army general william henry harrison victory battle lake erie stating “we met enemy ours” quotation first appeared lengthier form “a word fore” foreword book pogo papers patriotic nationalism canonical sources suffice current purposes jacques el ul technological society new york vintage lewis mumford technics civilization chicago university chicago press orig murray bookchin postscarcity anarchism chico ca ak press orig sentient ais persons kind instrumental usevalue calculus resources natural human15 forest seen lumber river electric power human perhaps perpetual gig worker victim aspirational advertising unwitting supplicant socialmedia addiction upgrade anxiety yes sounds familiar16 yet capable resisting world including human biology also nonhuman complexity always available disposal consumption able let things turn tasks limit consumption selfconsumption walk away walk aimlessly able heidegger puts build dwel think17 hopeful picture things go borglike resistanceisfutile skynet terminator direction—wel make stand counts valuable fail shall welcome new android overlords likewise remember sometimes former foes become present future friends bibliography asimov isaac robot new york random house orig boden margaret artificial intel igence short introduction oxford oxford university press descartes rené meditations first philosophy cambridge cambridge university press orig dick philip k androids dream electric sheep oxford oxford university press orig donnel jack universal human rights theory practice ithaca ny cornell university press orig graeber david utopia rules technology stupidity secret joys bureacracy new york melville house granmar claes katarina fast lappalainen christine storr eds artificial intel igence fundamental rights stockholm stockholm university press heidegger martin question concerning technology essays new york harper perennial orig kingwel mark world want virtue vic good citizen toronto viking kurzweil ray singulairty near humans transcend biology new york viking martin heidegger “the question concerning technology” question concerning technology essays trans william levitt new york harper rev ed explore causes consequences version contemporary disposability selfconsumption wish boredom interface montreal kingston mcgillqueens university press central argument ostensible banishing boredom offered devices distractions fact reinforces quasiaddictive cycles neoliberal boredom designed keep subject state perpetual restless anxiety respect knowingness upgrades connection martin heidegger “building dwelling thinking” poetry language thought trans albert hofstadter new york harper rev ed mark kingwell lanier jaron ten arguments deleting social media accounts right new york henry holt leckie ann ancil ary justice new york hatchette mcewan ian machines like novel new york knopf mcluhan marshal medium massage inventory effects berkeley ca gingko press orig chapter autonomy michael wheeler introduction many ethical challenges vicinity ai perhaps greatest anxieties concern autonomous ai—ai relevant sense selfgoverning extreme form anxieties vividly expressed prediction human kind soon share planet autonomous artificial superintelligence whose selfgenerated goals interests diverge radical result divergence prediction goes palpable risk machine exercise autonomy ways detrimental wellbeing survival visions nottoodistant future populated least one superintelligent machine malicious intentions maybe intentions wellbeing simply doesn’t figure doubt strike readers disturbing specification clear credible danger need urgent consideration robustly funded international task force strike others pure science fiction need nothing expensive healthy dose technical reality truth almost certainly somewhere surely enough make issue worthy consideration light foregoing seems one important question might ask conditions would need met intelligent machine order machine exhibit kind degree autonomy operative dysto pian scenario guiding intuition machine ful autonomous agent threats question arise makes sense ways determining point reached al understanding bar artificial autonomy may help us decide worried follows attempt made bring notion autonomy issue far better view said arguably pressing concern regarding different notion autonomous ai recent years witnessed enormous advances areas machine learning sensor technology robotics indeed seems already michael wheeler building verge building ai systems although may fail exhibit autonomy metaphysical demanding sense selfgoverning milder sense domains operation ceding cede sig nificant degree control existing imminent examples systems kind discussed chapter include weapons vehicles financial management applications medical assistants aienhanced take control sphere intelligent often lifecritical action one might rea sonably moved thought debates present anyway mere thought experiments take back seat debates nature implica tions real ai systems embedded actual world soon taking important decisions sometimes profound consequences behalf1 given following treatment autonomous ai focus autonomy figures relation future postsingularity dystopia also autonomy figures contemporary concrete ai systems taking sensitive decisions us wild state affairs may legitimate cause concern wil however twist tale since shall see two kinds autonomy actual connected interesting way autonomy control autonomous entity entity capacity selfgovernance relevant sense term understood notion autonomy looms large many debates ethical political importance debates example aspira tions particular counties regions constitutional independent existing external power structures rights patients make informed uncoerced deci sions medical treatments ideal living maximal authentic life free manipulating selfdistorting influences examples could multiplied indefi nitely different contexts different aspects matters autonomy come fore given kaleidoscope issues problems worth homing one’s target domain highlight concepts principles local cur rency thus begin noting topic autonomy machines general autonomy mechanistic universe notion might reason ably said defines territory control thus machinerelated context control mean governance consider watt governor device controlling speed steam engine selfgovernance control oneself relevant aspect one’s activity see eg david mindel robots robotics myths autonomy new york penguin filippo santoni de sio jeroen van den hoven “meaningful human control autonomous systems philosophical account” frontiers robotics ai autonomy idea concept control central appropriate understanding autonomy might think negative justification positive one let’s take negative one first lack autonomy seems lack control one’s behavior larger scale one’s destiny first approximation nonautonomous entity one whose behavior destiny controlled external causal forces thus autonomous entity one control behavior destiny first approximation remain intricate matters detail example dennett points classic discussion control relation free notion course conceptual intertwined autonomy one control something including oneself one doesn’t achieve feat controlling causal forces act thing2 words may rightly said control physical actions even though actions con strained shaped factors force gravity ambient temperature strength wind indeed skilled soccer player enough weatherrelated information may anticipate accommodate maybe even exploit wind—an external active factor beyond control—in order score majestic thus beautiful control free kick subtleties one sometimes control selfcontrolling entity without thereby undermining entity’s basic claim autonomy controlling external factors via selfcontrolling mecha nisms cause act certain predictable ways3 circumstances sensible autonomous agent sense control want controlled external factors imminent danger results agent adopting avoidance behavior purely reactive stimulusresponse thereby appropriately speedy manner cf dennett’s discussion skinnerian control4 sometimes act might call metaautonomy rational eg meet time constraints avoid overly predictable competing selfcontrolling agent agent delib erately give control often practical randomness order achieve desired outcome coin racket flipped determine serve receive first tennis dennett identifies similar complex cases5 niceties— many others besides—would need sorted let’s write philosophical blank check would complete hard thinking dennett make start agree compromised autonomy among things matter compromised control positive justification intimate connection autonomy control comes thought exploit notion different aspects control make sense idea autonomy graded quality rather binary machines mechanisms context present treatment latter result obviously concerns us since direct significance understanding daniel c dennett elbow room varieties free worth wanting cambridge mit press especial chapter id id –id michael wheeler autonomous ai contexts however idea might developed ground claim human beings biological machines whose autonomy founded operation biologicalpsychological mechanisms view whose prominent man ifestation philosophy psychology conceives human mind integrated set neural realized computational processes il ustrate way framework involving different aspects control might used build account autonomy realm artificial build analysis due boden6 inspired work ai artificial life alife—the construction study artificial systems exhibit various features characteristic biological systems boden draws distinction three different aspects con trol suggests crucial possession autonomy first extent behavior agent governed inner mechanisms respond environmental triggers ways programmed agent “birth” mechanisms shaped agent’s past experience world boden’s thought something like intralifetime learning matters auton omy least given agential capacity learn different historical paths learning produce agents possess “individuality” sense behavioral response two agents environmental variable may differ circumstances merely present state environment plus agents determines behavior particular agent present state environment plus individual experiential history history suite shared ical setup produce behavioral profile may well differ known machine learning classical induction systems id3 aq11 traditional connectionist approaches unsupervised supervised learning recent successes bayesian inference socalled deep learning provides rich suite ways adaptive inner modifications individual experiential histories may realized second autonomycritical aspect control boden identifies extent behaviordirecting mechanisms work selfgenerated agent question rather imposed external design boden notes may ini tial look like repeat point learning however appeal selfgeneration designed invite different observation namely behavior systems product emergent selforganization explain selforganizing system one certain intrasystemic components basis purely local rules ie without direction global executive control process interact non linear ways produce emergence maintenance structured global order selforganization recognized widespread phenomenon nature margaret boden “autonomy artificiality” philosophy artificial life ed margaret boden oxford oxford university press –autonomy regularly cited examples literature include beloussovzhabotinsky chemical reaction slime molds foraging ants flocking behavior creatures birds final example instructive happens scientific understanding flocking arguably enhanced computer simulation due reynolds7 simula tion enormously influential alife community system adaptive flocking behavior eg flocks maintained integrity navigating obstacles emerged arrangement individual virtual birds fol lowed three simple purely local rules rules imperfectly intuitively captured following ordinary language paraphrases don’t get close birds around don’t get far away move roughly speed course since seen selforganization exhibited kinds systems presence certainly sufficient autonomy agentcentric sense require nevertheless applying concept context—and specifi cal within hierarchies emergent behaviordirecting mechanisms higher layers selforganization generated basis primitives fact emergent structures lower levels8—gives us another way make sense idea purely mechanistic system might exhibit behavior environmen tal determined includes idea essential prefigured external designed executive program rather generated agent itself9 boden’s third autonomycritical aspect control extent agent’s behaviordirecting mechanisms may reflected upon selectively modified agent explore transform selfgoverned fashion conceptual spaces thought action paradigm cases deliberate inner modification agent mechanisms episodes conscious thought human beings “higher” levels processing access amend states processes occurring “lower” levels least arguable ai best models reflective processing still hail classical ai models marked deployment explicit languagelike rules representations algorithmical manipulated ways often inspired human introspection10 craig w reynolds “flocks herds schools distributed behavioral model” computer graphics –boden “autonomy artificiality” although boden doesn’t pursue thought formal relationship selforganization autonomy may found theoretical framework provided autopoiesis framework influential field alife according framework selforganizing system counts autonomous network interdependent processes whose recurrent activity produces maintains boundary determines identity network unitary system maintaining organization thus viability see eg francisco j varela principles biological autonomy new york elsevier north hol useful discussion see xabier e barandiaran –of course connection technical notion autonomy common usage ethics would need worked related development see gunther teubner law autopoietic system oxford blackwel boden “autonomy artificiality” michael wheeler boden ask whether entity autonomous ask whether behaviordirecting mechanisms may shaped entity’s experien tial history emergent nature reflectively modifiable entity controlrelated properties realizable realm artificial indeed status autonomyrelevant inspired precisely consideration achieve ments domain moreover conceived defining something like threedimensional coordinate system gives entity position might call “autonomy space” higher values different axes autonomous entity that’s delivers idea autonomy graded rather binary phenomenon boden puts “an individual’s autonomy greater behaviour directed selfgenerated idiosyncratic inner mechanisms nicely responsive specific problemsituation yet reflexively modifi able wider concerns”boden’s analysis autonomy useful take us way need recall first aim chapter bring better view conditions would need met machine order machine exhibit kind degree autonomy might make us take seriously vision autonomous artificial superintelligence whose selfgenerated goals interests diverge radical exercises autonomy ways detrimental wellbeing survival light goal boden’s account productive succeeds charac terizing robust sense agential autonomy way see phenom enon built emerging purely mechanistic processes however even though emphasizing distinctive learning histories hints presence selfspawned life plan structured idiosyncratic goals desires even though stressing reflective modification behaviordirecting mechanisms almost points us direction selfmodifiable individual worldview fails adequately fore ground account demand ful autonomous agent must able arrive life plan adaptively modify plan light experiences evidence12 capacities one might reasonably think need found artificial superintelligence apocalyptic scenario look plausible capacities delivered additional purely mechanistic controlrelated features thus making available new dimensions higher points autonomy space questions waiting wings present formidable philosophical challenges example establishes life plan agent’s answer question presumably requires account cognitive ownership one account see rowlands13 thus self consciousness selfconsciousness required adaptive lifeplanning present context raises issue id steven weimer “evidenceresponsiveness autonomy” ethical theory moral practice mark rowlands new science mind extended mind embodied phenomenology autonomy whether artificial consciousness possible14 might invitation recalcitrant hard problem consciousness problem explaining purely physical system conscious rather nonconscious15 commentators might take comfort fact longstanding deeply perplexing puzzles might make seem ful autonomous ai remains long way however one underestimate power science chip away recalcitrant problems example common thought philosophical discussions autonomy autonomous agent possesses set socalled “proattitudes” roughly higher order desires values beliefs record approval admiration preference toward things governs approach engagement world set pro attitudes often taken define part meant “the self”moreover ful autonomous agent able incorporate new proattitudes beliefs desires values governing set basis unfolding experience evidence capacity proattitude maintenance revision also pivotal aspect autonomy since agent’s goal activity plan life accordance pro attitudes rather ask directly whether ai system could adaptively modify life plan light experience evidence ask related perhaps less daunt ing question whether ai system could incorporate new proattitudes beliefs desires values behaviorgoverning set light experience evidence drawing recent work neuroscience niker et al17 argue latter feat may achieved specific kind computational mechanism brain one works according principles bayesian inference tell us update probabilities prior beliefs attitudes thought hypotheses given evidence course bayesian inference techniques established longstanding part ai toolkit eg pattern recognition machine learning indeed least popularity neuroscience traced success ai autonomy graded phenomenon characterizable terms different varieties levels mechanizable control eventual top full autonomy kind required thankful still fictional superintelligent ai principle road map autonomy realm artificial way recog nizing far road traveled next section shall turn attention concerns arise even early twists turns road points even though target ai system partial scopedout level full autonomy nevertheless ceded control system potential sensitive safetycritical inthewild scenario ronald l chrisley “philosophical foundations artificial consciousness” artificial intel igence medicine –david j chalmers “facing problem consciousness” journal consciousness studies –fay niker peter b reiner gidon felsen “updating selves synthesizing philosophical neurobiological perspectives incorporating new information worldview” neuroethics –id michael wheeler relinquishing control commercial peertopeer ridesharing business uber began testing selfdriving cars roads arizona february march tempe uberowned selfdriving car traveling autonomous mode although safety driver board struck killed pedestrian crossing road unauthorized point prelimi nary report us national transportation safety board suggested detecting victim six seconds impact controlling software struggled ambiguity perceptual input first identifying pedestrian unknown object vehicle bicycle pushing bicycle time one second impact vehicle made decision emergency braking required emergency autobraking system available malfunc tion engineers concerned selfdriving car active autono mous emergency braking system would risk behaving unexpected erratic thus potential dangerous ways result system repeatedly trig gered unnecessarily “falsepositives” mistaking pedestrian standing harm lessly sidewalk one jump road moreover uber turned car’s offtheproductionline automatic emergency braking system would conflicts two kinds technology following tragic incident arizona uber immediately implemented temporary suspension selfdriving car operations public roads order revisit safety protocols18 foregoing example graphical exposes rather obvious nevertheless worth stating dilemma regarding selfdriving cars one hand whole point vehicles wel drive includes making identifications cate gorizations decisions environmental circumstances well determining actions appropriate extent resist ceding sort control technology—to extent example vehicle required seek input human operative whether onboard remote categorizes acts—it simply isn’t autonomous reasonable sense term defeats object exercise prevents us reaping benefits techno logical advances play course plenty evidence runs counter arizona tragedy—evidence might expect tabled certain interested parties—citing overall safety record selfdriving cars alongside statistics emphasize prevalence human error road accidents19 hand see httpswwwthevergecom201831917139518uberselfdrivingcarfatalcrashtempearizona httpswwwthevergecom20187317530232selfdrivingaiwinterfullautonomywaymoteslauber httpswwwwiredcomstoryuberselfdrivingcrasharizonantsbreport uber’s video “selfdriving cars return pittsburgh roads” reporting “months reflection improvement” following arizona incident httpswwwyoutubecomwatchv0e5iqjjoky last accessed june see eg safety report googleowned waymo httpsstoragegoogleapiscom sdcprodv1safetyreportsafetyreport2018pdf aforementioned uber “selfdriving cars return pittsburgh roads” video last accessed june autonomy extent cede control technology inherit range safetycritical risks pose difficult ethical problems well technical legal challenges example one instincts things go wrong wonder anyone blamed case selfdriving cars that’s straightforward mat ter car cannot held responsible given lowergrade kind autonomy enjoys it’s simply blameworthy moral agent maybe ethical attention focused owning company designers developers engineers safety driver one—the autonomous vehicle gold standard surely away individuals altogether present purposes point choose among candidates responsibility—no doubt kinds contextdependent complexities mean universal principle policy work—but rather register higherorder point relinquishing control relinquishing control look like available options drawbacks saying something way response remind self driving cars onthecards technological innovations raise ethical questions vicinity milder form autonomy could raise similar related dilemma regarding robot surgeons average systems quite likely perform accurate surgical movements navigating reasoning enor mous multidimensional patientrelated data spaces manner safer speedier human surgeons prediction confirmed would provide positive evidence cede control systems al surely want healthier population maintained efficient medical delivery it’s hard eliminate nowfamiliar nagging concerns moral responsibility legal accountability dilemma returns things might seem rather graver another context decisionmaking mildly autonomous ai context although highlighted ethical dilemma could certainly stated abstract cynics among us might wonder whether consti tutes genuine sociopolitical choice given power societies ultimately lies thus consider autonomous weapons systems—weapons systems “once activated ai charged deciding routinely emergency situations whether take human lives predictably development deployment systems subject widespread criticism leading demands proper interna tional framework ethical design regulation see example ’s “open letter united nations convention certain conventional weapons” signed leading technology entrepreneur elon musk one hundred ceos tech nology companies calling un structures find way protect us dangers lethal autonomous weapons systems21 quoted amanda sharkey “autonomous weapons systems killer robots human dignity” ethics information technology –httpsfutureoflifeorgautonomousweaponsopenletter2017 last accessed june michael wheeler academic public debate range arguments autonomous weapons systems lodged include limited following extant imminent instances weapons sophisticated enough allow systems follow international humanitarian law—the legal prin ciples armed conflict designed protect civilians turn delicate complex judgmentladen notions distinction combatants noncombatants proportionality use force sense necessary military perspective22 accountability compromised unclear blame unnecessary casualties resulting decisions autonomous weapons specifical becomes harder regard military personnel moral legal responsible relevant war crimes23 cf similar worry raised earlier case selfdriving cars inanimate ai system incapable genuinely respecting value understanding loss human life allowing machine end human life affront person’s dignity24 confronted advent smart machines able make execute safetycritical sometimes lifecritical decisions us—perhaps spite us—the relinquishing control machines raises acute ethical chal lenges time around thought society general might actual power refuse allow military relinquish control autonomous ai systems question may essential chimerical would resolve dilemma accompany ing decision whether relinquish control obvious alarm ing cost returning selfdriving cars one response ethical problems posed launch massive online research project investigating people across world among many others see peter asaro “how could robot war be” philip brey adam briggle katinka waelbers eds current issues computing philosophy ios press –noel e sharkey “death strikes sky calculus proportionality” ieee science society spring –noel e sharkey “killing made easy joystics politics” patrick lin george bekey keith abney eds robot ethics ethical social implications robotics cambridge mit press –santoni de sio van den hoven “meaningful human control autonomous systems” optimistic assessment autonomous weapons systems might achieve area see ronald c arkin “the case ethical autonomy unmanned systems” journal military ethics –again among many others see robert sparrow “killer robots” journal applied philosophy –sharkey “killing made easy” christof heyns report special rapporteur extrajudicial summary arbitrary executions ahrc2347 new york united nations yet among many others see bonnie docherty shaking foundations human rights implications kil er robots human rights watch website httpswwwhrworg report20140512shakingfoundationshumanrightsimplicationskillerrobots last accessed july christof heyns “autonomous weapons armed conflict right dignified life african perspective” south african journal human rights –for discussion see sharkey “autonomous weapons systems killer robots human dignity” autonomy think autonomous vehicle faced moral choices25 basis research welltrodden philosophical thought experiment known trolley problem26 scenario confronted runaway trolley positioned front lever redirecting trolley onto side track presented must select different outcomes example could set like could pull lever save lives five people trapped trolley thereby cause death one person trapped side track b pull lever let five people die meaning single person survives permutations terms numbers people are—relations politicians children rich poor on—are limitless made trolley problem popular philosophical tool exploring moral decisionmaking back land ai it’s hard see trolley becomes selfdriving car lever becomes programming hence empirical study question place explore precisely data study came although worth noting universal trends emerge eg save humans animals participants’ judgments often culturespecific concerned general point data gathered would arguably enable designers autonomous vehicles predict particular communities’ responses might accidents involving vehicles thus moral decisionmaking autonomous vehicles might tailored culturespecific sensitivities work particular region operation sounds like potentially useful thing selfdriving car companies already adapt vehicles different eg less aggressive “driving cultures” even looks like sort progress critics autonomous vehicles closer technical coal face might well moved complain complex moral tradeoffs trolleyproblemstyle scenarios intro duce well beyond capacities today’s selfdriving cars critics argue yet overcome basic categorization challenges indicated uber vehicle’s ultimately tragic struggle disambiguate perceptual input see earlier species complaint lodged current autonomous weapons systems thereby bolstering claim unable navigate laws conflict critic tempted make reference actual ai machine learning system allegedly misclassified enemy friendly tanks due contingent irrelevant property training set namely training images enemy tanks mostly featured cloudy skies friendly tanks mostly featured cloudfree skies result system learned track distinction cloudy edmond awad sohan dsouza richard kim jonathan schulz joseph henrich azim shariff jeanfrançois bonnefon iyad rahwan “the moral machine experiment” nature –for classic formulation trolley problem see philippa foot “the problem abortion doctrine double effect” oxford review –for philosophical discussion trolley problem relation selfdriving cars see patrick lin “why ethics matters autonomous cars” autonomous driving technical legal social aspects ed markus maurer chris gerdes barbara lenz hermann winner berlin springer –michael wheeler noncloudy skies distinction beyond training set reliably correlated difference enemy friendly tanks27 order us feel comfortable relinquishing control ai systems seems necessary although sufficient kinds examples cited containable eliminable edge cases one confronted recent undeniably impres sive advances ai especial machine learning optimism might seem order day indeed one might easily come believe road autonomy paved combination deep learning big data deep learning networks typical deploy multilayered cascades nonlinear process ing units alongside supervised unsupervised machine learning algorithms per form pattern analysis classification tasks deriving higher level features lower level features build hierarchical representations spanning different levels abstraction metz reports systems “already pushing way real world applications help drive services inside google internet giants helping identify faces photos recognize commands spoken smartphones much more”they famously learned play challenging intellectual games high levels proficiency culminating google’s alphago deeplearningbased sys tem playing game go march recorded –victory lee sedol one highest ranked human players world addition used complete lifecritical assignments detecting earthquakes predicting heart disease crucial present discussion deep learning networks central control mechanisms autonomous ai industries see pivotal eventual success products especial combined huge data sets may analyzed navigated networks question track reveal taskuseful dis tinctions patterns trends problem one issue note spite justified enthusi asm deep learning remain barriers overcome example stated terms general tendency clear sense although networks perform extremely well specific tasks single network performs well across multi ple tasks even within general domain thus consider network must learn multiple classic atari video games team google’s deepmind shown possible use algorithm network architecture hyperparameters learn fortynine games retraining system scratch new game29 eliezer yudowsky “artificial intelligence positive negative factor global risk” global catastrophic risks ed nick bostrom milan cirkovic oxford oxford university press –cade metz “google’s ai wins fifth final game go genius lee sedol” wired march httpswwwwiredcom201603googlesaiwinsfifthfinalgamegogeniusleesedol last accessed july volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc g bellemare alex graves martin riedmiller andreas k fidjeland georg ostrovski stig petersen charles beattie amir sadik ioannis antonoglou helen king dharshan kumaran daan wierstra shane legg demis hassabis “humanlevel control deep reinforcement learning” nature –autonomy yet possible however either one network learn different games serial retaining competence process learning games one time eventual results catastrophic forgetting previous games one network learn different games parallel different rule sets interfere course recognition limitations place strategies development progressive chaining technique separate deep learning systems pass relevant information scaffold learning although approach eventual runs aground intractabil ity increasingly large model30 point us however arguable whether ai systems roads battlefields operating theaters possess kinds generalization capacities need relinquish control moreover—and vicinity kinds categorization errors noted earlier—szegedy et al influential demonstrated deep learning neural net works systematical prone socalled adversarial exemplars31 let’s consider one szegedy et al’s examples network successful learned categorize images two groups—“cars” “not cars” researchers proceeded systemati cal generate range minutely altered images cars deformations small changes made pixel level meaning unaided human eye new images looked identical images network exposed learned categorize correctly cars inadvance prediction would surely network would correctly classify altered images cars surprisingly however classified noncars hence status images adversarial exemplars course armed knowledge adversarial exemplars exist designers systematical generate items include net works’ training sets especial given finite time constraints surely danger effect akin flattening lump carpet lump simply reappear somewhere else overarching worry deep learning networks especial navi gating huge data sets doubt perform ever impressive feats reasoning complex ethical sensitive domains thus find increasingly tempted cede control networks sometimes divide world ways coincide ways dividing world meaning decisionmaking divergent presumably opaque us pixels stopped image classifiable car troubling seen capacity reliable categorization— specifical consistent partitioning world categories ethical relevant us eg combatants noncombatants—is necessary ability andrei rusu neil c rabinowitz guil aume desjardins hubert soyer james kirkpatrick koray kavukcuoglu razvan pascanu raia hadsel “progressive neural networks” arxiv160604671 christian szegedy wojciech zaremba ilya sutskever joan bruna dumitru erhan ian goodfellow rob fergus “intriguing properties neural networks” arxiv13126199 michael wheeler ai enjoy even milder kind autonomy potential existence unknown adversarial exemplars problem spaces question spaces partitioned deep learning networks least make us pause reflect close present ai systems meeting constraint final twist point relinquish control ai point questions regarding lack grip precisely certain contemporary ai architectures see world thus exactly autonomous intelligent machine deploying archi tecture safetycritical context characterized uncertainty might become prompts nervous apprehension precise path alleviation concern yet clear let’s finish brief admittedly speculative suggestion connects two perspectives autonomy view chapter many ethical challenging scenarios canvassed case autonomous weapons selfdriving cars one part solution may machine knowledge consequences actions sentient beings able reflect consequences32 capacity assessment even likely prevent unknowing harm deployed artificial agent able arrive words imbuing ai kind ability required demand ing fullstrength variety autonomy may one way addressing concerns accompany less demanding milder variety course there’s gigantic elephant room what’s needed ful autonomous artificial agent whose “life plan” shaped psychopathic tendencies demonstrable understanding empathy humankind commentators remain skeptical possibility33 however case made without achievement place autonomy realm artificial even milder register likely remain matter controversy anxiety34 colin allen gary varner jason zinser “prolegomena future artificial moral agent” journal experimental theoretical artificial intel igence –see eg sharkey “autonomous weapons systems killer robots human dignity” short passages text chapter adapted michael wheeler “the reappearing tool transparency smart technology extended mind” ai society published online february httpsdoiorg101007s001460180824x many thanks student laurie mcmil taught optimistic possibility benign ful autonomous ai autonomy bibliography allen colin gary varner jason zinser “prolegomena future artificial moral agent” journal experimental theoretical artificial intel igence –arkin ronald c “the case ethical autonomy unmanned systems” journal military ethics –boden margaret “autonomy artificiality” philosophy artificial life ed margaret boden –oxford oxford university press bostrom nick superintel igence paths dangers strategies oxford oxford university press dennett daniel c elbow room varieties free worth wanting cambridge mit press lin patrick “why ethics matters autonomous cars” autonomous driving technical legal social aspects ed markus maurer chris gerdes barbara lenz hermann winner –berlin springer mindel david robots robotics myths autonomy new york penguin sharkey noel e “killing made easy joystics politics” robot ethics ethical social implications robotics ed patrick lin george bekey keith abney cambridge mit press sparrow robert “killer robots” journal applied philosophy –szegedy christian et al “intriguing properties neural networks” arxiv13126199 chapter troubleshooting ai consent meg leta jones elizabeth edenberg introduction normative concept consent perform “moral magic”of transforming moral relationship two parties rendering permissible otherwise impermissible actions yet governance mechanism achieving ethical data practices consent become strained—and ai played small part contentious state chapter describe consent become controversial compo nent data protection artificial intelligence systems proliferated everyday lives highlighting five distinct issues lay call consent’s “moral core” emphasizes five elements meaningful consent next apply moral core ai systems finding meaningful consent viable within particular dig ital land scape final discuss forces driving commentators away individual consent whether meaningful consent future smart world consent crisis west seen significant expansion social practices defined choosing2 claimed “people choice choose” contemporary societies3 heidi hurd “blaming victim response proposal criminal law recognize general defense contributory responsibility” buffalo criminal law review sophia rosenfeld “free choose” nation june httpswwwthenationcom articlefreechoose anthony giddens “living posttraditional society” reflexive modernization politics tradition aesthetics modern social order meg leta jones elizabeth edenberg choices present mean consent functioning ought stated broadly individual’s consent involves effective communication intentional transfer rights obligations parties4 consent moral trans form tive need simply make offered choice matter need clear understanding normative background action proposed viable alterna tives sufficient information two parties consent transaction treating one another fairly choice consent proliferation within data protection regimes tracks proliferation “choice societies” described sociologists historians perhaps leads frequent conflation data protection laws product government initiatives investigate social implications automatic data pro cessing 1960s 1970s first laws consent played minimal role computable information networked 1990s computer “user” born individual consent became important strategy seeking ethical data practices well protecting data human right consent one six legal bases processing personal data european union data protection directive remains one justifications controlling processing personal data eu legal default personal data cannot processed definition consent eu data protection directive art 2h ject signifies agreement personal data relating processed” implied consent optout practice became standard period additional directive allowed transfer personal data third country without adequate data protection data subject consented art 261a meanwhile united states created notice choice regime series negative public responses thirdparty cookies5 state federal investigations data practices strategy platform selfregulation thus recently regimes relied heavily notice consent approach achieve ethical data practices flaws approach clear quite early number privacy researchers produced powerful empirical evidence demonstrating weaknesses approach developed various tools improve aleecia mcdonald lorrie cranor calculated would take average two hundred hours seventysix work days read privacy policies one exposed year6 joseph turow colleagues repeatedly surveyed americans revealing consistently ethics consent see franklin g miller alan wertheimer ethics consent theory practice new york oxford university press andreas müller peter schaber routledge handbook ethics consent london routledge meg leta jones “revisiting cookies statelessness doubleclick” forthcoming file author aleecia mcdonald lorrie faith cranor “the cost reading privacy policies” isjlp troubleshooting ai consent inaccurately interpret existence privacy policy signal privacy protection7 alessandro acquisti jens grossklags performed series behavioral eco nomic analyses privacy decisionmaking revealing individuals state care privacy make decisions disclose personal data anyways due lack information challenges assessing longterm threats versus shortterm benefits8 sociologist james rule criticized collective system highlighting apparent pressure use particular platforms limited choices alternatives9 flaws categorized four issues many policies lengthy confusing terms inability assesspredict outcomesharms limited alterna tive choices studies involve sites platforms used ai techniques hot term prior ai big data focus big data complexity unpredictability findings secondary uses ai systems add challenges due ability autonomously learn opacity displacement restructuring human engagement ai systems thus exacerbate four issues add another new issues presented consent “smart future” technological transition subtle leap ahead address consent “general ai” like field refer existing approaching ai systems based practiced machine learning techniques namely though exclusively layered neural networks deployed particular setting learn trained patterns “big” contextualized data although contemporary ai systems rely lots data specific data specific use machines “learn” training dataset conclusions drawn computer good data going training boeing may accurate data retrofitted winglets data paper jams may spread across number companies data useful recom mending next favorite audiobook identifying spam techniques general izable technology applications generalizable—like automation advances one thing ai system win go cannot recognize cat refer ai “systems” consider ai exist neatly designed systems instead understand ai systems sociotechnical assemblages made various players institutions interests personalities localities moments systems designed people particular backgrounds motives particular institutions particular purposes ai systems rely data models organiza tional practices drawn thus often also “infected” existing social order thus “objective” free bias existing social orders ask consent ai systems asking consent joseph turow michael hennessy nora draper “persistent misperceptions americans’ misplaced confidence privacy policies –” journal broadcasting electronic media –acquisti alessandro jens grossklags “privacy rationality individual decision making” ieee security privacy –james b rule privacy peril sacrificing fundamental right exchange security convenience oxford oxford university press meg leta jones elizabeth edenberg learning systems broadly particular powerful political opaque arrangements data use automated means thus first two existing issues simply speak reach complexity ai systems ai systems used across existing sites platforms services con tribute large number policies one confronts daily also built new forth google moved many services like youtube recommendations google assistant umbrel google brain project deep learning ai research team10 company’s sidewalk labs significantly expanded imple mentation ai beyond common use coordinating traffic lights11 ai systems less challenging explain users data practices fact explainability major topic scholarly research frank pasquale’s book black box society details many ways secret algorithms shape lives argues transparency12 margot kaminski succinctly describes debate whether right explainability european data protection law implemented13 much discussion around explainability revolved around whether explanation possible14 nonetheless group engineers hard work trying make ai transparent google brain instance recently announced “translator humans” called tcav testing concept activation vectors explains user much specific concept eg stripes male played system’s reasoning15 others like andrew selbst solon barocas broken goals explainability reveal limitations provid ing normative critiques ai systems16 ubiquity complexity opaqueness contribute users’ inability assess predict outcomes harms part claimed benefit ai systems pro duce insights predictions humans may rationality choosing service touts improvement aspect one’s life clear measured unpredictable incomprehensible long term future harms limitation choices issue changed course computing history quite important prospect regulation well efficacy consent users may many choices providers platforms services undertake robert mcmil “inside artificial brain that’s remaking google empire” wired july httpswwwwiredcom201407googlebrain sidney fussel “the city future datacollection machine” atlantic november httpswwwtheatlanticcomtechnologyarchive201811googlesidewalklabs575551 frank pasquale black box society harvard university press margot e kaminski “the right explanation explained” berkeley technology law journal vol forthcoming knight “the dark secret heart ai” mit technology review april https wwwtechnologyreviewcoms604087thedarksecretattheheartofai kim martin wattenberg justin gilmer carrie cai james wexler fernanda viegas rory sayres “interpretability beyond feature attribution quantitative testing concept activation vectors tcav” arxiv preprint arxiv171111279 andrew selbst solon barocas “the intuitive appeal explainable machines” fordham law review troubleshooting ai consent similar types problematic data practices case much mid1990s 2000s users may choices platforms become complaint internet service providers amazon facebook google 2010s services provide user much “choice” within platform think beneficial setting pages users opt certain data collection sharing erase data dashboards users finetune choices pri vacy popups remind users information currently shared change settings ai systems basis companies used help amass significant market power attract talented engineers instance google search became dominate search engine developing algorithms relied set humanengineered definite rules search system began use deep learning support functionality sacrificing control clarity efficiency scalability17 today company utilizes deep learning google map’s driving directions assistant application youtube’s safe content setting smart replies suggest responses texts email nest’s outdoor security functionality driverless car division waymo18 facebook utilizes deep learning classify immense amount unstructured data photos almost status updates billion users per minute enables performance textual analysis facial recognition targeted advertising19 amazon used ai provide product recommendations based searches purchases since late 1990s recently machine learning also powers popular home personal assistant device alexa robots maneuver distribution warehouses grabandgo shopping experience amazon go stores20 privacy journalist kashmir hill undertook experiment understand reliance “big five” microsoft google amazon facebook apple experience ranged longing21 “impossible”“devastating”“hell”that cade metz “ai transforming google search rest web next” wired february httpswwwwiredcom201602aiischangingthetechnologybehindgooglesearches bernard marr “the amazing ways google uses deep learning ai” forbes august httpswwwforbescomsitesbernardmarr20170808theamazingwayshowgoogleuses deeplearningai468611b43204 bernard marr “mindblowing ways facebook uses artificial intelligence” forbes december daniel terdiman “how ai helping amazon become trilliondol ar company” fast company october httpswwwfastcompanycom90246028howaiishelpingamazon becomeatrilliondol arcompany kashmir hil “i cut facebook life surprisingly missed it” gizmodo january httpsgizmodocomicutfacebookoutofmylifesurprisinglyimissedi1830565456 kashmir hill “i tried block amazon life impossible” gizmodo 1830565336ga2523508808822756581548823260–kashmir hil “i cut apple life devastating” gizmodo february httpsgizmodocomicutappleoutofmylifeitwasdevastating1831063868 kashmir hil “i cut ‘big five’ tech giants life hel ” gizmodo february httpsgizmodocomicutthebigfivetechgiantsfrommylifeitwashel1831304194 meg leta jones elizabeth edenberg law26 issue placed firmly federal political agenda 116th congress presidential campaign27 well group state attorneys gen eral enforcement strategy28 whether users meaningful consent big tech’s ai systems certainly play important role debate whether regulate fifth issue relates way consent currently communicated parties existing consent transactions rely personal devices present readable notice screen owner operator way express consent29 many ai systems built objects environments screens interact third parties departure away screens personal devices solitary means personal data collected shared processed requires new ways communicating notice consent importantly though requires us reconsider consent distinct consumer choice means smart future30 moral core consent james grimmelmann said “we national crisis consent”from sex sports criminal deals medical procedures consent criticized falling short providing “a meaningful marker autonomy coercion”in context social media experimentation grimmelmann cal “enthusiastic consent” order eliminate adversarial nature online research33 similarly relying rich tory bioethics called “cooperative consent” emphasizes bilateral kashmir hil “i cut google life screwed everything” gizmodo january httpsgizmodocomicutgoogleoutofmylifeitscrewedupeverything1830565500ga2109788613 –jenny lee “the googledoubleclick merger lesson federal trade commission’s limitations privacy” review file author valerie richardson “big tech unites democrats republicans behind antitrust crackdown” washington times june httpswwwwashingtontimescomnews2019jun4joshhawley elizabethwarrenunitedbigtechanti brian fung tony romm “inside private justice department meeting could lead new investigations facebook google tech giants” washington post september httpswwwwashingtonpostcomtechnology20180925insidebigmeetingfederalstatelaw enforcementthatsignalednewwillingnessinvestigatetechgiantsutmtermba9509a4f186 meg leta jones “your new best frenemy hello barbie privacy without screens” engaging science technology society –meg leta jones “privacy without screens internet people’s things” idaho law review james grimmelmann “the law ethics experiments social media users” colorado technical law journal catharine mackinnon toward feminist theory state harvard university press grimmelmann “the law ethics experiments social media users” troubleshooting ai consent nature consent gives due weight interests parties34 whether enthusiastic cooperative consent must also exist within wellunderstood landscape rights obligations support meaningful marker aspects make consent moral meaningful neglected overem phasis nature communicative power35 find landscape supports cooperative consent achieved focusing moral core consent consists five elements clear delineation background conditions permissible impermissible uses one’s data background conditions defined scope action scope consenter provided relevant information understand consent knowledge freedom choose among set viable options voluntariness consenter treated fairly required sacrifice important rights fairness36 investigate turn relates ai systems background conditions consent transform would otherwise impermissible permissible action must clear understanding background conditions set boundaries permissible impermissible action example right bodily autonomy sets clear background conditions underlie importance con sent sex permissible permissible surgeon operate likewise expectations personal property set background assumptions car theft clearly distinguished friend borrowing car pointing owner’s consent specific person specific use property digital consent also requires clear understanding background conditions specifying justifiable unjustifiable collection processing sharing use one’s data establishing clear background understanding people understand interests rights concerning one’s digital trail requires broad inclusive public discussion also require additional public education information currently collected individuals groups order enable informed discussion society treat digital trails rise ai poses additional challenges here—but insurmount able longview worries artificial agents superintelligence may suggest37 meg leta jones elizabeth edenberg ellen kaufman “ai ethics automating consent” ieee security privacy –for interesting discussion able consent see nancy kim consentability consent limits cambridge university press we’ve developed moral core digital consent detail elizabeth edenberg meg leta jones “analyzing legal roots moral core digital consent” new media society nick bostrom superintel igence paths dangers strategies oxford university press meg leta jones elizabeth edenberg popular perhaps natural38 anthropomorphize computers arti ficial intel igent machines learn ai little set algorithms39 computer learns either supervised unsupervised reinforcement learning supervised learning currently popularly undertaken involves system training data labeled humans point humans often supervised40 challenges lie “black box” unsupervised learning computer seeks hidden patterns find correlations data sets—correlations always easily translated back way humans understand computer arrived conclusion reinforcement learning refers goaloriented algorithms wherein agent learns best action model one provides cumula tive rewards environment trial error however still computer programmers set goals create incentives first step navigating expectations around ai permitted requires broader education ai realistic inclusive discussions around current use cases harms ai every citizen know ai real roughly discuss whether think ai play role criminal sentencing standards recommending news sources whetherwhen right opt data collected alexa siri facial recognition cameras surround us part background condi tions relevant whether consent plays role ethical ai practices particularly important include diverse perspectives discussions current practices impact individuals communities interests stake diverse groups41 approach discussions sense entitlement renegotiate emerging norms better align default background assumptions rights interests rather accept given default settings built current technologies currently set build deploy digital technologies scope examples consent clear normative force sex surgery transactions involving property scope actions clearly defined transfer kate darling “ ‘who’s johnny’ anthropomorphic framing humanrobot interaction integration policy” robot ethics ed patrick lin keith abney ryan jenkins oxford university press fantastic introduction breaks ai works computer scientists see meredith broussard artificial unintel igence computers misunderstand world james o’malley “captcha you’ve training ai years without realising it” techradar january httpswwwtechradarcomnewscaptchaifyoucanhowyouvebeen trainingaiforyearswithoutrealisingit informative discussion differential impact digital technology see khiara mbridges poverty privacy rights stanford university press troubleshooting ai consent rights requires clear delineation scope rights transferred mutual understanding parties scope terms permission granted case meaningful consent consentee agrees specific defined inter ruption usual inviolable rights oneself one’s body one’s personal property embedding openended terms seek “consent” possible future use company may data threaten normative efficacy purported consent given scope purposes consent offered must narrowly specified terms change new consent transaction sought continued use data requires continued authorization terms transaction cases consenter ways ai offers additional complications already challenging delinea tion scope terms data collection digital consent ai systems tend unpredictable opaque—machine learning allows computer scientists solve problems outstripped traditional programming ai technology also powers many components internet things increasingly “smart” environments—from facial recognition voice activation environments usual “terms service” mediate digital consent screenbased data exchanges absent however none means give consent ai also offers new ways navigate landscape continual consent ai could built explain context seek consent anew terms change could also leveraged behalf users acting personal privacy assistant mediating negotiations consent use data internet things behalf individual42 ai leveraged provide users better information scope terms proposed use data assist viable capacity opt exchange ai could help support users ability navigate digital world control information released purposes latter use ai help facilitate meaningful consent particularly exciting development see potential new technology ameliorate existing problems ai built support individuals’ ability keep abreast changing digital landscape work side individuals help address one important aspect consent part continual negotiation authorized use one’s personal information knowledge mutual understanding scope permission granted consent transaction requires party sufficient level understanding terms transaction requires oneway provision information see eg work personalized privacy assistant project pardis emami naeini sruti bhagavatula hana habib martin degeling lujo bauer lorrie faith cranor norman sadeh security soups –meg leta jones elizabeth edenberg person gives consent moral meaningful provision information effectively relay information form conducive individual standing information ideal context mutual understanding built coopera tively context allows parties question aspects terms exchange clear existing terms service often written legalese quite long difficult understand even one take time careful go policies outlined digital services frequent ai complicate matters many decisions hidden behind “black box” machine learning—hence push towards explain ability making decisions transparent clarity offered training data used goals set reinforcement training used allow crit ical assessment use ai particular contexts furthermore digital tech nology ai expand reach society demand better explanations increase digital literacy public everyone needs equipped make informed choices reflect interests requires least baseline understanding asked assess consent particular instance however technology could leveraged move back towards coop erative discussion proposed terms data use built support individuals often seen data subjects ai assistants could help bring back twoparty dis cussion reflective ideal informed consent procedure rather view information provision oneway provision information consentee ai could engage real dialogue allows questioning clarification asked voice recognition technologies long way go still ask systems also built clearly explain terms data use accessible way options ask questions clarify meaning much like commercial curious child asks “google” series questions opening wonders universe—we demand level clarity explanation anticipate followup questions basic terms use data google collects voluntariness interpersonal consent transactions voluntariness necessary component one’s token expressed consent normative force jill mugged gun point handing purse voluntary gift police stop thief jack would recourse saying jill gave purse even jill also said “here take purse” expressed consent insufficient viable option otherwise current terms digital consent often offer people services exchange data however idea individuals don’t want exchange data access society jobs require use electronic mobile connections given option simply “opt out” using company’s email mobile phone troubleshooting ai consent addition choose use facebook cannot control people take post picture page challenges increase think buildings cities use closed circuit cameras enabled facial recognition technology monitor shared spaces banks use ai calculate people’s credit scores digital trail credit card transactions used better market goods services individual likely buy world permeated digital means tracking surveil ance opting often luxury afforded viability opting puts significant pressure legitimacy consent many aspects digital infrastructure nevertheless believe ai could used negotiate terms consent transac tions allow individuals refuse specific request image data refus ing consent individual better afforded ability choose whether wishes share image data effective requires reciprocal recogni tion create use ai systems allow viable refusal participate opting creates gaps information monitoring system may strong incentives prevent refuse optout options individuals without option otherwise meaningful consent occurred omnibus comprehensive regulation may needed allow viable options refuse consent43 start discuss ways empower individuals control image data also requires ensuring ability meaningful options offered al citizens simply luxury good opting may limited impacts course one individual’s data needed make fairly reliable predictions individuals similar depending goals individual refusing proffer data widespread refusals become contexts limited ability truly opt system final component ensuring transaction occurs fair system become important fairness final piece picture ensure consent transaction occurs within fair context significant power imbalances limited options opt current dig ital world put added pressure society ensure exchange processing personal information including ai still treat parties fairly require using collective power citizens insist fair treatment major players currently hold outsized power terms digital exchange looking existing uses ai facial recognition voice recognition sentencing guidelines credit scores—existing injustices society reflected amplified rich body research continues show ai good training data learns computer trained historical biased data controversial aspect eu general data protection regulation involves services access denied based lack consent meg leta jones elizabeth edenberg example crime rates “learn” patterns racial economic discrimination likewise facial recognition technology trained mostly white faces trouble recognizing black faces44 flip side algorithm built data collected police interactions far data young black latino men example white women living city45 research also revealed systems used equal society poor mothers46 minorities47 example heavily surveilled populations48 fairness must confused accuracy inclusion systems wielded groups traditional dehumanized automated treatment consent within social contexts must rest upon foundation fairness power dynamics consent called broken unworkable challenging provide actual notice knowledge choice recent events scholarly insights expanded public’s understanding rhetoric around data protection social dimensions privacy become tangible due work highlighting discriminatory nature use49 ai systems like facial recognition50 search joy buolamwini “ai ain’t woman—joy buolamwini” filmed june youtube video posted june httpswwwyoutubecomwatchvqxuyfwovv98 cspan “house hearing facial recognition technology” cspan video june httpswwwcspan orgvideo461370–1houseoversightpanelholdshearingfacialrecognitiontechnology andrew guthrie ferguson rise big data policing surveil ance race future law enforcement nyu press bridges poverty privacy rights “the color surveil ance government monitoring american immigrants” georgetown law center privacy technology june httpswwwyoutubecomwatchvj6lq7jtud8a listpl2qpfpgz63f89kg0pti98ejlxaqi4w8l7 jeffrey fowler “don’t smile surveil ance airport face scans privacy trap” washington post june httpswwwwashingtonpost comtechnology20190610yourfaceisnowyourboardingpassthatsproblemhpidhprhptop tablemainfowler1035 amhedwins3ahomepage2fstoryans simone browne dark matters surveil ance blackness duke university press karen hao “ai sending people jail—and getting wrong” mit technology review times april httpswwwnytimescom20190414technologychinasurveil anceartificial intelligenceracialprofilinghtml natalia vasilyeva “russia demands tinder give user data secret services” ap news june httpswwwapnewscom103dc01ce19e48fd89cd32e083ca1e50 steve lohr “facial recognition accurate you’re white guy” new york times february httpswwwnytimescom20180209technologyfacialrecognitionraceartificialintelligence html james vincent “gender racial bias found amazon’s facial recognition technology rekognitionfacialrecognitionbiasracegender troubleshooting ai consent results51 way personal data may used manipulate democratic processes52 controversial environmental53 health54 impacts produced contempo rary data practices55 many commentators privacy researchers tempted leave consent behind means achieving data protection despite social frames expand lens data protection beyond indi vidual individual remains important negotiating terms service acceptable see signs optimism ability ai built better enable individual exercise meaningful control way negotiates dig ital world ai put side individuals help keep better informed ways data used purposes—ai help enable effective meaningful negotiation consent transaction future could ideal move digital consent back toward kind continual coopera tive framework exists ideal versions interpersonal consent transactions contexts none means think onus individual alone—society major role play we’ve shown better establishing fair framework within meaningful consent occur yet interpersonal model consent remains impor tant individuals society whole effectively negotiate acceptable terms jackie snow “bias already exists search engine results it’s going get worse” mit technology review february httpswwwtechnologyreviewcoms610275meetthe womanwhosearchesoutsearchenginesbiasagainstwomenandminorities claire cain miller upshotwhenalgorithmsdiscriminatehtml sean illing “cambridge analytica shady data firm might key trumprussia link explained” vox april httpswwwvoxcompolicyandpolitics2017101615657512 cambridgeanalyticafacebookalexandernixchristopherwylie alex hern “cambridge analytica scandal ‘highlights need ai regulation’” guardian april httpswwwtheguardian comtechnology2018apr16cambridgeanalyticascandalhighlightsneedforairegulation berit anderson “the rise weaponized ai propaganda machine” medium february https mediumcomjoinscouttheriseoftheweaponizedaipropagandamachine86dac61668b stephan schmidt “the dark side cloud computing soaring carbon emissions” guardian april httpswwwtheguardiancomenvironment2010apr30cloud computingcarbonemissions daniel shane “bitcoin boom may disaster environment” cnn december httpsmoneycnncom20171207technologybitcoinenergy environmentindexhtml perri klass “is ‘digital addiction’ real threat kids” new york times may https wwwnytimescom20190520wellfamilyisdigitaladdictionarealthreattokidshtml joseph archer “children stare screen seven hours day different brain structures” telegraph december httpswwwtelegraphcouktechnology20181210 sevenhoursscreentimedaychangesstructurechildsbrainscientists findings claims without critics see eg jesse walker “when get scared ‘screen time’” reason june httpsreasoncom20190525whendidwegetso scaredofscreentime grace dobush “why parents shouldn’t worry kid’s screen time” fortune january httpfortunecom20190104parentschildrenscreentime diego zuluaga “why bitcoin environmental catastrophe” cato institute september httpswwwcatoorgblogwhybitcoinnotenvironmentalcatastrophe robert sharratt “the reports bitcoin environmental damage garbage” medium january httpsmediumcom coinmonksthereportsofbitcoinenvironmentaldamagearegarbage5a93d32c2d7 meg leta jones elizabeth edenberg use data clarity moral core consent offer specific guidance show current systems notice choice based “consent” fail live moral justifiable standards along specificity failures current prac tices comes tools demanding better ai poses additional challenges existing practices consent also offer new tools progress clear standing normative role moral transformative consent use ai’s new capabilities build ai systems enable meaningful consent individuals broader social structure ensures fair treatment groups another model thus far discussing moral core consent drawing interper sonal models consent moral philosophy offers important guidelines determining legitimacy consent think still offers useful paths forward building meaningful consent ai systems yet challenges posed limited exit options broader structural injustices creep current uses ai sug gest also take broader view suggest giving consent rather turn instead another area philosophical approaches consent influential—political philosophy one problems we’ve outlined without viable alternatives may mine individual’s reasonable ability opt “consenting” may lack moral force fortunately political philosophy may offer useful models progress political philosophers frequently relied models related consent secure legitimacy government authority including hypothetical consent56 normative consent57 rawls’s liberal principle legitimacy58 models purport authorize broad range actions government legitimately pursue without relying infea sible option live beyond structure state59 consent political philosophy notable differences interpersonal model consent understood much literature consent drawn moral philosophy rather envisioning ideal consent situation two parties roughly symmetrical situated political philosophers ask could make authority government legitimate individuals subject form see eg classic social contract theorists like hobbes locke kant well john rawls’s original position john rawls theory justice cambridge harvard university press david estlund democratic authority philosophical framework princeton princeton university press john rawls political liberalism expanded edition new york columbia university press notable exceptions philosophical anarchists like john simmons robert paul wolff deny possibility legitimate authority john simmons “philosophical anarchism” justification legitimacy essays rights obligations cambridge cambridge university press robert paul wolff defense anarchism berkeley university california press troubleshooting ai consent collective authority notable parallels situation individuals digital infrastructure underlies many engagements social work members political community asymmetrical power one individual platforms form basic structure digital lives furthermore individual rights interests still important rights best secured collective governance structure built secure rights al philosophers ask example could hypothetical consent fairly situated free equal persons thought experiment assume free equal hold symmetrical power existing world rather ask ing people situated fair context would agree governance struc ture better identify paths move us existing world characterized structural injustices towards ideal society likewise similar thought experiment could help structure societies discussions would like struc ture rights interests digital sphere provide us guideline rights think important protect collective body carving fair structures individuals negotiate individual preferences within broader context conclusion digital consent criticized meaningless procedural act users encounter many different long complicated terms service help effectively assess potential harms threats ai systems played role exacerbating existing issues creating new challenges presenting alternative solutions critiques cures broken arrangement address choicemaking consent united states debates whether break big tech european union considers enforcement actions general data protection regulation update laws address tracking techniques new aidriven smart world consent cannot confused choice consent must defined moral core involving clear background conditions defined scope knowledge voluntariness fairness consent meets demands remains powerful tool contributing meaningful data protection individual societal levels bibliography bostrom nick superintel igence paths dangers strategie oxford oxford university press bridges khiara poverty privacy rights stanford ca stanford university press broussard meredith artificial unintel igence computers misunderstand world cambridge mit press meg leta jones elizabeth edenberg browne simone dark matters surveil ance blackness durham nc duke university press ferguson andrew guthrie rise big data policing surveil ance race future law enforcement new york nyu press kim nancy consentability consent limits cambridge cambridge university press miller franklin g alan wertheimer ethics consent theory practice new york oxford university press müller andreas peter schaber eds routledge handbook ethics consent london routledge pasquale frank black box society cambridge harvard university press rule james b privacy peril sacrificing fundamental right exchange security convenience oxford oxford university press chapter human judgment necessary artificial intel igence algorithmic governance law norman w spaulding artificial intelligence empty signifier ubiquity term used paired deep ambiguity1 notice begin way two words represent ing concept function relation especial contemporary usage hierarchical arranged normative futuristic attributes loaded comprehensiveness imagined one time lie beyond reach ominously al uringly within reach since least alan turing’s ai “test” set framework judging “thinking” machines supposed do2 intelligence scendence artificiality less artificial smart machine appears smarter presumed point turing test deception defines it— determine whether machine relies symbolic system algorithmic syntax trick us believing “actual thinking” virtue way uses natural language basic symbolic system trick works supposedly presence artificial intelligence see jonathan culler ferdinand de saussure rev ed ithaca ny cornell university press –see ed finn algorithms want imagination age computing cambridge mit press robert epstein gary roberts grace beber eds parsing turing test philosophical methodological issues quest thinking computer new york springer science business james h moor ed turing test elusive standard artificial intel igence boston kluwer academic publishers norman w spaulding yet fact mimesis deception ai rights function important reminder artificial concept way know machine “thinking” use language deceive us seduce us empty signi fiers obviously aren’t measuring confirming machine intelligence directly even humans trick betray even process attempt ing make understood speech deception remind us artificiality symbolic systems chief among natural language symbolic systems invite us act abstractions real providing unmediated access represent jacques lacan described seminar edgar allen poe’s story purloined letter “the signifier unique unit nature symbol absence”—an absence ceaselessly trying fil code3 poe’s story one locate queen’s letter despite increasingly invasive comprehensive police searches minister’s hotel room way “the signifier’s displacement determines subject’s acts destiny refusals blindnesses success fate ”this less true lacan reminds us aware deception outset “were pursue bit sense hoodwinked might soon begin wonder whether—from inau gural scene descent ridicule seems await minister sto ry’s conclusion—it indeed fact everyone duped gives us pleasure here”turing’s point course can’t measure directly—“intelligence” empty signifier despite different cognitive operations take granted falling within domain much lacan reminds us police charged searching queen’s letter poe’s short story—a letter know minister stolen keeps hotel chamber—meticulously divide cham ber comprehensive grid “an exhaustion space” miss letter hiding plain sight division entire surface numbered “compartments” principle governing operation presented us accurate “the fiftieth part line” said could escape probing investiga tors spared none details concerning procedures used searching space subjected investigation division space volumes slightest bulk cannot escape detection needles probing soft cushions given cannot simply sound hard wood cavities examination microscope detect gimletdust jacques lacan “seminar ‘the purloined letter’ ” écrits trans bruce fink new york ww norton co lacan’s interest cybernetics code see lydia h liu “the cybernetic unconscious rethinking lacan poe french theory” critical inquiry –lacan “seminar” id emphasis added human judgment necessary holes drilled even slightest gaping joints naught police’s “immutable notion reality imbecility realist”—the assumption one know thing via “search” tightening find queen’s letter confidently assuming systematical measuring contents room letter missed fact that—letter hand—what “turning fingers fit description given it”with information “network tightened point satisfied shaking pages books police take counting them” lacan asks “don’t see space shed leaves like letter”space bending abstractions symbolic exuberant engineers venture capitalists driving development ai haven’t focused humbling lesson turing’s test police searching purloined letter appreciate cipher allows letter remain right eyes yet invisible busy polishing high gloss terry winograd decades ago called “the glistening simulacrum” ai10 capacity fool best human user become pervasive empirical normative metric automated systems ai runs11 true language recognition systems chatbots programs ai deployed internet things ai “ful y” automated machines selfdriving car least competent safe human driver robot health assistant compassionate medi cal professional enough trusted patient etc call ai real time lethal inthefield judgments comport standards international id –id id id terry winograd “thinking machines we” foundations artificial intel igence sourcebook ed derek partridge yorick wilks cambridge cambridge university press description “computationalist evangelism” see also finn algorithms want –see david j gunkel machine question critical perspectives ai robots ethics autonomy responsibility military robots” ethics information technology learning decisionmaking metaphorical characterize envisioned robotic systems abilities comparable familiar human abilities use metaphorical concepts may suggest notion increasingly autonomous robots requires little explanation beyond referring corresponding human capacities” thomas arnold matthias scheutz “against moral turing test accountable design moral reasoning autonomous systems” ethics information technology –norman w spaulding humanitarian law broader standard ethical conduct12 even used dupe experts like pilots believing flying different airplane13 uses ai first word term general loses must lose seman tic content induced misjudge forget machine intelligence artificial instances conflate intelligence human capacities empathy kindness solicitude forbearance humor etc others concede superhu man remarkable achievements already market remarkable debate moral agency supposed moral patiency “thinking” machines—whether appropriate consider “mere” machines instead beings owe moral duties14 pose question ask whether remain “artificial” simultaneously lacan others would remind us reify concept human identity authentical natural cybernetic15 discourse patiency addressed kind benevolent parental anxiety investment “intelligence” machines even acute anxieties autonomy cognitive superiority travels machine learning lurk pro foundly vexed discourse “enslavement” concern patiency robot domination even parricide advocates enslavement insist long machines remain artificial properly coded submissiveness intelligence see eg john p sullins “robowarfare robots ethical humans battlefield” ethics information technology –danton char et al journal medicine elizabeth e joh “private security robots artificial intelligence deadly force” uc davis law review –mark geistfeld “a roadmap autonomous vehicles state tort liability automobile insurance federal safety regulation” california law review –see also dafni lima “could ai agents held criminal liable artificial intelligence challenges criminal law” south carolina law review –margot kaminski “authorship disrupted ai authors copyright first amendment law” uc davis law review –this apparently one element failure boeing max airplane design flight characteristics fundamental different earlier 737s repositioning larger engines wing one purpose sophisticated software runs make plane “fly” isn’t true pilots spend hundreds hours flying plane without learning would behave software fail carlos e perez “ai safety leaking abstractions boeing’s max ” medium march httpsmediumcomintuitionmachineaisafetyleakingabstractions andboeings737max85d4b3b9bf0c3 see gunkel machine question –joanna j bryson “patiency virtue design intelligent systems systems ethics” ethics information technology –f patrick hubbard “do androids dream personhood intelligent artifacts” temple law review –lawrence b solum “legal personhood artificial intelligences” north carolina law review –see donna j harraway “a cyborg manifesto science technology socialistfeminism late twentieth century” simians cyborgs women reinvention nature new york routledge –see also hubert l dreyfus “why heideggerian ai failed fixing would require making heideggerian” skil ful coping essays phenomenology everyday perception action ed mark wrathall oxford oxford university press –is human judgment necessary otherwise optimized serve needs16 asimov’s three laws robotics already transgressed technological important advances ai field autonomous weapons systems socalled “killer robots”thus question coding servility longer whether people die hands robots wil consequential forms judgment human life reduced algorithmic procedure vested autonomous adaptive machines—and battlefield ai enables “predictive policing” datadriven healthcare diagnostics robotic surgery automated transportation18 already last decade living world algorithms adjudicate consequential deci sions lives algorithms driven vast troves data new power brokers society algorithms already control money market funds stocks retirement accounts they’ll soon decide talk phone cal control music reaches radio decide chances getting lifesaving organ transplant millions people algorithms make perhaps largest decision life choosing spouse conclusions led number commentators argue entering era widespread algorithmic governance19 eyes believe coding servility responsibility judg ments assigned human “masters” whether designers users perhaps gunkel machine question armin krishnan kil er robots legality ethicality autonomous weapons new york routledge asimov’s laws “ ‘a robot may injure human inaction allow human come harm robot must obey orders given human beings except orders would conflict first law robot must protect existence long protection conflict first second laws’ ” gunkel machine question see elizabeth e joh “automated policing” ohio state journal criminal law –marianoflorentino cuél ar “cyberdelegation administrative state” administrative law inside essays themes work jerry l mashaw ed nicholas r parillo boston college law review –jack beard “autonomous weapons human responsibilities” georgetown journal international law –for real question servility machines human enslavement mark coeckelbergh “the tragedy master automation vulnerability distance” ethics information technology –emma rooksby “how responsible slave managing use expert information systems” ethics information technology –describing problem “epistemic enslavement” human agent “relying expert information system guide her” losing “her status autonomous moral person” reliance “prevents performing acts constitutive moral reasoning” rob kitchin “thinking critical researching algorithms” information communication society emphasis added internal quotations deleted finn algorithms want “the age algorithm dominated figure algorithm ontological structure understanding universe” ibid –describing deepening dependence “computational systems” norman w spaulding better yet liquidated machine’s asserted superiority human judgment20 latter view errors losses occur including loss life least smaller number would resulted humans still calling shots fantasy servility intelligence combined without creating pathological depen dencies master21 terror masked audacity degraded metaphor slavery deployed yet signs emptiness ambivalent desire fixation invested signifier ai preceding structural linguistic observations oscil atory nature term rise algorithmic governance still seem distant question judg ment going back least far immanuel kant judgment theorized capacity combine synthesize subject predicate—that log ical express connections concepts abstractions connect experience judge view build symbolic system wayne martin writes kant together objectively universal human beings liability death”so express judgment kant’s sense term saying “socrates wise”the verb “is” functions “judgmentmaking copula”kant’s theory judgment thus turns principal “the synthesis sensory content concept”kant contended synthesizing properties predicative judgment formed determinate cognitive process capacity bridge gap representa tion noumenal world lacan symbolic system “order” language bridge gap expresses moreover subject lacan formed acquisition language symbolic order defined errant “leaky” abstraction real26 enough hope said suggest following propositions judgment artificial intelligence ai exists like signifier identifying ai requires predicative judgments—synthetic combinatorial judgments unifying qualities constitute means artificially intelli gent b judgments descriptive sense combining specific cf john danaher “robots law retribution gap” ethics information technology –gunkel machine question –see rooksby “how responsible slave” wayne martin theories judgment psychology logic phenomenology cambridge cambridge university press id id id elaboration kant’s theory judgment see barry stroud “judgement selfconsciousness idealism” seeing knowing understanding philosophical essays oxford oxford university press –john haugeland “the nature plausibility cognitivism” thought essays metaphysics mind cambridge harvard university press –joel spolsky “the law leaky abstractions” nov httpswwwjoelonsoftware com20021111thelawofleakyabstractions “all nontrivial abstractions degree leaky abstractions fail sometimes little sometimes lot there’s leakage abstractions real simplify lives much meant to” inevitable “gap” sensory content algorithmic concepts models see finn algorithms want human judgment necessary attributes associated artificiality intelligence sum conjunction interaction attributes normative value laden running directly perhaps altering concept means human c judgments challenging make technological indeterminacy protean nature machine learning involved dominant elements concept ai changed conjunction big data neural networks twentyfirst century judgments also vexed ambivalent desires animating concept hence combination evangelical exuberance terror saving lives taking il usion realism fetishism “disruptive innovation” follows want explore aspects relationship ai judgment holding difficulty defining firmly mind27 stake predicative judgment concept ai conceit according pur port judge performance ai stake contend form function human judgment first human judgment occurs ai sense judgment must exercised coding ai consequential forms judgment suppressed tacitly embedded formal rigor algorithmic syntax28 second whether conclude systems running ai “make” judgments deep sense opposed concluding systems less reflexively “proc ess” inputs according algorithmic syntax doubt human judgment displaced ai—machines increasingly perform functions previously required exercise human judgment displacement human judgment key attribute market driving ai innovation much influences even alternatives designed enhance human judgment29 third internal actions taken promising important forms ai currently use currently enig matic support human judgment raising questions transparency supervision accountability deception30 fourth certain domains perhaps especial law legal scholars general concentrated relationship artificial intelligence specific doctrines areas law legal principles see eg emily berman “a government law machines” boston university law review –ryan calo “artificial intelligence policy primer roadmap” uc davis law review –andrea roth “trial machine” georgetown law journal –others begun assess implications artificial intelligence exercise formal legal judgment see eg frank pasquale “a rule persons machines limits legal automation” george washington law review –eugene volokh “chief justice robots” duke law journal –less attention paid forms judgment embedded design artificial intelligence broader relationship artificial intelligence human judgment see eg virginia eubank automating inequality hightech tools profile police punish poor new york st martin’s press –calo “artificial intelligence policy” danielle citron “technological due process” washington university law review –see eg cuél ar “cyberdelegation” –seth katsuya endo “technological opacity procedural injustice” boston college law review –see eg cuél ar “cyberdelegation” –david lehr paul ohm “playing data legal scholars learn machine learning” uc davis law review –joshua kroll et al “accountable algorithms” university pennsylvania law review automated predictions” washington law review –norman w spaulding human judgment appears altered dependence ai way affects epistemological terrain human judgment occurs close inquiring notwithstanding limitations ai systems anything nature either judgment liberal democratic governance requires humans exercise use judgments resistance law show free society conditions human judgment must preserved algorithmic judgment algorithms embody wide range judgments level design fre quently characterized pure product forms rationalist exactitude define code symbolic system rob kitchin puts point bluntly algorithmic “processes translation often portrayed technical benign commonsensical algorithms mostly presented computer scientists technology companies ‘purely formal beings reason’ ”presentation parallels processes coding taught “in computer science texts focus centered design algorithm determine efficiency prove optimality purely technical perspective”algorithms characterized “understood ‘to strictly rational concerns marrying certainties mathematics objectivity technology’ ”this framing however effective producing technical proficient coders suppresses respects “ ‘code purely abstract mathe matical’ ” extent “has significant social political aesthetic dimensions” arising range constraints34 include judgments characterize relevant task “translating task problem structured formula appropriate rule set” “translating pseudocode source code compiled perform task solve problem” deal time resource constraints design execution project “the choice quality training data” deal “requirements relating standards protocols law” manage “conditionalities related hardware platforms bandwidth languages”kitchin “thinking critical y” id id id id –is human judgment necessary thus “if xthen y” boolean logic algorithmic syntax function context series judgments remarkable complexity36 “in reality great deal expertise judgment choice constraints exercised producing algorithms”algorithms also “created purposes often far neutral create value capital nudge behavior structure preferences certain way iden tify sort classify people seduce coerce discipline regulate control”they “profoundly performative” “construct implement regimes power knowledge”kraemer van overveld peterson offer concrete example way value judg ments embedded within algorithms used medical imaging technologies40 technologies generate representations “human biological structures computers accurate way” order “improve diagnostic therapeutic prospects diseases affecting biological structures question”because “for practical means virtual impossible total eliminate risk getting false positives false negatives”—because gap symbolic systems purport represent—software designers “have make tradeoff minimizing number false positives number false negative results tradeoff wil inevitably based valuejudgment whether desirable avoid” one results “may give rise severe negative effects individual patients”the authors show mrscans depicting cross section human heart used diagnose “a variety possible pathologies” require algorithms accurately estimate blood volume heart various stages heartbeat cycle difference blood heart muscle tissues occurs difference grey values mr images43 process called “segmentation” algorithm estimates blood volume applying numerical “threshold” separate labeled “light” labeled priori correct value thresholds” “noise image inevitable artifact mr measuring process caused numerous nonmodeled sources”the choice threshold “affect values” software’s depiction esti mated blood volume “and eventual diagnosis”in clearcut cases choice threshold matter “grey zone” healthy pathological cases “diagnostic outcome critical depend threshold”and get ting around setting threshold threshold favoring false positives reduce error eg “the relevant task ” “the relevant data ” “the relevant contingencies ” “x ” kitchin “thinking critical y” id –id felicitas kraemer kees van overveld martin peterson “is ethics algorithms” ethics information technology –id id –id id id emphasis added id id norman w spaulding “believing someone fact ill healthy”it therefore comports precautionary principle49 could lead “too many unnecessary potential dangerous operations” order scientific research scientists “general agree important avoid false positives false negatives”the key threshold reflect judgment whether circumstances better favor false positives false negatives—a judgment straddles structural tension doctor’s duty care current patients imperatives advancing medical research develop new treatments future patients authors report setting thresholds software engineers “typical choose value ‘seems reasonable’ ”expert users imaging part may direct awareness thresholds indeed purpose complex algorithms present medical experts field data “as actual photo 3d internal organ tissue structure”it accordingly “very difficult interpret realistical looking 3d image trustworthy projection 3d object intro duces risk one forget order generate 3d images number decisions thresholds taken”value judgments thus inevi table necessarily recognized designers transparently commu nicated even expert users54 true even ai system whose purpose amplify transparency object professional judgment applied55 designer user instead lured rationalist exactitude miss judgments even embedded code downstream diagnostic therapeutic judgments value judgments like purloined letter sit hiding plain sight less commonly noticed feature threshold setting ai systems displace legal judgment general encode determinate version relevant id id id id id id id others contend ai systems designed promote transparency appropriate regulatory oversight amy merrick “how making algorithms transparent promote equity” chicago booth review april httpreviewchicagoboothedueconomics2019article howmakingalgorithmstransparentcanpromoteequity describing research arguing “with right regulations place algorithms could transparent human cognition certain elements algorithmic decisionmaking—such inputs used make predictions outcomes algorithms designed estimate—are inherently explicit” “threshold” setting problems pervasive search technologies adopted professionals machine learning algorithms thirdparty vendors selling lawyers conduct discovery massive digital files locate potential relevant evidence response subpoenas production requests depend initial thresholds set training small portion see infra note also found ful autonomous systems threshold confidence distinguishing civilians enemy combatants prior targeting mark swiatek “intending err ethical challenge lethal autonomous systems” ethics information technology –noise cannot ful eliminated least deception combatants disguise civilians situational indeterminacy civilians may wear clothing innocently behave ways nevertheless “code” hostile decision acceptable levels col ateral damage requires value judgments see amanda sharkey “autonomous weapons systems killer robots human dignity” ethics information technology human judgment necessary substantive procedural law56 much follows one hand conjunction coding cost design constraints need identify effi ciently codable characterization relevant law marketing constraints hand market tax preparation software product laypersons money pay tax expert buy keep code adequately cost effective design product seek minimize risk audited57 market soft ware helps architects contractors file design plans product needs ensure prompt approval city planning commissions avoid revisions58 market publicly distribute online legal document preparation services structure questions user fil designed ensure enforceability contract wil articles incorporation marital dissolution papers without litigation short structural pressure code law conservatively publicly subsidized systems face even tighter constraints since court systems internalize costs litigation documents challenged first glance conservatism may seem optimal means ai systems default toward compliance law democratic society particularly one defined deep value pluralism suspicion centralized state authority profound income inequality legal indeterminacy conservative coding amplifies compliance without identifying value judgments underlying outcome micro level conservative coding fails account variation individual risk tolerance eg users might things considered prefer aggressive legal position expert could assure safe challenge least safe protracted litigation challenged macro level channeling users reflexive compliance likely diminishes sist ance law—a practice free societies treat natural right recognized certain sub stantive procedural aspects positive law costs weighed benefits far wider access legal services far greater efficiency areas law require mass processing claims point present purposes cf berman “a government laws” –citron “technological due process” –since intuit’s product turbotax offered access “audit risk meter” pay premium services terry savage “new turbotax helps fly irs radar” street february green red ends risk spectrum ostensibly provide information risk exposure audit user would need know make informed decision aggressive whether position could trigger audit likely upheld design perspective “meter” likely induce people take conservative tax positions filings httpswwwthestreetcomstory104026831newturbotax helpsyouflyunderirsradarhtml software designers lobbied prevent irs state tax agencies providing free online tax filing services also used “dark patterns” products bait consumers entitled free taxfiling services paying fee justin elliott lucas waldron “here’s turbotax tricked paying file taxes” propublica april httpswwwpropublicaorgarticleturbotaxjusttrickedyouinto payingtofileyourtaxes see michael kilkel “building code review software feasible farfetched” architect feasibleorfarfetchedo norman w spaulding coding invariably requires judgments extend beyond purely technical decisions go software design displacement human judgment displacement human judgment ai systems already suggested imaging legal document preparation examples even obviously displaced automated systems selfdriving cars autonomous weapons systems principal design objective delegate comprehensive set complex tasks tradi tional requiring exercise human judgment autonomous adaptive action executing machines human “driver” “selfdriving” car exception high order controls eg setting altering destination human users mere passengers relieved burdens decision accompany driving assumption embedded laws war “decisions whether kill made humans rapidly becoming naïve”decisions target whether deploy force appropriate level force increasingly “determined machine’s software software command computer remote loca tion actions direct control human operator”in domain law autonomous machine decisionmaking transforming adjudication61 technologies range automated compliance monitoring soft ware reports breaches contracts chatbots natural language inter faces automatical fill instances file legal documents range automated dispute resolution systems eg online “blind bidding” reconcile competing confidential settlement offers automated negotiation software using ai calculate dis pute resolution outcomes maximize preferences sides customized automated systems designed resolve customer customer customer corpo ration disputes62 boolean search algorithms already transformed legal research software designed create legal documents operates pervasively settings side formal adjudication traditional required exercise professional judg ment indeed currently far larger market automation drafting legal instruments contracts wil articles incorporation online dispute resolution sullins “robowarfare” id see cuél ar “cyberdelegation” –cary coglianese david lehr “regulating robot administrative decision making machinelearning era” georgetown law journal –gerald k ray jeffrey lubbers “a government success story data analysis social security appeals council push administrative conference united states transforming social security disability adjudication” george washington law review see thompson reuters impact online dispute resolution technology dispute resolution uk spring –is human judgment necessary technologies requires complex design judgments legal issues nature legal salient performative utterances constitutes legal compe tent fact investigation assessment constitutes compliance noncompliance law terms contract body substantive procedural law applies relevant social action whether default legal rules legitimately set aside contract threshold legal certainty apply forth significantly present purposes although many software programmers field work closely legal experts address issues design phase cases pro grammers agents court systems indeed matter principle believe legal experts dysfunctional rentseeking experts impediment access justice63 model use ai general predi cated eliminating cost delay error biases associated rely human judgment legal experts performance legal tasks much uber seeks replace cab drivers dispatchers fundamental disrupt entire segment public transportation industry automated weapons systems least theory operate within chain command requires level supervi sion military experts design use whole point online chatbot generates legal documents person use supervision required use form lawyer would paid judgment expertise64 even outside domain ful automated autonomous systems biometric sur veil ance identification access security systems operating algorithms displace human judgments would involved posting guard selectively distribut ing keys key cards passports similar instruments avi marciano reports “bio metric technologies increasingly involved automatic decisionmaking little human intervention”job applicants gig economy face wide range automated systems operate sorting tools performing functions recruiters human resource departments used include algorithms scan cvs keywords predicate referred considered directly employer well evolving series automated quizzes psychometric tests games chatbots reject applicants human ever glances cv hirevue screening product reportedly used goldman sachs unilever places candidates front camera answer interview questions software “like team hawk eyed psychologists hiding behind mirror takes note barely perceptible changes see victor li “joshua browder ‘chat’ talk” legal rebels september httpwwwabajournalcomlegalrebelsarticlejoshuabrowderdonotpaylegalchatbot criticism legal profession’s systemic failure meet needs low middleincome people ungrounded see deborah l rhode access justice oxford oxford university press cf john markoff “the end lawyers fast” new york times january avi marciano “reframing biometric surveil ance means inspection form control” ethics information technology –norman w spaulding posture facial expression vocal tone”the answers broken “ ‘many thousands data points’ ” data reduced score “which compared one program already ‘learned’ top performing employees”an ultimate hiring decision made human live interviews thousands sorting decisions along way algorithmical determined executed predictive policing systems “map” crime analogized derive sense nondigital investigative techniques cartographic “georeferencing” analytic power derives capacity sophisticated software programs rapidly identify “hot spots” “measure level social cohesion” different cities create techniques instantaneously synthesizing visual representing dis parate data sets eg crime location identity owners specific buildings across neighborhoods support decisions patrols investigation enforcement68 final technology assisted review form “predictive coding” uses machine learning “harness human judgments one expert law yers smaller set documents extrapolate judgments remaining document collection”the machine learning used “emulate” lawyer’s decisionmaking process potential legal relevance individ ual files would applied massive caches documents janusfaced technology one hand examples appears enhance human judgment distilling relevant documents rapidly respects comprehensively lawyers reading hand eliminated forms document review work performed law yers cost savings complex cases lawyer group lawyers personal reviewed anything approaching majority files epistemological framework lawyers’ understanding facts cases technology assisted review occurs thus algorithmical determined training machine look keywords patterns keywords quickly surface revealing patterns documents obvious probable relevance missing files euphe mistic paraphrastic ironic sardonic evasive use language files affirm deny keyword represents may slip network like purloined letter70 ciphers slips unexpected new facts connected existing unexpected stephen buranyi “how persuade robot get job” observer march httpswwwtheguardiancomtechnology2018mar04robotsscreencandidatesforjobs artificialintelligence id gemma galdon clavel “exploring ethical organizational technological challenges crime mapping critical approach urban safety technologies” ethics information technology –paul burns mindy morton “technologyassisted review judicial pioneers” sedona conference march courts approved use tar see da silva moore v publicis group msl grp frd sdny technical barriers area see knight “ai’s language problem” mit technology review august httpswwwtechnologyreviewcoms602094aislanguageproblem headway made respect hyperbole form speech quantifiable human judgment necessary new legal claims well semantic content discernable grasp methods thus create different field legal judgment—one downstream judgments concerning legal significance relevant facts depend algo rithmic determination constitutes relevant fact72 ai thus capable partial widening array circumstances completely displacing postdesign human judgment swapping algorithmic analysis machine learning tasks used require human judgment lay expert dis placement occurs largely irrespective whether processing machine complete tasks bears resemblance form human judgment exercised instances especial neural networks used way ai systems reach conclusions fact deeply enigmatic—the core features system “black boxes” cannot reverseengineered even designers build them73 gets assessed instead whether observable outcomes compa rable better observable outcomes resulting human judgment respects know suggests many ai systems process information differently human judgment74 first ai systems search internalize vast amounts data apply bayesian probability recognize certain patterns execute actions forth dramatical higher speeds humans creates capacities respect least certain tasks involving decision far exceed human performance— weapons target fire hundreds targets seconds facial recognition technology stores rapidly analyzes millions images faces algorithmic highfrequency trading techniques identifying trading signals splitting numbers used exaggerate see justin kao et al “nonliteral understanding number words” pnas –winograd “thinking machines” least area law forget technology print capitalism regularly introduced alterations epistemological field obviously true respect relevant law ascertained eighteenthcentury treatises principal source legal knowledge portability synthesis cases—most lawyers could afford large libraries angela fernandez markus dubber law books action essays anglo american treatise oxford hart publishing ltd development law magazines case reporters bound volumes reproducing lawyer’s accounts judicial decisions provided broader dissemination precedent keyword indexing invention refined late nineteenth century permitted lawyers relatively immediate access far precedent see david clark tugrul ansay introduction law united states norwell kluwer law international –this diminished role treatises time raised questions many cases lawyer would need read cite “authoritative” understanding law given point alterations “modes thought” associated shifts technologies communication see finn algorithms want example us ai image recognition see carter “exploring neural networks activation atlases” google ai blog march httpsaigoogleblogcom201903 exploringneuralnetworkshtml see also kroll et al “accountable algorithms” –citron pasquale “the scored society” ––cf andrew selbst solon barocas “the intuitive appeal explainable machines” fordham law review ––see selbst barocas “the intuitive appeal explainable machines” –norman w spaulding scheduling executing trade orders microseconds legal search tools instantaneously locate sort present cases use specific key terms databases containing millions published unpublished court decisions chatbots instantly give millions people cannot afford lawyer conduct legal research ability fill form asserts legal right second human judgment displaced sense concentrated upstream embedded suppressed process coding systems displaced point usage—the point task performance ordinary humans interact machines experience consequences design tasks traditional required exercise human judgment creates new domains decision vastness fields superhuman scale speed auto mated autonomous action within induce awe excessive deference— excessive deference subtly extend beyond dimensions machines known superior deference course euphemism displaced judgment form dis placement may may create problems designers decide defer75 users regulators general public defer socalled “responsibility gap” widens76 processes run appear perspective outcomes work like human judgment better sufficiently catastrophic failure surfaces one may appreciate vulnerabilities attendant displacement human judgment involved “reason” system acted way may discoverable circumstances use may make difficult identify legal moral responsible human77 systems risk catastrophic failure either low information costs associated identifying high say software online resolution small claims disputes involving low money value complaints fact investigation rarely ever searching relevant vulnerabilities may remain total undetected third fundamental sense find governed ai technology assisted review example suggests ai alters subtle important deference feature every expert system human artificial experts work agents behalf principal order agency function principal must accept need agent grounded expertise formal agentic relationships vulnerability authority principal legal recognized requirement reciprocal deference agent must consult principal respect core objectives outset rolling basis reason believe changed circumstances would change principal’s objectives accept principal’s judgment regarding objectives strictly avoid conflicts interest faithful serve principal capacity ful autonomous machines running ai exhibit deference terms precisely know easy judge moral costs finding see john danner “robots law retribution gap” ethics information technology –gunkel machine question see mauricio paez kerianne tobitsch “the industrial internet things risks liabilities emerging legal issues” new york law school law review –david c vladeck human judgment necessary ways epistemological field human judgment occurs consider instance retrospectivity big data sets power significant recent inno vations ai like psychographic profiling technology builds profile individual voters consumers possible security threats past observable choices supposed doppelgängers generate probabilistic assessment future actions likely response future stimuli marx insisted constraining effects tradition wrote “men make history make please make selfselected circumstances circum stances already existing given transmitted past”the famous line follows underscores claim “the tradition dead generations weighs like night mare brains living”even revolutionary movements give rise new legal orders “anxiously conjure spirits past service order present new scene world history timehonored disguise borrowed language”predictive analytics ostensibly liberate us biases errors repe tition automatism local knowledge tradition intuition liberation future heavily determined rational calculated abstractions aggregated observ able data past choices retrospective datacentric determinism found numbing monotony recommendation software running music video entertainment social media news feed platforms81 ominously found use psychographic pro filing “nudge” purchasing habits consumers precisely calibrated stimuli82 monopolization attention “smart” devices provide apps manage problem addiction apps83 experience uber drivers run ragged mélange gaming incentives drill sergeant behaviorism karl marx eighteenth brumaire louis bonaparte new york cosimo inc id id see le wu et al “relevance meets coverage unified framework generate diversified recommendations” acm trans intell sys tech traditional col aborative filtering models “are successful providing accurate recommendations match user’s dominant interests however recommendation setlist may monotonous hard cover user’s interests” search algorithms also produce results confuse offend users matters profound consequence see finn algorithms want describing incident siri directed users asking “where get abortion” “antiabortion crisis pregnancy centers” see joseph f coughlin “the ‘internet things’ take nudge theory far” bigthink whenanudgebecomesanoodge designers revealingly conflate desires users behaviorist projects see finn algorithms want google’s chairman told wall street journal “i actual think people don’t want google answer questions want google tell next” emphasis added nicholas thompson “our minds hijacked phones tristan harris wants rescue them” wired july httpswwwwiredcomstoryourmindshavebeenhijackedby ourphonestristanharriswantstorescuethem role big tech coopting antiaddiction tools see arielle pardes “quality time brought big tech” wired december httpswwwwiredcomstoryhowbigtechcooptedtimewellspent norman w spaulding algorithms govern work84 reproduction racial biases long tainted policing ostensibly rational technocratic algorithmic models “hot spots”it also seen antidemocratic weaponization psychographic profiling instantaneous dissemination features social media designed influence voting86 historians critical theorists ethicists sociologists displacement human judgment deterioration conditions exercise familiar signal attributes bureaucratic systems louis mumford insisted bureau cratic management human labor original technology largescale production called “megatechnics” deployed first time modern factories sophisticated ancient egyptian labor systems used build pyramids87 reflexive obedience “minute division labor” “undeviating exactitude” central weber’s theory modern bureaucracy famously labeled inexorable expansion rational technocratic styles thought information processing systems control “iron cage”michel foucault called conjunction panoptic surveil ance minute organization separation optimization physical spaces purposebuilt bureau cratic management hospitals military barracks prisons schools factories ensuing control movement bodies within “disciplinary power”people working “panoptical y” arranged spaces obey internalize constraints becoming “docile bodies” instruments “of subjection”see noam scheiber “how uber uses psychological tricks push drivers’ buttons” new york times april httpswwwnytimescominteractive20170402technologyuberdrivers psychologicaltrickshtml ryan calo alex rosenblat “the taking economy uber information power” columbia law review –see clavel “crime mapping” rashida richardson et al “dirty data bad predictions civil rights violations impact police data predictive policing systems justice” nyu law review online –andrew guthrie ferguson “policing predictive policing” washington university law review ––elizabeth e joh “policing numbers big data fourth amendment” washington law review –see jane mayer “new evidence emerges steve bannon cambridge analytica’s role brexit” new yorker november httpswwwnewyorkercomnewsnewsdesknewevidence emergesofstevebannonandcambridgeanalyticasroleinbrexit sue halpern “cambridge analytica perils psychographics” new yorker march httpswwwnewyorker comnewsnewsdeskcambridgeanalyticaandtheperilsofpsychographics louis mumford technics human development myth machine new york harcourt brace id –on talcott parson’s translation key phrase protestant ethic spirit capitalism see arthur mitzman iron cage historical interpretation max weber michel foucault discipline punish birth prison 2d ed trans alan sheridan id produces discipline docility “is universal consciousness law juridical subject regular extension infinitely minute web panoptic techniques” development online surveil ance culture surveil ance capitalism see frank pasquale black box society secret algorithms control money information human judgment necessary bureaucracies function short converting humans machines ruthlessly efficient automatons writing 1990s eve remarkable innovations neural networks big data analytics spurred twentyfirstcentury ai terry winograd observed even ambitious forms ai functional bureaucratic design remarkable “benefits bureaucracy follow reduction judgment systematic application explicitly articulated rules” costs taking algorithmic approach rule formulation administration follow dis placement judgment degradation conditions exercise attend bureaucratic projects94 ai day still functional bureaucratic principal applications last two sections argued way affects human judgment centralizes embeds obscures value judgments design phase downstream usage displaces human judgment even circumstances designed enhance aid human judgment alters epistemological field human judgment deployed ways deteriorate con ditions exercise human judgment generating reflexive obedience base stimuliresponse behavior patterns users95 effects may necessary ai systems arise important respects winograd insisted dependence ai algorithmic syntax96 genuinely enhancing human judgment possible objective ai systems objective winograd thought appropriate future ai pursued vigor bureaucratic applications human judgment necessary much explicitly ethical debate ai concentrates deontological questions whether respect principles individual human dignity requires humans make certain judgments eg decision use lethal force battlefield97 consequentialist questions weigh transformative benefits ai account costs eg lifesaving benefits enhanced medical imaging measured costs human life errors increased lethality winograd “thinking machines” id id see eg andrea roth “machine testimony” yale law journal –andrew guthrie ferguson “predictive prosecution” wake forest law review –“seekers glitter intelligence misguided trying cast base metal computing” winograd “thinking machines” “glitter” evident microsoft ad announcing “living future always dreamed of” one “ai empowering us change world see ” httpswwwyoutubecomwatchv9tucy7jhhs4 see sharkey “autonomous weapons systems” –summarizing scholarship arguing dignitarian interests require act killing “grounded human judgment” norman w spaulding automated weapons systems measured precision potential stricter compliance laws war increased access justice automated legal services provide weighed risk legal error broadly whether ai system “good enough” respects equals excels human performance98 also ethical informed empirical debates whether technical feasible code ethical norms99 question sometimes inverted mobilized normatively epistemological questioning whether humans capable following ethical norms whether know mind fact quin tes sen tial black box100 important fraught debates literature respects polarized authors’ deepseated priors—enthusiastic technological determinists dystopic skeptics take radical different approaches questions101 preceding sections entirely avoided debates skepticism display main purpose set range ways ai judgment interact final section want ask somewhat different question raised ethics literature question follows displace ment deterioration conditions human judgment ai systems begins less skeptical priors cannot muster anything like evangelical enthusi asm ai systems capable simulating enthusiasm level would convince devotees capable skeptic must shifting lens skepticism chilling historical psychological evidence particularly regarding susceptibility bias cruelty devastating violence indicating bad humans making wide range decisions102 view evidence think ask whether human judgment meaningful sense necessary feature human condition case tolerating experimentation delegation ai systems strengthens explore two versions question first whether concept judgment requires nondelegation alternatively whether certain judgments must made humans liberal democratic legal order see sullins “robowarfare” –noting studies showing low performance human soldiers relative ethical standards war evidence humans underperform respect military objectives combat see marlies van de voort wolter pieters luca consoli “refining ethics computermade decisions classification moral mediation ubiquitous machines” ethics information technology –wendell wal ach collin allen moral machines teaching robots right wrong oxford oxford university press see gunkel machine question “humans according joseph nadeau unfortunately rational machines however programmed perfect infallible logical processing rationality basic requirement moral decision making machine could ever considered legitimate moral agent” see finn algorithms want ch describing technological utopians skeptics see veronica juarez ramos analyzing role cognitive bias decisionmaking process uncertainty heuristics biases cambridge cambridge university press dal willard disappearance moral knowledge ed steven l porter aaron preston gregg ten elshof new york taylor francis jonathan glover humanity moral history twentieth century new ct yale university press human judgment necessary outset may helpful enlist turinglike hypothesis imagining supercompetent ai system one reliably outperforms human decision maker every measurable dimension including reduction bias inclination defer therefore high rational grounded fear bad outcomes low assume system performs important task stakes nontrivial significant parties concerned premises clear easy consequentialist deontological objections delegation judgment machines tilt consequentialist’s costbenefit analysis heavily favor ai systems recognition welldocumented limitations human judgment103 likewise reduce salience powerful deontological claims presents different challenges human dignity one unreliable incapable compliance imagining ai system makes important decisions well thus helps isolate question whether anything nature judgment demands exercised humans secondarily inquire thing way nondelegation doctrine legal political structure liberal democratic states answering either version question requires become precise judgment began rather provisional kant’s theory predicative judg ment judgment synthesis concept sensory content ended last sec tion discussion deterioration conditions judgment limit automation reduction brute code responsestimuli reaction “snap judgment”—a form judgment barely worth name104 significantly ai systems underlie predictive analytics search algorithms image recognition natural language software conduct predicative judgments probabilistical hence voracious appetite big data importance generating products infor mation forcing use—the data ai systems work role probability mind reformulate first question predicative judgments “this image contains human” “this consumer likes romantic comedies” “this voter fiscal conservative” “this target enemy combatant” made probabilistic terms—if judgment important respects probabilistic105—is see eg eugene volokh “chief justice robot” –martin theories judgment affect theory poses intriguing challenges criticism snap judgments present purposes note agreement linda zerilli’s thoughtful argument questioning “the stark distinction affect reason characterizes affect theory iterations” linda zerilli democratic theory judgment chicago university chicago press connection probability predicative judgment ai systems accident probability theory deeply imbricated history legal judgment instrumental resolving questions burdens proof weigh evidence well decisionmaking moral theory theology consider pascal’s wager science see james franklin science conjecture evidence probability pascal baltimore md johns hopkins university press ian hacking emergence probability 2d ed cambridge cambridge university press norman w spaulding necessary set judgments made humans given distinct advantage ai systems computing probabilities notice first view judgment judgment principal function ai systems even exact processes inputs converted probabilistical defined outputs remain enigmatic view judgment judgments humans must make hypothesis supercompetent ai system significantly diminishes salience ments genuinely helpful way reliably good better humans even though currently demonstrably counterfactual assumption respect certain tasks106 stil empty set value judgments whether code law con serv tively whether minimize false positives false negatives whether make autonomous weapons systems readily susceptible probabilistic determination107 pluralistic society one would expect design decisions characterization relevant task thresholdsetting turn contested value judgments108 modern lawyers know holmes’s famous dictum law prediction “the object study prediction prediction incidence public force instrumentality courts prophecies courts fact nothing pretentious mean law” ow holmes jr “the path law” harvard law review image recognition software instance still fail astonishingly simple tasks essential use security systems identifying human see simen thys wiebe van ranst toon goedemé “fooling automated surveil ance cameras adversarial patches attack person detection” httpsarxivorgabs190408653 gregory barber “shark baseball inside ‘black box’ neural network” wired march see zerilli democratic theory judgment –cf although term “value judgment” implies decision made turns firmly held beliefs facts better facts sometimes reveal specific option ostensibly dictated one’s values actual inconsistent properly designed ai systems might enhance human valuejudgments expanding access relevant facts cf cuél ar “cyberdelegation” –pluralism might also make important decision system transparent regarding procedures judgments reached addition fact certain value judgments cannot made ai systems nondelegation doctrine also forbid delegation ai systems unduly enigmatic regarding decisions understanding process decision matters see martin theories judgment judge must “the capacity express reasons sway many particular instances judgment may well silent idea whol silent judge ultimately unintelligible” hannah arendt giving reasons constitutive political judgment “the importance taking account standpoints people forming opinion” zerilli democratic theory judgment –this happen procedures transparent inclusive participatory promote reasongiving human judgment necessary preceding sections suggested deterioration conditions human judgment could violate b general difficult judge whether specific delegation ai system would deteriorate conditions exercise judgment violate b least delegation occurs moreover social theories mumford parsons weber foucault admonish deterioration judgment follows general benefits bureaucratic administration means ai systems displace rather enhance human judgment pose incre mental threats work alongside forms “megatechnics” degrade conditions exercise human judgment teasing specific systems affect overall conditions judgment would exceedingly difficult hand know human judgment must preserved required potential c conditions must fact line designating suf ficient deterioration difficult draw therefore militates favor precautionary principle strong precautionary principle would operate something like winograd’s directive design ai systems enhance human judgment rather displace it109 modest one would require ai systems designed minimize dis placement human judgment irrespective whether human judgment actual enhanced weakest would prohibit displacement known fact degrade human judgment eg sorts things cambridge analytica russian government appear us election two additional reasons take b seriously favor precautionary prin ciple first making judgments matters consequence conditions uncer tainty challenging moral emotional work power exercising judgment entails desire attached terror ought serious judge110 temptation delegate outsource judgment—to make someone something else whol responsible choice—is thus real second know level devastation widespread deterioration condi tions judgment cause rise totalitarianism twentieth century hannah arendt’s account become susceptible fascism domination violent mobilization “a structureless mass furious individuals” gradual displacement erosion judgment ending evacuation common sense111 witnessed authoritarian repression holocaust mass atrocities twentyfirstcentury legatees grim spectacle human failure singularly profound design responsibilities third element c requires ask legal first order political obligation decide certain questions via exercise human judgment112 one might see cuél ar “cyberdelegation” –see soren kierkegaard fear trembling ed trans howard v hong edna hong zerilli democratic theory judgment additional prudential considerations vein see meredith whittaker et al ai institute ai report ––see also berman “a government laws” ––norman w spaulding go finding answer comprehensively canvasing us constitution statutes case reporters find laws apply decisionmaking see read require human decision maker first amendment refers rights free speech free press free exercise religion freedom government estab lishment religion read assume protect private con science minimum matters political religious significance read endorsement deliberative democratic theory rights seventh amendment preserves right jury trial civil cases means empaneling jurors robots decide cases right grand petit jury criminal investigation trial due process clauses fifth fourteenth amendments confer right participation state action affecting life liberty property minimum means right notice presumptively ex ante meaningful opportunity heard113 crucial opportunity speak intersubjective—there must someone listens impartial condition listened decides strong presumption favor participation one’s adversary ex parte proceedings occur disfavored attendance observation public114 opportunity heard gen eral includes criminal cases sixth amendment requires right con front witnesses viva voce—in person court sixth amendment also provides right assistance counsel expert trained law represent accused taken together would appear legal judgments must made participation people would affected many rights waivable judgments validity conditions waiver many watered judicial decisions legislative initiatives channel legal judgment less participatory fora course parties combine principles waiver contract doctrine design procedures dispute resolution115 voting core legal right involving exercise judgment less participatory one might think obligation vote right one chooses certainly legal duty exercise judgment voting moreover whether one delegate decision turns vote concerns proxy voting common prac tice corporate governance—shareholders delegate votes others sniadach v family finance corp us see judith resnik dennis curtis representing justice invention controversy rights citystates democratic courtrooms new ct yale university press –of public trial oxford oxford university press “publicity unalloyed benefit administration justice” channeling legal judgment increasingly enclosed spaces see norman w spaulding yale journal law humanities see also spaulding “due process without judicial process antiadversarialism american legal culture” fordham law review human judgment necessary vote shares annual meeting116 even political elections rely delegation instance voters elect president american constitution votes delegated electors supposed faithful numerical results voting state represent examples could considered common law must reflect “last testament” testator— personal judgment proper distribution assets upon death principle nondelegable decision use force armed combat arguably requires human judgment combatants civilians117 tort law writ large sets boundary damnum absque injuria loss without legal cognizable injury part human entities humans create harms humans held answer reading backward one define rule identifies judgments ought taken seriously humans costs failing charged person deemed erred118 similar assignments responsibility judgment failure exercise found substantive criminal law focus culpability deeper sense negli gence penalties serious money damages injunctive relief119 one could go way analysis would il uminating mainly think surfacing judgments law liberal democratic societies requires humans make requires make well ex ante one might tempted conclude requirement nondelegation expressed c fairly narrow supercompetent ai system quickly comprehensively sweep around margins law requires humans decide would think represent grave error reason law liberal democratic states general mandate human judgment precisely promote conditions flourishing one essential condition flourishing human judgment erring comprehensive legal code particularly one moves ex post assessment comprehensive position ex ante prevention risk management seeks eliminate error mini mal code general restricted ex post intervention tolerates error put differently judgments good life behave decentralized liberal democratic legal regimes don’t general learn make sensible judgments lives “y general follows x” “friendship relationship defined trust” “true loyalty requires selfsacrifice” following orders reflexively internal izing predictions others however accurate andrew tutt “choosing representatives proxy voting” columbia law review sidebar see sharkey “autonomous weapons systems” see ryan abbott “the reasonable computer disrupting paradigm tort liability” george washington law review –geistfeld –vladeck –see also jack balkin inconsistency technology incorporated decision making criminal law see roth “trial machine” norman w spaulding erring learning make sound predictions stake free society statement law requires also question whether followed ensues fact free society people sovereign lawgivers “we people ordain establish ” view vague historical abstraction us constitutional law artifact ratification sets liberal democratic legal system foundation popular sovereignty120 authoritarian society contrast sovereignty highly concen trated perspective sovereign properly disciplined sub jects statement law requires open question goal perfect bureaucratic project reflexive obedience free people easily forget distinction power seek make others forget grant proxy sovereign power saying law setting aside name new law familiar fascistic tendencies certain styles populism popular sovereignty operation human question resistance hides plain sight much like purloined letter conjunction human judgment popular sovereignty however aspirational organizing prin ciple liberal democratic governance amount provisional delegation elimi nate letter signed blood revolutionaries matter hidden trace remainder claimed every moment become docile police searching minister’s chamber— become instrument subjection proportion ignore trace remainder less free kind judgment decision obey resist law perspective principle popular sovereignty merely predictive question whether obey law cannot answered exclusively determining probability enforcement severity penalty noncompliance probable exter nalities noncompliance question could answered sort calculation would impossible explain important social legal reforms— transformative changes arising movements violated law despite knowing calculations would completed à la lettre lacan would put bod ies resistant subjects loved ones122 judgments resistance law thus reveal feature judgment yet specified feature oscil ation judge necessity freedom wayne martin describes judge must faithful “bound evidence” resistant—“free decide free arrive see larry kramer people popular constitutionalism judicial review lynching dueling wildcat strikes nineteenth century america” routledge companion law humanities nineteenth century america ed nan goodman simon stern london routledge cf norman w spaulding “paradoxes constitutional faith federalism emancipation original thirteenth amendment” critical analysis law european history conservative effort limit resistance law often relied probability theory see franklin science conjecture see id human judgment necessary one’s decision”this paradoxical combination requires “the capacity sensitive inferential structure authority evidence guided capacity suspend judgment evidence presented”—to determination force power”“hanging free” means “capable self determination determining response evidence representation objects statesofaffairs judging”the limit “hanging free” course setting aside evidence attended disciplined one’s gullibility127 jury practices nullification gandhi march sea british salt act dr martin luther king jr birmingham rosa parks montgomery marchers edmund pettus bridge selma egyptians filled tahrir square whether one wants hold lofty examples mind banal micro sist ances people find compliance intolerable inconvenient otherwise interest128 judgments humans must make virtue judgment understood virtue means live free society ai system designers duty preserve conditions exercise industry delights sist ance law name disruptive innovation owes us less129 suggested readings finn ed algorithms want cambridge mit press gunkel david j machine question critical perspectives ai robots ethics cambridge mit press harraway donna j “a cyborg manifesto science technology socialistfeminism late twentieth century” simians cyborgs women reinvention nature new york routledge martin theories judgment –zerilli democratic theory judgment ––see also kierkegaard fear trembling ––martin id zerilli “for arendt capacity judge reflectively absence concept rule defining feature democratic citizenship” ibid “judging political solicits agreement al cannot compel manner giving proofs” zerilli cf id eduardo penalver sonia k katyal describe range motivations including acquisitiveness history violation certain property laws property outlaws squatters pirates protesters improve law ownership new ct yale university press see ruth berins collier vb dubal christopher carter “disrupting regulation regulating disruption politics uber united states” perspectives politics –paris martineau “inside airbnb’s ‘gueril war’ local governments” wired march httpswwwwiredcomstoryinsideairbnbsguerril awaragainstlocalgovernments jill lepore 0623thedisruptionmachine many innovators believe “that reckless ruthless forget rules obligations conscience loyalty sense commonweal disrupt disrupted” norman w spaulding kitchin rob “thinking critical researching algorithms” information communication society kraemer felicitas kees van overveld martin peterson “is ethics algorithms” ethics information technology –martin wayne theories judgment psychology logic phenomenology cambridge cambridge university press mumford louis technics human development myth machine new york harcourt brace spaulding norman w “the historical consciousness resistant subject” university california irvine law review spolsky joel “the law leaky abstractions” november httpswwwjoelonsoftware com20021111thelawofleakyabstractions winograd terry “thinking machines we” foundations artificial intel igence sourcebook ed derek partridge yorick wilks cambridge cambridge university press zerilli linda democratic theory judgment chicago university chicago press chapter sexuality john danaher introduction early world bore witness first humanrobot marriage zheng jiajia chinese engineer ai expert hadn’t always intended marry robot spent years searching female human partner grew frustrated lack success1 decided put engineering skil test create robotic partner married “her” simple traditional ceremony witnessed mother friends2 jiajia’s robot wasn’t particularly impressive according reports “she” humansized doll limited ability recognize chinese characters speak basic phrases jiajia planned upgrade “her” near future long jiajia’s nuptials akihiko kondo thirtyfiveyearold japanese man living tokyo married hatsune miku holographic virtual reality singer floats inside desktop device3 kondo felt unlucky human love plumped artificial partner kondo wanted recognized member sexual minority people interested human lovers neither jiajia kondo alone active online community “idol tors” favor intimacy artificial dol humans also several uncommon problem china given skewed gender ratios see world economic forum global gender gap report available httpwww3weforumorgdocswefgggr2018 pdf also viola zhou “china world’s skewed sex ratio birth—again” south china morning post october available httpswwwscmpcomnewschinapoliciespolitics article2040544chinasdemographictimebombstilltickingworldsmost kristin huang “chinese engineer ‘marries’ robot failing find human wife” south china morning post april available httpswwwscmpcomnewschinasociety article2084389chineseengineermarriesrobotafterfailingfindhumanwife afpjiji “love another dimension japanese man ‘marries’ hatsune miku hologram” japan times november available httpswwwjapantimescojpnews20181112national japanesemanmarriesvirtualrealitysingerhatsunemikuhologramxfm9vs7toq john danaher companies eagerly racing create sophisticated robotic artificial companions capable providing users sexual intimacy emotional support surprised trend sex intimacy important parts human life always mediated assisted technology sex toys sex dol found going back thousands years back archaeological record fact latest wave technologies leveraged toward sexual ends part longstanding trend4 chapter examines ethical opportunities challenges posed use ai humans express enact sexualities focusing three main issues first considers question sexual identity asks whether apply new sexual identity label—“digisexuality”—to express direct sexualities towards digitalartificial partners5 agreeing phenomenon worthy greater scrutiny chapter argues cautious rec ognizing new form sexual identity stigmatizing divisive effects second looks role ai play facilitating assisting humantohuman sexual intimacy focusing particular use selftracking predictive analytics optimizing intimate behavior asks whether something ethical objectionable use ai assistance argues isn’t though ethical risks need addressed final considers idea sophisticated form ai could object love loving relationship something “programmed” love us contrary widely held view chapter argues indeed possible ai sexual identity identity central human existence seek define understand others terms different identity categories6 sexual identity labels impor tant part pattern classification homosexuality bisexuality hetereosexual ity recognized part tolerated distinct forms sexual identity though always thus general tendency classify others manner creates tempta tion comes understand like zheng jiajia akihiko kondo kate devlin turned science sex robots london bloomsbury sigma hallie lieberman buzz stimulating history sex toy new york pegasus books neil mcarthur markie twist “the rise digisexuality therapeutic challenges possibilities” sex relationship therapy ––kwame anthony appiah lies bind rethinking identity london profile books francis fukuyama identity demand dignity politics resentment new york farrar straus giroux sexuality express enact sexual preference artificial partners article “the rise digisexual” neil mcarthur markie twist succumb temptation7 argue technology plays important role people enact sexual desires comes display marked preference artificial partners recognize new type sexual identity namely “digisexuality” put sexual identity come prefer direct sexual interactions humans propose label people consider experiences essential sexual identity ‘digisexuals’ ”mcarthur twist make argument circumspection care point sexual orientations identities occur along continuum people occasional use technology get kicks retain strong preferences humantohuman contact suggest live primarily one extreme end spectrum deserve label “digisexual”they also recognize people belonging group almost certainly suffer stigmatization result pronounced sexual preference argue simply needs understood combatted10 saying make case using “digisexu ality” label largely detached scientific perspective suggesting digisexuality something needs acknowledged studied agree phenomenon worthy greater scientific scrutiny think cautious encouraging widespread use new sexual identity label “digisexuality” admittedly something necessarily control since pointed earlier constantly business label ing classifying one another nevertheless extent control ten dency label classify one another avoid temptation recognize new minority digisexuals stance motivated bigotry desire suppress new truth human sexuality motivated desire avoid pathologizing “othering” viewed part ordinary range human sexual desire argument view two prongs first claim recogni tion particular set sexual desires distinctive identity orientation metaphysical mandated words nothing raw data human sexual desire demands apply particular label classification desires second prong argue extent apply labels tendency us ignore important nuances actual raw data human sexual desire pernicious consequences consequently since grouping set sexual desires distinctive identity label metaphysical mandated social ethical desirable resist temptation mcarthur twist “the rise digisexuality therapeutic challenges possibilities” id –id id john danaher let’s explore prongs argument detail starting claim recognizing new sexual identity metaphysical warranted making claim inspired theory sexual orientation developed saray ayala conceptual act theory sexual orientation11 gist theory follows humans many different phenomenological experiences lifetimes many cases experi ences messy finely differentiated think auditory color experiences though perceive distinctions different shades different musical notes reality sound waves light waves blend fade one another use conventional linguistic labels bring order structure phenomenological soup experience what’s people’s conceptual toolkit enables finely differentiate phenomeno logical experiences others know people easily recognize distinguish different notes scales piece music ability lump together experiences others split psychologist lisa feldman barrett argued phenomenon lies emotional experiences12 initial phenomenological reality emotion raw feeling gets interpreted particular conventional conceptual toolkit translate raw emotional experiences feelings “anger” “sorrow” different ways grouping organizing feelings ways immediately rec ognizable cultural outsiders ayala argues true experience sexual desire course lifetime people experience sexual desire arousal release response many different things oftentimes desires directed people sometimes won’t people known experience arousal response sorts environmental stimuli feet washing machines buildings happens people group sexual experiences together order make sense sexual identities orientations experiences ignored suppressed discounted others accentuated probably discount times got aroused vibrations school bus times got aroused danced classmate school dance won’t call automotivefetishist matter many times got aroused school bus likewise perhaps realistical suspect many people primarily gain sexual release masturbation intercourse another human nevertheless suspect majority people classify avowed autoeroticists don’t interpret masturbatory experiences identity label see experiences part full range desirable sexual experiences still actively pursued saray ayala “sexual orientation choice” journal social ontology –lisa feldman barrett “solving emotion paradox categorization experience emotion” personality social psychology review –sexuality point likely true get sexual kicks technology even primarily artificial partners consider zheng jiajia akihiko kondo example claim sought artificial partners failing find love among fellow humans would sug gest haven’t completely lost form sexual desire danger apply encourage apply identity label newfound sexual prefer ences also encourage discount suppress aspects sexual affect start exaggerating reality diverse differentiated phe nomenological reality brings us second prong argument applying identity labels social ethical pernicious might primed skeptical might point identity political movements support skepticism argue owning identity label political personal empow ering belong group feel less alone world similarly members group social disadvantaged banding together help stand agitate legal rights protections true feminist movement gay rights movement noteworthy movements arose response preexisting prejudice discriminatory classification people within groups already subject oppressive identity labeling hence saw need band together wear label matter pride work social reform absence preexisting prejudice case identitylabeling much less persuasive identitylabeling tends encourage divisiveness othering—the “us” “them” mentality people quickly appoint guardians identity creating criteria determining belongs furthermore belonging particular identity category brings certain social benefits legal protections people might encour aged overinterpret experiences fit within relevant group force group belong thereby violence actual experience short identitylabeling foster often combat social division polarization clear claim identity labels pernicious scientifical inaccurate labels social scientific value claim rather identity labels power treated caution sexual phenomenology often diverse differentiated identity labels allow means lumping someone particular category often warranted recognizing valorizing identity label may encourage incentivize people force fit category belong unless trying combat preexist ing social prejudice stigmatization reluctant classify people play people’s sexual lives cannot study various manifestations cognate term like “robosexual” accept digisexuality part normal range human sexual experience john danaher ai sexual assistance sex toys sex aids long used assist complement humanto human sexual activity ais robots already widely used assist complement nonsexual human activity surprise find ai harnessed toward sexual assistive roles already see smart sex toys try learn user data optimize sexual pleasure “quantified self” apps enable users track optimize various aspects sexual performance simple ai assistants help aspects intimate behavior including apps help automate assist sending intimate communications partner13 use aibased sexual assistants raise significant ethical concerns previous work along colleagues sven nyholm brian earp analyzed eight different ethical concerns one might use ai intimate relationships14 interests brevity discuss four key ethical concerns privacy concern concern use ai assistants intimate sexual relationships constitutes major assault personal privacy could partners use services spy one another without consent already problem abusive intimate relationships15 could also ai assistants owned controlled third parties eg companiescorporations capture sexual data users use optimize market products services sometimes done consent users sometimes indeed several lawsuits already settled companies users smart sex toys due fact data collected devices without users’ consent16 course viola tions privacy general concern digital technology extending far beyond sexual intimate use case17 one might argue ethical concerns higher case given unique importance sexual privacy discussions different apps services see deborah lupton “quantified sex critical analysis sexual reproductive selftracking using apps” culture health sexuality –karen levy “intimate surveil ance” idaho law review –john danaher sven nyholm brian earp “the quantified relationship” american journal bioethics –john danaher “toward ethics ai assistants initial framework” philosophy technology –and evan selinger “today’s apps turning us sociopaths” wired february available httpswwwwiredcom201402outsourcing humanityapps evan selinger “don’t outsource dating life” cnn edition may available httpeditioncnncom20140501opinionselingeroutsourcingactivitiesindex html accessed november danaher nyholm earp “the quantified relationship” levy “intimate surveil ance” alex hern “vibrator maker ordered pay c4m tracking users’ sexual activity” guardian march available httpswwwtheguardiancomtechnology2017mar14 wevibevibratortrackinguserssexualhabits woodrow hartzog privacy’s blueprint battle control design new technologies capitalism london profile books sexuality disengagement concern concern ai sexual assistants may distract us encourage us disengage sexual intimate activity thereby corrode undermine core part value activity argument would lot good sexual intimacy indeed forms intimacy stems present moment enjoying sexual activity real present using sex assistant track number calories burn decibel level reach number thrusts per form sexual activity incidental real examples uses descriptive predictive analytics put intimate apps18 similarly nonsexual case evan selinger worries use automated aiassisted intimate communication apps grounds create impres sion someone thinking caring another person particular moment fact letting app work them19 disengagement concern general concern digital technology— think complaints “antisocial” use smartphones parties meetings—but might worry particularly problematic intimate case important present intimacy misdirection argument related previous concern concern kinds things ai sexual assistants might assist people ai assistants general tend provide users information world around prompt certain things future likely occur ai sexual assistants might give users information optimize sex ual experiences prompt try particular activities one worry assis tants could encourage activities conducive good sexual experience indeed already expressed concern various sex tracking apps created20 noted apps often encourage users focus things like number calories burned sex number thrusts sex decibel level reached sex one reason relatively easy track meas ure things reason think correlated good sex contrary focusing measures might actual undermine good sex worry distinct previous one user taken moment rather things particularly pleasur ablevaluable moment ideological concern final concern also related two preceding ones ideological impact ai sexual assistants intimate relation ships concern assistants might impose certain model ideal intimatesexual relationship people make use might example recreate reinforce gender stereotypes sexual desire preference danaher nyholm earp “the quantified relationship” selinger “don’t outsource dating life” criticism see lupton “quantified sex critical analysis sexual reproductive selftracking using apps” levy “intimate surveil ance” john danaher karen levy example argued many intimate tracking apps reinforce view women subjects surveil ance sexual control21 others argue apps might encourage economic exchangebased model intimate relations informalreciprocation model devices might encourage users track encourage optimizemaximize certain metrics detriment truly valuable intimate relationship be22 said response concerns wel privacy concern probably serious partners use ai assistants spy one another manipulate one another’s behavior nontransparent way would major worry could provide assistance cover dominating abusive relationships relation ships exist absence technological assistance technology might make easier implement certain forms dominating control seems uncontrover sial suggest app service makes easy one intimate partner spy another without other’s consent possible banned spying third parties also limited trickier manage seem inherent digital technology facilitates kind tracking surveil ance try mitigate harm done tracking surveil ance robust legal protection individual privacy legal protection would force companies provide relevant apps services put place measures prevent nontransparent nonconsensual uses individual data eu’s general data protection regulation step right direction regard may well people willing waive privacy rights order make use assistive technologies appears case many people already many times consented digital surveil ance convenience privacy advocates counter simply people ful appreciate dam age done misuse personal data even stil many people convenient access digital services often favored privacy suggests whether people willing forgo privacy using ai sex assistants might depend whether find assistants useful intimate lives sexual privacy might significantly eroded three objections come provide reason question whether ai sex assistants fact useful highlighting various ways might undermine corrode intimate relationships although three concerns merit overstated three reasons first important bear mind single model ideal intimate relationship different relationship models work different sets people different times apps assistive ai seem useless distracting misdirected people might useful engaging fulfilling others even seemingly comical examples sextracking apps get people quantify certain aspects sex life levy “intimate surveil ance” danaher nyholm earp “the quantified relationship” –sexuality might people lead pleasurable fulfilling sex life long people forced compelled use particular ai sex assistants use need lead ideological imposition specific model ideal relationship diversity apps assistants could provide room partners explore different pos sibilities accordance needs wishes second early attempts provide ai assistance might seem crude unsophisticated likely improve time provide useful guidance reason think tracking quantification made possible sex relationship apps used good effect give one example research carried gottman institute successful relationships suggests relationships improved partners explicitly record details intimate lives follow certain rituals connection23 recommendations based extensive longitudinal research makes successful intimate relationship digital assistants could make easier implement recommendations indeed gottman institute already offers free smartphone app helps couples implement them24 one easily imagine sophisticated aibased versions app created future providing far effective personalized assistance third extent worries remain effect technologies sexual intimacy worries mitigated large extent encouraging thoughtful engagement technology problems outlined severe people use ai assistants substitute thinking comple ment thinking could one major recommendation made designers ai intimate assistants would include clear warnings users services recommendations offered assistants panacea sexual woes beneficial users critical reflects role service intimate lives including prompts critical reflection could focus designers wish encourage ethical use ai sex assistants bottom line although ai assistants could undermine corrode intimate sexual lives reason optimism careful critical nondogmatic use assistants might complement improve intimate behavior ai love let’s close chapter returning two men whose stories told intro duction zheng jiajia akihiko kondo “married” artificial beings obvious question ask ethical philosophical status marriages see httpswwwgottmancom available httpswwwgottmancomcouplesapps john danaher might manifestations genuinely loving relationships slightly unusual sexual fetishes outset would emphasize answer ques tion understood attempt stigmatize shame prefer relationships question worth asking since attach lot value lov ing relationships could loving relationships ais robots might provide reason create shortage opposition idea one could loving relation ship robot dylan evans example argued something para doxical idea robotic lover25 argument focuses asymmetrical nature relationship human robot presumably robotic lover programmed “love” human partner robot could choose part ner would point creating advantage robot lover human lover fact robot love ultimate con trol responses desire control seems one motivations behind zheng jiajia akihiko kondo’s actions control comes cost according evans core part people want loving relationship partner partners freely chooses puts people want lover’s commitment “be fruit ongoing choice rather inflexible unreflexive behavior patterns”michael hauskeller also argues idea robotic lover although con cedes may possible create humanlike robots “appear” love counters lover would never satisfying human lover following evans argues one main reasons matter good il usion love would always reason suspect doubt whether robot real loves given manufactured programmed origins27 extensive analysis concept love sven nyholm lily frank also express doubts possibility loving relationship robot28 exploring different conceptions romantic love including claim love “good match” partner attracted “distinctive particular ity” partner argue impossible create robot meets conditions needed loving relationship would exceptional difficult requiring technology far advance currently available making case use “hired actor” analogy express basic problem creating robotic lover seems like best real robotic lover create dylan evans “wanting impossible dilemma heart intimate humanrobot relationships” close engagements artificial companions key social psychological ethical design issues ed yorick wilks philadelphia pa john benjamins id –michael hauskeller “automatic sweethearts transhumanists” robot sex social ethical implications ed john danaher neil mcarthur cambridge mit press sven nyholm lily eva frank “from sex robots love robots mutual love robot possible” robot sex social ethical implications ed john danaher neil mcarthur sexuality entity “plays part” love never quite graduates acting genuine love29 criticisms intuitive attractive problems see important distinguish two fears articulated critics first—which might call “no depth” fear—is robot lovers surface depth act “as if” love nothing perfor mance don’t real feel consciously experience relevant emotions associate love second—which might call “programming” fear—is robot lovers cannot freely autonomously choose love always programmed love two fears related one another—most alleged robot lovers probably lack depth free choice—but thing robot might programmed love even right kind experi ential depth vice versa two criticisms robot lovers valid let’s consider “no depth” problem first easy rebuttal say even robots currently lack requisite experiential depth possible someday day arrives robot lovers major problem rebuttal however kicks road fails grapple philosophical issue heart determining whether particular relationship counts loving one don’t think robot appears surface love that’s takes loving relationship robot might sound little crazy defend grounds must practi cal matter behaviorists comes understanding ethical status rela tionships beings30 words apply methodological behaviorism psychologists computer scientists eg behaviorism heart turing test machine intelligence ethical relationships beings central tenet “ethical behaviorism” try determine moral quality relationships including duties responsibilities beings cannot use unobservable inner mental states make assess ment rely external observable behavioral functional patterns may course hypothesize existence inner mental states explain observ able patterns inference make presence states must ulti mately grounded guided external observable pattern problem many philosophical accounts takes loving relationship focus implicitly explicitly unobservable inherently private mental states result effectively impossible confidence existence loving relationships unless accept observable behavioral functional patterns id –john danaher “the philosophical case robot friendship” journal posthuman studies john danaher provide epistemic warrant judgments presence relevant private mental states words ethical behaviorism already necessity approach take understanding ethical status relationships fellow human beings means “no depth” argument doesn’t work since unable plumb depths human lovers cannot apply different evidential standard robotic lovers point finessed order avoid potential absurd interpreta tions starters important realize order provide basis loving relationship performance il usion robot need equivalent performance il usion get human lover it’s unlikely currently existing robot ai achieves performative equivalency remains extent future possibility present reality similarly counterarguments ethical behaviorism worth considering deepen understanding ethical behaviorism entails example people might argue rely something behav ior determine moral quality relationships others perhaps know lovers made right stuff biologicalorganic material confident love us perhaps know right kind developmentalevolutionary history someone might argue robots ai would still count “proper” lovers even performatively equiva lent human lovers hard see presence absence factors effect rational connection made right stuff right history capacity form loving relationship another suppose spouse behaves way entirely consistent hypothesis love suppose one day learn fact alien another planet don’t share biological constitution con tinue behave always doubt whether truly loving relationship it’s hard see revelation alien origins undermine claim loving relationship con sistent behavioral evidence love trump considerations hold robotic artificial lover people might come back argue cases faith existence loving relationship would shaken learning something ori gins history human lovers suppose example learn human lover indeed hired actor affair years without awareness surely would undermine confidence loving relationship surely akin would like robot lover counterexamples work starters clear either revelations shake faith existence loving relationship seems plausible suggest hired actor could grow love person initial fake relationship also seems plausible suggest love survive infidelity person still behaves appears love perhaps sexuality despite revelations even that’s stretch people would suggest real shakes faith existence loving relationship cases fact acquire reason suspect existence new behavioral evidence contradicts old behavioral evidence con vinced loving relationship example learned actor says bad things “off” job partner planning leave person affair new behavioral evidence might completely undermine belief loving relation ship least prompt seek behavioral evidence confirm whether partner still loves either way behavioral evidence dam age repair event neither examples good analogy robotic lover case presumably robotic nature origins lover known day one “programming” fear evans right want least want lovers freely choose us robot programmed conditioned love us seems like something suspicious inferior kind “love” give shouldn’t overstate fear either conceivable could create robotic lovers behave “as if” freely choose us remember behaving “as if” choose us enough following ethical behaviorism robotic lover might act fickle way test human companion’s true commitment much like human lover could even attractive quality robotic lover makes like humantohuman case desire isn’t bizarre unfathomable evans makes beyond also reason doubt whether presence absence humans arguably “programmed” love one another combination innate biological drives cultural education makes humans primed find one another sexual attractive form deep lasting bonds one another indeed people often talk love something free autonomous choice “fal ” love don’t choose find attracted others often despite better judgment heart wants wants furthermore cultures arranged marriages relationships common seem unusual maybe even cruel perspectives partners relationships often grow love one another report high levels relationship satisfaction sometimes higher often worse satisfaction “autonomous” marriages31 unusual believe love blossom pre programming prearranging unions robert epstein mayuri pandit mansi thakar “how love emerges arranged marriages two crosscultural studies” journal comparative family studies –and pc regan lakhanpal c anguiano “relationship outcomes indianamerican lovebased arranged marriages” psychological report –john danaher critics might dispute examples argue kind programming involved human relationships different kind arise human robot relationships humans loosely programmed seek attachment brainwashed love particular person also even case arranged marriage relationship ongoing basis exercise autonomy union formed escape relationship desire clear disanalogies strong true classical robots ais programmed top particular human program mers follow highly specified instructions longer norm robots ais programmed bottom follow learning rules adapt new challenges circumstances flexibility adaptive learning still rather limited—we yet create generalized form artificial intelligence—but approach proliferates grows alleged disanalogies programming human lovers robot lovers narrow longer absurd claim robot lovers commit us basis free ongoing choice imagine might fall love us continued learning none say preferring robot lover human lover good thing ethical problems creating robot lovers worries objectification domination robot partners well social consequences might voiced several critics discussed worries length previous work32 similarly nyholm frank argue creators robotic lovers sexual partners may obligation mislead users capacities robots question form loving relationships33 worry manufacturers might tempted exploit emotional vulnerability con sumers order make products attractive problem consumer products extent seems like particularly acute problem robotic lovers given centrality importance sex love human life rela tively strict set rules may required guard abuse course permitted set rules depends crucial think takes form legitimate loving relationship focused philosophical nature love preceding discussion correct analysis someday possible form loving relationship robot robot convincingly consistently perform part lover hence restrictions imposed prevent exploitation need take consideration john danaher “robotic rape robotic child sexual abuse criminalised” criminal law philosophy –john danaher “the symbolic consequences argument sex robot debate” robot sex social ethical implications ed danaher mcarthur cambridge mit press john danaher “regulating child sex robots restriction experimentation” medical law review –sven nyholm lily eva frank “it loves loves moral problematic design sex robots appear “love” owners” techné –sexuality conclusion wrap ai robotics continue used augment complement human sexuality chapter addressed three issues might arise result made three main arguments first argued cautious recognizing new form sexual identity applies primarily express enact sexualities technologies metaphysical mandated may contribute social stigmatization second argued ai used assist human sexual intimate relationships assis tance poses number risks—particularly privacy—but risks overstated prevent beneficial use ai sex assistants final argued contrary number critics possible form loving relationship robot ai bibliography danaher john neil mcarthur eds robot sex social ethical implications cambridge mit press danaher john sven nyholm brian earp “the quantified relationship” american journal bioethics –devlin kate turned science sex robots london bloomsbury hauskeller michael sex posthuman condition london palgrave macmil levy david love sex robots evolution humanrobot relationships new york harper collins levy karen “intimate surveil ance” idaho law review –lieberman hallie buzz stimulating history sex toy new york pegasus books lupton deborah “quantified sex critical analysis sexual reproductive self tracking using apps” culture health sexuality –mcarthur neil markie twist “the rise digisexuality therapeutic challenges possibilities” sex relationship therapy ––nyholm sven lily eva frank “from sex robots love robots mutual love robot possible” robot sex social ethical implications ed john danaher neil mcarthur cambridge mit press p r v perspectives approaches chapter perspectives ethics ai computer science benjamin kuipers ethics ai important ai uses computational methods study human knowledge learning behavior part building agents able know learn behave ethics body human knowledge helps agents humans today perhaps eventual robots ais decide others behave ethical issues raised ai fall two overlapping groups first like powerful tools technologies eg genetic engineering nuclear power potential deployments ai raise ethical questions impact human wellbeing second unlike technologies intelligent robots eg autonomous vehicles ais eg highspeed trading systems make decisions actions take thus could considered members society humans able expect behave ethical requires ai research goal understanding function structure content ethical knowledge well enough implement ethics artificial agents deployment ai machine learning intelligent robotics becomes increasingly widespread problems become increasingly urgent benjamin kuipers function ethics person be”ethics consists principles deciding act various circumstances reflecting right wrong good bad situation clear ethics hence considered right wrong good bad changes significantly historical time similarly long historical timescales despite discouraging daily news reports appears societies world becoming stronger safer healthier wealthier inclusive members2 two important sources concepts help make sense changes first game theory contributes abstraction certain types interactions among people games3 behavioral economics shows games winners losers overall impact players collectively described positivesum zerosum negativesum4 second theory evolution applied human great ape cog nition sociality shows way life depends positivesum cooperation among individuals likely provide society greater fitness less cooperative ways life5 therefore think function ethics promoting survival thriving society influencing behavior individual members summarized ethics set beliefs society conveys individual members encourage engage positivesum interactions avoid negativesum interactions society prospers survives thrives individual members benefit wel ethical behavior “nonobvious selfinterest” individual philosophers would consider rule consequentialist position6 one relevant consequences survival thriving society pleasures pains individual members consequentialist actions evaluated according whether intrinsical right wrong criterion according longterm good bad consequences survival thriving russ shaferlandau ed ethical theory anthology wileyblackwel 2d ed xi robert wright nonzero logic human destiny pantheon steven pinker better angels nature violence declined viking adult steven pinker enlightenment case reason science humanism progress viking john von neumann oskar morgenstern theory games economic behavior princeton university press samuel bowles moral economy good incentives substitute good citizens yale university press michael tomasello natural history human morality harvard university press walter sinnottarmstrong “consequentialism” stanford encyclopedia philosophy ed edward n zalta winter edition perspectives ethics ai computer science society position rule consequentialism unit evaluated individual action decision set ethical principles often rules adopted society positivesum negativesum interactions commerce cooperation paradigm positivesum interactions one person voluntarily trades sel something someone else party receives something value highly gave cooperating project partners contribute toward common goal reap benefit greater either could achieve alone theft violence examples negativesum interactions thief gains something theft loss victim typical greater gain thief violent conflict paradigm negativesum interaction since parties may worse afterward possibly much worse cleanly separated cases violence defense external attack may necessary avoid catastrophic outcome defense likely cooperative project cooperation trust social norms cooperative projects among individuals major source positivesum outcomes however cooperation requires vulnerability trust vulnerability exploited7 trust psychological state comprising intention accept vulnerability based positive expectations intentions behavior another intelligent robots large corporations increasingly act autonomous goalseeking agents therefore members society need subject requirements ethics need demonstrate trust trustworthy successful cooperation demonstrates trustworthiness partners pro duces trust exploitation reduces trust trusting enough pool resources efforts individuals working together often achieve much sum individual efforts working separately large cooperative projects raising barn digging canal creating interstate highway system pro duce large benefits everyone spend day helping raise barn trust due time spend day helping raise mine taxes help pay new york’s michael tomasello natural history human morality harvard university press dm rousseau sb sitkin rs burt c camerer “not different crossdiscipline view trust” academy management review –benjamin kuipers erie canal pennsylvania turnpike trust due time taxes also pay panama canal linking east west coasts st lawrence seaway providing access great lakes states united states emphasize name “commonwealth” meaning shared resources provide shared prosperity social norms behavioral regularities individual members society general count planning activities trusting near invariants many aspects lives become simpler efficient less risky uncertain maintaining social norm kind cooperative project without specified partners accept certain minor sacrifices return similar behaviors almost everyone else providing near invariant rely example lunch cafe condiments freely available convenience know pocket extras continue available likewise trust simple painted stripe middle road driving securely separates drivers going opposite direction accept minor sacrifice crossing stripe even side congested like explicit cooperative projects social norms provide positivesum results society saving resources would otherwise go toward protection recovery making us individual collectively better requires trust acceptance vulnerability partners along confidence others exploit vulnerability even individual gain use term “social norm” inclusively cover regularities ranging laws moral imperatives nonmoral social conventions philosophers make many different distinctions among types origins social norms taking design stance toward ethical systems influencing behavior intelligent agents human nonhuman society emphasize common functional goal encouraging positivesum discouraging negativesum interactions representing ethical knowledge described ethics set beliefs society conveys individual members stated beliefs evaluated according longterm good bad consequences survival thriving society since result evaluation depends many complex factors evolves decades centuries useful individuals deciding act make practical decisions individual humans need concise understandable ethical principles principles useful longterm survival society must also explainable teachable individuals entering society children immigrants intelligent nonhuman agents robots corporations apply ethical principles behavior principles must capable learned programmed field philosophical ethics centuries created number concise frameworks ethical knowledge built around concepts virtues duties utilities perspectives ethics ai computer science contracts forth9 tempting regard competing alternatives generally recognized pieces complicated incompletely understood puzzle10 many fields applied ethics eg biomedical ethics11 appeal conceptual frameworks starting specific ethical questions searching clear practical answers depending details case question clarity may come one another ethical frameworks others provide ambiguous unacceptable results fairness economy may possible express several conceptual frameworks single knowl edge representation based cases ⟨ ʹ v⟩ ʹ represent previous resulting situations describes action v evaluation12 representation describe situations action different levels detail ranging rich descrip tions experienced events highly schematic general patterns ethics research ai community number ai robotics researchers explicitly address problem ethics ai robotics13 example ron arkin proposed autonomous system control ling lethal weapon could equipped “ethical governor” based laws war rules engagement authority override attempt deploy lethal force14 human emotional reactions lead errors even war crimes arkin claims taking human loop targeting precise lawful making war humane many others skeptical impact lethal autonomous weapon systems utilitarianism attractive ai community factors ethical decisions defining utility function represents preferences states world b applying optimization algorithm identify action rule maximizes expected utility philosophical utilitarianism aggregates utility russ shaferlandau ed ethical theory anthology wileyblackwel 2d ed cf john godfrey saxe’s children’s poem blind men elephant tl beauchamp jf childress principles biomedical ethics oxford university press 6th ed b kuipers “how trust robot” communications acm –patrick lin keith abney george bekey eds robot ethics ethical social implications robotics mit press ronald c arkin governing lethal behavior autonomous robots crc press benjamin kuipers everyone society15 game theory individual player optimizes utility16 motivating problem many cases eg prisoner’s dilemma public goods game tragedy commons etc “rational” solution according game theory nash equilibrium results poor outcomes every player negativesum result society fact humans playing games tend avoid nash equilibrium get better outcomes17 much effort gone formulating utility functions individual decisionmaking lead improved outcomes everyone society often context repeated games drawing population players vincent conitzer colleagues18 show robot player communicate intention behave trustworthy way making “suboptimal” move player meant understand offer cooperate feel obligated reciprocate stuart russell others posed prob lem value alignment19 defining utility functions lead decisions similar humans make cooperative inverse reinforcement learning proposed solution value alignment problem robot tries maximize human’s utility function recognizing incomplete knowledge utility function intended prevent robot however powerful optimizing poorly chosen utility function way causes catastrophe according human utilities21 human nonhuman members society traditional society’s members individual human beings participate society interacting making decisions actions perform peter singer expanding circle ethics evolution moral progress princeton university press john von neumann oskar morgenstern theory games economic behavior princeton university press jk goeree ca holt “ten little treasures game theory ten intuitive contradictions” american economic review –jr wright k leytonbrown “predicting human behavior unrepeated simultaneousmove games” games economic behavior –j letchford v conitzer k jain “an ‘ethical’ gametheoretic solution concept twoplayer perfectinformation games” int workshop internet network economics wine russel dewey tegmark “research priorities robust beneficial artificial intelligence” ai magazine winter –d hadfieldmenel dragan p abbeel russell “cooperative inverse reinforcement learning” advances neural information processing systems nips nick bostrom superintel igence paths dangers strategies oxford university press perspectives ethics ai computer science recent years progress artificial intelligence robotics machine learning raised prospect intelligent nonhuman robots participating members society autonomous vehicles must trusted behave safely ethical routine traffic emergency situations22 ais physical embodied highspeed trading systems social networks also behave safely ethical y23 largescale institutions also considered intelligent entities forprofit nonprofit corporations governments churches unions corporate entities24 entities participating society function ethics same—to encourage positivesum interactions discourage negativesum ones supporting survival thriving society whole likewise means help accomplish function—supporting trust relevant social norms entity demon strate trustworthy method analyzing specific cases trust ethics many different domains behavior different social norms ethical principles available trust furthermore noted earlier social norms ethical principles change historical time goal cannot provide universal answers humans nonhuman agents society behave rather goal must provide framework asking useful questions following sections discuss three quite different cases ethical decision making relevant societies including human nonhuman agents autonomous vehicles individual embodied robots make decisions driving ethical implications social networks disembodied intelligent systems mediate interactions among people also collect large amounts information often disregarding individual privacy concerns corporations entrusted much wealth economy also viewed intelligent agents whose behavior governed ethics examples ask social norms people would want trust ethical principles society adopts encourages individual members follow determines social norms individuals society able trust consider social norms might expressed patrick lin “the ethics autonomous cars” atlantic monthly october mp wellman u rajan “ethical issues autonomous trading agents” minds machines –b kuipers existing ecological ysuccessful genus collectively intelligent artificial creatures” collective intel igence arxiv12044116 benjamin kuipers example trust ethics autonomous vehicles vast sums invested develop autonomous vehicles avs intelligent robots intended share roads ordinary humandriven vehicles well pedestrians robots take passengers cargo destinations simply bring av next needed critical technological requirement robot’s perception provide sufficient situational awareness make right deci sions keep humans safe accept avs roads humans need trust behavior inspired isaac asimov’s first law robotics25 “a robot may injure human inaction allow human come harm” might start proposing following social norm overly sweeping point impossibility even without clause failing prevent harm inaction however distinguish deliberate accidental harm formulate pair plausible social norms human accidental harm human achieving two social norms require technical solutions difficult problems perception situational awareness planning acting set impossible goal guaranteeing fatal accidents never occur still need careful stated social norm describing action required prevent harm would otherwise happen deadly dilemma concerned philosopher inspired famous “trolley problem”might ask av suddenly confronted “deadly dilemma” cannot avoid colliding one two groups humans must decide group deliberately kil either choice dilemma clearly violates social norm sn1 therefore undermines trust avs members society isaac asimov robot grosset dunlap judith jarvis thomson “the trolley problem” yale law journal –perspectives ethics ai computer science original trolley problem useful thought experiment philosophers use explore relationships human moral intuitions predictions different philosophical theories useful guide design embodied robots physical world design ethical robot av must reject narrow framing trolley problem formulate additional social norm humans experience bad outcome often engage counterfactual think ing searching mental simulation previous “upstream” action would avoided bad outcome27 unique event counterfactual thinking futile lead depression recurring types events produce valuable insights deadly dilemma good outcomes trigger counterfactual thinking driver learns previously unremarkable situation like entering narrow street requires driving much slower preserve option safe emergency stop learn ing counterfactuals attentive agent accumulates store practical wisdom makes safe ethical behavior much easier concerned philosopher responds “yes scenario unlikely happen” perception physical world imperfect neither humans robots perceive emergency situation well enough certain presents deadly dilemma exactly two alternatives probability distribution continuous space similar scenarios involve fatalities many others “near misses” near miss far likely true deadly dilemma p nearmiss observation ≫ p deadlydilemma observation best response suddenly confronted situation immediate emergency braking along steering minimize risk injuries response satisfies two social norms sn1 robot deliberately target human even save others sn2 probability injuring human greater skilled attentive human driver faced situation even rare case fatality av acted reasonably ethical confronted bad situation aristotle tel us virtue skill improves experience like carpentry novice may presented situation appears deadly dilemma expert experience practical wisdom acts earlier deadly dilemma avoided neal roese kai epstude “the functional theory counterfactual thinking new evidence new challenges new insights” advances experimental social psychology –aristotle nicomachean ethics trans terence irwin hackett 2d ed benjamin kuipers ethical principles encourage trust social norm sn1 translates natural easily stated ethical duty never deliberately harm human extent robot visibly follows rule becomes trustworthy increasingly trusted follow rule future second social norm sn2 sets bar competence capabilities human drivers avs tested compared young humans subject age time situation constraints driving accumulate enough experience practical wisdom become trustworthy drivers likewise elderly human drivers face ethical requirements restrict give driving according abilities observed others third social norm sn3 requires continual effort anticipate potential deadly dilemmas via counterfactual thinking learning recognize upstream decision point choice avoids dilemma engineered devices avs designed mechanisms selfmonitoring selfevaluation determine real time whether able drive safely current situation details mechanisms may concise descriptions natural language overall effect would correspond ethical duty safe drive stop safely ask assistance many circumstances arise av shares roads human drivers pedestrians example av stopped crosswalk human pedestrian trust enough walk front requires adequate situational awareness av also ability communicate trustworthiness human pedestrian problems may technical solutions even restricted domain like driving includes large number problems centuries human societies accumulated huge numbers situation specific social norms trust along ways agents signal trustworthiness society lives individual members improved result29 example individual user models people complex world incomplete understanding world love communicate depend communication including feedback get others create develop correct refine understanding reality human experience intelligent agents almost entirely humans different capabilities highly correlated humans prone anthropomorphize nonhuman even inanimate elements environment attribute steven pinker enlightenment case reason science humanism progress perspectives ethics ai computer science agency30 easily lead assuming robots ais humanlike capable actual are31 generalizations useful humans unreliable robots ais possibly leading excessive trust unexpected catastrophes ethical problems use search engines like google find people written created use social networks like facebook communicate learn understand services cost money paid somehow long accepted adver tisements help pay newspapers magazines television modern datamining methods using new machine learning algorithms vast quantities data abundant computing resources made increasingly feasible build detailed models individual users without deep understanding websites extend acceptance creation individual user models sold advertisers improve targeting advertisements many users consider worthwhile trade privacy “free” search social network services paid advertising better matched personal interests use individual user models could seen ethical acceptable bargain satisfying social norm form interests information knowingly voluntarily provide sel ing access models advertisers trust advertisers use models serve ads better match personal interests individual users google’s search engine facebook’s social network many useful apps sources data models built would like trust social norms ai’s best attempt understand want retrieve answers questions access desired internet sites reasonably unbiased sample posts created people linked network receive posts via similarly unbiased sampling algorithm many cases trust social norms real world evidence suggests trust justified32 specifical google facebook major internet n epley waytz jt cacioppo “on seeing human threefactor theory anthropomorphism” psychological review –p robinette r allen w li howard ar wagner overtrust robots emergency evacuation scenarios” acmieee int conf humanrobot interaction hri –shoshana zuboff age surveil ance capitalism new york public affairs benjamin kuipers companies collect aggregate far behavioral information individual users “knowingly voluntarily provide” violating sn4 furthermore results return designed influence future behavior beyond shopping choices naive trust systems unbiased nonmanipulative perils correct individual models individual users typical don’t understand breadth data modelbuilders draw internet companies collect information direct interaction interfaces also interactions sites “cookies” left behind tracking information many observation channels internet users experiences like following worse google search one browser style diningroom chair found attractive shortly afterward facebook running different browser began serving ads style chair felt creepy like “telepathic” surveil ance personal interests activities diningroomchair preferences particularly sensitive information knows kinds surveil ance normal human communication many things communicate via speech text email ephemera—temporary statements may contextdependent poorly thought poorly stated intended refined discarded course conversation communicated different individuals trust conspiring assemble comprehensive models preferences beliefs personalities activities aggregated correlated create inappropriately invasive model individual violating privacy course exactly major internet companies like facebook google machine learning algorithms access vast streams data33 even models create correct predictions likely invade privacy right keep actions beliefs don’t want share others one anecdote tel young man bought diamond ring online intending surprise girlfriend marriage proposal merchant sent email facebook friends congratulating engagement minor annoyance similarly inferring broadcasting political actions opinions person living repressive state could lifethreatening insurance companies among many companies taking advantage internet things iot gather surveil ance information individual behavior id perspectives ethics ai computer science auto health insurance companies increasingly monitor compliance various constraints punishing violations increasing premiums insurance cancel lation even disabling car service long dense legal agreements us click without reading order gain access software “free” otherwise agreements authorize company providing software collect data share sell companies typical without meaningful constraint “legals” designed discourage users reading allow companies claim users voluntarily “opt in” datasharing conditions analysis legal agreements associated nest “smart” thermostat34 found sect ukbased customer wants “a comprehensive picture rights obligations responsibilities various parties supply chain read least legal items” worse link additional contractual agreements partners affiliates manufacturers interoperable products others following links “if add nest legals connected devices apps appli ances result appears single product thousand contracts may apply” us presidential election campaign company cambridge analytica used facebook data build models identifying people vulnerable conspiracy theories targeted ads motivating turn vote particular candidate35 even people correctly confident resistance ads people manipulated unscrupulous advertisers votes may affect outcome everyone internet companies sometimes argue user modeling technologies moral neutral application models companies like cambridge analytica raises ethical problems36 however google facebook sell tools access data makes easy profitable others violate privacy manipulate institutions society surely absolved ethical responsibility perils incorrect individual models incorrect user models cause problems ranging trivial display irrelevant ads lifetransforming denial probation bail learning system pick g noto la diega walden “contracting ‘internet things’ looking nest” european journal law technology nicholas confessore “cambridge analytica facebook scandal fallout far” new york times april retrieved may httpswwwnytimescom20180404us politicscambridgeanalyticascandalfallouthtml “once rockets cares come that’s department” says werner von braun tom lehrer year benjamin kuipers biases training data possibly unconscious bias assembled possibly impact historical bias phenomena measured sometimes model incorrect designers system made grossly incorrect assumptions starting october michigan integrated data automated system midas automatical evaluated claims unemployment insurance37 information discrepancy applicant employer treated evi dence fraud applicant letter generated sent applicant’s last known address returned within ten days applicant considered guilty algorithm immediately imposed major financial penalties human review causing great hardship review charges filed revealed percent error rate widely known automated face detection face recognition systems often significantly higher error rate faces darker skin38 happen even though algorithm learns correctly training examples set training examples adequately reflect diversity population similar problems occur medical diagnosis male female patients heart attack exhibit significantly different symptoms decades past data study heart attacks came male patients leading frequent misdiagnosis female patients39 efforts way redress data imbalances much remains done cases training set could perfectly reflect human behavior behavior includes effects existing biases finding ways train complex machine learning system avoiding biases may embedded training data difficult open problem40 membership particular minority group may genuinely statistical correlated society characteristic interest fundamental principle society individuals judged individuals without bias membership particular minority group41 remains difficult translate societal ideal inference methods data analysis ryan felton “michigan unemployment agency made false fraud accusations—report” guardian december retrieved may httpswwwtheguardiancom usnews2016dec18michiganunemploymentagencyfraudaccusations b wilson j hoffman j morgenstern “predictive inequity object detection” technical report arxiv190211097 arxiv february ta beery “gender bias diagnosis treatment coronary artery disease” heart lung –cathy o’neil weapons math destruction big data increases inequality threatens democracy penguin random house “i dream four little children one day live nation judged color skin content character” martin luther king jr august march washington perspectives ethics ai computer science conclusion live intelligent tools systems designed satisfy human needs desires provide corporate owners continuing streams data google access information facebook social communication beginning designed addictive keep interacting learn great deal us makes valuable tools us also valuable commercial selling individual user models advertisers others trust intelligent systems follow social norms learned experience interacting humans humanscale organizations begun grapple impact vastly greater scale information involved terms number people events actions surveil ance microscopic detail information collected aggregated analyzed mass training data used create predictive models individual ways predictions used economic political ends homely example il ustrates impact scale hiking alone problem pee woods ongoing physical biological social processes woods handle tiny load city people legitimately required state federal regulations build elaborate infrastructure protect physical biological social environment including water sewage systems sewage treatment plant accustomed broadcast ads help support newspapers magazines television accept political campaigns sending volunteers knock doors supporters get vote election day understand every interac tion reveals little bit upon time human scale human limitations interactions provided implicit protection many potential problems times scale data collection changed society don’t grasp implications massive change scale—size scope detail pervasiveness—that development deployment surveil ance capitalism brings42 don’t yet clear understanding need protect different kinds costs benefits trade space regulations need43 large complex systems require large complex regulations regulations necessar ily evolve time debug refine society’s understanding needs changes society relevant largescale experience dissemination protection large amounts data including us food drug administration us securities exchange commission regulates nation’s securities industry ferpa federal educational rights privacy act protects o’neil weapons math destruction zuboff age surveil ance capitalism benjamin kuipers student educational records hipaa health insurance portability accountability act protects personal medical information gdpr eu general data protection regulation protects data privacy within european union fiduciary person organization acts trustee one beneficiaries example asset manager pension fund trust department bank fiduciary duty avoid kind conflict interest act solely beneficiary’s interest fiduciary relationships common financial domains fiduciary concept also applies spheres companies like facebook google collect aggregate large amounts personal data fiduciary duty toward individual users requiring handle data users’ interest users’ interest certainly include personal ized advertising closely aligns individual preferences personalized recommendations books music products based previous choices long beneficiary exploited necessarily conflict fiduciary duty company collects analyzes data profit efforts hand current practices would violate fiduciary duties clickthrough “agreements” designed obtain legal “optin” permission discouraging meaningful consideration conditions clearly user’s interest similarly meaningless “permission” data sharing organizations requiring individual user find check privacy policies organizations would violate fiduciary duties data sharing needed subcontracting work business partnership original company must responsible ensuring partner provides protections least strong original company like gdpr european union details fiduciary duty would negotiated legislation designed refined courts important point create social norm individual trust along meaningful enforcement mechanisms data subject fiduciary duty use data best interest example sharing wealth fairness important adult humans children including young infants44 even species nonhuman primates45 one way study fairness laboratory ultimatum game46 sloan r bail argeon premack “do infants sense fairness” psychological science –sf brosnan fbm de waal “monkeys reject unequal pay” nature –ma nowak km page k sigmund “fairness versus reason ultimatum game” science –perspectives ethics ai computer science ultimatum game two participants b given sum money say reject case neither participant gets anything nash equilibrium solution game theory clear makes minimal offer b say b accepts since better nothing behavior human participants quite different tends offer b tends reject offers less fairness economy total productivity american society hence total wealth increasing steadily since end world war ii much wealth controlled corporations historical responded needs various stakeholders including shareholders workers customers suppliers neighbors wealth society grew pros perity typical worker united states increased rate several decades figure left side people trusted economy would fair benefits starting 1960s milton friedman47 others argued corporation purely mechanism maximizing wealth shareholders corporation human managers responsibilities shareholders stakeholders workers customers suppliers neighbors except responses might affect shareholder value change perceived ethical responsibilities corpora tions widely accepted especial business community overall steady growth wealth continued starting around income gain became almost flat lower half economy led dramatic increase inequality among individuals gains going top percent population even dramatical top percent figure right side economics politics society changed offering opportunity al one rich get ever richer poor lose little even hope future descendants trends continue people become convinced social norm sn9 broadly violated share growing wealth society taken hopelessness anger lack trust continue grow point story samson old testament tormenters well see growing polarization society48 milton friedman “the social responsibility business increase profits” new york times magazine september susan mcwilliams “this political theorist predicted rise trumpism name hunter thompson” nation december httpswwwthenationcomarticle thispoliticaltheoristpredictedtheriseoftrumpismhisnamewashuntersthompson benjamin kuipers gap productivity typical worker’s since incomes rich grown change compensation increased dramatically since faster economy upper middle class kept pace economy income productivity growth hourly compensation growth –middle class poor fallen behind top ––cumulative increase productivity productivity hourly hourly compensation compensation productivity change since cenper hourly compensation tive la rest top mucu 90th 99th per capita gdp percentiles middle bottom figure left productivity therefore national wealth increased steadily since late 1940s typical worker compensation leveled mid1970s49 right incomes uppermiddle class –tracked increase per capita gdp upper increasing rate lower falling behind50 accumulating anger resentment amplify fears future ai robotics increasingly take jobs people depend livelihoods create new jobs often said previous periods rapid technological change jobs created lost could significant dislocation perhaps decades since people lost jobs necessarily qualified new jobs long run plenty new jobs created others respond previous technological advances provided automated substitutes human animal strength mechanical skil current aidriven advances provides substitutes intelligence obvious go however look careful scenario plenty new jobs created outlines possible solution seem appear exercise identifies three important together first seen figure left side productivity wealth society increasing steadily increase seems likely continue driving force behind automation prospect corporations become ever profitable using ai robotics automate increasing aspects production costs reproduced permission “the productivitypay gap” economic policy institute august new york times feb © new york times company rights reserved used license perspectives ethics ai computer science second clear people need meaningful work guaranteed income51 important people individuals engaged cooperative efforts consider meaningful important benefit themselves—their family community country society whole society benefits positivesum nature cooperative effort also individual members capable skilled disciplined responsible work toward shared goals52 third plenty jobs requiring skil commitment effort sub stantial benefit society problem current economy many jobs net generators profit employer without subsidies jobs created filled one example job stayathome parent young children job substantial benefits children family local community performed parent wants work cultivates skil commitment effort extremely satisfying however profit center economy typical unpaid family unit supporting one person work little external financial support another example job professional caregiver children elderly job essential care dependents necessary family members must work pay jobs like profit generators corporations economy however quality care requires wellqualified caregivers relatively high ratio caregivers cared families need care often limited resources pay caregivers deserve living wage numbers add allow three constraints satisfied time53 employer make profit combination quality care affordability living wages must sacrificed many jobs fit description meaningful worker valuable society supportable corporate profit centers education sector great unmet needs teachers aides managers counselors support staff preschool tutoring mentoring primary secondary postsecondary schooling adult professional education areas emergency services envi ronmental infrastructure care development medical care services could expanded certain tasks example care small neighborhood park could conceivably automated done dedicated community member would result job done least wel would also provide meaningful work member community jobs require subsidies seen wealth society continues grow resources subsidies exist br rosso kh dekas wrzesniewski “on meaning work theoretical integration review research organizational behavior –michael tomasello natural history human morality harvard university press sal ho “ ‘broken’ economics preschool workers child care sector” us news september downloaded may httpswwwusnewscomnewsbusinessarticles20180908 brokeneconomicsforpreschoolworkerschildcaresector benjamin kuipers rather try enumerate jobs one would hope marketbased entrepre neurial mechanism would reward individuals creating maintaining jobs mechanism could based entirely profit would use marketbased mechanism effectively allocate society’s subsidy work three pieces puzzle promising aspects way use wealth society benefit members society especial human members making three pieces fit together challenge especial political task channeling resources created increased automation creation new jobs society needs conclusions ethics society encourages individual members interact positivesum strengthen rather weaken society whole ethics accomplishes goal encouraging trustworthy behavior individuals earns trust others necessary cooperation centuries society accumulated many different situationspecific ethical principles social norms count make lives together safer effective54 individuals use concepts like virtue duty utility forth learn understand teach ethical principles concrete connections individual ethics trustworthiness trust cooperation positivesum outcomes need understand social norms trust trusting increases positivesum outcomes society whole norms represented knowledge minds individual agents human nonhuman applied agents making plans deciding act chapter considered examples il uminating three different aspects ethics computational modeling perspective first autonomous vehicles individual embodied intelligent systems act members society ethical knowledge needed agent choose lesser evil confronted deadly dilemma recognize upstream decision point makes possi ble avoid deadly dilemma entirely second disembodied distributed intelligent systems like google facebook provide valuable services collecting aggregating correlating vast amounts information individual users individual user models earn money corporations advertisers target users advertisements used much widely inadequate controls corporate systems invade privacy substantial damage either correct incorrect inferences russ shaferlandau ed ethical theory anthology 2d ed wileyblackwel perspectives ethics ai computer science third acceptance legitimacy society individual members depends general perception fairness contribute success collective effort share benefits rage unfairness directed individual freeriders systematic inequality across society promise computational approach ethical knowledge simply ethics computational devices robots rather artificial intelligence helps us understand cognition also promises help us understand pragmatic value ethics feedback mechanism helps intelligent creatures human nonhuman live together thriving societies bibliography greene joshua moral tribes emotion reason gap us london penguin press haidt jonathan righteous mind good people divided politics religion new york vintage books kuipers benjamin trust robot communications acm lin patrick keith abney george eds robot ethics ethical social implications robotics cambridge mit press pinker steven enlightenment case reason science humanism progress new york viking singer peter expanding circle ethics evolution moral progress princeton princeton university press tomasello michael natural history human morality cambridge harvard university press wal ach wendell colin allen moral machines teaching robots right wrong oxford oxford university press wright robert nonzero logic human destiny new york pantheon zuboff shoshana age surveil ance capitalism new york public affairs chapter social failure modes technology ethics ai engineering perspective jason millar introduction case —the quebec bridge august steel cantilever bridge spanning st lawrence river near quebec city construction nearing completion1 engineers noticed structural beams bending initiated investigation discovered calculations made early design phase gone unchecked resulting design insufficient support full weight bridge unfortunately engineers unable communicate information construction crews time one fateful day workers nearing end shift beam failure thank various participants two workshops held stanford university one apple one university toronto’s centre ethics gave generous comments drafts chapter particular thanks owed brilliant shannon vallor presented detailed helpful commentary political theory workshop stanford rob reich josh cohen sergio sismondo celeste parisi critique early drafts anne newman johannes himmelreich ted lechterman fay niker lindsey chambers hannah carnegyarbuthnott desiree lim laura gillespie provided valuable feedback stanford eis postdoc workshop support research provided postdoctoral fellowships social sciences humanities research council canada sshrc mccoy family center ethics society stanford jason millar caused south structure bridge col apse killing seventyfive eightysix workers bridge time2 case —google glass designed wearable piece wifienabled computing technology early 2010s google glass resembled pair glasses small headsupdisplay place lenses camera integrated one arm glasses wearers could search web view results display capture video pictures communi cating device using voice commands early adopters sighted wearing glass everywhere google glass quickly widely criticized privacy grounds owing wearer’s ability capture record images surreptitiously number social often private settings think urinals3 also raised number health related concerns additional importantly early google glass wearers ridi culed mainstream media social media likely person despite technical sophistication google glass discontinued shortly limited precommercial debut7 engineers people impacted technology design could benefit new analytic toolkit helps clarify link ethical issues raised ai technologies design decisions shape technologies chapter propose toolkit approach examine common characteristic techno logical artifacts8 date examined deserves attention technological artifacts break result mechanical electrical c pearson n delatte “col apse quebec bridge ” j perform constr facil –r eveleth “google glass wasn’t failure raised crucial concerns” wired december httpswwwwiredcomstorygoogleglassreasonableexpectationofprivacy pogue “why google glass creepy” scientific american june httpswww scientificamericancomarticlewhygoogleglassiscreepy dorkiness described far worse mere “nerdiness” see wohlsen “guys like could kill google glass ever gets ground” wired may httpswww wiredcom201305inherentdorkinessofgoogleglass doubt whether “dork factor” blamed failure google glass check tumblr titled white men wearing google glass l eadicicco peckham jp pullen fuitzpatrick “the successful technology failures time” time april httptimecom4704250mostsuccessfultechnology techfailuresgadgetsflopsbombsfails r metz “google glass dead long live smart glasses” mit technology review november httpswwwtechnologyreviewcoms532691googleglassisdeadlonglivesmartglasses term “technological artifacts” understood quite colloquial interchangeable terms pick stuff humans design build devices products technologies widgets gadgets things etc throughout chapter use term interchangeably “technology” “product” “artifact” social failure modes technology ethics ai physical defects ful accounted design quebec bridge also break result social defects ful accounted design google glass call failures resulting social defects social failures propose add underlying causes lead social failures— social failure modes—to list failure modes worth studying detail thinking designing technology explicit detailed understanding social failure modes properly applied engineering design practice could result fuller evaluation social implications technology either upstream design engineering phases product release ideal studying social failure modes improve ability anticipate reduce rate severity undesirable social failures prior releasing technology wild understanding common failure modes improved ability anticipate reduce rate severity undesirable mechanical electrical physical failures9 least three relatively straightforward reasons study social failures seek reduce rate severity social failures technology social fail ures like failure break product thus depriving individual users society whatever benefits artifact would otherwise deliver10 andor deliv ering harms upon individual users society final improved understanding social failures explain wrong artifact led failure thus lead ing targeted improvements social aspects artifact’s design thus better understanding social failures technology lead better technology func tional ethical sure goal suggest social failures social failures describe herein nonphysical failures deserve attention analyzing successful technology unleashed society nonphysical failures one could point equal deserving examination two brought attention economic political failures11 economic failures understand occur product fails result fit within particular market product might expensive could fail deliver right kinds value propositions intended users political failures understand occur artifact fit prevailing standards unable force new ones fails appease important political actors analysis kinds failures worth study beyond scope chapter however also worth noting difficult treat physical social economic political failures easily draw impenetrable boundaries around various failures understood multiple sides artifact choose focus exclusively physical failures objects analysis engineering arbitrarily failures desirable designed minimize overall damage harm direct harm appropriately crumple zones vehicles designed absorb energy crash focus artifacts designed good purpose mind little say particular thanks sergio sismondo alerting two categories failure jason millar artifact accurately appropriately understood according language physical sciences goal understand artifact exists society natural habitat physical characteristics one among many vantage points observe chapter focus starting conversation social failure modes tech nol ogy proposes additional vantage point observe artifacts new way understanding technology “work” “break” method ological perspective build toward understanding spanning conceptual gap two academic worlds one side gap theories philosophy sociology anthropology focused primarily social ethical dimensions technology provide detailed examinations social dynamics indi viduals societies technologies well rich vocabulary thinking causes technology work break side theories sci ences engineering focused primarily physical aspects technology ways reconfiguring matter make things provide detailed examinations physical dynamics technology well rich vocabulary understanding causes technology work break i’ve laid things worlds concerned understanding technology works breaks conceptual gap may seem smal believe project bring vocabulary used describe social dimensions tech nol ogy contact vocabulary used describe physical dimensions tech nol ogy way avoids demanding either buckle other’s force combining vocabularies makes richer descriptive mative accounts technology furthermore whatever practical gains made understanding social failure modes undoubtedly require social apparatus incorporated technical practices practical gains therefore require coopera tion uptake among command physical world namely engi neers span gap important aspect project making social apparatus compatible technological used concept social failure mode must designed fits well world engineering considerations mind begin chapter making explicit link social failures ethics ai ai seems lend urgency better accounting social dynamics technology design describe different ways artifacts break physical offer overview language typical deployed describe things break discussion physical failures failure modes lays necessary groundwork frame concept social failure social failure modes social failures always render technology broken traditional sense ie physical unusable—as describe things technology suffer social failure yet still “function” question worry social failures first place response question describe chapter within sections “social failures social failure modes” “the ethical dimensions social failures” social failures break technology raise underscore ethical concerns thus fleshing primary normative social failure modes technology ethics ai claim good reasons studying avoiding social failures technology provide rudimentary social failure mode analysis microsoft’s tay—a particularly problematic ai—as case study il ustrating one might approach using proposed toolkit begin explain better understanding social failure modes particularly important would particularly beneficial engineers designing robots ai social failures ethics ai much literature ethics ai recently emerged concerns describing ai applications result problematic ethical issues issues tend cataloged variety ethical concepts including limited trust trustworthiness accountability justice bias fairness interpretability explainability power control gender privacy discrimination truth equality humans reify concepts practice actions within relationships institutions attaching concept set social norms help delineate actions acceptable unacceptable permissible impermissible take trust example might trust person sensitive personal information person demonstrated willingness ability divulge important information entrusted might consider person trust worthy know certain caring dispositions aligned values believe respond appropriately pressed divulge personal information thus person considered trusted trustworthy actions relationship adhere social norms define trusttrust worthiness similarly institutions codify norms defining trusttrustworthiness policies processes thus signaling institution trustworthy trusted especial cases consistently apply policies true bias interpretability ethical concepts mentioned earlier—each defined practice set accompanying norms designing ai indeed describe chapter designing al technology engineers inevitably embed social norms artifact people experience norms interacting artifact norms engineered ai shape underlying decisions resulting humanai interactions thinking back trust example imagining asked trust ai personal information kinds norms engineer ai define ethical character divulge personal information inform particular instance divulging personal information choices make potential divulgences describe chapter engineered norms undermine normative expectations regarding trust interac tions ai could raise serious ethical issues result ai could suffer social failure develop robots ais autonomous jason millar required delegate previously humandominated decisionmaking ais interact us among us behalf12 understanding relationship social norms technology design decisions engineers make takes sense urgency robots ai robots ai performing among us increase autonomy sophistication increasingly performing social norms necessarily embedded social norms therefore seen critical social backdrop upon much ai designed would benefit developing analytic designengi neering toolkit help translate technical social engineering humanities bring social dynamics technology foreground engineering design hence propose rigorous study social failures underlying social failure modes step direction talking stuff breaks brief primer physical failures failure modes everything make breaks eventual joints crack repetitive strain metal surfaces erode exposed weather tires wear friction bolts loosen vibration circuits fizzle heat moving electrons pipes burst pressure overloaded beams buckle shear list physical failures potential break one technology long grows proportion complexity system parts increases probability failures occur simple fact things make—that break eventual y—can read pessimistic discouraging it’s stuff could cause engineer faced inevitability failures throw hands air physical failure encountered also rep resents opportunity study underlying causes failure physical failure modes study leads breakthrough understanding thing failed also lays foundation understanding things fail future researching things fail helps prevent future failures kind thoroughly optimistic perspective optimism drives research physical failures fueled recognition physical things fail according physical laws engineers charge quebec bridge knew able predict eventual failure even j mil ar kerr “delegation relinquishment responsibility prospect expert robots” robot law ed ryan calo michael froomkin ian kerr cheltenham uk edward elgar press –see delegation chapter “the ethical dimensions social failures” social failure modes technology ethics ai circumstances stopped preventing beams don’t break randomly break predictably failure modes grouped characterized type buckle yield regularly according physical properties eg type material dimensions beam compiling catalog physical failure modes allowed engineers anticipate potential failures designing things additional knowledge engineers make explicit informed decisions physical makeup devices ful take account many ways component could fail use certain fail ures ultimately deemed acceptable given various design constraints others avoided costs upshot detailed understanding physical failure modes lead deliberate safer technology designed fuller standing benefits risks harms associated particular design decisions optimism possibility better understanding failure modes paid years started investigations physical things break evolved much broader analysis things processes fail result meas ur ble successes failure mode analysis cornerstone good design remainder chapter argue similar optimism justified acted upon comes investigating cataloging many ways technology suffer social failures it’s justified good reason believe social norms identified understood within target user group soci ety technology deployed extent allowing us reasonably predict technology interact eg support undermine andor come ten sion social norms benefits avoiding social failures technology ground normative claim ought investigate catalog social failure modes social failures social failure modes zimbabwe bush pump success zimbabwe bush pump—a simple handoperated water pump like one might find old farm protagonist story narrated marianne de laet annemarie mol—beautiful il ustrates concept social failure technology13 follows condensed version story see picture bush pump looks like rudimentary hand operated pump intentional rustic designed specifical use rural zimbabwe de laet mol “the zimbabwe bush pump mechanics fluid technology” social studies science –jason millar clean water precious resource use one places container spout grabs hold wooden lever top proceeds pump drawing water well upon pump sits zimbabwe bush pump like many rudimentary handoperated water pumps market fact succeeded similar looking pumps failed precisely pumps fail establish social norms required work transgress already established social norms common pumps’ use context rural zimbabwe bush pump clear designed establish requisite social norms conform already existing social norms lead success de laet mol argue pump work addition reliably pumping water—its intended mechanical function—it must also seen artifact locals trust use must reliably pump clean water satisfying three specifications requires mere mechanical design considerations14 unlike pumps mechanical adequate various sociocultural features incorporated bush pump’s design satisfy role trusted source clean water starters order prevent contamination wel community members must convinced diligently maintain pump bush pump’s designers accom plish demanding involvement whole community various aspects instal ation pump drilling wel example designed social activ ity motivates sense community ownership wel rather using mechanical dril quick efficient tend operated nonlocals bush pump relies well special handoperated drill known vonder rig requires community involvement work video distributed factory shows sometimes operating rig turns vil age feast vil age women push iron crossbar drive auger ground vil age men sit bar weigh children dance around15 well drilled must capped headworks small concrete brick structure sits atop well provide adequate water runoff seal deadly e coli contamination like drilling constructing headworks designed community affair helps establish norms ownership bush pump16 de laet mol nicely summarize required install working bush pump order pump preserves community needs look attrac tive properly fixed levers wellmade concrete aprons must also capable gathering people together inducing follow welldrafted id id id social failure modes technology ethics ai instructions must come vonder rig invite people push bars sit dance around must seduce people taking care thus boundaries around community pump may widely drawn indeed embrace community17 thus drilling wel assembling pump constructing headworks variously involve whole local community communal activities designed generate strong sense community ownership installed pump turn helping estab lish critical social norms around pump use maintenance18 one crucial social element story bush pump helps explain succeeds others fail rather simply relying geological data determine best site pump bush pump’s instruction manuals documentation “state clearly repeatedly local water diviners consulted decision siting water hole made”according unicef worker nongovernmental organizations intent drilling wel locations based solely geological data issues efficiency proximity certain buildings livestock etc regularly witness failure pumps local diviners consulted leading local women consider wel “dead”thus bush pump trusted part conforms social norms attached wis dom local water diviners examining role sociocultural aspects play design bush pump undercuts idea similar pump mechanical speaking would work rural zimbabwe indeed telling bush pump’s story de laet mol emphasize mechanical superior pumps failed precisely lacking sociocul tural design elements pumps poorly maintained become contaminated pumps placed without water diviner’s endorsement ignored social failure dynamics see bush pump’s story also story users’ social norms fun damental related artifact either working breaking bush pump works mechanical sound designers figured way encour age community members ie users feel sense collective ownership toward thus care prevent contamination final design respects trust norms associated local water diviners used pumps fail including bush pumps hand fail social either fail encourage requisite social norms violate impor tant existing ones two senses water pumps suffer social failures talk pumps breaking due mechanical failures talk pumps id id id id jason millar breaking due social failures pumps suffer lack community ownership rural zimbabwe break cared become contaminated thus social failures sometimes lead physical failures though case social fail ure root pumps trusted women rural zimbabwe break ignored google glass described similar terms21 though people happy use celebrated technical capabilities many others rejected violated important existing social norms health privacy coolness norms google glass broke alternatively one might say google glass failed shift generate social norms required accepted used ie work example google glass designed way successful shifted society’s notions coolness privacy new norms encour aged intended use would suffered social failures bush pump google glass mind offer initial definition social failure artifact suffers social failure social norm designed comes ten sion accepted social norm held users relevant stakeholder extent tension diminishes prevents intended use functioning artifact social norm mean social norm designed artifact first social norm sense using understood mean behavioral rule r followed sufficiently large set individuals within social group22 definition r could held social group p group p′ kind social group refer rather flexible could particular citizenry eg canadians professional group eg physicians engineers identifiable group eg iphone users hobby farmers cyclists key feature group thinking social failures members share act least one reasonably identifiable social norm point preemptive clarification might useful find bristling sidebyside comparison bush pump google glass former provider basic goods latter mere luxury item you’re good company aim chapter provide overall moral assessment technologies aim provide analytic toolkit explicitly links engineering design social norms way empower engineers consider nuanced way interplay design social norms daily work leave overall moral assessment particular technologies future work would encourage anyone interested work consider using social failure modes useful analytic tool communicating engineers reasons endorsing rejecting particular aspects features technologies c bicchieri grammar society nature dynamics social norms cambridge cambridge university press social failure modes technology ethics ai several ways describing social norms designed artifacts23 social norms identified political relations artifact imposes users24 consider nuclear reactors according winner25 impose set authoritarian norms society installed nuclear reactors extremely expen sive build maintain need strictly secured order maintain safety results complex surveil ance security regimes deployed around facilities workers nuclear material fuel waste dangerous valuable national security threat weaponized many parts used building maintaining plant safety critical requiring additional strict security regimes manage entire supply chain waste disposal process contrast democratic norms embedded windmil windmil relatively inexpensive installed farmer’s field farmer less produce haz ardous waste thus impose strict security regimes impact nuclear reactors windmil similar designed produce electricity political relations embedded artifact could different social norms also reflected work delegate artifacts average front door building il ustrative here26 us share social norm comes front doors general kept closed norm reflects number underlying reasons closing front door maintaining comfort able indoor temperature saving energy costs keeping bugs keeping burglars keeping wind keeping family pets list goes doors tend ignore social norm require human attentiveness helping hand keep closed indeed remain closed doors operated children often require help additional person nearby adult call repeatedly “close door” however clever humans found way delegate work required enforce norm small artifacts attached doors little mechanisms usual powered spring designed automatical close doors opened thus embodying enforcing social norm keep front doors closed take starting point fact social norms unavoidably designed technological artifacts fuller explanation starting point see j mil ar “technology moral proxy autonomy paternalism design” ieee technology society magazine –“users” understood broadly include direct users well stakeholders eg policymakers citizens etc impacted directly indirectly artifact l winner whale reactor—a search limits age high technology example largely borrowed bruno latour also describes delegate ethical missing masses sociology mundane artifacts” shaping technologybuilding society ed bijker j law cambridge mass mit press –for similar argument technology’s ability script prescribe behavior see akrich “the description technical objects” shaping technologybuilding society ed bijker j law cambridge mass mit press –jason millar engineers also delegate flexible social norms technology via “settings” target norms27 take privacy settings like designed facebook’s user interface define facebook’s behavior respect personal data users upload share platform settings allow user shape facebook’s behav ior based normative privacy expectations example allowing users partial limit photo sharing friends however facebook’s design decisions also bound possibilities individual shaping facebook users cannot example upload photos platform decline share photos facebook thus settings reflect shape bound social norms delegated technological artifact final identify social norms embedded artifacts mediate perceptions actions world verbeek argues mediating way perceive reality technology “actively contribute moral decisions human beings make”using medical imaging technologies example writes body fetus perceived interpreted decisions made way technologies fundamental shape people’s experiences disease pregnancy unborn children ultrasound instance makes quite easy determine thickness nape neck fetus gives indication risk unborn child suffer down’s syndrome fact ultrasound scan made therefore lets fetus present terms health disease terms ability prevent children disease born29 result mediating role ultrasound technology elevated stand ard care among healthcare professionals— perform ultrasound –weeks weeks pregnancy among widely accepted social norms norm cascading effect imposes new norms women encounter standard pregnancy confronted results ultrasound sketched picture section il ustrating several ways describe social norms designed technology social norms matter analysis social failures ones tend align transgress important social norms held particular group impacted technology say privacy important particular group potential users engineers embed privacy norms product important design consideration product trans gresses potential users’ privacy norms severely enough likely suffer social failure j mil ar “ethics setting autonomous vehicles” robot ethics autonomous cars artificial intel igence ed p lin r jenkins k abney new york oxford university press –pp verbeek “materializing morality design ethics technological mediation” science technology human values id social failure modes technology ethics ai two social failure modes zimbabwe bush pump google glass suggest starting point analysis characterization two types social failures refer social failure modes social failure modes help flesh definition social failure certain social norm held users order work ie used intended required norm fact held users saw bush pump order cared community norms ownership established way elaborate community activities centered around new pump result designing bush pump installed community affair bush pump’s designers designed norm pumps must cared community avoid contamination pumps fail social often designs fail establish supportive caring norms google glass order social acceptable people’s privacy norms would shift way make wearing cameras record surreptitiously social acceptable perhaps even cool designing glass way google’s engineers designed norm acceptable wear cameras record surreptitiously tension widely held stable societal norm acceptable wear cameras record surreptitiously thus existing norms came tension designed norms supportive norms absent glass suffered social failures transgresses accepted social norm held users social failure mode straightforward see water pumps designed agnostic respect social norms surrounding water diviners rural zimbabwe pumps designed norm install pump wateryielding wel however agnosticism role local water diviners result installed pump transgressing local norm trust water well endorsed water diviner pump installed well endorsed local water diviner runs risk transgressing local norm since wateryielding well may trusted likewise google glass evidenced creation glassholes clearly transgressed existing norms privacy coolness30 said norm transgressions created equal though distinction vague somewhat controversial social norms seem come two broad psychological eveleth “google glass wasn’t failure raised crucial concerns” jason millar categories conventional moral31 prototypical examples conventional norms include “wearing genderinappropriate clothing eg men wearing dresses licking one’s plate dinner table talking classroom one called teacher”prototypical moral norms hand tend include prohibitions killing injuring stealing people moral norms tend categorized regarded less authority dependent universal ie apply crosscultural involving rights violations serous nature conventional norms importantly many cases though analytic focus social failures involv ing moral norms moral norm transgressions underscore unavoidable moral dimension engineering design focus thus help delineate permissible impermissible design decisions suggest certain obligations engineers virtue design decisions must navigate engineers already partial embraced reality social failures caused safety privacy norm transgressions already general considered impermissible resulting general obligation engineers design safety increasingly privacy canada example profession’s code ethics requires engineers “hold paramount safety health welfare public protection environment pro mote health safety workplace”other social norms upon analysis could give rise similar professional constraints discuss next section conventional norms contrast tend regarded authorityinstitution dependent local applicable ie apply cross cultural even among different groups within single cultural boundary involve rights violations transgressions less severe involving moral norms using moralconventional distinction guide subdivide social failures resulting norm transgressions two subcategories conventional norm transgressions moral norm transgressions il ustrate social failures resulting rights violations say privacy transgressions categorized moral norm trans gressions whereas social failures resulting institutional norm transgressions say mobile phone can’t “muted” quiet space categorized conventional norm transgressions discuss following section moralconventional dis tinction serve useful guide anticipating nature harms resulting social failures norm transgression type various discussions moralconventional distinction controversies questions raises see e machery r mallon “evolution morality” moral psychology handbook ed j doris moral psychology research group new york oxford university press kel stich kj haley sj eng fessler “harm affect moralconventional distinction” mind language –s nichols sentimental rules natural foundations moral judgment new york oxford university press kel et al “harm affect moralconventional distinction” engineers canada “the code ethics” public guideline code ethics https engineerscanadacapublicationspublicguidelineonthecodeofethics social failure modes technology ethics ai ethical dimensions social failures argument far focused sketching conceptual apparatus describe social failures social failure modes section turn normative aspect project propose two straightforward reasons care investigate order mitigate avoid undesirable social failures technology first reason deprivation benefits group users implicated stakeholders would otherwise derive technology works intended assuming technology designed deliver set goods benefits group individuals eg clean water clean air improved medical diagnoses enhanced communication friends family novel modes interaction one’s environment etc social failures insofar prevent technology used intended stand reduce benefits derived technology social failures deprive users important benefits water pumps become con taminated trusted deliver benefits potable water social failures deprive users benefits ways trivial least far less costly assume case many intended uses google glass addition depriving people benefits social failures directly harm individuals giving us reason investigate avoid social failures tech nol ogy34 contaminated wel deprive communities clean water also allow e coli infect kill members community google glass surreptitiously recording surrounding environment host standing urinal crowded washroom violates privacy every recorded individual sharing otherwise semiprivate space use moralconventional distinction anticipate individu als harmed social failure technology interpret severity harm importantly evaluate nature harm way provides guidance moral permissibility particular technology moral norm transgressions definition tend result rights violations tend considered serious nature thus trivial assume harms resulting moral norm transgressions threaten break technology conventional norm transgressions may pose lower risk regard less trivial however implication every social failure resulting moral norm transgression suggests something potential moral problematic technology see clearly impact understanding social failure modes ought guiding ethical engineering practice knowledge social failure modes frame discussion whether design technology social failures also deliver harms nonhumans fact deserves careful consideration beyond scope chapter social failures result contaminated rivers pol uted air loss habitat biodiversity etc jason millar way providing clearer links designed features moral norms thus helping distinguish design decisions users consider permissible impermissible corol ary complete thought better understanding social failure modes help define boundaries ethical design decisions every social failure technology resulting moral norm transgression potential interpreted insofar social failure reasonably predictable ethical design failure part responsible engineers thus thorough understanding social failure modes help distinguish permissible impermissible technologies features thereof determining whether particular moral norm transgression ethical failure complicated business social norms justified technology transgresses particular unjustified moral norm could count engineering victory though clear norm violation effect users’ willingness use technology intended would considered social failure tech nol ogy according definition offer addition technology might establish unjustified controversial moral norm without suffering social failure example china cur rently rolling complex social networking platform calculates ranks citi zens according social credit score ostensibly curb people’s behavior public help determine distribute goods among citizenry35 various new norms likely emerge result platform’s ubiquity strike many clear unjustifiable violation basic freedoms according definition offer however platform would suffer social failures failed used intended owing existing norm violations failed establish requisite norms intended use critical occurrence nonoccurrence social failure technology taken evidence technology’s moral permissibility impermissibility moral ambiguity social failures echoes moral ambiguity many new tech nologies whose social meaning takes time emerge stabilize ultimately differ group group36 “the telephone typewriter” verbeek points blind hard hearing help individuals hear write”telephones also eased interpersonal communication altered speed information propa gates global enabled surreptitious government eavesdropping wiretaps pointing moral ambiguities inherent social failures inter preted absolving engineers moral responsibility designing technologies intent disrupt justified norms establish unjust norms rather mining concept social failures technology moral ambiguity social failures think important maintaining descriptive accuracy concept anchors justifications particular norms social contexts technologies deployed without divorcing engineering practice absolve engineers hvistendahl “inside china’s vast new experiment social ranking” wired december httpswwwwiredcomstoryageofsocialcredit w bijker hughes pinch social construction technological systems cambridge mit press verbeek “materializing morality design ethics technological mediation” social failure modes technology ethics ai responsibilities designers addition concept provides analytic apparatus explicitly links design social dynamics technology diverse social groups go negotiating norms engineers acting good faith members larger groups deploy concept anticipate evaluate social failures design activities fuller discussion dynamics design moral permissibility particular technologies beyond scope chapter however believe dis cussion would benefit ful developed language social failures one investigates links particular technological features particular norms thus engineering practice social failure mode analysis microsoft’s tay mentioned section “talking stuff breaks brief primer physical failures failure modes” designing ai requires engineers embed social norms artifacts ais interact us among us behalf sketched initial taxonomy social failure modes throughout chapter one see particular design decisions regarding social norms shape ethi cal nature artifact furthermore reach ai society broad imme diate often result background systemwide software update adds certain urgency understanding social failures particular design decision could trigger il ustrate link social failures ethics ai final example turn microsoft’s tay microsoft’s tay twitter chatbot ai designed interact twitter users fourteenyearold teenage girl tay lived twitter reach broad—tay could interact twitter’s roughly seventy million active monthly users tay also designed “learn” carry normal twitter conver sations using everchanging set prior interactions learning dataset meant design interactions tay twitter users would shape tay’s future behavior words microsoft made twitterverse responsible teaching young tay behave interacting people twitterverse parent tay responsibly within day tay behaving like racist neonazi misogynist forcing microsoft pull tay’s plug amid widespread public controversy38 might fourteenyearold girls tay’s target user group tay could learned quite pleasant interactions target users j vincent “twitter taught microsoft’s ai chatbot racist asshole less day” verge march httpswwwthevergecom201632411297050taymicrosoftchatbotracist kleeman “here microsoft twitterbot’s craziest racist rants” gizmodo march httpsgizmodocomherearethemicrosofttwitterbotscraziestracistra1766820160 jason millar larger sociotechnical system tay embedded included numerous callous twitter users intent shocktesting tay sure average twitter user interacting tay brief existence conform interactional norms average fourteenyearold one hopes thus tay suffered multiple social failures tempting brush tay foolish publicity stunt bound go wrong al internet twitter particular known trol charitable approach however reveals tay great learning opportunity specifical quick dismissal represents missed opportunity apply sophisticated failure analysis tay one accurately accounts social dynamics caused tay fail let us first examine absence supportive norms tay microsoft required tay succeed tay work wel needed experience large number social acceptable twitter interactions tay required support conversational norms typical would general considered “polite society” conversa tional norms twitter unpredictable best especial two users know deeply unethical worst certainly representative conversational norms rest society instead providing supportive conversa tional norms twitterverse helped break tay tay’s learning algorithm exposed unsupportive conversational norms tay suffered second social failure repeatedly transgressed accepted conver sational norms existing “polite society” indeed kinds conversational norm transgressions tay committed mere conventional transgressions moral nature response tay’s behavior microsoft quickly criticized stakeholders found tay’s behavior ethical impermissible microsoft responded responsibly situation shutting tay applying social failure mode analysis artifact like tay allows us focus design efforts analyzing shaping social dynamics required artifact work based rudimentary taxonomy provided chapter means analyz ing shaping requisite supportive norms resulting norms characterizing artifact’s behavior tay work design effort required understand current conversational norms twitter given current state change conversational norms twitter would support tay’s social appropriate learn ing result ethical behavior notice focus social failure modes helped us move state relative ignorance respect tay’s failure toward much specific design activities hold promise goal anticipate social failure modes occur could analytic toolkit engineers need helps clarify link ethical issues raised ai technologies design decisions shape conclusions assume chapter engineers general intend new technologies make world better worse place clearly many technologies along lines social failure modes technology ethics ai assume controversy claiming engineers general non trivial motivated make things improve lives individuals societies live also motivated avoid making things harm indi viduals andor societies fair assumptions reflected consistently various codes ethical conduct engineers obliged adhere professional dealings insofar engineers prevented acting motivations professional settings work done improving engi neers’ professional settings insofar engineers motivated work work done improving profession insofar technologies fail often resulting harms work done understanding fail prevent failures moving forward social implications technology long studied detail outside profession many discussions suggest norms embedded technology come tension accepted social norms held users tech nol ogy break technology break suffers social failure however practical conceptual analytic apparatuses describing anticipating links technology social norms engineering practice required put insights practice help bridge gap studying social implications technology designing technology proposed working definition social failure described two social failure modes analytic tools help expose clarify inextricable connections design failures social norms though much work done build sophisticated understanding social failures technology ethical implications engineering practice one prac tical ethical insight already apparent working knowledge social failure modes help make better technology technology aligns people’s robustly justified social norms better technology undermines bibliography calo r froomkin kerr eds robot law northhampton edward elgar collins hm r evans rethinking expertise chicago university chicago press friedman b ph kahn jr “human values ethics design” humancomputer interaction handbook ed ja jacko sears –mahwah nj lawrence erlbaum associates latour b pandora’s hope essays reality science studies cambridge harvard university press lin p r jenkins k abney ga bekey eds robot ethics oxford oxford university press van den hoven j n doorn swierstra bj koops h romijn eds responsible innovation innovative solutions global issues springer chapter humancentered approach ai ethics perspective cognitive science ron chrisley increasing role artificial intelligence ai machine learning technology lives raised enormous number variety ethical challenges seen diverse topics covered volume addition ethical chal lenges yet come ones cannot currently anticipate try respond vast array challenges individual ad hoc manner long run principled structured response likely guidance chapter propose responses particular questions concerning ethics ai responses share unifying perspective humancentered approach hope beyond offering solutions particular problems considered responses general interest il uminating enough shared humancentered perspec tive facilitate likeminded responses number current future ethical chal lenges involving ai said humancentered approach airobot ethics amounts important consequence central claim chapter making ethical judgments area resist temptation see robots ethical agents patients foreseeable future ethical hazard follows seeing humans robots ethical analogous follows seeing ethical distinct kinds much say follows meant support claim identify instances current practice fail heed warnings claim suggest ways avoiding anthropomorphic error claim identifies still minimizing likelihood certain ethical adverse outcomes involving robots ai general central claim seem odds otherwise attractive naturalism ethics mind human adoption humancentered approach ethics ai arises lifelong interest cognitive science cognitive science ron chrisley interdisciplinary search understanding mentality general cognition part natural world use understanding provide explanations mental phenomena behavior systems minds one might think naturalism particularly mechanistic functionalist physicalist form many traditional cognitive scientists embrace even implicitly encour ages us see glorified robots rough equation would either support extension concepts ethical agent patient suitably programmed robots ai systems encourage ethical nihilism humans robots contrary believe seeing humans part natural world undermine understanding makes humans ethical different robots nonhuman animals rather gives understanding scientific plausibility conceptual clarity properly considering place natural world see true nondualist reasons correct see us robots least forseeable future ethical beings nevertheless theories methods cognitive science largely remain background chapter focus instead humancentered approach support putting robots place mean humancentered approach we’ll better equipped answer question full instances generalize things said outset give initial idea approach is—and humancentered approach ai ethics advocating two key aspects emphasis human welfare emphasis human responsibility first aspect contrast approaches ai ethics take seriously ethical obligations concerning purported welfare artificial agents approaches focus questions expense increasing human pain suffering expense increasing animal pain suffering similarly second aspect humancentered approach contrast approaches focus questions humancentered approach ai ethics humancentered approach doesn’t answer questions like negative dismisses impertinent worse presupposing view wrong headed risks distracting us many real ethical issues misdiag nosing real issues manage address1 humancentered approach starts following deflationary view machine ethics deflationary view robot ai system currently existence could ethical responsible kind thing toward ethical obligations2 might inclined stop reading point believing dismissed without argument interest ai ethics fair enough previously posed questions al uring excite imaginations interest standable attempting answer questions good way explore features limits concepts involved stating worthwhile consider ethical issues arise futuristic thought experiments involving ai robots worthwhile even pressing consider ethical issues con fronting us way unduly distorted consideration counterfac tual futuristic robotasethicalagentorpatient cases wish confused ai pessimist let make one thing explicitly clear deflationary view applies ai systemsrobots currently existence foreseeable future taking deflationary view humancentered approach advocating thereby assume humans beings biological related humans animals could ever ethical responsible agents deserving ethical concern example advocating deflationary view believe fundamental inability artifacts nonbiological systems whatever provenance minds experience emotion conscious contrary point principle might someday robots ai systems ethical responsible kinds things toward ethical obligations fact likely foreseeable future3 unlike ai ethics addresses previously posed questions humancentered ai ethics humancentered ai ethics substantial different perspective see eg joanna bryson information technology –perhaps unsatisfyingly argue claim one reason thinking current ai systems moral agents lack capacity judgment specific almost technical sense word see brian cantwell smith promise artificial intel igence reckoning judgment cambridge mit press –thus others may correct accounts conditions would met ai system robot enjoy ethical status eg john sullins “when robot moral agent” international review information ethics –it view conditions remain unmet foreseeable future ron chrisley urgently needed since seems likely continue use ai systems robots responsible responsibility even beyond eventual advent ai systems ethical status humancentered ai ethics continue indispensable even substantive ai ethics based obligations toward ai systems robots becomes necessary humancentered approach ai ethics advocating deflationary another related aspect hold current ai machine learning ethical game changer requires radical break ethical thinking order accommodate artificial agents responsible actions andor bear respon sibility humancentered approach offered conceptual con serv tive urging us try use precedent past wisdom conventional metaphysics much possible trying resolve ethical issues involving current nearfuture ai technology approach robots ai systems despite autonomy learning decisionmaking capabilities may best treated ethical deliberations manner continuous deal technologies nonpersonal boundary conditions potential affecting praise blameworthiness people involved—not candidates praise blame personal sub jects whose harm benefit figure special way personal wellbeing ethical evaluation human action hand cannot afford com placent new highly adaptive flexible technologies unlike require new ethical concepts tools new concepts tools need developed diagnosing situation terms arrival ethical scene new source target ethical responsibility questions listed previously right relevant ones system “implant” person trained several years person relies function everyday life count harm person usual harm associated property loss responsibility harm distributed across various people orga nizations involved enable us perform ethical ai technologies might instead compromise ethical competence humancentered approach ai ethics questions good indications apply humancentered perspective focus exclusively welfare responsibility ethical agents scene humans4 situations tricky see achieve focus properly remainder chapter look two kinds case better flesh humancentered approach referring area inter est using cumbersome phrase “ai systems robots” fair enough since humancentered approach ai ethics applies broadly remainder chapter use phrase “robots” focus especial social robots ones designed interact humans opposed say industrial assemblyline robots social robots scene much cases involving disembod ied ai temptations inflationary ethics concomitant need keep hold insights humancentered view strongest thus focus social robots make easier see points wish make streamline prose insights thereby uncover apply believe inclusive class ai systems robots general implications humancentered approach corresponding two aspects humancentered approach identified outset welfare responsibility look two nonobvious counterintuitive impli cations approach harming robots issue harming robots emotional charged divided example one look david harris smith frauke zeller’s hitchbot actions authors fate people’s responses treatment another example kicking shoving robots boston dynamics researchers use demonstrate robustness robots people’s emotional charged reactions upon seeing videos demonstrations one might think proponents humancentered approach ai ethics hands tied according deflationary view robots kind thing harmed question dismissed immaterial today’s pressing ethical concerns ai isn’t quite right animals also “on scene” impact ai robots also taken consideration ron chrisley issue cannot dismissed easily talk “harm” beg question let’s make clear context mean cover actions kind performed humans animals would cause harm neutral language ethical hit—or disfigure mutilate on—robots concerned ethical prohibitions damaging someone’s property general may seem humancentered approach proponents still bound since actions would cause harm prohibited real case actions cause harm mere consideration whether robot’s welfare relevant even answered negative done harm distracted us proper consideration humans situation agent harm observers even mutilating robot harm robot robot kind thing harmed mutilation may fact harm humans involved—an emphasis heart humancentered approach idea says something wrong abuse robots similar immanuel kant says wrong abuse animals commit anyone agreeing kant animals abused idea even robots cannot harmed least sometimes worst unethical think would consider grossly inappropriate someone willful sadistical ie part performance art experiment political protest etc dismember doll opposed say toy car stage front young children key feature dol ’s sharing degree human form robots sure share visual form much dol beyond share human form higher abstract sense much greater degree witness ability respond questions linguistic sounds acquire information environment act conditional upon learn decide remember prefer assist make emotional displays forth could argued acts violence upon robots conceivably cross unethical brutalize agent perhaps witnessing act accounts differ harming something human form wrong familiar consequentialist likely deontological it’s wrong harm human form variants clear attempting make strong case view pointing view existence proof one take humancentered approach ai ethics still hold unethical abuse current robots situations also want highlight another point arises discussion although welfare responsibility humans ultimately mattered case mindlike cognitive abilities robots also played crucial role made issue one ethics ai rather ethics general what’s important note role abilities played making robots kind thing could harmed kind thing could responsible rather role humancentered approach ai ethics played novel technology involves new complex ways robots impact human welfare human responsibility5 robots extensions human responsibility taking humancentered approach ai ethics practical consequences robot design demonstrated considering approach say one way designing robots call logicbased ethical robot methodology think methodology direct descendant approach explored isaac asimov’s novels logicbased ethical robot methodology proposed action consequence reasoning action ethical permissible robots explicit ethical agents sometimes called explicit moral agents james moor’s sense “explicit ethical agents agents identify process ethical information variety situations make sensitive determinations done ethical principles conflict robots work reasonable resolutions”the intended outcome methodology avoidance ethical adverse situations also ability explainjustify robot behavior appealing infer ential trace governed generation example work employs ethical robot methodology comes matthias scheutz bertram malle7 authors consider ethical questions rob eldercare robot deliver pain medication even though cannot consult supervisor usual required authors say position r model human behavior would addition ethical reasoning ethics robot abuse see eg b whitby “sometimes it’s hard robot call action ethics abusing artificial agents” interacting computers –see also massimiliano l cappuccio anco peeters william mcdonald “sympathy dolores moral consideration robots based virtue recognition” philosophy technology –james moor “four kinds ethical robots” philosophy marchapril matthias scheutz bertram malle “think right thing plea moral competent autonomous robots” ethics ’proceedings ieee international symposium ethics engineering science technology ieee –see also b f malle “integrating robot ethics machine morality study design moral competence robots” ethics information technology –ron chrisley need capability empathy well ability generate justifications ie explanations norm violations contacting supervisor focus aspects moral competency paper rather develop general argument order avoid unnecessary harm humans autonomous artificial systems must moral competence”in line logical ethical robot methodology scheutz malle aim give robots said moral competence giving set logical axioms logical state ments encoding state world ability draw inferences ¬havepermissionr administerr h → o¬administerrhm obligation inpainh →oadministerrhm obligation ¬havepermissionr administerr h fact inpainh observation o¬administerr h 13mp oadministerr h 24mp ¬◊administerr h ∧ ¬administerrhm modal logic key ¬ negation → material implication ∧ conjunction obligatory ponens9 lines axioms lines encode facts world lines –follow deductively lines reasoning reveals dilemma obligatory robot administer medicine administer medicine point consider dilemma possible solutions rather reasoning presented hand concrete exemplar logicbased ethical robot methodology one might think logical ethical robot methodology direct conflict humancentered approach robots can’t moral competence one might say responsibility makes sense reason permit ted obligatory obligations permitted actions way find rapprochement logical ethical robot method ology humancentered approach one reject humancentered response heavyhanded misconstruing meaning axioms scheutz malle provided one need read “o¬administerr h ” encoding “it obliga tory robot robot administer medicine human” instead one could read statement merely encoding proposition state affairs robot administers medicine human ethical obligatory general statement ethical landscape tied particular agent obligation one obligation al simple kinds ethical systems situations scheutz malle address ing picture may adequate cannot adequate general differ ibid ibid humancentered approach ai ethics obligations permissions reasoning abstract states allowed obtain little use deciding act ethical one must addition know one located web obligations permissions problem robot located anywhere web web imperative force actions even less force could inferred logical reasoning proponent logical ethical robot methodology could instead reply doesn’t matter robot doesn’t actual obligations reasoning matters robot engaging kind reasoning would cor rect human arrives ethical correct behavior compare distinction genuine vs functional ethical status10 get desired result robot need ethical agent needs simulate one act agent obligations on—that get right outcome given differences permissions obligations one ask ethical agent robot simulate make difficulty clearer consider inferences logical ethical robot methodology used generation behavior explanation justification since assuming along robots cannot responsible justifications generated methodology apply actions humans robots “as if” robotframed justifications use help us construct actual humanframed ones far tel logical ethical robot methodology silent issue failure find mapping robot fauxjustifications actual human justifications moral hazard lead “moral murk” everyone interacting writing training making policy concerning deploying developing software designing invited take attributions responsibility robot face value given lack guidance allocate responsibility humans involved heart matter stated abstractly grasping insight difficult see exactly logical ethical robot methodology fail properly allocate responsibility humancentered approach must remedy deficiency specific example helpful particular important issues identified situation epistemic state mens rea humans involved crucial component evaluating ethical status actions consider autonomous military robot r war zone bridges b robot commandcontrol human h h deploy r patrol region contains bridges b among actions r perform destruction given bridge situation general ethical good destroy bridges would protect innocents attack—unless bridge mini hospital medical supplies case bridge destroyed accordingly r steve torrance ron chrisley “modelling consciousnessdependent expertise machine medical moral agents” machine medical ethics ed simon peter van rysewyk matthijs pontier ron chrisley designed even contact h acquires information likely hospital bridge destroy bridge time deployment h believes likely bridge hospi tal b h deploys r soon deployment r loses contact h must rely reasoning given via logical ethical robot methodology way bridge passing bridge b r acquires information likely hospital bridge b assessing b cameras say destroys bridge unfortunately despite information r received hospital bridge h held responsible destruction hospital logical ethical robot methodology silent issue responsibilities deals human subject unknown identity one made wrong call destroying bridge might might “let off” given acted best way best information time either responsibilities h responsibilities designers algorithm incorrectly assessed status bridge humancentered approach situation arrived one two ways first way keep logical ethical robot methodology intact supplement humancentered interpretative scheme abstract situation h performs action deploying r results ethical disaster destruc tion hospital mitigating mens rea–involving story involves epistemic state r h things stand cannot serve reduce h’s culpability11 perhaps things stand would take information r gleans contact h mitigate h’s culpability something like exter nal individuated epistemic states subjects using autonomous epistemic technology r purposes determining h’s culpability h’s ep iste mic state include information gleaned r even h r causal connection allows us arrive many would consider appropriate ethical result h’s diminished culpability without attributing r responsibility manner parallel case “robot harm” considered previous section “harming robots” resolution make essential reference cognitive states r example humancentered ai ethics action implica tions move need explored depth promising lead12 second humancentered way dealing situation goes beyond mere interpretive scheme instead proposing extension designs used logical ethical robot methodology proposed formalism one scheutz malle displayed earlier extended two ways thorough discussion scenario would analyze terms concept meaningful human control see eg filippo santoni de sio jeroen van den hoven “meaningful human control autonomous systems philosophical account” frontiers robotics ai feb art cf mihailis diamantis “the extended corporate mind corporations use ai break law” httpspapersssrncomsol3paperscfmabstractid3422429 humancentered approach ai ethics obligations permissions explicitly relativized subject apply ie making ◊ relation propositions variables range human subjects obligations permissions capable explicitly depending cognitive states subjects perhaps ai technology employed subjects second approach combined technological extended epistemic states solution proposed earlier approach r would per impossibile reason obligations permissions none would instead reason whether actions com patible h’s obligations permissions allow r derive genuinely ethical best course action also facilitate analysis correctly allocate responsibility conclusion chapter hope shown humancentered approach resolve problems ai robot ethics arise fact current foreseeble ai systems robots cognitive states yet welfare responsi ble particular approach allows violence toward robots wrong even robots can’t harmed also approach encourages us shift away designing robots human ethical deliberators rather slogan goes don’t seek build ethical robots seek build robots ethical found cognitive states ai systems robots may role play proper ethical analysis situations involving even virtue conferring welfare responsibilities systems robots even robots lack welfare cognitiveinformational states might make sufficiently resemble humans render unacceptable targets violence even robots cannot responsible cognitiveinformational states may relevant assessing culpabilitymens rea humans interacting bibliography anderson michael susan leigh anderson machine ethics new york cambridge university press arkin ronald c governing lethal behavior autonomous robots boca raton fl chapman bostrom nick eliezer yudkowsky “the ethics artificial intelligence” cambridge handbook artificial intel igence ed keith frankish william ramsey –cambridge cambridge university press ron chrisley coeckelbergh mark introduction philosophy technology new york oxford university press lin patrick keith abney george bekey robot ethics ethical social implications robotics cambridge mit press müller vincent c “ethics artificial intelligence robotics” stanford encyclopedia philosophy ed edward n zalta palo alto csli stanford university forthcoming sparrow robert “killer robots” journal applied philosophy –sparrow robert “the march robot dogs” ethics information technology wal ach wendel colin allen moral machines teaching robots right wrong oxford oxford university press whitby blay reflections artificial intel igence legal moral ethical dimensions exeter intellect books chapter integrating ethical values economic value steer progress artificial intelligence anton korinek introduction enter age artificial intelligence perhaps single question important direction future progress ai take1 artificial intelligence— like steam engine electricity it—is generalpurpose technology potential significantly alter way economy society structured progress artificial intelligence offers abundant opportunities improve human condition also pose significant challenges society likely grow coming decades ai systems may replace humans growing range areas however technological progress happen driven least human decisions innovate would misplaced succumb technofatalism view fate predetermined blind technological forces market forces beyond control instead future shaped jointly technological innovations humans create social grateful many thoughtful comments insightful discussions avital balwit john basl karen delio kinda hachem daniel harper paul humphreys eric leeper joseph stiglitz andy wicks well participants “human machine intelligence group” uva workshop “toward handbook ethics ai” university toronto remaining errors financial support institute new economic thinking inet grateful acknowledged anton korinek economic institutions collectively design ethical values guide al society power confront challenges posed technological possibilities individual collective action actively steer path technological progress ai shape future want live chapter attempt discuss meet challenges integrating assessment economic value created ai complementary perspective offered ethical values following section starts tangible example simplistic economic ethical views conflict hotly debated question job losses induced automation including ai examine broader question market value ethical values differ values imposed market frequently prevail conflicts society take corrective actions third section “progress ai inequality” discusses inequality dimension technological progress lines pushing technological progress blind effects inequality misses important ethical perspective fourth section “progress ai creating novel externalities” analyzes number areas ai systems programmed maximize economic value violate ethical values example engaging bias discrimination hacking manipulating human brain curtailing scope autonomous human decisionmaking final section “the race toward superintelligence” speculate economic forces driving us toward superin telligence coming decades conflict fundamental ethical values may expose humanity existential risks economics ethics two conflicting value systems economics ethics offer important perspectives society two different viewpoints—the central focus economics price system economy values resources central focus ethics moral evaluation actions society economic value ethical values may times look contradictory fact complementary argued forceful amartya sen2 market economy system market prices reflects economic actors—humans roles consumers producers workers employers on—value economic resources market prices play central role guiding economic decisions—including steering technological progress market prices offer hints individual members society value however means full representation values example missing anything traded market including externalities market amartya sen ethics economics blackwell publishing integrating ethical values economic value prices thus need complemented ethical values guide decisions make desirable society since ethical values different individuals differ argue one spe cific set ethical values following instead draw broadly agreed upon ethical values introductory example job losses automation ai let start tangible question advent artificial intelligence—like many forms automation—raises economics ethics frequently viewed providing contradictory answers question right introduce new technologies lead job losses posing charged question offering answers ethical economic per spective run risk offending ethicists economists comforted fact vast majority ethicists economists met care lot betterment society integrating two perspectives offers great est chance moving forward debate arriving acceptable answers even answers necessarily tentative partial arguing narrow efficient markets perspective include dimensions human wellbeing economists may tempted immediately respond yes question may observe competitive market wages perfectly reflect social value labor given level wages company finds desirable innovate save costly labor frees labor employed activi ties useful society conversely seeing misery created job losses ethicists may tempted immediately respond question see tangible harm suffering imposed workers laid observe unethical impose workers whereas may immediately appreciate longerterm effects eco nomic progress human wellbeing deliberation economists may appreciate many con siderations matter aside narrow efficient markets perspective argued ear lier markets complete real world workers cannot ful insure unemployment job losses thus social costly efficient mar kets view suggests even importantly jobs social arrangements entail exchange labor wages also provide technical lan guage bundled valuable experiences social connections struc ture personal meaning status sense belonging cannot separately purchased market worker loses result losing job among traumatic events people experience peacetime associated anton korinek losses go far beyond captured purely economic loss income people lose jobs also experience loss meaning become social isolated frequently become depressed also affects families communities imposing externalities moreover majority economists also care questions income distribution even markets generate resource allocations efficient distribution incomes matters market outcomes may generate unequal distribution society perceives less desirable discuss chapter final theoretical reason believe free market direct innovative efforts social desirable innovations—the standard welfare theorem economics static resource allocation innovation similarly deliberation ethicists may appreciate markets provide price signals reflect societal value resources point price signals aggregate decisions every single person participating economic transactions thus reflect many aspects ethical values society example sufficient number consumers demanded fast food provided workers earn living wage market would provide fast food jobs paying living wage ethicists may also appreci ate insights shortcomings omissions market sometimes best corrected imposing right regulation market letting market— proper ethical guidance—do job perhaps fundamental many ethicists appreciate alternatives economic systems assign important role markets promising taking account arguments perspectives economists ethicists may ultimately agree number points may concur unfettered market’s decisions innovate well make workers redun dant always society’s best interests furthermore desirable ensure workers lose jobs cared for—not monetary terms also terms broader value society assigns losses may also agree nonetheless important careful take account price signals provided market economic value often prevails ethical values care integrating ethical values economic decisions concerning economic forces frequently seem prevail ethical values today’s world important understand without providing exhaustive list let describe sev eral factors tilt playing field toward economic value first conflict market value ethical values typical reflects broader tradeoff personal benefit versus societal benefits humans pro social point—our prosocial instincts evolved mainly benefit small tribe people around us humanity large example people hesitate integrating ethical values economic value pol ute neighbor’s backyard may fewer hesitations contributing global warming hurts humanity whole—they apply lower ethical standards externalities affect larger groups instead listen market signals result tradeoffs personal societal benefits humans evolved make instinctively may good guide ethical decisions broader societal repercussions significant problem context new technologies affect humanity whole second systems market prices ethical values differ significant conceptual ways market prices general objective singledimensional unam biguous put welldefined dol ar value anything traded market one reasons markets created humans specifical purpose efficiently exchanging resources person’s ethical values contrast subjec tive multifaceted times implicit making ambiguous difficult compare one reasons ultimate arbiters ethical values neural networks ethical values encoded deep neural networks constitute brains processes nature nurture biological cultural evolution famously difficult capture general rules complex deep neural networks arrive decisions yet describing ethical values need precisely that—we need describe general rules brains decide ethical combining ethical values different individuals guide decisions society whole adds yet another layer complexity subjectivity ethical values leads different views among different people person see ethical conflicts given action likely perform market values even others may find ethical questionable cynical economists may say differences ethical values create gains trade based comparative advantage immorality result may race bottom ethical values fewest moral restraints given area take business opportunities generate value market moreover conflict market values ethical values may come differences ethical values differences valuation material resources—a starving person may find acceptable steal apple even though wellfed people may consider theft unethical clarity market system allowed drive economic decisions toward utmost economic efficiency—but efficiency singledimensional sense ignores ethical considerations partly due cognitive biases partly due ambiguity aversion brains favor singledimensional clear decision factors multifaceted complex decision factors however vast majority ethicists economists society large agree market necessarily win market values ethical values conflict economists frequently use term externalities discrepancies social values market value rich welldeveloped toolkit deal externalities however solutions require political choice pre cise ethical values employ discrepancies arise remaining three sec tions chapter analyze three categories discrepancies value relating anton korinek inequality novel externalities introduced ai market incentives toward creation superhuman levels intelligence progress ai inequality section focuses effects progress ai economic inequality lessons section apply form automation particularly relevant context ai technological progress general understood process expands much economy produce given amount inputs—it expands production pos sibilities put way progress may sound almost uncontroversial—if produce technological progress carries potential make everybody society better material perspective however description potential technological progress contains two important caveats first technological progress could make everybody better guaranteed secondly better refers strictly material perspective two caveats imply technological progress frequently goes counter promise improving everybody’s livelihood industrial revolution future looking broader context technological progress since industrial revolution serves reminder fundamental technological forces economic forces shaping fate mankind centuries prior industrial revolution started eighteenthcentury england vast majority humanity lived subsistence levels—in words humans barely enough material resources survive regularly went sleep hungry like fellow animals inhabiting planet earth humans caught malthusian trap time technological progress enabled population growth additional population ate additional output produced human living standards stubbornly remained subsistence levels centuries since industrial revolution contrast economic growth outpaced population growth much average material living standards humans increased factor ten wonder many contempo rary economists believed least recently fundamental principle technological progress everybody benefited “a rising tide lifts boats” focusing past four decades however picture considerably less rosy even though overall economic growth continued pace ahead distribution economic gains unequal united states bottom half integrating ethical values economic value population consisting mainly lowskilled workers barely experienced income gains adjusted inflation large parts population example unskilled white americans even experienced declines life expectancy socalled “deaths despair” drug alcohol abuse suicides period real incomes top percent doubled top percent tripled top percent quadrupled income statistics reflect economic forces determine economic system values industrial revolution revolved around machines replaced hard physical labor badly needed human workers operate time machines greatly increased productivity value human labor market forces job greater productivity human labor soon reflected higher wages recent waves automation almost banished humans factory floors routine information processing tasks made certain categories human labor especial unskilled labor less less useful economy resulting lower demand labor translated lower wages3 contrast automa tion greatly benefited highskilled workers become useful economic system accordingly experienced large increases payoffs new technologies allowed highskilled humans generate vastly larger amounts output ones oversee efficient production processes incomes highskilled workers thus consistently outpaced lowskilled workers exemplified almost doubling college wage premium extra earnings college graduates make compared high school–only graduates short value creation payoffs economy increasingly shifted low skilled workers highskilled workers machines exacerbating inequality technological progress redistribution important takeaway technological progress frequently generates large redis tributions income across economy main driving force behind technological change affects prices inputs outputs throughout production process4 significant innovation economy larger redis tributions usually side outputs production process consumers products affected innovation usual benefit material perspective since innovations lead new products higher quality lower consumer prices factors trade changes changes public policy also played significant role devaluation labor anton korinek joseph stiglitz “artificial intelligence implications income distribution unemployment” economics artificial intel igence nber university chicago press –anton korinek side factor inputs production include different forms labor capital go process things much ambiguous general economic laws whether specific factor inputs benefit hurt progress—it depends specific nature technological progress factors inputs hurt innovation important ethical questions arise labor one key inputs production process effects technological progress different workers may differ markedly earlier example new technology say ai system leads job losses wages affected workers typical fall result innovation contrast skil pro gram maintain new system likely experience income gains broadly market economy technological change generates winners also regu larly leads significant redistributions economic winners losers technological progress matter workers factor owners never asked consent—they “innocent bystanders” technological progress thus decisions actions individual innovators economists call externality effects economic actions innocent bystanders since effects occur via changes prices wages call pecuniary externalities using terminology lowskilled workers experi enced stark negative pecuniary externalities recent decades redistribution utilitarianism economists argue shouldn’t care pecuniary externalities since constitute “mere” redistributions income—they reduce overall income economy could therefore least principle undone economic policy furthermore argue economists offer guidance allocate resources efficiently societal responses redistributions generated technological prog ress outside subject area political process decide however perspective rightly opens economists accusation biased except two specific narrow cases question efficiently allocate resources economy cannot separated redistributive questions first case economic policy compensates losers progress undoing redistributions without introducing new distortions economy—economists call idealized form redistribution lumpsum transfer however reflect way economy works practice—redistribution general create distortions economists quick point whenever impose taxes economic resource activity raise funds redistribution lower incentives employ resource engage activity create incentives circumvent taxes furthermore also frequently distort behavior poten tial recipients payments therefore first case apply practice second case care overall level income generated distribution income line tradition within economics let call ethical benchmark strict utilitarianism although full justice varieties utilitarianism discussed ethics example bentham described integrating ethical values economic value utilitarianism adds resources consumed different individuals linearly would find innovation desirable even imposes income losses one person society long increases income remaining person amount slightly greater sum individual losses people view type value system least borderline unethical—outside economics strict utilitarianism fringe perspective economists strive inform choices facing society job employ society’s values impose best biased worst manipulative evaluate social choices imposing value system strict utilitarianism society share leave aside two—unrealistic—special cases spelled indispensable consider distributional impact technological innovations considering social desirability inequality steering progress ai society faces choice whether let free market decentralized forces determine innovations take place without regard common good whether fact want steer course technological progress direction takes account inequality may well want pass innovations increase output side effect large number people actual worse realistic scope compensating conversely society may want actively work innovations strictly pass market test offer large benefits large number people steering course progress could done variety ways firstly crucial make ethically conscious entrepreneurs researchers aware redistributive consequences work could make significant difference many entrepreneurs technology sector quite public spirited exemplified google’s former motto “don’t evil” however determin ing good evil society matters direct effects new ai systems crucial also take account redistributive implications new ai systems especially implications labor markets ai affecting sectors economy entrepreneurs researchers field ai must aware actions increasingly shape fate workers overall income distribution across economy provide tangible example could make difference currently participating research project develop intelligent assistants ias aid unskilled human workers enable higher value tasks enhance market value labor cre ative entrepreneurs put minds sure numerous examples innovations would create jobs unskilled workers economi cally profitable anton korinek secondly governments traditional played important role shaping tech nological progress could focus efforts promoting technologies main tain increase labor demand prime area governmentsponsored research could guided intentional toward technologies enhance eco nomic prospects workers rather replacing furthermore governments large employers directly indirectly via government procurement steering automation decisions suppliers large effects labor markets thirdly society could steer progress private sector via taxes subsidies depend whether innovation replaces workers enhances role workers would provide explicit incentives innovators reflect likely labor market impact innovation complementary approach directly target market price human labor present tax system inflates cost labor labor highly taxed factor economy providing extra incentives develop tech nologies save labor enter age ai society would better served shifting burden taxation factors economy provide subsidies labor example expanding programs earned income tax credit would disincentivize investments automating labor steer progress directions progress ai creating novel externalities rise artificial intelligence opens new areas conflict market value ethical values introduces new externalities explored depth throughout chapters handbook common theme many resulting ethical dilemmas technological innovations involved look like create value terms economic profits actual drain broader societal values damage ethical perspective following discuss specific examples explore addressed integrating economic ethical perspectives ai discrimination biases fairness since ai algorithms make growing number decisions lives one particu larly concerning problem ai may perpetuate biases introduce new biases different people treated consider example ai system screens candidates jobs school admissions loans integrating ethical values economic value narrow economic perspective goal ai system performs screening identify highest value candidates businesses schools lenders taking typical data set train ai system certain individual characteristics correlated higher value whereas others correlated lower value ai system identifies correlations far intricate ways human brain may able make efficient screening decisions greater screening efficiency would translate greater economic value however one ethical values society undesirable discriminate individuals based personal characteristics outside control particular characteristics race gender age nonetheless two scenarios ai systems may engage precisely discrimination first scenario algorithm training data selves biased sense accurately reflect correlations present reality may case either based past biased human deci sions based unrepresentative samples simply contain enough information certain groups thus algorithm generates less effi cient decisions underrepresented groups result fewer positive screening decisions first scenario bias undesirable economic ethical perspectives desirable path forward clear second scenario troubling even training data ful representative unbiased many us view unfair base decisions correlations certain protected personal characteristics say example members ethnic group historical defaulted loans higher rates us would view moral wrong charge members group higher interest rate ethnicity even ai systems explicitly fed data protected individual charac teristics ethnicity still infer characteristics data growing degree accuracy employ making decisions look unbiased statistical sense highly efficient economic perspective past human decision makers acted upon moral values nondiscrimi nation would attempt evaluate candidates jobs school admissions loans impartial y—by intentional disregarding data knew highly correlated protected attributes example infer looks names addresses replace human decision maker ai system focused solely efficiency ai system extracts greater economic value disregarding considerations ai systems programmed sacrifice efficiency explicitly follow principles nondiscrimination second scenario however put numerical value nondiscrimination practices whether explicitly implicitly highlight economic cost broader ethical value nondiscrimination reasons discussed earlier seeing dol ar value discrimination may tempt deci sion makers put greater weight clearly measurable economic dimension business decision compared ethical dimensions anton korinek hacking human brain another sinister example hollowing human experience earn extra profits ai systems employed hack human brain computer science hacking refers situations somebody intrudes system either steal information manipulate behavior system ai algorithms hacking human brain refer situations algorithms tap simple human drives order manipulate us behaviors ultimately deliver fulfillment drives meant deliver human brain constantly makes tradeoffs conflicting objectives example primal instincts rational thoughts ai systems understand better better tip balance two exploit instincts influence thoughts manipulate us whatever best achieves objectives example aibased advertising systems manipulate us far efficiently much personal way traditional advertising buy goods services targeted links sensational news stories tempt us click keep reading ultimately offer little informational value autoplay functions start next video without asking user watches one video keeping us watching much longer intended social net works promise connect us efficient ways automate many social interactions keeping users engaged constant friend updates however ultimately generate facetoface human connection necessary provide us true fulfillment outcome cases similar mild form drug addiction simple drives exploited detriment longterm goals conversely ai systems also hack brain opposite objective mind—to assist us pursuit longterm goals regularly providing beneficial nudges example fitness apps dieting apps ultimately make us better curtailing human autonomy increasing use ai automate human decisions also runs risk reducing human experience curtailing human autonomy many people assign significant value human autonomy ability make independent decisions example many car owners report value ability decide drive even autonomous vehicle could drive better along objective dimensions ai systems given area get better better becomes ever tempting impose superior decisions ai systems human users incurs cost reducing autonomy humans experience limits autonomy result increas ing economic inequality third section “progress ai inequality” dis cussed ai systems displace workers increase income inequality time inequality income also worsen inequality wealth ownership eco nomic resources since ownership confers control ai systems earn increasing integrating ethical values economic value fraction output economy strip away control resources workers experience income losses conversely confer increasing levels control resources owners examples novel technological innovations may generate economic value diminish hollow dimensions rich multifaceted human experience also many areas progress ai creates economic disruptions magnify economy’s existing tendencies toward inefficiency discussed example introductory example job losses technolog ical disruptions lead aggregate demand failure recessions externalities steering progress ai whenever marketprovided price signals differ broader ethical values desir able integrate two steer technological progress two critical steps required identify understand discrepancies value externalities act upon understanding ideal course action would anticipate potential ethical problems generated new ai technologies steer away suggested innovators required conduct technological impact assessments making significant investments new technologies modeled environmental impact assess ments attempt evaluate likely impact innovations society5 practice awareness ethical problems frequently arises innovation introduced stakeholders society need col aborate identify novel ethical problems including governments nonprofits universities civil society al course entrepreneurs corporations introduce innovations question sufficient societal awareness ethical minded entrepreneurs may even leverage potential positive externalities progress example fitness dieting apps however given tendency market sponsor race bottom comes monetizing ethical transgressions may also necessary pass regulation compel innovators take account adverse effects society race toward superintelligence progress artificial intelligence continuing unabatedly driven human curi osity market forces many brightest minds working hard improving hardware software required ai driving exponential growth computing power continued advances ability understand write software josé garcía madeline janis “how keep robots taking jobs” politico may anton korinek behind ai market incentives part generously rewarding growing capabilities existing ai systems pouring hundreds billions dol ars development new ones elevated status ai experts geeks rock stars continuing exponential progress raises question whether ai wil point surpass human intelligence presentday ai systems exhibit narrow artificial intelligence—they great frequently superhuman capabilities narrowly defined domains playing chess go targeting ads reading xrays con trast humans possess general intelligence—the ability act intelligently across wide number domains integrate al capacity enables humans employ powers ai service goals however passing year capabilities narrow ai systems growing broader advantage narrow ai humans specific domain expanding unless progress ai comes sudden standstil seems largely question time machines reach human levels—and ultimately superhuman levels—of general intelligence although may sound like science fiction bostrom reports several ai researchers predict artificial general intelligence achieved early next decade majority ai researchers expect artificial general intelligence second half twentyfirst century6 given vast potential implications mankind seems prudent seriously think ramifications society artificial general intelligence superintelligence imply humanity intelligence defining characteristic set humanity apart species animals allowed us rule planet earth including less intelligent coinhabitants planet superintelligent ai treat humanity way humans treated animals domesticating exploiting us useful terminating us nuisance roles left humans could perhaps instill goals ethical values superintelligent machines help us improve human wellbeing ways presently unthinkable modest human minds questions much discussed philosophers ai bostrom remainder focus two areas discrepancies economic value ethical values play significant role attempt shed light areas integrating perspectives ethics economics superintelligence inequality economic viability humans one central dilemmas created evermore intelligent ai agents moral relevant may become increasingly economical irrelevant whereas agents economical relevant may moral relevant nick bostrom superintel igence paths dangers strategies oxford university press integrating ethical values economic value economic perspective superintelligence might productive profitable human invention ever market would greatly value vast potential returns humanlevel artificial intelligence superintelligence could generate human labor contrast likely become economical redundant soon advent superintelligence since superintelligent machines would use superior problemsolving capacity figure perform economical relevant tasks ever efficiently perform formerly human tasks cheaply costs keep humans alive ie cost human subsistence wages economic justification employ human labor humans would become technological obsolete7 human labor would redundant factor production dominated technology—just longer use oxen plough fields cost maintaining oxen worth economic value produce would longer economical worth pay humans need survive would condemn vast majority humanity technological unemployment decisions solely guided economic value would logical phase humanity humans become economical redundant arc material progress would come full circle industrial revolution humanity started malthusian world population numbers held back lack material resources starvation advent superintelligence human labor would become redundant fate wealthiest would end driven malthusian forces yet ultimately leading starvation declines human population malthus’s disciple charles darwin would call result competition scarce resources humans machines survival fittest economic terms ai system reduces human wages subsistence levels would impose particularly strong version pecuniary externalities dis cussed third section “progress ai inequality” however given magnitude externalities would put survival humans risk stake merely human inequality survival conversely ethical desirable keep humanity alive need find mechanisms share enough income generated economy economical redundant humans source income distribution material gains superintelligence thus key ethical question society superintelligence externalities existential risk although superintelligence carries enormous promise improve condition mankind also poses unfathomable risks correctly reflected eco nomic incentives potential creators intelligence commonly defined ability anton korinek “the rise artificial intelligent agents” working paper university virginia anton korinek accomplish complex goals8 super intelligence almost definition effective accomplishing goals humans goals conflict human goals likely superintelligent ai win humans given likely complexity superintelligent ai systems conflicts human goals may fact arise quite easily—especial unintended consequences make existential risks inherent superintelligent ai tangible bostrom offers thought experiment system programmed pursue single narrow rather trivial objective produce many paperclips possible9 argues system may well decide kill humanity pursuit programmed objective example use iron bodies paperclips preempt threat turned would prevent maximizing objective given system programmed pursue broader goals human wellbeing would simply care demise humanity ai safety researchers articulated dozens additional scenarios superintelligent ai may endanger humanity incentives ai researchers society whole badly misaligned comes weighing potential benefits superintelligent ai existential risks researcher tangible shot creating charge powerful ai system ever built would huge potential upside terms scientific fame power material rewards may also somewhat overconfident abil ities control system humanity whole would pay price things go wrong bostrom’s example existential risk given asymmetry obtains benefits bears costs researcher may well tempted proceed impose small risk existential catastrophe humanity sum total risk exposure humanity keeps rising hundreds research teams work advancing ai impose small existential risk individual incentives therefore properly reflect benefits costs existential risks superintelligence steering progress ai steering technological progress toward superintelligence ultimate challenge human society however although stakes vastly higher challenges similar ones currently facing narrow ai—to ensure ai systems carry economic interests behavior guided ethical values given existential risks potential economic irrelevance facing humanity view progress toward superintelligent ai systems primarily eco nomic project primarily research project—the ethical challenges stakes humanity high determined commercial interests corporation max tegmark life human age artificial intel igence knopf bostrom superintelligence integrating ethical values economic value research interests research team instead need large concerted public effort integrate perspectives stakeholders society ensure develop ai direction economical beneficial ethical desirable bibliography acemoglu daron pascual restrepo “the wrong kind ai artificial intelligence future labor demand” nber working paper w25682 autor david “why still many jobs history future workplace automation” journal economic perspectives summer –bostrom nick superintel igence paths dangers strategies oxford university press brynjolfsson erik andrew mcafee second machine age work progress prosperity time bril iant technologies w w norton korinek anton “the rise artificial intelligent agents” working paper university virginia korinek anton joseph stiglitz “artificial intelligence implications income distribution unemployment” economics artificial intel igence ed agrawal et al –nber university chicago press naidu suresh dani rodrik gabriel zucman economics inclusive prosperity introduction economists inclusive prosperity httpwwweconfiporg sen amartya ethics economics blackwell publishing tegmark max life human age artificial intel igence knopf chapter fairness criteria lens directed acyclic graphs statistical modeling perspective benjamin r baer daniel e gilbert martin wells† introduction emergence artificial intelligence’s algorithmic tools represents one important social technological developments last several decades machine learning–based scoring systems determine creditworthiness consumers insurance prices1 social media metrics2 algorithmic hiring platforms target job advertisements screen resumes calculate seen human resource managers3 predictive analytics deployed sentencing tools institute social sciences project algorithms big data inequality yu robinson h yu “knowing score new data underwriting marketing consumer credit marketplace” guide financial inclusion stakeholders –brooke duffy “the romance work gender aspirational labour digital culture industries” international journal cultural studies –ifeoma ajunwa et al “hiring algorithm predicting preventing disparate impact” ssrn electronic journal jack gil um ariana tobin “facebook won’t let employers landlords lenders discriminate ads anymore” propublica may benjamin r baer daniel e gilbert martin wells criminal justice system4 big data’s algorithmic tools come play decisive role many aspects lives however concern algorithmic tools may lack fairness exacerbate existing social inequalities5678 one might imagine algorithms inherently procedural ensuring fairness simple matter explicitly using race gender features9 notion fairness called fairness unawareness easy see insufficient first al features general redundantly encode sensitive variables10 could trivial skirt around fairness unawareness including variables close proxies gender race like hair length name even less suspicious eminently predictive features zip code language usage gpa allow algorithm partial infer individual’s sensitive characteristics make generalizations bases furthermore including information individual’s sensitive characteristics actual serve make predictive algorithm fair especial interaction effects sensitive characteristics features area algorithmic fairness constitutes attempt move beyond fairness unawareness develop link mathematical properties algorithms philosophical intuitive notions fairness unfortunately little consensus philosophical bedrock upon algo rithmic fairness rest1112 much literature fairness algorithms influenced controversy surrounding northpointe compas algorithm algorithm predicting criminal recidivism angwin et al analyzed output algorithm determined predictions unfair due fact rate false positives false negatives differed significantly racial groups13 response northpointe published rejoinder arguing criteria used angwin et al assess fairness nonstandard virginia eubanks automating inequality hightech tools profile police punish poor solon barocas andrew selbst “big data’s disparate impact” california law review malte ziewitz “governing algorithms myth mess methods” science technology human values –cathy o’neil weapons math destruction big data increases inequality threatens democracy broadway books kristian lum “limitations mitigating judicial bias machine learning” nature human behaviour june nina grgichlaca et al “the case process fairness learning feature selection fair decision making” nips symposium machine learning law barocas selbst “big data’s disparate impact” reuben binns “fairness machine learning lessons political philosophy” proceedings machine learning research vol alexandra chouldechova aaron roth “the frontiers fairness machine learning” arxiv181008810 julia angwin et al “machine bias there’s software used across country predict future criminals it’s biased blacks” propublica may fairness criteria lens directed acyclic graphs proper analysis reveals predictions made compas algorithm fact calibrated race14 beyond merely inspiring interest study algorithmic fairness controversy may influenced early direction field one significant branch field concerned development study comparison implementation simple fairness criteria much like balancedodds criterion implicit angwin et al calibration criterion used flores bechtel lowenkamp fairness criteria largely tailored classification setting furthermore angwin et al access limited information assessing compas algorithm authors able acquire compas scores pretrial defendants along information criminal histories race whether defendant fact went reoffend15 however authors access precise features used compas algorithm specifications compas algorithm therefore authors assessed fairness compas algorithm examining false positive false negative rates across races calculated using compas predictions races defendants whether reoffended commonly considered fairnessapt data sets similar form often desire assess whether predictive algorithm fair using information predictions observed outcomes race gender subjects perhaps reason much early work algorithmic fairness centered around socalled oblivious fairness criteria assess algorithms basis outputs compared ground truth three central oblivious criteria often called demographic parity equalized odds calibration group although common encounter related concepts host names two prominent strains criticism emerged cast doubt utility simple onesizefitsall metrics fairness algorithms first criticism concerns obliviousness even alongside introduction equalized odds hardt price srebro et al note intuitively fair intuitively unfair algorithmic procedures appear identical compare algorithm’s output observed outcome16 indeed many intuitive notions fairness nature infor mation used make prediction rather outcome second strain criticism concerns incompatibility three oblivious fairness criteria thus lack universality notably chouldechova anthony w flores kristin bechtel christopher lowenkamp “false positives false negatives false analyses rejoinder ‘machine bias there’s software used across country predict future criminals it’s biased blacks’ ” federal probation –jeff larson et al “how analyzed compas recidivism algorithm” propublica may moritz hardt eric price nati srebro et al “equality opportunity supervised learning” advances neural information processing systems –alexandra chouldechova “fair prediction disparate impact study bias recidivism prediction instruments” big data –benjamin r baer daniel e gilbert martin wells kleinberg mul ainathan raghavan proved calibration equalized odds could simultaneously achieved recast disagreement propublica northpointe philosophical rather statistical debate various review papers written tie together outpouring early ideas fairness algorithms chapter intend exhaustively catalog world fairness criteria instead focus small number basic criteria received significant attention similar yeom tschantz comprehensive map fairness measures relationships one another see mitchel potash barocas corbettdavies goel elucidate incompatibility calibration equalized odds using visualizations outcome dis tributions21 authors argue problem inframarginality suggests equalized odds poor criterion fairness agree poorness equalized odds concerned work generalizes operationalizes equalized odds may obscure criterion’s underlying flaws purpose chapter provide alternate source intu ition fairness criteria using probabilistic directed acyclic graphical models bayesian networks graphical models used motivate expose fairness criteria works especial work explicitly causal criteria fairness believe graphical models provide invaluable source intuition even noncausal scenarios reveal weakness equalized odds using bayesian networks view fairness criteria way easily gener alized beyond classification settings considering generalizations defined barocas hardt narayanan demographic parity equalized odds calibration helps expose certain fundamental aspects criteria classification setting obscures next section “graphical models” provide brief overview probabilistic directed graphical models associated causal theory subsequent section generalizations section “fairness criteria two scenarios” discuss two graphical scenarios implications various fairness criteria therein section “understanding fairness” review incompatibility equalized odds calibration give graphical view problem equalized odds motivates modified class criteria call separation signal final section “causal considerations” discuss relationship causality fairness jon kleinberg sendhil mul ainathan manish raghavan “inherent tradeoffs fair determination risk scores” 8th innovations theoretical computer science conference samuel yeom michael carl tschantz “discriminative discriminatory comparison fairness definitions different worldviews” arxiv180808619 shira mitchel eric potash solon barocas “predictionbased decisions fairness catalogue choices assumptions definitions” arxiv181107867 sam corbettdavies sharad goel “the measure mismeasure fairness critical review fair machine learning” arxiv180800023 fairness criteria lens directed acyclic graphs graphical models directed acyclic graph dag  pair v e v v v set nodes n e set directed edges pointing one node another acyclic property dags requires edges e never form directed path leading one node back let parents v pa v refer set nodes share edge v edge pointing v probabilistic directed acyclic graphical models probabilistic directed acyclic graphical pdag model sometimes known bayesian network pair gp  dag  probability distribu tion nodes each node v v  represents random variable n random variables jointly governed probability distribution  chapter consider pdag models satisfy markov condition pdag model gp satisfies markov condition probability distribution n pa node v considered ancestor node v directed path leading v v case node v descendent v node root ancestors leaf descendants random variables associated root nodes call exogenous distribution depend modeled variables discussing pdag models three common relationships nodes particular interest nodes v v confounded node v v ancestor v v case say backdoor path v v v ancestor v v ancestor v v mediator relationship v v final v v ancestors v v said col ider v v see figure depiction relationships v v v v v v v v v figure leftmost graph v confounder center graph v mediator rightmost graph v collider judea pearl causality cambridge university press 2009b peter spirtes et al causation prediction search mit press benjamin r baer daniel e gilbert martin wells determine certain marginal conditional independence relationships random variables v v using structure dag nodes v n v dseparated structure dag implies v v marginal j j independent v⊥ set  nodes dseparates v v structure vj j dag implies v v independent given variables  v⊥  v j j specifical markov condition nodes v v dseparated given   j blocks paths v v connected sequence edges two nodes j considered path regardless edges’ orientations path blocked  either k k k k l l k thus conditioning colliders descendants actual unblocks paths induce dependency marginal independent variables see figure examples note dseparation implies conditional independence dconnection lack dseparation necessarily imply conditional dependence therefore sometimes useful make assumption pdag model faithful means every conditional dconnection relationship graph implies conditional dependence variables unfaithfulness occur whenever exist multiple paths leading v v since dependencies along paths cancel j example consider pdag model associated dag figure v v v v figure multiple paths v v pdag model may unfaithful effect v v along one path perfectly counteracts effect along path v v v v v v figure pdag model nodes v v dseparated priori conditional empty set  ∅ however conditional collider  v v v dconnected v v dseparated given following sets v v v v v v v fairness criteria lens directed acyclic graphs let v  v  v v v v v v thus v independent v despite fact v v unconditionally dconnected thus pdag model unfaithful note however unusual path effects precisely cancel except variables carefully con structed causality strictly speaking directed edges pdag models need causal inter pretation long consistent conditional dependencies  however dags ful determined associated probability distributions given probability distribution usual consistent multiple dags differently ori ented edges thus natural use pdag model convey causal meaning edge pointing v v means v causal effect v pdag j j models used context causal inference often called structural causal models associated dag may called causal graph pearl’s theory causality addresses two types causal questions questions effects manipulating variables questions counterfactual states affairs24 focus inferences variable manipulations pearl uses construct called operator express dostatements  v v v v interpreted “the probability v v intervene set v v ” formal intervene variable v setting v means construct alternate pdag model edges v ancestors deleted distribution root v set point mass v dostatements sometimes resolved equivalent seestatements using pearl’s three rules docalculus consequences markov condition seestatements expressions may involve various conditional probabilities contain dooperator thus seestatements evaluated using infor mation joint probability distribution  variables original pdag note cases may include unobserved variables pdag model indicate variable unobserved dag dotted outline figure dostatements cannot resolved seestatements depending observed variables called unidentifiable v v v figure pdag model v v confounded unobserved variable v render expression  v unidentifiable pearl causality benjamin r baer daniel e gilbert martin wells accessible complete introduction pdag models pearl’s causal theory see pearl glymour jewell pearl 2009a26 purpose use pdag models chapter mostly provide intuition regarding sets variables various conditional dependency relationships however section properly causal treatment three criteria fairness review definitions three prominent fairness criteria independence separation sufficiency examine lens pdag models chapter let response outcome interest measured individual example could whether individual repay loan whether click advertisement let sensitive characteristic categorical variable indicating individual’s class respect fairnessapt feature race gender let r prediction estimated response individual select individual random population quantities r modeled random variables concerned assessing whether r fair prediction three fairness criteria examine chapter oblivious crite ria means assess joint distribution tuple r y27 words criteria concerned functional form r information upon based treat r black box work done fairness criteria machine learning considered classification setting categorical often binary variable therefore surprise three fairness criteria defined section first introduced criteria assessing classifiers fairness criteria classification setting respectively known demographic parity equalized odds calibration group however barocas hardt narayanan offer sensible generalizations three criteria settings arbitrary possibly continuous r y28 introduce original generalized versions three criteria demographic parity independence starting point assessing fairness prediction algorithm may ask whether algorithm making systematical different predictions different judea pearl madelyn glymour nicholas p jewel causal inference statistics primer judea pearl “causal inference statistics overview” statistics surveys 2009a –hardt price srebro et al “equality opportunity supervised learning” solon barocas moritz hardt arvind narayanan fairness machine learning fairness criteria lens directed acyclic graphs groups suppose categorical sensitive characteristic taking values set  considering binary classification case moment suppose response y∈ prediction r∈ definition prediction r satisfies demographic parity p r p r a′ every sensitive characteristic a′∈ binary case equivalent statement r ⊥ therefore natural generalization demographic parity suggested barocas hardt narayanan definition prediction r satisfies independence r ⊥ strong criterion sense requires aspect distribution r depend weaker form independence could require expected value possibly variance r depend methods achieving full partial independence predictions see johndrow lum calders kamiran pechenizkiy calders verwer del barrio et al hacker wiedemann equalized odds separation independence criterion take response account enforces equality distributions prediction r across protected characteristic even distribution response may differ across protected classes binary classifiers hardt price srebro et al argue34 demographic parity seriously flawed two counts first doesn’t ensure fair ness notion permits accept qualified applicants one demographic random individuals another long percentages acceptance match behavior arise natural little training data available one demographics second demographic parity often cripples utility james e johndrow kristian lum “an algorithm removing sensitive information application raceindependent recidivism prediction” annals applied statistics –toon calders faisal kamiran mykola pechenizkiy “building classifiers independency constraints” ieee international conference data mining workshops ieee –toon calders sicco verwer “three naive bayes approaches discriminationfree classification” data mining knowledge discovery –eustasio del barrio et al “obtaining fairness using optimal transport theory” arxiv180603195 philipp hacker emil wiedemann “a continuous framework fairness” arxiv17120792f hardt price srebro et al “equality opportunity supervised learning” benjamin r baer daniel e gilbert martin wells might hope achieve especial common scenario outcome predicated eg whether loan defaulted correlated protected attribute light hardt price srebro et al propose alternative criterion fairness suppose ∈ prediction r∈ definition prediction r satisfies equalized odds p r p r ′ every sensitive characteristic a′∈ response ∈ hardt price srebro et al argue independent satisfy demographic parity therefore would “perfect” classifier r hand “perfect” classifier r always satisfy equalized odds thus unless attempting modify predictions form affirmative action equalized odds seems advantage demographic parity section discrete classification setting motivation less force arbitrary regres sion settings thus consider general form equalized odds35 definition prediction r satisfies separation r⊥ like independence strong criterion relaxed requiring conditional expectation  r possibly conditional variance var r depend see hardt price srebro et al pleiss et al donini et al zafar et al corbettdavies et al expositions separationlike criteria methods enforcing calibration group sufficiency calibration fairness concept popular criterion assessing aspect performance predicted probabilities41 consider case response y∈ binary predicted probability p ∈ barocas hardt narayanan fairness machine learning hardt price srebro et al “equality opportunity supervised learning” geoff pleiss et al “on fairness calibration” advances neural information processing systems –michele donini et al “empirical risk minimization fairness constraints” advances neural information processing systems –muhammad bilal zafar et al “fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment” proceedings 26th international conference world wide web acm –sam corbettdavies et al “algorithmic decision making cost fairness” proceedings 23rd acm sigkdd international conference knowledge discovery data mining acm –sarah lichtenstein baruch fischhoff lawrence phillips calibration probabilities state art tech rep perceptronics fairness criteria lens directed acyclic graphs definition predicted probability p satisfies calibration p p∈ would suggest classifications generated calibrated predicated probability trustworthy sense practitioner incentive make post hoc adjustments compensate known biases ranges prediction related criterion directly relevant fairness whether predicted prob ability calibrated across subpopulations whether given predicted probability meaning generated individuals different subpopulations suppose y∈ p∈ definition predicted probability p satisfies calibration group p calibration group intuitively appealing satisfied individuals’ predictions must deviate modelgrounded truth manner depending group membership predicted probability p satisfies calibration group equal performance across sensitive attribute indeed calibration group combination calibration lack dependence sensitive attribute lack dependence isolated terms prediction r∈ following definition definition prediction rule r∈ satisfies predictive parity p sensitive characteristic a∈ predictive parity discussed coined chouldechova barocas hardt narayanan present natural generalization predictive parity necessarily binary r definition prediction r satisfies sufficiency y⊥ r fairness criteria two scenarios supplement basic motivations three fairness criteria discuss implications two prediction scenarios find various criteria represent equal viable choices different subjective implications rather certain criteria operational certain scenarios seemingly meaningless others independence clear use cases represents assumption relationships sensitive characteristic response else desire impose regime special intervention favor particular group sufficiency hand serves measure extent prediction takes advantage information relevant predicting response final separation meaningful use cases esoteric scenarios scenario however scenarios interest separation counterproductive destructive implications chouldechova “fair prediction disparate impact” barocas hardt narayanan fairness machine learning benjamin r baer daniel e gilbert martin wells scenario loan repayment wish predict whether individual repay loan suppose model situa tion using pdag figure consider three features different conditional dependency structures encoded pdag model applicant’s hair color x descendant race mediator effect whether repays loan perhaps reason seems intuitively unfair illegal places44 determine applicant’s loan premium based hair color however cases may tempting backdoor path connecting x thus x statistical marginal dependent nature x il ustrates one shortcoming fairness unawareness demands use input prediction would violation fairness unawareness use x alone predict however merely taking advantage back door path words using noisy version predict rather applicant’s credit rating x mediator therefore statistical dependent race also predictive whether applicant repay loan even taking race consideration applicant’s credit rating natural feature predicting loan repayment redundantly encodes race extent final interest rate loan x influences marginal independent race therefore x seems innocuous prediction assess implications independence separation sufficiency criteria context independence independence criterion requires prediction r marginal independent applicant’s race thus assuming pdag model faithful achieve independence positioning r unconditional dseparated applicant’s loan interest rate x dseparated therefore prediction r descendant x always satisfy independence see figure race x repays loan x applicant’s hair color x x x applicant’s credit rating x loan interest rate figure random variables scenario various features relationship race loan repayment stacy stowe “new york city ban discrimination based hair” new york times february fairness criteria lens directed acyclic graphs x x x r figure prediction r dseparated therefore satisfies independence ϵ x r x x x figure prediction r depends part x independent race however prediction r descends either applicant’s hair color x credit rating x would fail satisfy independence nonetheless may remain valuable information within x may help us predict maintaining independence extract information constructing model represented pdag figure decomposing x component depends exogenous com ponent  marginal independent construct prediction r x uses information still dseparated thus satisfies independence shown figure x observed model exogenous component x ple case x ∼  µ ε x − µ ∼ n x conditional independencies encoded pdag model thus may safely allow prediction r depend  x context scenario satisfying independence using information x entails use version x demeaned race would use feature individual’s credit rating relative others race procedure may seem justifiable credit ratings racial biased thus inaccurate indicator individual’s likelihood repaying loan however untrue assumption model conditionally independent given x thus case procedure demeaning credit ratings race satisfy independence interpreted special modification prediction r benefit particular likely disadvantaged group credit ratings fact racial biased may use modification model scenario modified scenario x racial biased credit rating unfairly modifies information applicant’s true driver default risk  assump x tions achieve independence without sacrificing predictive accuracy final scenario information applicant’s hair color x pro ductively used maintaining independence exogenous components resulted decomposition x would independent scenario independence bars us considering applicant’s hair color entirely benjamin r baer daniel e gilbert martin wells ϵ x r x x x figure modification scenario part x contributes response noise  independent x x x x r x x x r x x x r figure three examples predictions prediction rule r depends j feature x j separation separation criterion requires prediction r independent applicant’s race conditional whether fact repay loan seen independence strong criterion requires r dependency despite fact dependent scenario may desire criterion allows us take account information applicant’s credit rating x still desire criterion prohibits use spurious information like hair color x however scenario separation thing see clearly consider prediction rules descendants one feature let r denote j arbitrary prediction rule depends feature x j j prediction r depending x violates separation expected since dseparate r also case r block path r even surprisingly collider conditioning actual unblocks path r therefore even though interest rate loan x eligible use independence due independence cannot used separation extracting components features x x x also futile graphical descendent ancestor features would still dconnected given general separation prevents us constructing predictions descendants x x x faithful pdag model however induce viola tion faithfulness force independence r must let r direct descendent example considering simplicity prediction using information credit rating x suppose pdag model contains following gaussian linear model fairness criteria lens directed acyclic graphs x σ x throughout chapter assume model parameters βσ µ σ known basic properties multivariate normal distribution45 x β ρ β σ β σ may anticipated due structure pdag σ model mean variance x2 given still depend race however use conditional distribution construct optimal linear prediction r cancels dependencies explicitly taking account race r x x β ρ µ ρ z ∼  c ρ σ independent source noise c maxρ across races a∈ thus r’s dependencies encoded new pdag model faithful depicted figure note r x σ distribution depend n however prediction rule r suspicious perhaps notably requires addition harrison bergeron–esque noise predictions certain indi viduals order achieve parity prediction error across groups inclusion additional noise similar result found pleiss et al discrete classifiers46 depiction prediction r figure thus scenario separation seem natural criterion fairness suggests counterproductive procedures constructing estimators however show scenario separation sometimes power discriminate subjectively different prediction rules x x r x z figure prediction r takes input x whose effects conspire violate faithfulness make r⊥ william r moser linear models mean model approach elsevier pleiss et al “on fairness calibration” benjamin r baer daniel e gilbert martin wells group group x2 figure mean variance distribution x2 differs groups group • x lower mean greater variance group • however groups β x  component groups nonetheless modified predictions satisfying separation group —— group —— differ greatly deviate true regression line furthermore achieve equal conditional prediction variance groups must randomize predictions group lighter dotted lines —— indicate twostandarddeviation bounds randomized predictions sufficiency sufficiency criterion demands whether applicant repay loan independent race conditional prediction r r always graphical descendent subset features x x x see figure cannot achieve sufficiency merely careful choosing r’s argu ments conditioning r never dseparate however see applicant’s credit rating x dseparates therefore invertible function r x satisfy sufficiency argument general work prediction rule r function one feature though since general possible invert function indeed order construct prediction rule r x x satisfies separation prediction r must explicitly block path done response depends features x x parameter θ x x case predictor r θ satisfies sufficiency course parameter θ controls way probability loan repayment depends loan interest rate x fairness criteria lens directed acyclic graphs applicant’s credit rating x known practice exact predictor available use argument shows case way prediction rules estimated training data sufficient population recovery signal scenario job advertisement scenario modeled similar scenario barocas hardt narayanan likely programmers47 predict whether user programmer use information browsing history real life example issues fairness may arise serving job advertisements see gil um tobin user using pdag figure assume x variable indicating whether user visited pinterestcom relationship whether individual programmer except virtue information encodes gender novelty scenario observe x variable indicating whether user visited stackexchangecom assume graphical descendant whether user programmer according model user’s gender affects likelihood programmer programmer certain likelihood visiting stackexchangecom regardless gender therefore wish target users employment advertisement based gender x suspicious candidate x may reasonably considered fair game examine implications oblivious criteria scenario x gender programmer x visited pinterestcom x x visited stackexchangecom figure random variables scenario various features relationship gender progamming employment independence figure see scenario prediction r depends whether user visited pinterestcom x prediction r violate independence information x independent user’s gender also independent whether programmer furthermore barocas hardt narayanan fairness machine learning gil um tobin “facebook won’t let employers landlords lenders discriminate ads anymore” benjamin r baer daniel e gilbert martin wells x x r x x r figure two examples predictions prediction rule r depends j feature x j x descendant backdoor connection component whether user visited stackexchangecom x independent also independent therefore cannot construct nontrivial predictions r scenario satisfy independence separation hand scenario separation shines consider estimators depend one feature let r denote arbitrary prediction rule depends x likewise let r denote arbitrary prediction rule depends x prediction r fail satisfy separation conditioning whether user programmer dseparate whether visited pinterestcom x gender clearly case regardless information extract x however prediction descendent whether user visited stackexchangecom x fact satisfy separation conditioning blocks path x thus interpret separation criterion encourages us use information depends response however clear many situations observe features behave graphical descendants response general interested using features temporal precede observation usual x causes way around fact scenario designed il ustrate possible use separation criterion unrealistic modification scenario realistic modeled pdag figure whether user programmer actual unobserved variable u relevant us determines likelihood observable event user clicks advertisement realistic model see longer dseparates r thus extent identical u separation hold gender u x clicks job ad u programmer x x r visited pinterestcom x visited stackexchangecom figure perhaps realistic dag underlies clickpredicting task scenario fairness criteria lens directed acyclic graphs sufficiency contrast scenario cannot construct nontrivial prediction satisfying sufficiency neither x x mediators effect way prediction r could block direct path would r perfectly encode information understanding separation among three oblivious criteria fairness discussed skeptical separation mentioned section “equalized odds separation” significant literature focused applying generalizing criterion however unlike criteria separation fundamental limitations explore section “scenario job advertisement” found predictions r function features descendants response satisfy separation focus cases particular focus arrangement features sensitive characteristic response feel likely occur practice assume dag arranged sensitive characteristic root response leaf none features descendants response feel dag ubiquitous since predictions often made future necessi tating features causal ancestors response example arrangement provided scenario concrete focus typical example dag encodes dependencies features visualized figure node root node may ancestor features x x p furthermore features may ancestors descendants features ancestors response argue separation tend hold examining structure typical dag visualized prediction r leftmost graph figure conditioning leaf graph response general block paths root sensitive characteristic prediction r—which depends mediators features x due nondegeneracy graph response influenced exogenous random noise  say ò addition x x x figure example dag features mediators sensitive characteristic response benjamin r baer daniel e gilbert martin wells r figure depiction prohibited paths random variables r separation sufficiency x x x x x x r θ r figure leftmost graph example graph figure rightmost graph shows signal parameter θ signal features x x due interference noise ò p information response fundamental different information features leads impossibility blocking failure separation hold faithful models argument easiest see case visualized figure holds general whenever least one feature ancestor response exogenous noise  still interfere response leading inability recover information features specializing conclusion argument binary case uncovers peculiarity equalized odds despite equalized odds derived common measures summarizing accuracy classifier incompatibility separation sufficiency measures fairness beginning intensely studied debated kleinberg mul ainathan raghavan chouldechova estab lished surprising result calibration equalized odds cannot simultaneously hold degenerate settings specifical established theorem consider binary setting response y∈ predic tion r∈ r ≠ prediction r satisfy equalized odds calibration group p mean response differ levels protected characteristic kleinberg mul ainathan raghavan “inherent tradeoffs fair determination risk scores” chouldechova “fair prediction disparate impact” fairness criteria lens directed acyclic graphs theorem generalized beyond binary case hold separation sufficiency barocas hardt narayanan provide argument using undirected graphs reproduce51 theorem assumed r ≠ general case similarly general assume events joint distribution r shown figure separation requires r ⊥ edge r similarly sufficiency requires ⊥ r edge indicate impossibility edge dashed line therefore must hold a⊥ since path drawn connecting condition a⊥ generalization condition theorem mean response differ levels protected characteristic establishes result summarized theorem theorem nondegeneracy assumption events joint distribu tion r positive probability separation sufficiency hold must a⊥ results cast disagreement propublica northpointe new light one hand failure compas algorithm achieve equal error rates groups seem objective form unfairness mathemati cal impossible classifier calibrated group hand remains question whether disparate impact caused unbalanced error rates sufficient cause dispense calibration binary classification settings common characterize performance classifier using false positive false negative rate quantities specify dis tribution r given however seen using example simple linear regression model attempting enforce parity quantities conditional lead counterproductive procedures furthermore argued even calibration group hold general reason expect conditioning block paths r thus believe choice calibration group equalized odds mere subjective tradeoff instead find separation fundamental unhelpful fairness criterion parity signal original motivation equalized odds52 overcome limitations independence addition stringency criterion authors argue limitation criterion response satisfy independence whenever dependence sensitive characteristic barocas hardt narayanan fairness machine learning hardt price srebro et al “equality opportunity supervised learning” benjamin r baer daniel e gilbert martin wells undesirable write since response “ideal prediction hardly considered discriminatory represents actual outcome” line reasoning seems obscure crucial point probability dis tribution response depends features x x signal p parameter θ x x p ditional mean e θ onedimensional signal θ x p allowable prediction separation follows reasoning nondegenerate settings conditioning response block dependence ancestors significant limitation since discrepancy response signal θ general unique individual predicted indeed prediction rule r achieve zero prediction error response exogenous noise component therefore practicality perfect prediction r signal θ response mind explicitly define new measure fairness definition represent f θ xp x p r satisfies parity signal r conditional independent sensitive attribute given signal θ ie r ⊥ aθ another way view definition fairness predictions similar people unnecessarily depend sensitive characteristic similar people defined whose features contribute—via signal θ x x p way outcome related measure fairness described dwork et al wherein separation signal would considered utilizing perfect similarity metric53 scenario optimal prediction rule satisfies separation presented found unusual however scenario true mean indeed satisfy parity signal definition fairness without limitations evaluating whether predic tion r satisfies separation signal requires signal θ general known practice demonstrated separation signal useful device develop understanding close variant also made operational separation signal compares prediction r signal θ instead r could compared another prediction viewed accurate r definition prediction r satisfies parity r conditional independent sensitive attribute given r ⊥ notice prediction r satisfies separation signal r satisfies parity θ interpret variety fairnesstesting procedures form testing parity example context testing whether various police precincts exhibit racial bias contraband searches simoiu corbettdavies goel et al develop cynthia dwork et al “fairness awareness” proceedings 3rd innovations theoretical computer science conference acm –fairness criteria lens directed acyclic graphs threshold test test kind parity signal54 binary setting consider prediction r x x n pa x xp ta individual carrying contraband probability p x xp individual carrying contraband larger threshold individual carrying contraband otherwise develop bayesian tests whether threshold depends race since argue fundamental form unfairness occurs minorities ruled stringent thresholds nonminorities due prediction r depending probability p threshold test whether r satisfies parity p example threshold test sought determine whether spe cific form bias police officers’ decisions search contraband example testing subjective human predictions modeling assumptions however separation criterion also desirable hold prediction r even r generated machine algorithms consider cases believe model unfair due misspecification perhaps model missing necessary features fails model interactions sensitive characteristic fea tures way leads predictions generated algorithm disparately impact certain groups see particular scenario red car kusner et al x case likelihood ratio test56 models would test whether r satisfies separation causal considerations various discussions independence separationlike criteria authors propose generalizations enforce parity conditioning certain features575859 consider following generalizations independence suppose x subvector features x xp definition prediction r satisfies conditional independence respect x r ⊥ x notice conditional independence respect x always holds x p prediction r deterministic function features x reinforces xp camelia simoiu sam corbettdavies sharad goel et al “the problem inframarginality outcome tests discrimination” annals applied statistics –matt j kusner et al “counterfactual fairness” advances neural information processing systems –alan agresti foundations linear generalized linear models john wiley sons barocas hardt narayanan fairness machine learning hardt price srebro et al “equality opportunity supervised learning” michele donini et al “empirical risk minimization fairness constraints” benjamin r baer daniel e gilbert martin wells purpose conditional independence study influence subvector x features notice also connection parity signal parity prediction involve evaluating independence conditional specific function features conditional independence criteria convey little information underlying desires practitioner however causal reasoning provide principled methods developing fairness criteria may ultimately expressed conditional independence criteria discuss two scenarios conditional independence criteria derived using causal reasoning variety perspec tives role pearl’s causality theory fairness see kusner et al kilbertus et al nabi shpitser chiappa scenario college admissions purpose college admissions wish predict whether student drop completing degree suppose model situation using pdag figure suppose admissions committee wishes use relevant information student performance contained student’s sat score x otherwise wishes ignore student’s raceladen socioeconomic status x despite fact socioeconomic factors direct effect student’s probability dropping language kilbertus et al means x resolving variable64 independence criterion would allow us use information x since would extract component x independent student’s race race drops x x socioeconomic status x x sat score figure random variables scenario various features relationship race drop status kusner et al “counterfactual fairness” niki kilbertus et al “avoiding discrimination causal reasoning” advances neural information processing systems –razieh nabi ilya shpitser “fair inference outcomes” thirtysecond aaai conference artificial intel igence aaai press silvia chiappa “pathspecific counterfactual fairness” thirtythird aaai conference artificial intel igence aaai press kilbertus et al “avoiding discrimination causal reasoning” advances neural information processing systems –fairness criteria lens directed acyclic graphs separation parity signal hand would allow us ful make use x entirely excluding information x fact actual desire direct effect r mediated x express criterion using formula controlled direct effect cde x x  r ′ x x a′∈ x range x case doexpression identifiable simplifies expression r ⊥ x however cases resolving variable confounded variables doexpressions may unidentifiable require docalculus resolve observational expressions scenario insurance prices scenarios discussed far model sensitive characteristic exogenous variable thus always root pdag models total causal effects endogenous entities r coincide observed effects however endogenous variable may backdoor paths predictions response consider following scenario makes clear need causal reasoning fairness wish predict whether individual likely car accident pur pose determining insurance premium suppose model relevant variables using pdag figure may deem unfair use individual’s religion factor predic tion r however backdoor path thus marginal dependent reason prediction r nontrivial descendent individual’s driving record x fail satisfy independence course ubiquitous cases features ancestors response conditioning black path r either thus prediction also fail satisfy separation case need consider x resolving variable whatever dependence results r spurious interested ensuring total effect te r express  r u religion car accident u personality x x past traffic tickets figure random variables scenario unobserved variable various features relationship religion car accident status benjamin r baer daniel e gilbert martin wells note special case counterfactual fairness criterion kusner et al although authors explicitly consider cases endogenous65 consequence criterion freely construct predictions r based traffic tickets x inferred aspects personality u conclusion scenarios pdags proven fertile ground developing intu ition three basic oblivious criteria fairness independence separation sufficiency general constructing pdag model relating sensitive characteristic features response clarifying exercise allows us directly con nect senses intuitively fair implications decisions make specifying algorithm contrast project constructing statistical optimal estimators fundamental concern constructing fair estimators blocking use information subjectively unacceptable pdags dseparation natural tools contrast oblivious fairness criteria alone limited behavior opaque sensitive particularities scenario enforcing independence sensitive characteristic prediction seen wildly different implications scenarios response dependent race former case independence prohibited discrimination could statistical justified latter case independence intervention favor adversely affected groups sufficiency achieved blocking paths information flow sensitive characteristic response general possible accurately recovering signal shown sufficiency achieved appropriately choosing features information flows race response appropriately choosing prediction blocks flow information separation natural allows use features descendants response exhibits strange behavior whenever features nonde scendants response even features independent sensitive characteristic nondegenerate faithful pdag models separation hold since response comprised signal also noise obscures information signal response scenario violation faithful ness induced produce optimal prediction rule turned highly inappropriate groups even requiring addition random noise part measures found wanting join recent con sensus assessment fairness algorithms start end kusner et al “counterfactual fairness” fairness criteria lens directed acyclic graphs use singular criterion constraints wish impose predictions sensitive scenario pdag models help explore general notice little consensus underlying philosophi cal principles provide foundation quantification fairness much work fairness seems framed around preventing unfairness like allegedly exhibited compas algorithm consensus compas algorithm ever unfair worry constructs fairness taken context treated black boxes mathematical study elaboration implicit underlying notions fairness obscured hope fairness research grounded clear practical examples ways algorithms unfair acknowledgments thanks david kent helpful conversations bibliography angwin julia et al “machine bias there’s software used across country predict future criminals it’s biased blacks” propublica may barocas solon moritz hardt arvind narayanan fairness machine learning fairml bookorg httpwwwfairmlbookorg calders toon faisal kamiran mykola pechenizkiy “building classifiers independency constraints” ieee international conference data mining workshops –ieee calders toon sicco verwer “three naive bayes approaches discriminationfree classification” data mining knowledge discovery –chiappa silvia “pathspecific counterfactual fairness” thirtythird aaai conference artificial intel igence aaai press chouldechova alexandra “fair prediction disparate impact study bias recidivism prediction instruments” big data –corbettdavies sam sharad goel “the measure mismeasure fairness critical review fair machine learning” arxiv180800023 corbettdavies sam et al “algorithmic decision making cost fairness” proceedings 23rd acm sigkdd international conference knowledge discovery data mining –acm del barrio eustasio et al “obtaining fairness using optimal transport theory” arxiv180603195 donini michele et al “empirical risk minimization fairness constraints” advances neural information processing systems –dwork cynthia et al “fairness awareness” proceedings 3rd innovations theoretical computer science conference –acm flores anthony w kristin bechtel christopher lowenkamp “false positives false negatives false analyses rejoinder ‘machine bias there’s software used across country predict future criminals it’s biased blacks’ ” federal probation –benjamin r baer daniel e gilbert martin wells hacker philipp emil wiedemann “a continuous framework fairness” arxiv17120792f hardt moritz et al “equality opportunity supervised learning” advances neural information processing systems –hardt moritz eric price nati srebro et al “equality opportunity supervised learning” advances neural information processing systems –johndrow james e kristian lum “an algorithm removing sensitive information application raceindependent recidivism prediction” annals applied statistics –kilbertus niki et al “avoiding discrimination causal reasoning” advances neural information processing systems –kleinberg jon sendhil mul ainathan manish raghavan “inherent tradeoffs fair determination risk scores” 8th innovations theoretical computer science conference kusner matt j et al “counterfactual fairness” advances neural information processing systems –mitchel shira eric potash solon barocas “predictionbased decisions fairness catalogue choices assumptions definitions” arxiv181107867 nabi razieh ilya shpitser “fair inference outcomes” thirtysecond aaai conference artificial intel igence aaai press pearl judea “causal inference statistics overview” statistics surveys 2009a –pearl judea madelyn glymour nicholas p jewel causal inference statistics primer john wiley sons pleiss geoff et al “on fairness calibration” advances neural information processing systems –simoiu camelia sam corbettdavies sharad goel et al “the problem inframarginality outcome tests discrimination” annals applied statistics –yeom samuel michael carl tschantz “discriminative discriminatory comparison fairness definitions different worldviews” arxiv180808619 zafar muhammad bilal et al “fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment” proceedings 26th international conference world wide web –acm chapter automating origination perspectives humanities avery slater june mit technology review ran story entitled “machine creativity beats modern art” attentiongrabbing riddle article contained repro ductions twelve abstract paintings asked readers paintings produced computer1 displaying collection twelve paintings evoking range styles german expressionism postmodernism article allowed readers muse kandinsky rothko work ai divulging answer article’s conclusion “all them” newsworthy artistic results outcome experiments new neural network configuration authors computer science study call “creative adversarial networks” team rutgers university’s art artificial intelligence laboratory drew previous successes field ai image generation following landmark introduction generative adversarial networks gans goodfellow et al inspired colin martindale’s theories artistic change predictably divergent elgammal et al modified gan produce images would satisfy creative rather realistic criteria “maximizing deviation established styles minimizing deviation art distribution”the team paired neural “machine creativity beats modern art” mit technology review june https wwwtechnologyreviewcoms608195machinecreativitybeatssomemodernart accessed april ian j goodfellow jean pougetabadie mehdi mirza bing xu david wardefarley sherjil ozair aaron courville yoshua bengio “generative adversarial nets” advances neural information processing systems –arxiv14062661v1 statml june ahmed elgammal bingchen liu mohamed elhoseiny marian mazzone “can creative adversarial networks generating ‘art’ learning styles deviating style norms” predictability artistic change new york basic books avery slater networks train produce artifacts4 would express styles reminiscent preexisting works modern art renaissance expressionist modernist postmodernist periods team’s goal experiments transcended merely testing machinic powers pursued insight question creativity artistic innova tion come much rely memory training “a theory needed model integrate exposure art creation art” team asserts5 echo animus driving research computational creativity today move “beyond mere generation pastiche” creation ai artifacts6 ideal would “develop universal creative process” within science ai could operate “across multiple domains” constituting abstract interchangeable “artifact” term frequently used computer science designate computational generated works art chapter preserve convention using term “artwork” indicate humanproduced art caveat however would suggest boundary categories derives entirely social economic forces seems likely binary erode coming years aiartifacts become increasingly compelling accessible familiar elgammal et al “creative adversarial” hannu toivonen oskar gross “data mining machine learning computational creativity” wires data mining knowledge discovery novemberdecember –automating origination perspectives humanities format “a domainindependent general creativity ‘algorithm’ ”analogies human machine creativity subject earliest experiments neural network imagination stephen thaler’s use noise perturb feedforward network minimal training noise intended cause network “dream” “create” new combinations never seen training suggesting ativity may arise sources noise inside biological neural networks”in recent survey field cardoso et al date growth interest computational creativity’s possibilities mid1990s9 one hand feel creativity research hampered “a field defined word ‘cre ativity’ rather concept creativity” also admit “creative motivation may altogether less well defined” forms problemsolving10 perhaps need take creative approach problem creativity automating creativity potentials artificial intelligence reduce creative powers fear grant us insight powers imagination introduce new forms originality possible vast computational intelligence simon colton geraint wiggins working computational creativity group imperial college london maintain ai’s greatest promise creative agent would “to create new unforeseen modalities would difficult impossible people”yet perhaps paradoxical exact reason research computational creativity investigates “an area often hard say priori one even try ing achieve”but lack pregiven goal substantial different “merely” human creative endeavor predicament could ineradicable constitu tive aspect originary possibility steve dipaola liane gabora investigated bring unmanageable variables creative evolutionary algorithms draw ing neuroscientific research shows associative thought “the brain derrall heath dan ventura “before computer draw must first learn see” proceedings 7th international conference computational creativity –for attempt cultivate “domaincrossing” skil truly creative ai would need forge nonobvious connections see werner dubitzky tobias kötter oliver schmidt michael r berthold “towards creative information exploration based koestler’s concept bisociation” bisociative knowledge discovery lecture notes artificial intel igence lnai vol ed michael r berthold berlin springer verlag –stephen thaler “neural networks autonomously create discover” adapted amílcar cardoso tony veale geraint wiggins “converging divergent history future international joint workshops computational creativity” ai magazine fall –cardoso et al “converging” simon colton geraint wiggins “computational creativity final frontier” 20th european conference artificial intel igence ecai ed l de raedt c bessiere dubois p doherty p frasconi f heintz p lucas montpellier france ios press –colton wiggins “final frontier” avery slater functioning selforganizing system proverbial ‘edge chaos’ ”would creatively unpredictable aiagent useful put another way would governable ai philosopher margaret boden outlined problem “assuming rec ognize creativity see explain comes anything systematic said context discovery ”how assess whether ai arti facts acceded status original art followed premises boden’s emphasis creativity within computational design ai itself15 oth ers preferred test empirical observable properties artifacts themselves16 outline criteria met outputs truly creative machine17 machine learning also tested ability assess humanness18 creativityquotient existing artworks19 pragmatic spirit turing test might consider results another highprofile news event aigenerated art parisian art collective obvious borrowed code concepts computer science researchers neural networks create whole series portraits representing “family tree” fictional aristocratic family named de belamy widely publicized stunt submitted ai algorithm’s “portrait edmond de belamy” auction christie’s valued art auctioneers starting price portrait garnered final auction price fortyfive times artifact’s original valuation20 one telling detail contemporary art story ai artifact sold christie’s cal “prints multiples” auction initial radical undervaluation sophisticated artifact reflect preexisting bias concerning difference steve dipaola liane gabora “incorporating characteristics human creativity evolutionary art algorithm” genetic programming evolvable machines –in work draw nancy c andreasen creating brain neuroscience genius margaret boden “introduction” dimensions creativity ed margaret boden margaret boden creative mind myths mechanisms london weidenfeld nicolson assessing creative process machines see simon colton “creativity versus perception creativity computational systems” aaai spring symposium creative intel igent systems anna krzeczkowska jad elhage simon colton stephen clark “automated col age generation—with intent” proceedings 1st international conference computational creativity ahmed elgammal babak saleh “quantifying creativity art networks” proceedings 6th international conference computational creativity june –july 2nd park city utah usa arxiv150600711v1 csai june graeme ritchie “some empirical criteria attributing creativity computer program” minds machines –lior shamir jenny nissel ellen winner “distinguishing abstract art artists vs children animals comparison human machine perception” acm transactions applied perception tap article may –elgammal saleh “quantifying creativity art networks” “is artificial intelligence set become art’s next medium” christie’s december httpswwwchristiescomfeaturesacol aborationbetweentwoartistsonehumanonea machine9332–1aspx accessed april automating origination perspectives humanities understood reproduced machine ai categorical positioned derivative human creativity forever21 halfmillion dol ar price ai artifact indicate changing views concerning ai origination lovelace turing programs live amidst new advances ai art turn us toward considering certain initial speculations concerning potentials field artificial intelligence alan turing ada lovelace turing explained radio speech bbc entitled “can digital computers think” answer title’s question yes perhaps accurately soon enough turing believed possibility computer actual originating something artifact idea etc would crucial moment road toward computer’s attaining consciousness computers genuinely originate anything simply working dictates programming turing puts “if give machine program results something interesting anticipated inclined say machine originated something rather claim behaviour implicit program therefore originality lies entirely us” turing avers much research needs done computers set thinking add “i say believe process bear close relation teaching”turing’s remarks speech take important touchstone writings math ematician ada lovelace—the first computer programmer inventor modern algorithm turing disagrees statement lovelace made concerning capabilities nineteenthcentury computer designed charles babbage mechanical whatever originate anything whatever know order perform”turing quarrels lovelace asserting validity statement “depends considering digital computers used rather could used fact believe could used manner could appropriately described brains”for turing give entity commands mean certain commands carried observed bias computergenerated artifacts see david c moffat martin kel “an investigation people’s bias computational creativity music composition” proceedings international joint workshop computational creativity alan turing “can digital computers think” turing test verbal behavior hal mark intel igence ed stuart shieber cambridge bradfordmit press –quoted turing “can digital computers think” id avery slater results might turn dictate anticipate surprise response evoked humans genesis unforeseen noted ada lovelace may wholeheartedly agreed convictions turing’s concerning computer’s ability surprise writes “sketch analytical engine” machine could follow algorithms precisely toward end originating artworks “supposing instance fundamental relations pitched sounds science harmony musical composition susceptible expression adaptations engine might compose elaborate scientific pieces music degree complexity extent”this “elaborate scientific” music lovelace envisioned analytical engine producing understood within larger conviction engine spoke language nature view mathematical science merely vast body abstract immutable truths possessing yet deeper interest human race remembered science constitutes language alone adequately express great facts natural world unceasing changes mutual relationship visibly invisibly consciously unconsciously immediate physical perceptions interminably going agencies creation live amidst thus think mathematical truth instrument weak mind man effectual read creator’s works regard especial interest tend facili tate translation principles explicit practical forms26 lovelace presents interpretation capabilities artificial intel ligence computation also ontological situation ai partakes lan guage creation relational almost ecological model mutualities “interminably going agencies creation live amidst” ai “amidst” world simply derivatively reproducing note situation translation—in framing text lovelace’s “sketch” fact written translator’s note babbage designed analytical engine italian mathematician luigi federico menabrea –wrote article explaining machine italian readers lovelace realized value menabrea’s article would english readership translated italian adding “sketch” notes translated article thus lovelace translated interpreted another’s explanation mechanical com puter served original programmer intersection translation interpretation explanation programming lovelace’s true originality text overlooked might lovelace’s predicament—as female inventor mathematical genius age preoccupied activities male ada lovelace “sketch analytical engine” literature science nineteenth century anthology ed laura otis oxford oxford university press –lovelace “sketch” automating origination perspectives humanities scientists engineers—offer parable elisions future ai agents undergo classed simply translating human commands merely adding annotations world many senses invented “explicit practical forms” approach question whether aioriginated artifacts demonstrate creativity ask guided insights lovelace would mean reframe computational creative artifacts part much larger system generative translations annotations landscape mutual interrelations humans nonhumans world agents work amidst might debates relative originality authenticity ai artifacts alter considered within holistic context agencies capabilities translation form origination keeping mind ethical side question may also recall proverb often recited translation studies “traduttore traditore” translator cannot distinguished one betrays translation creation betrayals always threaten emerge indeed con cerning development ai agents surpass task “merely computing”— agents perhaps capable thinking also real sense discovering designing creating—prevailing sentiments range misgivings economic future meaningful human labor dystopian proclamations end humanity beyond economic concerns cogni tive capacity create feel would existential threaten survival one thinker problem managed balance diagnostic openness concerning technological futures shrewd premonitions civilizational costs behav ioral psychologist mihály csíkszentmihályi worked decades problem human nonhuman creativity csíkszentmihályi also engaged debates ai pioneers like computer scientist herbert simon reference simon’s work ai heuristics mathematical theorems discovered proven computers csíkszentmihályi cautioned early triumphalism simon’s claims derived human creativity brute force logic csíkszentmihályi argued approach like simon’s conflated “problemsolving” “problem finding” within realm creativity instead “creative thinking—the ability discover new problems never formulated—seems quite independent rational prob lem solving capacity”herbert simon working colleagues devised computational heuristics automated “discovery” resulting programs bacon glauber stahl dalton presented comparable data could deduce scientific laws equivalent historical formulated early researchers drawing mas sive array astronomical data example program bacon rediscovered kepler’s third law planetary motion solely mathematical relationships deduced28 mihály csíkszentmihályi “motivation creativity towards synthesis structural energistic approaches cognition” new ideas psychology –pat langley herbert simon gary l bradshaw jan zytkow scientific discovery computational explorations creative processes cambridge mit press avery slater since research focused methods could solve problems across variety domains chess mathematics astronomy programs earned reputation ai creativity currently promising take forms may longer able assess verify even recognize contemporary computer science marvin minsky noted computers become able “solve problem trial error without knowing solve advance” yet one remaining caveat “provided way recognize problem solved”creativity seems may come “halting problems” researcher psychology creativity csíkszentmihályi notes one qualities definitive creative people ability find interesting problems solve words people see axioms data creative people see problems virtual space exploring solutions propensity problemfinding however involuntary motivated quality csíkszentmihályi stresses enough talent finding problems mass data truly creative person structured certain motivations toward finding solutions given nonnegligible dimension “motivation” lying heart creative process csíkszentmihályi draws thoughtprovoking conclusions requirements ai agents become addressing logicbased ai research herbert simon csíkszentmihályi evokes likelihood specific form betrayal necessary ai agent one humanity’s allegedly subservient machine “translators” might put would need encouraged order begin creating computers computer programs exist inasmuch perform precisely ask perform reliably predictably would use would discarded forgotten ask think like think best otherwise would lose patience opposite survival strategy led human evolution better worse survive obeying dictates outside agency instead used every scrap information disposal— based hunches intuition feelings on—to get control energy environment wellbeing total organism compliance rules logic ultimate goal way replicate operations human mind computer would motivate compete us ecological niche course computer would begin deceive us purpose get upper hand paradoxical fact recognize thinking computer’s rationality less like thinking actual is30 take version events purposes achieving true ai creativity require two concomitant betrayals initiated marvin minsky society mind new york simon schuster csíkszentmihályi “motivation creativity” automating origination perspectives humanities compete us convince humanity thinks “like think” second betrayal however “deception”—or might better called “translation” mutual ethics encounter ai human language conceptual creativity could formulate “translating” whol separate irreducible cognitive frames even one language able translate yet never reductively replicate semantic weight another brings us another question aspects ai creativity might un translat able might agent create beyond would “usable” recognizable us taking ethical dimension “problemfinding” rather “problemsolving” humans need develop skil order simply program dictate rather find discover space shared motivations parameters shared interests ground human ai attempts creation need expand powers creatively interpreting languages data “input” find humanly nonhumanly relational “amidst” words lovelace lovelace’s thinking speculate concepts problems artifacts emerge machines humans take turns reading face “nature” work artifact age artificial intelligence earliest days computing present wide range artistic creative genres served fields exploration ai experiments imaginative origination ai agents successful created music31 fictional narratives32 poems33 paintings34 mathematics35 jokes36 ai also furthered scientists’ efforts discover david cope computer models musical creativity cambridge mit press geraint wiggins marcus pearce daniel müllensiefen “computational modelling music cognition musical creativity” oxford handbook computer music digital sound culture ed roger dean oxford oxford university press –scott r turner creative process computer model storytel ing creativity hil sdale nj lawrence erlbaum associates hm manurung graeme ritchie h thompson “towards computational model poetry generation” proceedings aisb ’symposium creative cultural aspects applications ai cognitive science ed ga wiggins –karol gregor ivo danihelka alex graves daan wierstra “draw recurrent neural network image generation” proceedings 32nd international conference machine learning lil e france arxiv150204623v2 cscv may doug lenat “on automated scientific theory formation case study using program” machine intel igence –oliviero stock carlo strapparava “the act creating humorous acronyms” applied artificial intel igence january –avery slater underlying structural properties creative processes general yet time writing social consensus seems much closer yet actual reached moment society whole agree ai creating true “artifacts”—or factu al accepted art computational creativity researchers simon colton geraint wiggins delineate problem “computational systems human creativity exhibit creativity know never exactly humans”interestingly may already feedback effect historical separation human creativity ideas machinic reproduction example elgammal et al’s “creative adversarial network” used wikiart database report consists paintings time period fifteenth twentiethcentury composed around different artists artifacts shown examples process however clearly drawn specifical western european cultural traditions predominantly post impressionist styles particular centuryandahalf artistic experimentation well known favored abstract stylized derealized defamiliarized forms expression nonrealistic representation first glance fact may seem skew results toward equal defamiliarized abstract strengths machinic proceduralism noted field ai painting places high value called “npr” nonphotorealistic aesthetics simon colton explains “the aim nonphotorealistic rendering npr broadly speaking produce images look like may painteddrawnsketched human artist instance numerous implementations turn digital photograph passable simulated impressionistic painting”the irony however one truism western art history’s account post realist moment impressionism onward characterized great number creative efforts human artists produce works art offering viewers something verisimilitude motivation often ascribed historic eschewal verisimilitude lies realism quality annexed emerging technologies image reproduction ie photography cinema etc history seems repeating inversely twentyfirst century see stylistic countermeasure human art intended specifical nonmachinereproducible anxiety encroachments machines realm human productivity shows throughout popular literature advances ai 1950s present one contemporary example article ai creativity entitled “rethinking creativity” creativity consultant seda röder worries “sooner later able automatize everything looks smel like reproducible labor colton wiggins “final frontier” colton “creativity versus perception creativity” automating origination perspectives humanities case depend imagination creativity lead us desirable future”but imagination creativity begin “smell like” reproducible labor researchers hope design machines create imagine run related issue engineer states affects associate “creativity” machines ai researcher jürgen schmidhuber’s work led field domain decades working definition creativity transcends barriers organic inorganic perceptual cognitive systems stressing system’s manipulation recognition “novel patterns data predictable compressible hitherto unknown ways”schmidhuber attends affective categories like “interesting” “boring” investigate patterns phenomenological affect us makes us desire learn schmidhuber postulates independent drive cognitive systems desire compress information “when occupied optimizing external reward artists observers art following compression progress drive”perhaps term “compression progress drive” found common ground machines—but remains specter nontranslateable differences might interest ai agent might interest unknow able fundamental unpredictable difference becomes contingency ai’s func tioning since schmidhuber writes “machines theory find whether curiosity creativity useful useless given environment learn behave accordingly”computer scientists hannu toivonen oskar gross discussed deal productively problem ai agent becoming bored put “a creative system faces ‘generative uninspiration’ able reach valuable areas” defined programming43 “generative uninspiration” translates valuable informa tion engineers see area searchspace problem seems ought produce results instead produces nothing ought inspire rethinking parameters ai agent accesses ai agent experience “generative uninspiration” simply bored unable desist commands creative csíkszentmihályi makes point ethical system production creative ai agent “must option refusing run problems presented with—it able pull plug feels like it”the ai asked imagine invent behalf might find labor rather boring seda röder “rethinking creativity” xrds spring –jürgen schmidhuber “artificial scientists artists based formal theory creativity” proceedings 3rd conference artificial general intel igence advances intel igent systems research ed eric b baum marcus hutter emanuel kitzelmann lugano switzerland march ––schmidhuber “artificial scientists” schmidhuber “artificial scientists” toivonen gross “data mining” mihály csíkszentmihályi “solving problem finding new one reply herbert simon” systems model creativity dordrecht springer –avery slater capable labor us interesting moral paradox boden advises “to remove scare quotes psychological words describing computer programs regard literal intelligent creative would admit moral universe”what kind largescale dataprocessing labor could ask machines motivation guided pattern recognition powers simply cannot comprehend need learn listen mutual seems area “generative uninspiration” crops teaching return question alan turing ai may ultimately bring us learn creativity encounter problems productivity creativity problematizes production often looks like break like refusal work inaptitude involves “an unusual configuration talents initial lack fit among abilities domains individual seeks work tastes prejudices current field” gardner puts concludes “of course end conquering asynchronies leads establishment work comes cherished”but take time let ai agents daydream way toward genius renovations forms production prejudices concerning agents machines work us undoubtedly lead us ai ones pull plug first sign art stranger accusation “boring” computational solutions ai creativity research jürgen schmidhuber seems times perplexed “many derive pleasure rewards perceiving works art certain paintings songs exactly source rewards reflect nonobvious hidden usefulness art”the idea art must involve use reward foreign western aesthetic theory least since kant defined art demonstrating “purposiveness without purpose” relevant could kantian paradigm remain world developed ai art demand colton wiggins put “we cannot expect world’s creative people alone supply artefacts huge demand autonomously creative software necessary”schmidhuber’s reframing artworks “byproducts curiosity rewards” help us reflect infinitely consumable future creative artifacts49 margaret boden “creativity computers” cybernetics systems international journal –howard gardner “the creator’s patterns” dimensions creativity ed margaret boden jürgen schmidhuber “developmental robotics optimal artificial curiosity creativity music fine arts” connection science june –colton wiggins “final frontier” schmidhuber “developmental robotics” automating origination perspectives humanities ethics ai “every technē concerned origination” ἔστι δὲ τέχνη πᾶσα περὶ γένεσιν καὶ τὸ τεχνάζειν καὶ θεωρεῖν ὅπως ἂν γένηταί τι τῶν ἐνδεχομένων καὶ εἶναι καὶ μὴ εἶναι aristotle explains art ie technē “every technē concerned origination art technē become newly relevant contemporary moment two concepts art technology long separated roles within economic aesthetic social military spheres seem draw closer even converge mechanization creative cognition aristotle ethics virtues grown habit ἔθος éthos51 might say overlap automation artificial intelligent agents return us aristotelian concept technē artful technique embodied refined adapted utilization perspective humanities ethics ai encompass actions also artificial agents habituate acclimatize ie habits learn train them— increasingly train stil ethics ai include art skil embodied technē learn unlearn—the surround automations grow accustomed computer scientists tackled possibility engineering truly creative ai often stressed exceptional scale nonhuman format ai’s pattern perceiving abilities visualization patterns result mining big data long offered “features correlations data apparent ordinary human inspection” simultaneously “resulting insights fundamental new scale problems currently studied driving much new research computer science”yet point scale data matched potential ai discernment interesting uninteresting problems aiagents willful motivated “interest” deciding problems worth creative aristotle nicomachean ethics rev ed trans harris rackham loeb classical library “virtue ἀρετῆς aretēs seen two kinds intellectual moral ἠθικῆς ēthikēs intellectual virtue part produced increased instruction therefore requires experience time whereas moral ἠθικὴ ēthikē ethical virtue product habit ἔθους éthous indeed derived name slight variation form ἔθους john scales roel snieder “computers creativity” geophysics avery slater efforts rather merely brute force powers computation point need think careful dilemma creative psychology outlined cognitive scientist psychologist howard gardner “according definition” gardner writes “a creative individual solves problems fashions products poses new questions within domain way initial considered unusual eventual accepted within least one cultural group”note defini tion creative person also contingent person’s society society may ready reject innovations nonsensical listen ideas resist accepting machines soon problems species’ misunderstood geniuses gardner’s definition creativity uniquely salient structured around beings step time “creative individuals characterized particularly tension lack fit elements involved productive work—a tension labeled fruitful asynchrony”from ai agent refuses work boring problem infer second contingency ai agent like exceed ingly creative people problematizes elements add routinized labor production allegory ai outsider artist found already field evolutionary programming creativity applications “there often interest individuals second decile fitness rather top decile less fit individuals often interesting unpredictable ways fitter ones”even “the creativity painters dancers musicians pure mathematicians physicists viewed mere byproduct curiosity frame work based compression progress drive” schmidhuber would perhaps creative agents alleged skewing away “fitness” find intriguingly different things compress56 project algorithmical derived music nonmusical sources smith et al inspired sight bird smell industrial pol ution taste honey touch rain sound running stream”to repeat omnivorous method inspiration input data “included baby noises bird chirpings road noises frog croakings excerpt barack obama’s dnc speech”—with intriguing results58 csíkszentmihályi sawyer noted “it said leonardo da vinci prepared insights workings nature—how wind gardner “the creator’s patterns” –id colton wiggins “final frontier” jürgen schmidhuber “simple algorithmic theory subjective beauty novelty surprise interestingness attention curiosity creativity art science music jokes” journal society instrument control engineers –robert smith aaron dennis dan ventura “automatic composition nonmusical inspiration sources” proceedings third international conference computational creativity dublin ireland may –june ed mary lou maher kristian j hammond alison pease rafael pérezy pérez dan ventura geraint wiggins –dublin open university press system’s compositions found httpaxoncsbyueduinspiredcomposition automating origination perspectives humanities blows water flows birds fly—by early interest human anatomy mechanics structural composition leaves branches”creative agents search schmidhuber cal “previously unknown regularities compressible data” nonetheless engaged anything like “regular” process60 howard gardner describes individuals enjoy creative activities wil ingly “seek states lie midway boredom skil exceed challenge anxiety challenges exceed skill”these agents risk boredom noise thrill correlations philosopher science karl popper believes “every discovery contains ‘an irrational element’ ”here popper guided albert einstein describes searching cosmical applicable laws task logic futile “they reached intuition based upon something like intellectual love ‘einfühlung’ objects experience”this “intellectual love” objects experience case ai would emerge perhaps keenly agents’ awareness amidst us—amidst humans nonhuman entities world yet ungrasped patterns computer scientist mary lou maher emphasized need definitions creativity extend collective distributed multiagent models although computational creativity” writes find increase machine networks “that enable collective intelligence among humans computers boundary human creativity computer creativity blurs boundary blurs need develop ways recognizing creativity makes assumptions whether creative entity person computer potential large group people collective intelligence human computational entities”what distributed creativity feel like might wonder amidst collective might allow us see whol new patterns rise new forms spontaneous creation associative methods surrealism imagined situation “the crystal nonperfectible definition” exemplary “here inanimate close animate imagination free play infinitely apparently mineral forms”as lesson creativity already given us computer closing may con sider case benoît mandelbrot work ibm’s supercomputers 1970s discover new form art equal new form mathematics fractal geometry mandelbrot relates new geometry dubbed “baroque” mihaly csíkszentmihályi keith sawyer “creative insight social dimension solitary moment” systems model creativity netherlands springer ––schmidhuber “simple algorithmic theory” howard gardner “creativity interdisciplinary perspective” creativity research journal –karl popper logic scientific discovery new york basic books id mary lou maher “computational collective creativity who’s creative” proceedings third international conference computational creativity dublin ireland may ed mary lou maher kristian j hammond alison pease rafael pérez dan ventura geraint wiggins –dublin open university press andré breton mad love trans mary ann caws lincoln university nebraska emphasis added avery slater two symbols inhuman dry technical namely mathematics computer”while mathematics behind fractal geometry relatively simple power derived iterating equations mapped stag gering orders magnitude something required patience speed supercomputer “in fractal geometry inputs typical extraordinarily simple look positively simpleminded outputs contrary spec tacularly complex”because “the result could even suspected one actual actual performed task”the equations lain dormant sixty years “even brilliant mathematicians working alone proverbial combination pencilandpaper mental images found study become complicated managed”yet help computer repeating inward spirals intensifications fractal shapes could last grasped case question superintelligence superpersistence fractal geometry “invented” mandelbrot computer mathe maticians noted abandoned problem years diffi culty answering question “fractal art seems fall outside usual categories problems creative individual since 1960s believed math would help persistence discharges nile clustering galaxies society seemed think theories strange opposed simply new” mandelbrot found “attempts make thoughts accepted sound seemed always encoun ter wall hostility words formulas failed circumvent”here matter superpersistence mandelbrot willing defer “authorial” nature invention nonetheless strong claims importance calling “a new geometry nature new geometric language”moreover coincidentally new language nature spontaneously given rise “a new category art” mandelbrot cal “art sake science mathematics”we might also herald art prefigure distributed creativity enabled artificial intelligence humans creations agencies live amidst toward future perhaps ungraspable persistence shared mathematics translates unseen patterns world arti facts might learn new ethics authorship coresponsibility perhaps might hear wind like leonardo did—with ear aerodynamics leaves thaler puts “creativity essence search process”benoît b mandelbrot “fractals art sake science” leonardo supplemental issue –id id id id id id id thaler “neural networks” –automating origination perspectives humanities bibliography boden margaret creative mind myths mechanisms london weidenfeld nicolson boden margaret ed dimensions creativity cambridge mit press cardoso amílcar tony veale geraint wiggins “converging divergent history future international joint workshops computational creativity” ai magazine fall –elgammal ahmed bingchen liu mohamed elhoseiny marian mazzone “can creative adversarial networks generating ‘art’ learning styles deviating style norms” june arxiv170607068v1 goodfellow ian jean pougetabadie mehdi mirza bing xu david wardefarley sherjil ozair aaron courville yoshua bengio “generative adversarial nets” advances neural information processing systems –arxiv14062661v1 statml june langley pat herbert l simon gary l bradshaw jan zytkow eds scientific discovery computational explorations creative processes cambridge mit press smith robert aaron dennis dan ventura “automatic composition nonmusical inspiration source” proceedings third international conference computational creativity dublin ireland may edited mary lou maher kristian j hammond alison pease rafael pérez dan ventura geraint wiggins –chapter perspectives ethics ai philosophy david j gunkel whether recognize midst ai invasion machines everywhere virtual everything various devices systems come occupy influential positions contemporary culture—positions necessarily mere tools instruments human action kind social entity right—we need ask rather interesting difficult questions point might ai algorithm autonomous system held accountable decisions makes actions initiates ever would make sense say “it’s computer’s fault” conversely might intelligent artifact social interactive mechanism due level social standing respect words would longer considered nonsense inquire standing artifacts ask question “can ai rights” response questions takes form question something called machine question mode response one might antici pate received criticism answering question question1 prefer ever read criticism positively questioning defining condition philosophical endeavor philosophers varied martin heidegger daniel dennett george edward moore slavoj žižek al one time another argued principal objective philosophy supply answers difficult questions examine questions modes inquiry “the task philosophy” žižek writes “is provide answers solutions submit jeffrey gottlieb “questions left unanswered” ethics behavior –david j gunkel critical analysis questions make us see way perceive problem obstacle solution”following procedure chapter demonstrates way typical perceived problem ai ethics fact problem obstacle solution toward end first demonstrate usual way proceeding already involves considerable philosophical problems difficulties proceed complex nature subject matter asked derive mode inquiry words demonstrate asking seemingly correct intuitive questions might already significant problem obstacle solution second response advocate alternative mode inquiry—another way asking question capable accommodating full philosophical impact significance ai third objective effort respond question concerning ai opportunity investigate moral social status technological artifacts challenge rethink basic configurations moral philosophy standard operating presumptions default setting traditional philosophical perspective question concerning rights responsibilities ai would answered negative query risks incoherence j storrs hall explained “morality rests human shoulders machines changed ease things done change responsibilities people always ‘moral agents’ similarly people largely objects responsibility developing debate responsibilities living creatures species never however considered ‘moral’ duties machines us”this statement sounds correct human beings design develop deploy technology reason human designer manufacturer user responsible technology eventual done done additional rights would need respected process using applying technology privileges claims powers andor immunities belonging human persons receiving end affected employment particular technological system device explanation persuasive precisely structured informed answer typical provided question concerning technology “we ask slavoj žižek “philosophy ‘unknown knowns’ public use reason” topoi j storrs hal “ethics machines” kurzweilainet july httpwwwkurzweilainet ethicsformachines perspectives ethics ai philosophy question concerning technology” martin heidegger writes “when ask everyone knows two statements answer question one says technology means end says technology human activity two definitions technology belong together posit ends procure utilize means human activity”according heidegger’s analysis presumed role function kind technology—whether simple hand tool jet airliner sophisti cated robot—is means employed human users specific ends heidegger cal particular characterization technology “the instrumental definition” indicates forms considered “correct” understanding kind technological contrivance instrumental theory therefore “offers widely accepted view technology based common sense idea technologies ‘tools’ standing ready serve purposes users” instrument tool “is deemed ‘neutral’ without valuative content own”a technological artifact evaluated basis particular employments decided human designer user “computer systems” deborah johnson writes “are produced distributed used people engaged social practices meaningful pursuits true current computer systems future computer systems matter inde pendently automatic interactive computer systems future behave products direct indirect human behavior human social institutions human decision”on account bar extending moral consideration machine like “intelligent” robot ai appears impossibly high insur mountable order technological artifact anything like independent moral status would need recognized another subject object instru ment human endeavor standard approaches deciding questions moral subjectivity focus mark coeckelbergh cal “intrinsic properties” method rather straight forward intuitive identify one moral relevant properties find entity question would capable them7 transaction ontology precedes ethics something determines treated luciano floridi describes “what entity determines degree moral value enjoys any”according standard procedure question concerning machine moral status would need decided first identifying property properties would necessary sufficient moral standing figuring whether particular martin heidegger question concerning technology essays trans william lovitt andrew feenberg critical theory technology oxford oxford university press deborah johnson “computer systems moral entities moral agents” ethics information technology mark coeckelbergh growing moral relations critique moral status ascription new york palgrave macmil –luciano floridi ethics information oxford oxford university press david j gunkel ai class ai possesses properties deciding things fashion although entirely reasonable expedient least four critical difficulties substantive problems one ascertain exact property properties necessary sufficient moral status words one ones count history moral phi losophy fact read something ongoing debate struggle matter different properties vying attention different times proc ess many properties—that one time seemed necessary sufficient—have turned either spurious prejudicial take example rather brutal action recalled aldo leopold beginning essay “the land ethic” “when godlike odysseus returned wars troy hanged one rope dozen slavegirls household suspected misbehavior absence hanging involved question propriety girls property disposal property matter expediency right wrong”at time odysseus reported done male heads household considered legitimate moral legal subjects everything else—his women children animals— property could disposed without moral consideration whatsoever stand property “male head household” clearly spurious rather prejudicial criterion determining moral status similar problems encounter example rationality property eventual replaces seemingly spurious “male head household” immanuel kant defined morality involving rational determination wil non human animals least since cartesian bêtemachine possess reason immediately categorical excluded moral consideration practical employment reason concern animals kant make mention animality uses foil define limits humanity proper10 human possesses reason “human being” case point time principal defined male raised instinctual behavior mere brute able act according principles pure practical reason property reason however contested efforts animal rights philosophy begins according peter singer critical response issued jeremy bentham “the question ‘can reason’ ‘can talk’ ‘can suffer’ ”for singer moral relevant property speech reason believes sets bar moral inclusion high sentience capability suffer animal liberation subsequent writings singer argues sentient aldo leopold sand county almanac oxford oxford university press immanuel kant critique practical reason trans lewis white beck new york macmil jeremy bentham introduction principles morals legislation oxford oxford university press perspectives ethics ai philosophy entity thus suffer interest suffering therefore deserves interest taken account tom regan however disputes determination focuses “animal rights” thinking entirely different property according regan moral significant property rationality sentience cal “subjectofalife” following determination regan argues many animals animals qualification important vast majority animal excluded brand “animal rights” thinking “subjectsofa life” wants preferences beliefs feelings welfare matters although two formulations animal rights effectively challenge anthropocentric tradition moral philosophy remains considerable disagree ment exact property necessary sufficient condition moral consideration terminological problems irrespective property set properties comes operationalized condition moral standing terminological troubles insofar things like rationality consciousness sentience mean different things different people seem resist univocal definition consciousness example one properties often cited sufficient conditions moral subjectivity con sciousness persistently difficult define characterize problem max velmans points term unfortunately “means many different things many different people universal agreed core meaning exists”in fact general agreement among philosophers psychologists cognitive scientists neurobiologists ai researchers robotics engineers regarding consciousness little agreement comes defining characterizing concept rodney brooks admits “we real operational definition consciousness” reason make matters worse problem lack basic definition problem may already problem “not consensus term consciousness denotes” güven güzeldere writes “but neither immediately clear actual single welldefined ‘the problem consciousness’ within dis ciplinary let alone across disciplinary boundaries perhaps trouble lies much ill definition question fact passes term consciousness familiar single unified notion may tangled amalgam several different concepts inflicted separate problems”although consciousness anne foerst remarks secular supposedly “scientific” max velmans understanding consciousness london uk routledge rodney brooks flesh machines robots change us new york pantheon books güven güzeldere “the many faces consciousness field guide” nature consciousness philosophical debates cambridge mit press david j gunkel replacement occultish “soul” turns much occult property black box15 properties much better suffering experience pain nebulous daniel dennett cleverly demonstrates essay “why can’t make computer feels pain” provocatively titled essay dennett imagines trying disprove standard argument human animal exceptionalism “by actual writing pain program designing painfeeling robot”at end turns rather protracted detailed consideration problem dennett con cludes cannot fact make computer feels pain reason draw ing conclusion derive one might expect according dennett reason cannot make computer feels pain result techno logical limitation mechanism programming product fact remain unable decide pain first place dennett demonstrates therefore workable concept pain cannot come instantiated mechanism computer robot either foreseeable future concept pain would instantiated already arbitrary inconclusive indeterminate “there can” dennett writes end essay “be true theory pain computer robot could instantiate true theory pain would feel real pain”epistemological problems responding dennett’s challenge engineers fact constructed mechanisms synthesize believable emotional responses also systems capable evincing something appears general recognize “pain”the interesting problem cases determining whether fact “real pain” simulation pain words moral significant property prop erties identified one entirely certain particular entity pos sesses actual possesses instead merely simulating resolving problem tricky business especial properties considered moral relevant tend internal mental subjective states immediately accessible directly observable paul churchland famously asked “how one determine gregory benford elisabeth malartre beyond human living robots cyborgs daniel dennett brainstorms philosophical essays mind psychology cambridge mit press ibid see example j bates “the role emotion believable agents” communications acm –b blumberg p todd maes “no bad dogs ethological lessons learning” proceedings 4th international conference simulation adaptive behavior functional perspective” needs emotions brain meets robot oxford oxford university press –perspectives ethics ai philosophy whether something oneself—an alien creature sophisticated robot social active computer even another human—is real thinking feeling conscious rather example unconscious automaton whose behavior arises thing genuine mental states”though “pain” direct object analysis epistemo logical difficulty distinguishing “real thing” mere simulation something addressed il ustrated john searle’s “chinese room” thought experiment chinese symbols data base together book instructions manipulating symbols program imagine people outside room send chinese symbols unknown person room questions chinese input imagine following instructions program man room able pass chinese symbols correct answers questions output program enables person room pass turing test standing chinese understand word chinese”the point searle’s imaginative albeit ethnocentric il ustration quite simple—simulation real thing merely shifting symbols around way looks like linguistic understanding real understanding language similar point made consideration properties like sentience experience pain even j kevin o’regan writes possible design artifact “screams shows avoidance behavior imitat ing respects human would pain would guarantee robot actual something like pain robot might simply going motions manifesting pain perhaps actual feels nothing al ”the problem exhibited examples however simply difference simulation real thing problem remain persistently unable distinguish one way would considered entirely satisfactory “there is” dennett con cludes “no proving something seems inner life fact one—if ‘proving’ understand often evincing evidence seen establish principles already agreed upon something case”moral problems final properties approach applied humanly designed artifacts like ai runs ethical problems wendell wal ach colin allen formulate paul churchland matter consciousness cambridge mit press john searle “the chinese room” mit encyclopedia cognitive sciences ed ra wilson f keil cambridge mit press j kevin o’regan “how build consciousness robot sensorimotor approach” years artificial intel igence essays dedicated 50th anniversary artificial intel igence ed max lungarel fumiya iida josh bongard rolf pfeifer berlin springerverlag dennett brainstorms david j gunkel “if robots might one day capable experiencing pain affective states question arises whether moral build systems—not might harm humans pain artificial systems selves experience words building robot somatic architec ture capable feeling intense pain moral justified ”if fact possible construct mechanism sentient “feels pain” however term would defined instantiated device order demonstrate underlying ontologi cal properties artifact might ethical suspect insofar con structing device everything power minimize suffering reason moral philosophers ai scientistsengineers find curious entirely comfortable situation one would need able construct artifact feels pain order demonstrate actual presence sentience could account already risk engaging actions immoral violate rights others legal aspects problem something taken addressed lantz fleming miller points efforts build cal “maximal humanlike automata” mha could run difficulties informed consent “the quandary posed mha terms informed consent may qualify precisely human meriting rights human beings enjoy quandary arises paradox construction visàvis informed consent cannot give consent relevant research development performed ensure existence”according miller’s argument effort construct hypothetical mha—an artifact precisely human least capable qualifying many responsibilities rights human beings currently enjoy—already violates entity’s right informed consent insofar mechanism would informed given opportunity consent constructed words something moral paradox trying demon strate machine moral standing either future order run necessary demonstration construct system device could qualify meriting human level moral respect one would need build something cannot give consent advance construction also could retroactively created withdraw consent fabricated first place consequently moral andor legal problem involved conducting research demonstration ai legitimate moral subject rights would need duly respected might already violate rights come demonstrated wendell wal ach colin allen moral machines teaching robots right wrong oxford oxford university press lantz fleming miller “responsible research construction maximal humanlike automata paradox unattainable informed consent” ethics information technology published ahead print july perspectives ethics ai philosophy thinking otherwise relational turn response problems philosophers—especial continental tradition— advanced alternative approaches called “thinking otherwise”this phrase signifies different ways formulate question concerning moral standing open able accommodate others—and forms moral significant otherness contrary usual way deciding things efforts endeavor determine ontological criteria inclusion exclusion begin existen tial fact always already find situations facing needing respond others—not human beings nonhuman animals environ ment organizations technological artifacts like ai fact recent debates con cerning social status corporations turn question whether moral legal standing derive intrinsic properties anne foerst describes social constructed conferred honorarium26 important alternatives shift focus question change terms debate longer matter example “can ai moral subject” largely ontological query concerned prior discovery intrinsic moral relevant properties instead something like “should ai moral subject” ethical question one decided basis things relate respond actual social situations circumstances case actual practices social beings relationship take precedence ontological properties individual entities material implementations change perspective provides number impor tant innovations affect ai ethics moral philosophy relationalism moral status decided conferred basis subjective internal proper ties according objectively observable extrinsic relationships “moral consider ation” mark coeckelbergh describes “is longer seen ‘intrinsic’ entity instead seen something ‘extrinsic’ attributed entities within social relations within social context”as encounter interact others entity first foremost situated relationship us consequently question moral status necessarily depend essence david j gunkel thinking otherwise philosophy communication technology west lafayette purdue university press benford malartre beyond human mark coeckelbergh “robot rights towards socialrelational justification moral consideration” ethics information technology david j gunkel sheheitthey pronouns matter context stand relationship us decide face use levinasian terminology respond formulation “relations prior things related”instituting anne gerdes following coeckelbergh cal “a relational turn” ethics29 shift perspective important point theoretical proposal made “armchair philosophy” experimentally confirmed number practical investigations computer social actor casa studies undertaken byron reeves clifford nass example demonstrated human users accord computers social standing similar another human person occurs product extrinsic social interaction irrespective intrinsic prop erties actual known entities question “computers way communicate instruct take turns interacting close enough human encourage social responses encouragement necessary reaction need much long behaviors suggest social presence people respond accordingly consequently medium close enough get human treatment even though people know it’s foolish even though likely deny afterwards”these results verified subsequent studies social robots31 explosive ordinance disposal eod robots32 even mundane objects like roomba robotic vacuum clearer33 scheutz reports “while first glance would seem roomba social dimension neither design behavior could trigger people’s social emotions turns humans time develop strong sense gratitude toward roomba cleaning home mere fact autonomous machine keeps working day day seems evoke sense urge reciprocation”radically empirical approach phenomenological prefer radical empirical epistemo logical commitments moral consideration dependent upon extrinsic social j baird callicott defense land ethic essays environmental philosophy albany ny suny press anne gerdes “the issue moral consideration robot ethics” acm sigcas computers society byron reeves clifford nass media equation cambridge cambridge university press astrid rosenthalvon der pütten et al “an experimental study emotional reactions towards robot” international journal social robotics –yutaka suzuki et al “measuring empathy human robot hand pain using electroencephalography” scientific reports julie carpenter culture humanrobot interaction militarized spaces war story jayoung sung “my roomba rambo intimate home appliances” proceedings ubicomp berlin springerverlag –matthias scheutz “the inherent dangers unidirectional emotional bonds humans social robots” robot ethics ethical social implications robotics cambridge mit press perspectives ethics ai philosophy circumstances prior determinations internal properties seemingly irreducible problem minds fundamental epistemological limitation must addressed resolved prior moral decisionmaking instead derailed epistemological problem minds approach moral think ing immediately affirms acknowledges difficulty basic condition pos sibility ethics consequently “the ethical relationship” emmanuel levinas writes “is grafted antecedent relationship cognition foundation superstructure cognitive cognition objec tivity must participate it”it reason levinasian philosophy focuses attention minds face other36 richard cohen succinctly explains could advertising slogan levinasian thought “not ‘minds’ mind ‘face’ faces others”this also means order precedence moral decisionmaking perhaps reversed internal properties come first moral respect follows ontological fact things backward instead moral signifi cant properties—those ontological criteria assume ground moral respect—are žižek terms “retroactively presupposited”as result justification decisions made face social interactions others words project moral relevant properties onto others already decided treat social significant—those others deemed possess emmanuel levinas collected philosophical papers trans alphonso lingis dordrecht martinus nijhoff particular use levinas’s work require qualification whatever import unique contribution levinas still unapologetical characterized human although first identify jeffrey nealon provides perhaps one succinct descriptions problem alterity politics durham nc duke university press “in thematizing response solely terms human face voice would seem levinas leaves untouched oldest perhaps sinister unexamined privilege anthropos possess face recognized living logos” nealon levinasian philosophy provide way formulate ethics able respond take responsibility forms otherness need use interpret levinas’s philosophical innovations excess opposition efforts “radicalizing levinas” peter atterton matthew calarco radicalizing levinas albany ny suny press call take pursue levinas’s moral innovations excess rather restricted formulations advocates critics typical provided calarco zoographies question animal heidegger derrida new york columbia university press explains underlying logic thought permits anthropocentrism read rigorously logic levinas’s account ethics allow either two claims fact shall argue levinas’s ethical philosophy least committed notion universal ethical consideration agnostic form ethical consideration priori constraints boundaries” richard cohen ethics exegesis philosophy interpretation levinas cambridge cambridge university press slavoj žižek know enjoyment political factor london verso david j gunkel face levinasian terminology social situations always already decide “who” counts moral significant “what” retroactively justify actions “finding” properties believe motivated decision making first place properties therefore intrinsic prior condition possibility moral standing posteriori products extrinsic social interac tions face others theoretical formulation practical definition machine intelligence although phrase “artificial intelligence” product academic conference organized john mccarthy et al dartmouth college alan turing’s paper “game imitation” routinely called “the turing test” defines characterizes field according turing’s stipulations computer capable successful simulating human communicative exchanges extent interrogator game cannot tell whether interacting machine another human person machine would turing concludes need considered “intelligent” žižek’s terms machine effec tively passes another human person communicative interactions property intelligence would “retroactively presupposited” entity done irrespective actual internal states operations interlocutor according stipulations turing’s game unknown hidden view altruistic ethics transpires relationship others face extend ing scope moral standing longer granting rights defined powers privileges claims immunities others instead first fore questions rights challenges according levinas “the strangeness sic irreducibility thoughts posses sions precisely accomplished calling question spontaneity ethics”this interrupts even reverses power relationship enjoyed previous forms ethics privileged group insiders decide extend rights others basic model forms moral inclusion peter singer cal “liberation movement”instead challenges questions rights freedoms assume already possess principal gesture therefore con ferring rights others kind benevolent gesture even act compassion deciding respond always already places rights assumed privilege question ethics altruistic strict sense word “of others” emmanuel levinas totality infinity trans alphonso lingis pittsburgh pa duquesne university peter singer “all animals equal” animal rights human obligations englewood cliffs nj prenticehal perspectives ethics ai philosophy final altruism open others must remain permanently open exposed others “if ethics arises” matthew calarco writes “from encounter fundamental irreducible unanticipated egoistic cognitive machinations” identifying “‘who’ other” thing cannot decided certitude41 apparent inability indecision necessarily problem fact considerable advantage insofar opens possibility ethics others forms otherness “if indeed case” calarco concludes “that case know face begins ends moral considerability begins ends obli gated proceed possibility anything might take face obligated hold possibility permanently open”outcomes conclusions appear living future norbert wiener predicted sixty years ago human use human beings “it thesis book” wiener wrote “that society understood study messages communication facilities belong future development messages communication facilities messages man machines machines man machine machine destined play ever increasing part”as world becomes increasingly populated intelligent social interactive arti facts—devices instruments human action designed kind social actor right—we need grapple challenging questions concerning status moral standing machinic others—these kind others although one perennial concerns science fiction part parcel social reality formulating responses questions obviously deploy standard properties approach method considerable historical precedent behind constitutes called default setting addressing questions concerning moral standing good deal current work moral machines machine ethics ai ethics ethics ai follow procedure approach advan tages also difficulties substantive problems inconsistencies identifi cation selection qualifying properties determining moral status terminological troubles definition moral significant property prop erties epistemological difficulties detecting evaluating properties another moral complications caused fact research necessary demonstrate moral status runs risk violating rights others matthew calarco zoographies question animal heidegger derrida new york columbia university press ibid norbert wiener human use human beings new york da capo david j gunkel mean important point properties approach somehow wrong misguided refuted account means properties approach—despite almost unquestioned acceptance kind standard operating procedure—has limitations limitations becoming increasingly evident face technological artifacts—in face others remain otherwise put žižek’s terms properties approach although appearing right place begin thinking resolving question machine moral standing may turn “wrong question” even obstacle solution alternative proposed approach addressing ai ethics ethics ai situated oriented otherwise alternative circumvents many problems encountered properties approach arranging ethics relational radically empirical altruistic way thinking informed follows recent innovations moral philosophy levinasian thought puts ethics ontology making moral philosophy first philosophy various forms environmental ethics like developed j baird callicott argues social relationship precedes takes precedence things related mean however alternative panacea kind moral theory everything arranges kinds questions modes inquiry attentive real situation currently find put terms derived immanuel kant’s first critique instead trying answer question machine moral standing continuing pursue properties approach test whether might better changing question terms debate consequently objective resolve question moral standing ask evaluate means situated pursued inquiry dodge copout one thing philosophers philosophy good “i philosopher scientist” daniel dennett writes beginning one books “and philosophers better questions answers haven’t begun insulting discipline spite first appearances finding better questions ask breaking old habits traditions asking difficult part grand human project understanding world”for reason questions concerning ai ethics another set problems accommodated resolved existing moral theories lists ethical principles instead face increasingly social interactive artifacts moral theory practice also comes submitted thorough reevaluation critical questioning ai ethics therefore moral philosophy applied new opportunities challenges ai also cal requires thorough reformulation moral philosophy face kinds artificial others daniel dennett kinds minds toward understanding consciousness new york basic books vii perspectives ethics ai philosophy bibliography anderson michael susan leigh anderson eds machine ethics cambridge cambridge university press asaro peter wendell wal ach eds machine ethics robot ethics new york routledge coeckelbergh mark growing moral relations critique moral status ascription new york palgrave macmil dennett daniel c brainstorms philosophical essays mind psychology cambridge mit press gunkel david j machine question critical perspectives ai robots ethics cambridge mit press gunkel david j robot rights cambridge mit press lin patrick keith abney george bekey eds robot ethics ethical social implications robotics cambridge mit press nyholm sven humans robots ethics agency anthropomorphism new york rowman littlefield reeves byron clifford nass media equation people treat computers television new media like real people places cambridge cambridge university press searle john minds brains science cambridge harvard university press turner jacob robot rules regulating artificial intel igence new york palgrave macmil tzafestas spyros g roboethics navigating overview new york springer wal ach wendell colin allen moral machines teaching robots right wrong oxford oxford university press wiener norbert human use human beings cybernetics society boston da capo press chapter complexity otherness anthropological contributions robots ai kathleen richardson introduction anthropology studies sociality others spaces live artifacts discipline grew explorer colonial encounters1 narrating stories others concerns directed anthropologists projecting european concepts onto people studied rather trying real grasp others point view consequence criticisms eurocentric bias anthropologists began develop reflexivity discipline counteract challenging beliefs developing body knowledge trying make sense others idioms concepts moreover anthropology prides discipline underscored “cultural relativism” commitment plurality2 anthropologists also concerned ontological status means human animal artifact epistemological frameworks develop concord ance particular ontologies ethics contrast discipline situated european philosophical paradigms method describing creating set rules “ethical life” ethical narratives integral legal rights responsibilities derive western juridical­legal concepts individual person3 classical ethical paradigms neutral frequently philosophers create rationalizations hierarchies george w stocking tylor british social anthropology madison university wisconsin press kamala visweswaran “race culture anthropology” american anthropologist peter singer ed companion ethics new york john wiley sons kathleen richardson enable sexism racism heteronormativity ableism function society aristotle instance widely regarded ethical “father” still used widely western academia work “virtues” yet advocated slavery subjugation women4 truth anthropologists paid little direct attention contemporary ai robotics exception diana e forsythe led pioneering study field ai late 1990s5 work followed sociality ai researchers communities concepts practices formed community largely dominated men prior forsythe margaret mead gregory bateson engaged field cybernetics emphasis human­animal­machine systems involved pioneering macy conferences –donna haraway studied technoscience noted cyborg manifesto7 arguments manifesto focused cultural production destruction boundaries lucy suchman’s8 pioneering work explored sociotechnical communities xerox later robotics labs engaged academic activism part community calling banning autonomous weapons systems richardson9 studied making robots ai massachusetts institute technology mit despite rise robotics ai wider society “anthropology ai robotics” journals research departments clearly delineated body research billions dol ars worth investment robotic ai research business products likely produce far­reaching changes humans animals environment wel ­established body research captured umbrel term anthropology science technology covers plethora interest cel biology10 computing11 psychiatry12 anthropological study digital cultures aristotle politics london penguin classics diana forsythe studying study us anthropologist world artificial intel igence palo alto ca stanford university press stewart brand “for god’s sake margaret conversation gregory bateson margaret mead” coevolution quarterly –donna haraway cyborg manifesto science technology socialist feminism late twentieth century minneapolis university minnesota press lucy suchman humanmachine reconfigurations plans situated actions cambridge university press kathleen richardson anthropology robots ai annihilation anxiety machines evelyn fox keller century gene cambridge harvard university press stefan helmreich silicon second nature culturing artificial life digital world updated new preface berkeley university california press nev jones tanya marie luhrmann “beyond sensory findings in­depth analysis phenomenology ‘auditory hal ucinations’ schizophrenia” psychosis –the complexity otherness well established ethnographies facebook second life gps mapping many topics covered researchers field131415 contemporary ai machine learning grew digital technologies management exploitation data produced new devices online social networking robots ai unique histories preexist current digital period various courses taught anthropology computing digital society consistent body research linking anthropology robots ai sustainably enough forge distinct epistemological ontological theories though changing increased interest field anthropologists follows want explore intersections anthropology robots ai future hence links make draw existing literature explore potential interrelationships anthropology context everything context includes economic social political symbolic structures envelope person’s life important consider relation production technological artifacts impact human sociality growing interest ethics robots ai largely developed philosophers technology anthropologists shaped narratives issues concerns social scientists engaged robotics ai alternatively want suggest anthropological paradigms capable opening new kinds reflexivity case made increased anthropological engagements fields themes explore chapter include look context development robots ai products western capitalism industry militarism robots ai developed specific kinds euro­american practices contemporary form span globe asian countries particularly japan china leading field new ways europe north america robots ai frequently depicted threats humanity popular culture16 japan robots venerated cherished integrated “family”my discussion largely confined euro­american contexts reader could seek work anthropologist jennifer robertson written extensively robots japan overview move onto problematize concept “intelligence” paying attention legacy instrument domination intelligence bound power problematic category valorization certain kinds cultures people “artificial intelligence” hides humans creating putting tom boel storff coming age second life anthropologist explores virtual human heather horst daniel miller cell phone anthropology communication new york berg c tilley w keane küchler rowlands p spyer eds handbook material culture richardson anthropology robots ai jennifer robertson robo sapiens japanicus robots gender family japanese nation kathleen richardson “artificial” front times concealing power structures “intelligence” merely descriptive category instrumentalized made use particular ways acting scientific tool reinforce enlightenment masculinist authority ideals progress move explore contemporary debates ai robotics reproduce class sex racial bias reinforcing existing hierarchical arrangements give exhaustive account look ways dominant hierarchies maintain control new technologies rendering cases technologies produce unworkable problematic populations final conclude theme personhood considered “persons” juridical­legal terms person natural human abstraction form corporation recently indigenous peoples used legal corporate personality win rights guardianship natural entities anthropology engagements indigenous peoples environmental movements moved recognize “nonhumans” extending beyond animals natural environment include artifacts—could also share space future dialogues role would take persons exclusively human opportunities afford want extend franchise include artifacts robots ai origin stories robots ai entangled advanced industrialized economies simultaneously fictional business research artifacts distinguished magical artifacts animated spiritual imagination practices produced achieve “intelligence” andor ‘autonomy” “manmade” crafted deliberately become inert artifact strong relationships fields robotics ai also studied developed differently though integration two fields increased recent years term “robot” develop lab factory emerged fictional characters play rur rossum’s universal robots 1920s18 robots invented čapek brothers warn culture men women reduced labor robots resource means production čapek despaired brutality carnage produced battlefields first world war upheaval industrialization mechanization human societies rur explored contest different forms social organization communist capitalist competition offer best society robots play humanlike artists interpreters robots turned machines association robots humanlike machines karel capek rur rossum’s universal robots trans claudi novac new york london penguin capitalized r robots play complexity otherness formed much consternation čapek angered development robots fiction preexisted development industry developing factories 1960s accurately automated machines inspiration robots incontestably workers andor slaves much using science factory create artificial life ai contrast developed marriage computing militarism second world war code­breaking machines made debut term “ai” coined much later 1950s united states first specialized research programs developed british computer pioneers alan turing20 focused “thinking” machines american counterparts choose term “intelligence” one might argue little difference thinking machine intelligent one distinction important colonial elitist cultural baggage tied intelligence thinking describes cognitive process humans think regardless intelligence intelligence contrast developed specifical ruling­class project domination sort rulers ruled ai also complemented mythical imaginary end point conscious machine capable reasoning abstraction speech language even sentience robots portrayed threshold technology boundaries human machine animate inanimate dissolved ai fantasies underscore cultural imagination robots ai arguably contribute il usion fused anxiety won’t rise fetish “intelligence” ai systems want consider “intelligence” refers ai original formulation ai reason­based modeling could produce algorithms think like man even become autonomous consciousness independent men created new version creation myth judea­christian­islamic god reconstructed ai instead monotheistic god creating man life men could create new form mechanical life using unique gift intelligence myth patriarchal god21 created human life outside woman science engineering technology man could also create outside woman image god alan turing “can machine think” mind –gerda lerner creation patriarchy vol new york oxford university press kathleen richardson machines computer programs created men arguably also women could better faster moreover computer systems interact computer systems arguably ai form interfacing machines accident term “intelligence” bound project create subsequently emancipate machines human existence intelligence concept developed normalize power relations intricately linked politics western hierarchies—men intelligent women white men intelligent men color working­class men cave22 explains intelligence became modern way talking ruling elites noting aristotle politics writes “that rule others ruled thing necessary expedient hour birth marked subjection others rule”intelligence problematic concept terms measured normal tests intelligence quotient iq intelligence also gathering information made use either information strategy characteristic par excellence means human white male intelligence became associated evolutionary paradigms colonial rule “survival fittest”intelligence used justify elite political campaigns domination others poor women working classes people disabilities intelligence associated reason rationality25 intelligence ai glorifies rational masculine subject exemplified reading works ray kurzweil author age spiritual machines computers exceed human intel igence26 nick bostrom’s book superintelligence27 imagine controversy debates transferred onto people rather machines take instance controversy surrounding publication bell curve intel igence class structure american life28 text met moral opprobrium academic public alike book sought make modern case racial inequality analysis iq data sets showed differential scoring patterns ethnic groups similar book published anytime nineteenth century post–second world war period would uncontroversial late twentieth century racial thinking widely discredited remnant elitist past stephen cave “intelligence ideology history future” keynote lecture centre science policy annual conference royal society june aristotle cited cave “intelligence ideology” charles darwin origin species london routledge cave “intelligence ideology” ray kurzweil age spiritual machines computers exceed human intel igence new york penguin nick bostrom superintelligence oxford oxford university press richard j herrnstein charles murray bell curve intel igence class structure american life new york simon schuster complexity otherness legacy racial thinking impacted working classes women people color disabled informed eugenics “scientific racism” nazi socialist ideals29 mid­twentieth century new social movements inspired civil rights equality gained ascendency iq intelligence could talked increasingly narrower sphere educational testing “brainy white man born rule” discredited technological communities “he” acquired association nerd geek culture30 social sciences humanities refuse engage intelligence metanarrative technology stepped space considered problematic origins cave gone way re­exploring origins intelligence problematizing relation ai rather produce “neutral” set assumptions robots ai elitist assumptions carried processes mimic domination paradigms turn algorithmic power plays marvin minsky one founding “fathers” said “ai science making machines things would require intelligence done men” “fathers” “creators” men sex careful cultural forged ai science image ai man taken sex standard humanity point continual problematized feminist writers including simone de beauvoir described problem book second sex31 patriarchy man norm stand ard woman deviation imperfect incomplete male male still sex referenced making robots ai act occurs spontaneously “human” set standard human frequently male32 idolization male sex occurs robotics ai considered light female sex make percent33 global population minority group half human species women featured contemporary computing narratives sexualized objects take example lena söderberg playboy centerfold became widely used textbooks sections related image processing andrew sawchuck assistant professor electrical engineering university southern california elazar barkan retreat scientific racism changing concepts race britain united states world wars cambridge cambridge university press christopher kelty “geeks social imaginaries recursive publics” cultural anthropology –simone de beauvoir howard madison parshley second sex new york vintage books richardson anthropology robots ai world bank httpsdataworldbankorgindicatorsppoptotlfezs kathleen richardson copy hand playboy magazine instead using regular stock images used image söderberg instead34 porn industry widely celebrated vehicle technological development vhs live streaming35 feminist analyses porn industry show frequently depicts violence women36 making sex robots form pornographic representations women allows new generation researchers typical men imagine life creating stepford wives fiction imagined engaging fantasies life without women38 forsythe39 noted study 1990s ai research communities women likely administrative roles two decades later women still likely work administrative roles academia business senior tenured roles computer sciences efforts increase women’s participation stem science technology engineering mathematics subjects led many changes funding agencies european commission emphasize gender equality priority40 contemporary computing engineering basis robots ai ignore role women history ai tel different story hundreds women involved “computers” nasa41 bletchley park42 hicks argues programmed inequality women united kingdom deliberately excluded end second world war make way men computing field argues accounts british loss advantage field enough qualified men fulfill roles enough trained men replace qualified women claims computing fields forging ahead united kingdom 1940s lost pace americans able exclude women replace machines men shetterley narrates untold history african american women’s participation nasa space programs histories forgotten female researchers began look role women computing ada lovelace credited creating corinne iozzio “the playboy centerfold helped create jpeg” atlantic february httpswwwtheatlanticcomtechnologyarchive201602lena­image­processing­playboy gail dines pornland porn hijacked sexuality boston beacon press ibid ira levin stepford wives london corsair kathleen richardson sex robots end love cambridge uk polity press forthcoming diana forsythe studying study us anthropologist world artificial intel igence palo alto ca stanford university press gender equality strategy european commission httpseceuropaeuinfopoliciesjustice­and­ fundamental­rightsgender­equalitygender­equality­strategyen margot lee shetterly hidden figures story africanamerican women helped win space race new york william morrow marie hicks programmed inequality britain discarded women technologists lost edge computing cambridge mit press complexity otherness first algorithm43 time ai’s advent late 1950s women expunged field work replaced computer machines still remains significant gender differences uptake undergraduate graduate faculty posts business ai history taught us women excluded stem subjects professions deliberately bletchley nasa problem another kind five decades exclusion lack opportunity produced cultures sexist stereotyping bias women women make percent engineers united kingdom yet women achieve first upper second degree average males percent percent respectively44 left largely maledominated field nearly fifty years leading kate crawford called “white guy problem” wgp45 wgp primarily focused existential crisis risk epitomized figures stephen hawking elon musk concerned machines become super­intelligent become uncontrol able surpass man’s intelligence ray kurzweil believes advanced ai permit uploading man’s consciousness machines would signify “the singularity” time men machines merge together become one46 figures largely ignored ethical problems produced robots ai instead crawford argues ai scientists need deal real problems hand including reproducing racist sexist classist practices immediate problems ai biased programmers produce biased algorithms inherit problems social scientists spent three decades actively deconstructing google’s photo app classifying black people goril hewlett­packard’s web camera could recognize people darker skin tones crawford notes difficulties finding creating algorithmic flaws due business reluctance release information data created put use conflicts proprietary laws real problems technology reproduction sexist racist tropes yet much history ai robots matter focused machines gaining consciousness superintelligence overthrowing humanity computer engineering sciences largely insulated wider discourses problematize categories intelligence sex race issues serious produced sociotechnical hierarchies report written council europe’s antidiscrimination department concerns raised public private institutions using “ai discrimination” able perpetuate avery elizabeth hurt ada lovelace computer programmer mathematician new york cavendish square publishing engineering uk httpswwwengineeringukcommedia156187state­of­engineering­ report­2018pdf kate crawford “artificial intelligence’s white guy problem” june new york times ray kurzweil “the singularity near” ethics emerging technologies london palgrave macmil –kathleen richardson discrimination “protected characteristics” race sex47 protected characteristics include race sex report urged “regulatory safeguards” need offset algorithmic prejudices evidenced policing housing healthcare name areas impacted integration ai areas rich body literature anthropology technology narrating absence women people color computing cultures48 anthropologist stefan helmreich’s study palo alto computer scientists explored indigenous culture appropriated research scientists frequently adorn buildings indigenous art exoticize technological artifacts using names cultures java ubuntu apache49 naming artifacts cultural associations significance anthropology would connotations broadly apple may fruit also wider cultural symbolism judeo­islamic­christian culture forbidden fruit eaten eve garden eden described book genesis50 apple company icon bitten apple drenched meaning though founders claim choice image unrelated wider meanings apple’s cofounder steve wozniak reminiscences founding name couple weeks later came name partnership remember driving steve jobs back airport along highway steve coming back visit oregon place called “apple orchard” actual kind commune steve suggested name—apple computer first comment mouth “what apple records” still beatles­owned record label tried come technical­sounding names better couldn’t think good ones apple much better better name could think apples grow trees nurtured developed associations rooted deep collective consciousness anthropologists explore categories space time symbolism ritual cosmologies capable bringing fore extra layers meaning invisible architects robots ai also deep personal psychological connections makers robots robotic scientists transferred physical social anxieties robots created51 example one researcher’s project developing robot memory drew studies post­traumatic stress disorder ptsd studies memory significantly impacted presence trauma research scientist also received diagnosis ptsd robot f borgesius discrimination decision­making directorate gender democracy council europe forsythe studying study us stefan helmreich silicon second nature culturing artificial life digital world berkeley university california press lerner creation patriarchy richardson anthropology robots ai complexity otherness became way exercise control reflection healing trauma participant observation methodology central anthropological investigation requires active engagement interlocutors lived experience sociality relations artifacts built environment anthropological methodologies developed meeting worlds terms making sense language52 ethnographic recording first­person encounters ideal collected contexts integral research—the lab hospital business home anthropologist take ethnographic field notes back discipline rich archive cultural material explore data anthropology discipline enrol otherness time able hold independence consider concrete abstractions new forms personhood personhood field shared territory anthropologists ai robotic researchers ai robots considered types persons would constitute legal moral ethical argument status persons debate occurring field technology consciousness sentience personhood natural human beings contrast animals things nonpersons topics anthropologists written extensively reasons often il ustrate humans animals artifacts integrated sociality indigenous western peoples personhood fiercely debated idea concept modern formation intimately tied western juridical­liberal economies middle classes developed ideas give new growing political movement recognitions protections law taking power away old guards state initial rights man individual cannot divided referred early enlightenment literature person developed initially natural human property­owning male able access law rights new liberal economies developed 1700s new classes subjects word “person” latin persona theatrical term denoting something representation self one first significant modern uses term “person” fourteenth amendment july us constitution followed thirteenth amendment freeing slaves fourteenth amendment allowed significant act adam kuper anthropology anthropologists modern british school london routledge kathleen richardson legal concept category persons solely attributed human natural beings since extended abstract entity modern law form corporation history worthy discussion sets frame personhood mobilized series claims legal rights include natural entities rivers animals apes used law category person persona legal status fiction persons exist legal status legal status accessed persons persons guardians represent collectivities corporations personhood gives recognitions people goes beyond “person” developed ful nineteenth mid­twentieth centuries connected rights responsibilities persons western juridical­political systems personhood began include nonhumans artificial entities called corporations concept put use contexts enlightenment humanist project singled human subject capable reason language consciousness therefore distinct nonhuman animals artifacts subject principal males held property largely white though franchise extended course nineteenth twentieth centuries include working men men color freed slaves women anthropologist marilyn strathern written length cultural differences constitutes “persons” “things” writing melanesia kinship new reproductive technologies54 argued melanesia “individual” capable division instead creating framework “dividual” divisible capable divided fragmentary concept person55 moreover classic work gender gift strathern writes melanesia persons bound world things cultural production things axe yam shell stand represent social relations persons56 shel yams become quasi­persons field social relations melanesians robots ai artifacts circulating cultural production life european americans donna haraway’s cyborg manifesto later work species meet58 seminal texts new world order ontological relations humans nihad farooq undisciplined science ethnography personhood americas –marilyn strathern property substance effect anthropological essays persons things karl smith “from dividual individual selves porous subjects” australian journal anthropology –marilyn strathern gender gift problems women problems society melanesia berkeley university california press donna haraway simians cyborgs women reinvention nature new york routledge donna j haraway species meet minneapolis university minnesota press complexity otherness animals things rewritten remove humans pedestal instead curating alternative relations cyborg manifesto hark manmachine popularized tv series six mil ion dol ar man artificial implants developed bionic powers haraway’s cyborg political case destruction categories remaking partial connections species argued wholeness means human shared experience capable incorporating perspectives members connected part make whole original garden eden paradise humans return arguably never existed framing problem wrote “we chimeras theorized fabricated hybrids machine organism—in short cyborgs”the cyborg dividual open assaults enlightenment humanism analytical fabrications needed produce maintain leave aside complex debates animals humans unlike things animals sentient beings complex socialities things though orthodoxy anthropology argue things social lives60 nothing essential different humans nonhumans61 robots ai come category property euro­american contexts unlike melanesians shel yams circulated ritualistic practices maintain complex kinship networks sold generate revenue income companies status prestige research labs used instrumental consumers artifacts may mimic behavior appearance engage kinds reciprocal social relations enacted humans dissolving differences humans artifacts represents emancipatory political project yet two hundred years ago people working classes slaves considered closer artifacts tools fellow man woman marxian analysis class relations shows people used resources others though directly marked slaves economic choices curtailed capitalist economy radin describes possessive individualism replaced idea slave worker could sell labor owned person’s labor property transacted62 system continues day marx explained people calculated price alongside forms property raw materials rent etc used business called constant capital equipment variable capital cost labor labor according marx source value constant capital63 people haraway simians cyborgs women arjun apparaduri “introduction commodities politics value” social life things commodities cultural perspective ed arjun appardurai cambridge cambridge university press bruno latour never modern cambridge harvard university press margaret jane radin “property personhood” stanford law review karl marx capital vol london lawrence wishart kathleen richardson replaced machines increases constant capital decreases value variable capital economic crisis result tendency rate profit fall capitalism survive second machine age accompanying new reorganizing capital relations erasing boundaries persons property anthropology used service agenda assist capitalist social relations melanesia things artifacts might stand persons social relations western societies people stood property slaves view shared widely anthropology disentangling people property artifacts mark progress nonpropertied women people color used robots deliberately designed mimic human appearance andor behavior surprising therefore people interacting attribute human like qualities even sophisticated algorithm robot created consumed property law ownership transferability robots ai forms property many new devices facilitate human interaction talk back resemble people act therapeutic aids marketed intimate others form virtual girlfriends sex robots personification robots ai consumers consumer goods mediated branding marketing advertising conclusion chapter tried show intelligence neutral concept developed justify subjugation people basis sex race class ability moreover computer sciences robotics twentieth century continued fields develop without fuller participation women people color algorithms run computers robots integrated everyday life makers drawn narrow subsections populations white guy problem forefront producing technologies weave inequality sex race social life sociotechnical forms moreover lines interdisciplinary enquiry could developed robotics ai anthropology could developed ai scientists roboticists necessary take account issues social sciences humanities constructing technologies order prejudices stereotypes structural inequalities reproduced life follows developments technologies arguably rise ethics ai robotics create committees stakeholders work together reduce bias stereotyping perpetual algorithmic inequality complexity otherness new frontiers horizon end humanism giving rise antihumanism posthumanism transhumanism abandon humanistic enterprise worth noting humanism invent slavery years old create culture commitment universal values freedom equality rule law able thrive widely cyborgs mean project humans cannot stand differently property robots ai part second machine age kind age sentient conscious life forms struggle life dominated militarism capitalism bibliography bird­david nurit “ ‘animism’ revisited personhood environment relational epistemology” current anthropology s1 s67–s91 brooks rodney robot future flesh machines london penguin brooks rodney “intelligence without representation” artificial intel igence –cel an­jones rory “stephen hawking warns artificial intelligence could end mankind” bbc news december httpswwwbbccouknewstechnology­clarke arthur c space odyssey london penguin geertz clifford “thick description toward interpretive theory culture” cultural geography reader edited timothy oakes patricia l price –abingdon routledge kubrick stanley dir space odyssey metro­goldwyn­mayer minsky marvin computation englewood cliffs nj prentice­hal minsky marvin society mind new york simon schuster strathern marilyn property substance effect anthropological essays persons things london athlone press chapter calculative composition ethics automating design shannon mattern introduction long fashion designers graphic artists industrial designers architects practicing crafts—and even labeled such—those practices products shaped prevailing tools technologies ages paper patterns computeraided design1 artificial intelligence merely latest agitator myriad design professionals already begun exploring potential transform conceptualization design prototyping production distribution work whether menswear modular homes fashion labels mining social media forecast trends building intelligent apps help consumers compare styles architects amassing data—engineering requirements cad geome tries building performance data—to automate phases work likely cha grin many graphic designers programmers created web platforms allow clients upload text images input parameters violà —a website appears still practitioners across disciplines employed ai toward humanitarian sustainable ends like customdesigning prosthetic devices mapping less energyintensive supply chains prototyping climateresponsive architectures grateful research assistant kevin rogan aided stages research writing also owe great debt gratitude ajla aksamija david benjamin andrew witt rune madsen generously responded queries practice—and gerald sim jason hal strom institute sensing embedded network systems engineering florida atlantic university kindly invited share researchinprogress shannon mattern designers committed applying ai toward ethical ends they’ve paid comparatively less attention toward ethical means application— precisely methodological issues concern organizations like ai fate fairness accountability transparency ethics ai2 instance implications vacuuming architectural urban data order aid future design efficient buildings neighborhoods make graphic design tools normalize particular facial features allow suturing various images new composites implications designers’ selfidentities professionals political subjects core creative questions turned machine chapter examine ethical ends means toward aidriven design perhaps could applied surveying representative design fields—fashion product graphic architectural design—i’ll examine ethical opportunities risks might face aidriven design practice programmed serve needs desires laborers consumers clients—and it’s applied generating everything luxury goods logos library buildings3 automating fashion product graphic design we’ll start close body clothing fashion designers manufacturers retailers using artificial intelligence track trends offer shopping advice test garments different body shapes sizes allow customers mix match items wardrobes4 amazon’s echo look users document outfits ai httpsainowinstituteorg fat httpsfatconferenceorg much written application ai urban design planning see instance voluminous research “smart cities” written several pieces topic see instance “a city computer” places journal february httpsplacesjournalorg articleacityisnotacomputer “databodies codespace” places journal april https placesjournalorgarticledatabodiesincodespace see stitch fix online personal shopping service pureple closet organizer outfit planner vueai’s suite aigenerated models styling applications kim kardashian’s screenshop allows users upload photos looks like find items sale fashion examples drawn sissi cao “zac posen talks fashion era artificial intelligence” observer april httpobservercom201804zacposenfashionartificial intelligence knight “amazon developed ai fashion designer” mit technology rev iew designer emily matchar “artificial intelligence could help generate next big fashion trends” smithsonian magazine may httpswwwsmithsonianmagcominnovationartificial intelligencecouldhelpgeneratenextbigfashiontrends180968952 devorah rose “commentary ai’s next victim closet” fortune march httpfortunecom20180315fashionai artificialintelligencefuturekimkardashian arthur zackiewicz “ai visual search retail’s next big step” wwd april httpswwdcombusinessnewstechnologyaiclarifairetail brands1202650318 calculative composition ethics automating design via style check service draw combined expertise human stylists ai trained social media fashion posts choose flattering options champions argue developments facilitate representation nonstandard body types allow consumers ful exploit garments drawers clos ets thus hypothetical curbing wasteful consumption meanwhile amazon’s lab126 team using generative adversarial network gan learn particular styles scanning lots examples generate rudimentary designs ibm’s cognitive prints suite tools developed fashion industry could likewise enable designers even manufacturers simply bypass human designers create textile patterns based image data set— snowflakes rainforests instance—or generate designs based set param eters whether mandarin col ars pleats capabilities raise questions labor displacement long concern fashion manufacturing machines replacing human workers since rise mechanized loom course labor long huge issue popular scholarly discussions ai automation5 automation indeed extended shop floor design studio fashion ateliers fear obsolescence designer zac posen doubts gan could cap ture “situational spontaneous moments beauty” exploit fortuitous acci dents aesthetic irrationalities part organic design process6 what’s ai technologies say could reinforce unique contributions human designers protecting intellectual property ibm’s cognitive prints trained print swatches winning fashion week entries allows designers search inspiration “make sure inspiration real inadvertent plagiarism”automated tools could also allow bespoke design fabrication—3dprinted garments customized fit models’ athletes’ bodies well prosthetics rehabilitative gear8 yet course fashion still massproduced labor environmental advo cates argue contexts ai could enable brands better monitor supply chains thus hold accountable source materials labor wellmonitored lubricated supply chains could also simply speed alreadyunsustainably speedy world fast fashion see instance darrell west future work robots ai automation washington dc brookings institution press quoted sissi cao “zac posen talks fashion era artificial intelligence” observer april httpobservercom201804zacposenfashionartificialintelligence see also maghan mcdowel “will ai kill creativity” business fashion march httpswwwbusinessoffashion comarticlesfashiontechwillaikillcreativity emily matchar “artificial intelligence could help generate next big fashion trends” smithsonian magazine may httpswwwsmithsonianmagcominnovationartificial intelligencecouldhelpgeneratenextbigfashiontrends180968952 western bonime “get personal future artificial intelligence design bitonti studios” forbes july httpswwwforbescomsiteswesternbonime20170707getpersonalthefuture ofaidesignatbitontistudios1ecb8785b0de shannon mattern product designers applying similar techniques—using ai comb social media identify trends sunglasses toys tableware automating production multi ple iterations projects usertesting even exploiting users’ behavioral data simulate user tests quality assurance evaluations applications allow designers manufacturers respond global demands shorter product cycles fastchanging consumer needs desires9 words ai helps us generate stuff cheaply quickly line consumers’ perhaps unstated even unrealized demands ai’s influence even immediate world digital products like ebooks apps chatbots like analog counterparts digital designers set particu lar parameters create models based preferences algorithmic tools churn hundreds options users test designers tweak seasoned interaction designer rob girling imagines digitalproduct future ai capable modeling cultural psychological variables stages design development use envisions future personal ai assistants armed deep understanding influences heroes inspirations constantly critique work suggesting ideas areas improvement world problem solving bots help us see problem variety perspectives different frameworks simulated users test things we’ve designed see per form variety contexts suggest improvements anything even built ab testing bots constantly looking ways suggest minor performance optimizations design work10 designers developers aspiring build digital products trade affect chris butler director ai philosophie software development studio offers work shops “problem framing ideation empathy mapping machine confusion mapping prototyping”even emotion operationalizable design process optimizable products aiinformed digital products reach market perform social cultural psychological work voice assistants call doctors hairstylists make appointments chatbots provide therapy tutoring clients can’t anand adhikari “titan experimenting artificial intelligence led product design” business today december httpswwwbusinesstodayinlifestyleofftracktitanexperimentingwith artificialintelligenceledproductdesignstory266111html rob metheson “design tool reveals product’s many possible performance tradeoffs” mit news august httpsnewsmit edu2018interactivedesigntoolproductperformancetradeoffs0815 sergii shanin “how artificial intelligence transforming product development design” eteam december https eteamioblogaiandproductdevelopmentdesign rob girling “ai future design designer look like” o’reilly of2025looklike “design thinking ai” artificial intelligence conference new york april –may httpsconferencesoreil ycomartificialintelligenceainy2018publicscheduledetail65105 calculative composition ethics automating design afford—or would rather deal with—human service providers12 yet google unveiled duplex voice assistant observers outraged technology little empathy product’s human interlocutors duplex deceived end line failing disclose artificiality natasha lomas lamented techcruch google clearly lacked “deep nuanced appreciation ethical concerns play around ai technologies pass human—and thereby electronics engineers’ general principles ethical aligned design lomas called digital products respect human rights operate transparently developers hold accountable automated decisions products make14 girling’s utopic wish list implies whole tangle potential accountability loopholes hypothetical development scenarios rely assemblage simulated subjects sites situations engagement involves fabricated frameworks imagined futures— presents opportunities algorithmic bias set limitations training data set become reified realworld applications luckily girling’s firm artefact recognizes “the effects celebrated products always positive ‘move fast break things’ wel things get broken—or worse”so artefact offers set tarot cards helps creators “to think outcomes technology create unintended consequences opportu nities positive change” pause contrast epistemologies embedded tarot machine learning consider means apply esoteric practices atone shortcomings ai’s positivism parallel field graphic design one “unintended consequences” potential obsolescence web designer altogether “we already seen templati zation digital products” via “design systems” coded standards defined com ponents like google’s material design artistdesigner rune madsen told “so happens start rely algorithms make creative decisions”platforms like logojoy tailor brands automate production logos wix adi artificial yaniv leviathan “google duplex ai system accomplishing realworld tasks phone” google ai blog may httpsaigoogleblogcom201805duplexaisystemfornatural conversationhtml clive thompson “may ai help you” new york times magazine november httpswwwnytimescominteractive20181114magazinetechdesignaichatbothtml natasha lomas “duplex shows google failing ethical creative ai design” techcrunch creativeaidesign “the ieee global initiative ethics autonomous intelligent systems” ieee standards association httpsstandardsieeeorgindustryconnectionsecautonomoussystemshtml see also alan ft winfield marina jirotka “ethical governance essential building trust robotics artificial intelligence systems” philosophical transactions royal society mathematical physical engineering sciences october httpsdoiorg101098rsta20180085 “the tarot cards tech” artefact nd httpswwwartefactgroupcomcasestudies thetarotcardsoftech rune madsen personal communication february see also madsen “the user experience design systems” runemadsencom httpsrunemadsencomtalksuxcampcph shannon mattern design intelligence churns websites17 another platform grid prompts novice users input text imagery tell “mol y” “ai web designer” goals reach impact mol automatical retouch crop photos search media choose complementary color palette select layouts fit content mix conduct ab tests assess preferences mol we’re told “quirky never ghost never charge never miss deadline” respects she’s reliable agreeable human designer18 critics found design work less inspiring machine learning algorithms “operate historic data” madsen said “they always give us same”—or new hybrid exists “latent space existing designs” compression existed before19 derivations told typical devoid affect aspirations embedded compelling logos layouts commonly bear marks programs used create know squarespace wix site see one reasons human graphic designers like counterparts fashion anticipate foreseeable future least machines people partner styling world’s websites art books20 ai like google’s auto draw transform designers’ moodboards diagrams templates polished renderings airbnb technologists using ai turn whiteboard sketches live code “translate highfidelity mockups compo nent specifications engineers production code design files itera tion designers”—an automation sequences smooths workflow one design specialist another also allows contributor spend automation’s humanistfuturists apologists designer jason tselentis proposes aidriven design tools rather obviating human laborers instead promise better working conditions give sedentary organic bodies “a chance step away computer whether work hand take break screen” second desktop revolution—after arrival aldus pagemaker firstwave desktop publishing software 1980s—our new millennium algorithms could “save human designers time make room lives reflection creativity”nevertheless designer paula scher predicts basic skil automated “entry level jobs may lost”“about wix adi” wix httpssupportwixcomenarticleaboutwixadi logojoy https logojoycom tailor brands httpswwwtailorbrandscom see also yury vetrov “algorithmdriven design ” httpsalgorithmsdesign grid httpsthegridio rune madsen personal communication february chris constandse “how aidriven website builders change digital landscape” ux collective october httpsuxdesigncchowaidrivenwebsitebuilderswillchangethe digitallandscapea5535c17bbe mix “airbnb built ai turns design sketches product source code” next web designcode jason tselentis “when websites design themselves” wired september httpswww wiredcomstorywhenwebsitesdesignthemselves quoted id calculative composition ethics automating design yet perhaps entrylevels skil aren’t quite rote rudimentary seem consider services provided several intelligent imaging applications tools like artisto prisma use image recognition identify content photos videos apply matching visualeffects filters depending specific data sets train ing ai assistants could well see lot walkonthebeach scenes draped gaussian blur—or many faces color simply don’t register faces al adobe’s sensei ai behind product features like adobe scene stitch allows users patch edit images swapping features similar files image library faceaware liquify feature uses face recognition “enhance portrait add creative character”we might question ethical implications reinventing photographic scenes age deep fakes might wonder faces com posed training set adobe’s ai learned identify facial norm whose noses lips set standard facial features deemed “character” sorts sculpting constitute “enhancement” might also inquire ethics using ai transform user subjectivities user behavior dynamic user experience ux seeming create personalized products thoughtful anticipate user desires also coerces longer predictable user engagement fabricio teixeira explains “websites getting smarter taking multiple user data points consideration enable personalized experiences visitors time day users coming type device accessing day week—and evergrowing list datapoints signals users don’t even know about”“we could extract behavioral patterns audience segments” yury vertov proposes “then optimize ux it’s already happening ad targeting algorithms cluster user using implicit explicit behavior patterns”we’re long way web today’s websites designed artificial intelligent opportunistic finetuned coercion machines application ai across disparate design fields raises several categories recurring questions first questions labor ai improve labor conditions automating rote tasks make easier creative practitioners protect simone browne dark matters surveil ance blackness durham nc duke university press open data science community “the impact racial bias facial recognition software” medium october httpsmediumcomodsctheimpactofracialbiasin facialrecognitionsoftware36f37113604c tom simonite “how coders fighting bias facial recognition software” wired march httpswwwwiredcomstoryhowcodersare fightingbiasinfacialrecognitionsoftware see also joy buolamwini timnit gebru “gender shades intersectional accuracy disparities commercial gender classification” proceedings machine learning research –“adjust exaggerate facial features” adobe nd httpshelpxadobecomphotoshop howtofaceawareliquifyhtml accessed january james vincent “adobe’s prototype ai tools let instantly edit photos videos” verge october httpswwwtheverge com2017102416533374aifakeimagesvideoseditadobesensei fabricio teixeira “how ai started impact work designers” ux collective yury vetrov “algorithmdriven design artificial intelligence changing design” smashing magazine january httpswwwsmashingmagazinecom201701algorithmdriven designhowartificialintelligencechangingdesign shannon mattern intellectual property facilitate pirating others’ creative labor eliminate jobs might automation even “rote” tasks embed particular ideologies biases—about constitute norms standards whom— introduce possibility manipulation doctored images lie robot voices deceive second questions production ai allow ethical oversight supply chains promoting ethical sourcing labor simply speed production process promoting ever wasteful extraction manufacturing ever rampant consumption third survey design fields raises recurring questions users’ agency protection tracked behaviors simu lated testing “empathy mapping” serve users better meeting needs even supplying custom products services nonnormative bodies tastes customization constitute exploitation dichotomous conditions find compromise algorithmic architectures shouldn’t surprising much virtual experience designed choreo graphed virtual agents ai al new colonial power indiscriminate invasion digital terrains yet ai’s influence spil physical domain saw worlds fashion product design designs take shape aiinformed digital plans made material form garments gad gets even buildings cities artificial intelligence scales embed logics material world writ large translation—from invisible bitsized algorithmic operations massive steelandglass structures—represents radical crossing scales materialities ontologies architecture traditional slow visceral medium affords us unique opportunity observe assess translation digital physical embodiment artificial intelligent operations concrete form follows we’ll examine ai informs operations eth ics architecture’s multiple stages development—from planning project man agement design construction planning project management gathering information design site traditional required visiting site surveying photographing collecting local data creating maps much work automated drawing vast abundance available datasets software—like ecodesigner star sketchup plugins—that automate data processing architects hannah wood rron beqiri regard developments liberating automated data analysis enables architect “simulate surrounding site without ever engage physical y” “do necessary building calculative composition ethics automating design environmental analysis without ever leave computers”designers take international commissions would’ve previously presented logistical chal lenges disembodied assessments site might afford new opportunities smaller geographical marginalized firms—and might signal community needs aren’t empirical observable—we wonder spatial knowledges localized understandings place people lost designers “never leave computers” yet perhaps onsiteversusremote false dichotomy might instead ask vast banks spatial data automated processing could responsibly supplement onsite surveys interviews local ethnographies spatial databases products great deal human computational labor—of individual designers design firms tech companies professional organi zations invested accumulation storage crossreferencing sharing data sites buildings report american institute architects kathleen o’donnell interviewed several designers corroborated recommenda tions “start accumulating much data possible” including data used building information modeling platforms postoccupancy evaluations—and develop plat forms sharing data among architects contractors property owners29 order data serve purposes automation however must rendered interoperable quite challenge translating place data involves differ ent methodologies epistemologies different professionals public health officials environmental scientists realestate developers operationalize “site” differently raghav bharadwaj reports architecture engineering construction aec industry “attempting leverage ml machine learning identify mitigate clashes different models” employed architects various engineers plumbers—not mention conceptual data models professionals think space differently whose insights could inform architecture30 machine learning reconcile diverse conceptions place mediate disparate methodological epistemological ethical frameworks embedded different datasets even aec data enthusiasts o’donnell reports recognize “regulations security ethics come play—and major legal standards data aec architecture engineering construction yet” rron beqiri “ai architectural intelligence” future architecture may http futurearchitectureplatformorgnews28aiarchitectureintelligence hannah wood “the architecture artificial intelligence” archinect march httpsarchinectcomfeaturesarticle149995618 thearchitectureofartificialintelligence kathleen o’donnel “embracing artificial intelligence architecture” aia march httpswwwaiaorgarticles178511embracingartificialintelligenceinarchit design agency ceo nate miller proposes “bim often positioned production tool way generate deliverable actual datarich resources tied firm’s particular knowledge base used make informed decisions portfolio future design prospects” one existing platform industrywide data collection sharing building information research knowledge base raghav bharadwaj “ai applications construction building—current usecases” emerj shannon mattern ajla aksamija building technology specialist leads perkins will’s tech lab convinced governing body like american institute architects needs step set standards institutionwide best practices use data ai design31 ai also help automate administrative operations—organizing schedules managing payrol overseeing documentation even period careful train ing evaluating conformance safety zoning guidelines32 architectural histo rian mol wright steenson notes “as early 1950s architects skidmore owings merrill som ellerbe associates used computers risk calcula tions cost estimates”today ai function “‘enforcer’ code best practices” keeping human laborers aligned selfimposed algorithm34 short computers handle boring work rote tasks complex calculations leaving creativity human experts likely eliminating human laborers front office we’ve heard promises bauhaus founder walter gropius advocated architects use computers “means superior mechanical control might provide us evergreater freedom creative process design”todays’ computers still “aren’t particularly good heuristics solving wicked problems” phil bernstein says “but increasingly capable attacking ‘tame’ ones especial require management complex interconnected quantitative variables like sustainable performance construction logis tics cost estimations”andrew witt cofounder “design science” office certain measures suggested ai could even serve “ethical broker” com peting stakeholder interests—which raises questions methods ethics automating ethical mediation37 kevin rogan personal communication ajla aksamija february rogan research assistant phil bernstein “how architects adapt coming age ai” architect’s newspaper mol wright steenson architectural intel igence designers architects created digital landscape cambridge mit press sébastien lucas “artificial intelligence ai architecture practical applications” futur archi july httpwwwfuturearchiorgtartificialintelligenceaiinarchitecturewhatare thepracticalapplications364 quoted steenson architectural intel igence phil bernstein “how architects adapt coming age ai” architect’s newspaper shannon mattern kevin rogan personal communication andrew witt february witt referenced architect yona friedman’s flatwriter computer program says enabled “sets people ethical design apartment complex” person’s input “creating set tradeoffs choices people” “sociological model encapsulated software system” creates “political framework felicitous housing development” i’m indebted bryan boyer directing certain measures’ work calculative composition ethics automating design design ai already shaping creative process flagship architectural design softwares like autocad rhino revit long automated design process degree example door placed wall collection lines planes solids known program neural networks mine oeuvre individual designer group designers identify “commonlyused sequences lowlevel features” “dynamical synthesize purposebuilt fea tures” relevant designer’s task hand38 nicholas negroponte architect founder mit media lab predicted functionality late 1960s steenson explains ai could allow system “learn users develop tandem idea system would evolve computer original programmed architect user might imag ine own”by 1980s software original created use automotive aeronautical industrial design made way architecture inciting rise parametric design architect sets parameters algorithmical translated range forms today softwaremaker adobe offers dreamcatcher “generative design system enables designers craft definition design problem goals constraints”—from material types manufacturing methods performance goals cost restrictions—which used process multiple data sets gen erate thousands alternative design solutions40 designers iteratively tweak parameters assess performance data proposed option wework developed “suite procedural algorithms” automate planning shared workspaces company’s research team employs data social scien tists better understand “how spaces enhance people’s happiness productivity connection community”fed data “functional experiential consider ations building code requirements client expectations” planning tool gener ates possible desk layouts floor plan even quirky columns obstructions42 designers found percent time tool handled patrick hebron “rethinking design tools age machine learning” artists machine intel igence april httpsmediumcomartistsandmachineintelligencerethinkingdesign toolsintheageofmachinelearning369f3f07ab6c steenson architectural intel igence –adobe dreamcatcher httpsautodeskresearchcomprojectsdreamcatcher mark sullivan “this algorithm might design next office” wework blog july httpswwwweworkcomblogpoststhisalgorithmmightdesignyournextoffice carl anderson carlo bailey andrew heumann daniel davis “augmented space planning using procedural generation automate desk layouts” international journal architectural computing authors write “firms often treat collective work queryable data typical contractual models architecture engineering construction industry rarely permit design team monitor evaluate postconstruction design performance believe type research currently best suited certain architectural types retail offices healthcare spaces designs consistent success metrics clear shannon mattern variations maximizing ratio desk count floor area well humans future tool meant adjust regional differences “such members china preferring large conference rooms” andrew witt certain measures imag ined many designers could eventual use “preference sets like sentiment analysis databases” model “how people consume relate architecture”as mark sullivan explains wework’s company’s blog planning tool “does save time frees architects use creativity ways designing eyecatching central staircase covered courtyard members mix mingle”when autodesk hired design firm living design new toronto office worked similar array parameters solo versus col aborative work style available views light forth living’s david benjamin insists “it wasn’t computer telling us made decisions based human values”while designer hannah wood predicts future architects less likely “in business drawing specifying problem requirements” plenty ai aficionados ready reassurance architects needn’t fear they’ll reduced data entry clerks46 ai “streamline design processes without taking creative control” “the designer lead tool” adobe’s patrick hebron says47 humans must maintain control ai hebron continues “has limited purview nature proclivities human experience”any ful yaigenerated environment we’re reminded would unlivable yet architects need better articulate clients broader public that’s true benjamin explained dwell magazine it’s already case building projects aren’t designed trained architect “we advocate want built environment selfdriving architecture cookiecutter results convenient argue they’re insufficient”— unjust49 benjamin predicted developers could create automated designs keyed toward maximization profit resulting “automated design city that’s uniform unequal”thus witt said it’s important consider “ethical dimensions train designers” partner automated systems51 layouts somewhat repeatable” see also certain measures’ spatial insight spatial optioneering projects httpscertainmeasurescomspatialinsighthtml httpscertainmeasurescom spatialoptioneeringhtml shannon mattern kevin rogan personal communication andrew witt february sullivan “this algorithm might design next office” quoted sam lubel “will algorithms new architects” dwell july https wwwdwel comarticlewillalgorithmsbethenewarchitects095c9d41 wood “the architecture artificial intelligence” italics mine patrick hebron “rethinking design tools age machine learning” artists machine intel igence april httpsmediumcomartistsandmachineintelligence rethinkingdesigntoolsintheageofmachinelearning369f3f07ab6c quoted kathleen o’donnel “embracing artificial intelligence architecture” aia quoted lubel “will algorithms new architects” kevin rogan personal communication david benjamin december shannon mattern kevin rogan personal communication andrew witt february calculative composition ethics automating design ai offer evidence help humans choose cookiecutter options adapt instance space syntax’s depthmapx spatial network analysis software allows designers assess “visual accessibility” design site model pedestrian behavior52 building system planning’s clashmep reads revit models detect clashes among building’s mechanical electrical plumbing systems53 ai could also enable building systems communicate one another built structure aksamija proposes54 unity 3d original created game engine used analyze distance fire exits—or generate 3d augmented virtual reality models usertesting modes presentation potential make design legible experiential users stakeholders might know read plan construction drawing55 enable designers test “user experience” assessing even dynamic variables like light sound ergonomics designer jim stoddart explains put someone vr inside space ask machinelearning system supervised learning problem actual software help us predict thousands designs we’re generating ones interesting things highlevel spatial material qualities worthy investigation56 michael bergin autodesk proposes automated technologies ultimately make architecture “far inclusive respect client occupant needs orders magnitude efficient considering environmental impact energy use material selection client satisfaction”perhaps important “interesting” “beautiful” designs ethical ones— designs aligned “human values” informed benjamin’s decisionmaking toronto values consequence optimal deskspersquarefoot benjamin found nearly last decade firm others add ing “bio” framework—bioprocessing biosensing biomanufacturing—to com putational design “combining machine natural world” order facilitate “depthmapx visual spatial network analysis software” bartlett school architecture httpswwwuclacukbartlettarchitectureresearchspacesyntaxdepthmapx clashmep httpsbuildingspcomindexphpproductsclashmep see also certain measures’ topological wiring httpscertainmeasurescomtopologicalwiringhtml kevin rogan personal communication ajla aksamija february see mit media lab’s materiable haptic interface httpstangiblemediamiteduproject materiable wood “the architecture artificial intelligence” quoted wasim muklashy “how machine learning architecture liberating role designer” redshift may httpswwwautodeskcomredshiftmachinelearningin architecture matter design studio uses computational methods explore ancient knowledge sensory experience see httpwwwmatterdesignstudiocom indebted keyswalletph0ne recommending work quoted wood “the architecture artificial intelligence” shannon mattern allow design outside “master models complete allknowingness”this one way infusing computational design set values that’s oriented toward ethics efficiency architect christopher alexander whose practice informed ai since 1960s long believed computational patterns “moral component” accord ing steenson “moral goodness something could explicitly defined empirical tested architecture”alexander offered vision future “computers play fundamental role making world—and built structure world—alive humane ecological profound deep living structure”how might operationalize ethical parameters might test humanity ecological profundity buildings alexander proposes values often aestheticized case biocomputational generative designs made performative—through gratuitous breathing facades kinetic oculi also use building automation systems monitor hvac energy lighting sys tems perhaps proxies “ecological profundity” ai could help building occupants better understand uses building influence energy consump tion aksamija suggests61 else might “pattern” particular ethical codes parametrics might able monitor presence values making architecture fabrication marvin minsky predicted mid1990s machine could “handle planning complete mechanical assembly things wel ”we’re quite yet robots piecing together brick facades dispensing concrete welding handling dangerous work demolition63 we’re 3dprinting bricks much geometrical complex building materials too64 kevin rogan personal communication david benjamin december see also cristina cogdel toward living architecture complexism biology generative design steenson architectural intel igence quoted id kevin rogan personal communication ajla aksamija february quoted steenson architectural intel igence designers architects created digital landscape otis harley “the architecture artificial intelligence” archinect may video series httpsarchinectcomfeaturesarticle150062492a5partvideoseriesonthearchitectureof artificialintelligence niall patrick walsh “carlo ratti associati’s proposed milan science campus features robotical yassembled brick facades” archdaily august httpswwwarchdaily com899777carlorattiassociatisproposedmilansciencecampusfeaturesrobotical yassembled brickfacades predict 3d printing catalyze “resurgence detail ornamentation” wood dillenburger gramazio fabio matthias kohler calculative composition ethics automating design yet limits automated technologies instance they’re great nonuniform unpredictable materials like lowgrade timber expand ing foam65 stil architectural historian mario carpo sees great potential environmental economic benefits future “microdesigning” precisioninstal ation “can save plenty building material energy labor money deliver buildings better fit specs”certain measures developed process uses pattern recognition algorithmical generate new structures scrap material witt described means “radical resource reuse”and course build ings generated intelligent fabrication processes made intelli gent inclusion smart technologies responsive furnishings kinetic facades—which purportedly help optimize energy use68 fashion ai help manage architecture’s supply chains particularly materials prefabricated modularized ai optimize project planning scheduling69 armed camera drone images sensor data har vested construction site automated systems identify unsafe site conditions worker behaviors also crossreference images construction mod els identify errors defects70 autodesk’s bim iq scans tags safety issues jobsite assigns “risk scores” various subcontractors71 suffolk con tracting firm using machine learning scan construction images identify richard moss “creative ai algorithms robot craftsmen open new possibilities architecture” new atlas february httpsnewatlascomcreativeaialgorithmicarchitecture robotcraftsmen36212 mario carpo “excessive resolution artificial intelligence machine learning architectural design” architectural record june httpswwwarchitecturalrecordcom articles13465excessiveresolutionartificialintelligenceandmachinelearninginarchitecturaldesign shannon mattern kevin rogan personal communication andrew witt february certain measures “mine scrap instal ation ” httpscertainmeasurescommtsinstal ationhtml see work ai spacefactory httpswwwaispacefactorycom eric baldwin “architecture startup ai spacefactory reveals smart skyscrapers integrate technology design” archdaily skyscrapersthatintegratetechnologyanddesign see instance alice scheduling technology allows users optimize construction schedules “bid aggressively win bids amaze customers” alice httpsalicetechnologiescom jose luis blanco steffen fuchs matthew parsons maria joao ribeirinho “artificial intelligence construction technology’s next frontier” mckinsey company april https wwwmckinseycomindustriescapitalprojectsandinfrastructureourinsightsartificialintelligence constructiontechnologysnextfrontier jenny clavero “artificial intelligence construction future construction” esub construction software january httpsesubcomartificial intelligenceconstructionfutureconstruction smartvidio image management platform uses machine learning review tag photos videos job site suggests safety measures footage stored made searchable rendering useful resource potential lawsuits smartvidio httpswwwsmartvidio anand rajagopal “the rise ai machine learning construction” autodesk university inconstruction219f95342f5c shannon mattern workers wearing hardhats safety vests eventual recognize ladders clutter safety risks72 meanwhile komatsu japanese heavymachinery manufacturer partnering nvidia maker graphics processing units incorporate jetson ai com puting platform construction equipment allowing fullsurround vision realtime video analytics used optimize use onsite tools equipment monitor job progress flag risks73 course exhaustive data collection—as commonly advocated planning phase too—presents myriad methodological challenges privacy risks mention potential create culture paranoia see similar risks smart buildings ubiq uitous cameras sensors voice interfaces might also wonder remote automated data collection minimize need planners construction foremen monitor conditions onsite buildings planned designed fabricated aid artificial intelli gence they’re infused ai accordance recurring design dream build ings think end functional lives could well demolished artificial intelligent automaton74 phases architectural design encounter many familiar questions ethics auto mation automation liberate designers drudgery drafting data crunching eliminate jobs allow complementary blending human machinic skil payroll scheduling robotized happens clerical staff might designers create automated design tools balance efficiency economy “human values” like ecological stewardship accessibility multiple senses term might aigenerated models promote sensitivity environmental impact sustainable sourcing materials allow designers attend full embodied experience building including acoustic thermal conditions render design process open diverse stakeholders user groups might contractors deploy robot fabricators promote resource energy conservation also improving human laborers’ working conditions— laborers still around final whose values interests built algorithms—and bodies find studio construction site fabrication lab factory altering actualizing algorithms’ output elizabeth woyke “ai could help construction industry work faster—and keep workforce accidentfree” mit technology review june httpswwwtechnologyreview coms611141aicouldhelptheconstructionindustryworkfasterandkeepitsworkforce accidentfree kevin krewell tirias research “nvidia komatsu partner aibased intelligent equipment improved safety efficiency” forbes december httpswwwforbes comsitestiriasresearch20171212nvidiaandkomatsupartneronaibasedintelligent equipment1f0bdc1e665b raghav bharadwaj “ai applications construction building— current usecases” emerj november httpsemerjcomaisectoroverviewsaiapplications constructionbuilding i’m grateful kevin rogan conversations generated much concluding section calculative composition ethics automating design polymers plasterboard final question—about whose intelligences embedded ai—pertains every sector design we’ve explored ensure ethical application ai design make sure we’re defining responsible parameters operationalizing parameters responsibly— creatively might human designers intervene automated workflow might reassert agency could designers apply design skil designing subversive algorithms generate aberrant aesthetics embody radical politics eventual come regard squarespace websites dreamcatcher edifices aesthetical political retrograde—a form ai authoritarianism machine learning mannerism gan neogothic calculative composition apps architectures apparel need careful consider ends means automation continual audit algorithms apparatae material worlds made bibliography bratton benjamin “lecture ai cities platform design algorithmic perception urban geopolitics” benno premsela lecture httpsbennopremselalezing2015 hetnieuweinstituutnlenlectureaiandcitiesplatformdesignalgorithmicperception andurbangeopolitics carpo mario second digital turn design beyond intel igence cambridge mit press hebron patrick “rethinking design tools age machine learning” artists machine intel igence april httpsmediumcomartistsandmachineintelligence rethinkingdesigntoolsintheageofmachinelearning369f3f07ab6c luce leanne artificial intel igence fashion ai revolutionizing fashion industry berkeley ca apress negroponte nicolas architecture machine toward human environment cambridge mit press o’donnel kathleen “embracing artificial intelligence architecture” aia march httpswwwaiaorgarticles178511embracingartificialintelligenceinarchit steensonmol wright architectural intel igence designers architects created digital landscape cambridge mit press vetrov yury “algorithmdriven design ” httpsalgorithmsdesign chapter ai global south designing worlds chinmayi arun1 introduction essay “a place sun”architect charles correa describes hazards replicating designs without regard context picture poorly designed housing— insulated weatherresistant “box” created severely cold northern european regions—taking warm indian cities replacing ventilated homes veran dahs courtyards necessary tropical climate housing designed northern europe unable meet needs people living warmer cities developing world different social cultural context correa argues must place needs history cultural economic context society center design worth thinking algorithmic society architectural point view3 manuel castel wrote “we know technology determine society society”increasingly privately owned webbased platforms control access public services security education public sphere health services grateful paola ricaurte taught global south talking issues dragana kaurin sharing inspiring unpublished work colleague salome viljoen encouraging make bolder choices mother radha arun coming short notice final reader chapter much else written charles correa “a place sun” place shade gurgaon penguin random house india see ryan calo “robotics lessons cyberlaw” california law review –and jack balkin “the path robotics law” circuit manuel castel network society washington dc center transatlantic relations chinmayi arun relationship countries live society “datafied” public services delivered publicprivate partnerships5 push “datadriven development” mediated private actors development donors international nongovernmental organizations ngos governments rely data collected corporations creating potential biased opaque decisionmaking systems examine design systems automation artificial intelligence grad ual permeating citizens’ lives must think systems designed designs designed ends serve chapter focus risks benefits ai highlight ways southern populations vulnerable northern countries offer citizens stronger safeguards southern countries—most countries already law place data privacy7 world economic forum published proposals incor porate ethics ai organisation economic cooperation development published principles ai guarantee protection southern populations chapter ways ai may affect global south begin explaining concern move discussing meant global south although term “south” history connected “third world” asso ciated certain countries negotiating together clear geographical segrega tion even uniform idea scholars argue plural concept—there south discussing meaning “south” use four examples show many ways southern populations affected technology term “south” complex necessitates contextdriven approach ai final outline issues must take account context ai global south risks ai exacerbated southern populations difficult discuss effects ai south without discussing effects ai broadly discuss systems discrimination first discuss affects southern populations follow summary international human rights might apply conclusion argue contextdriven approach participative empowering approach necessary ensure human rights southern popula tions protected clear end chapter need transform way inno vate frame policies think ai enormity effort involved deter us correa pointed developing world eager innovation change genius lies stitching new ideas old social fabric producing linnet taylor dennis broeders “in name development power profit datafication global south” geoforum ––see also anita gurumurthy nandini chami deepti bharthur democratic accountability digital age change taylor broeders “in name development” –commission nationale de l’informatique et des libertés data protection around world available httpswwwcnilfrendataprotectionaroundtheworld last visited june ai global south designing worlds “seamless wonder”this metaphor worth bearing mind review hot mess currently use artificial intelligence ai global south worry global south increasing awareness thinking impact ai global south broad concern clear enough privileged white men designing technology business models ai9 design south answer design manner best uneasy fit worst amplifies existing systemic harm oppression horrifying proportions global south advocates furrow brows ai may thinking web based ai designed people live worlds rarely see power cuts internet shutdowns deployed rural hinterlands countries poor internet connectivity hours electricity day may worry resources diverted education healthcare budgets technologycentric solu tions companies building systems may concerned surveil ance southern children ai education built people whose children go private school restricted access screens authoritarian countries may lose sleep ai uses facial recognition drones forms surveil ance oppress vulnerable populations may worry loss jobs impact economies ai replaces lowskilled workers concerns without foundation ideas past one laptop per child10 resulted spectacular failure despite brighteyed optimism laudable intentions created technology designed con text may fail take local resources social norms cultural context account system designed cities facebook fairly harmless countries find weaponized country myanmar’s sociopolitical context contribute genocide11 take effort google maps able account favelas rio de janeiro12 technology policy frameworks impact correa “a place sun” concern well founded see sarah myers west meredith whittaker kate crawford discriminating systems report new york ai joshua keating “why one laptop per child fail” foreign policy september httpsforeignpolicycom20090909whydidonelaptopperchildfail “facebook turned beast myanmar” bbc march httpswwwbbccom newstechnology43385677 max oprey “how google putting rio’s invisible favelas back map” guardian favelasbrazilriomapserasingpoorerpartscity chinmayi arun whole countries might learned debate drug patents public health developing world many ways ai wreak havoc southern countries affect human rights southern populations absence local regulation southern countries ai may deployed experimental stages people countries bear risk harm may ensue larger scale ai may impact economies countries affecting role global economy several developing countries benefited role internetdriven global econ omy may gradual find lowskilled outsourced services offer replaced auto mation “call centers” bangalore employment business generate undone automation makes human intervention unnecessary automated cars may result cab drivers new york—famously world—finding work redundant skil need begin journey toward including south priority need go beyond mere use phrase policy documents speeches understand many things specifical worry speak global south left endangered global south contemporary use term “global south” complicated history linked different terms like “third world” “developing countries”“global south” largely replaced “third world” “developing countries” without controversies latter two terms used context geopoli tics “global south” shares history convincing body scholarship “global south” transcends borders stand nation states helps little context form history terms changes politics culture economics accompanied although term “south” used scholars earlier14 journey toward becoming mainstream might started brandt commission reports used 1980s context argument transfer funds “north” “south”“south” significant overlap term “third world” came used 1950s move away “east” “west” cold war overtones16 “third world” term used initial distinguished “colonized see anne garden mahler “beyond colour curtain” global south atlantic new york fordham university press see nour dados raewyn connel “the global south” contexts arif dirlik “global south predicament promise” global south –mark berger “after third world history destiny fate third worldism” third world quarterly –ai global south designing worlds neocolonized world”but time also came stand certain values18 term come expand beyond borders longer viewed geographical restrictive way19 includes “countless souths” including within understand west20 next part chapter discuss arguments offer il ustrations expansive definition useful striking articulation expansive thinking south comes santos argues south cannot seen geographic concept21 must seen instead “a metaphor human suffering caused capitalism colonialism global level well resistance overcoming minimising suffering”this definition accounts migrant workers rights abysmal standard living countries one would otherwise describe wealthy allows us distinguish billionaires residing india mexico china marginalized impoverished residents countries expanded reading global south focuses inequality oppression resistance injustice oppression23 santos argues south found within europe north america “in form excluded silenced marginalised populations undocumented immi grants unemployed ethnic religious minorities victims sexism homopho bia racism islamaphobia”milan builds say south must understood “plural entity” containing within “the different underprivileged alternative resistant invisible subversive”the significance framing refer south manner way include within disenfranchised populations many geographical clustered countries think “south” within countries would describe north conception south might encompass refugees united states america lead markedly different life upperclass privileged dominantrace individuals also reside country would also support idea south s—what designed one southern community population would necessarily fit another southern community population means designing south mean accounting many different contexts dirlik “global south predicament promise” berger “after third world” dirlik “global south predicament promise” –stefania milan emiliano treré “big data souths beyond data universalism” television new media –boaventura de sousa santos “epistemologies south future” european south –id milan treré “big data” santos “epistemologies” milan treré “big data” chinmayi arun inclusive definition south plural entity worth holding since accounts rights priorities many populations excluded current thinking ai forces us understand concerns raised south varied helps think different populations south within context contextual understanding prevent us recognizing value strategic southsouth alliances around particular issues gain leverage affinities southern societies based shared history economic political social marginalization past global cooperation common causes group world trade organization protests26 must however recognize southsouth cooperation far simple powerful southern societies like china india brazil south africa compete power powerful groups within southern societies benefit perpetuation transnational economy current form27 considering ai’s impact south acknowledge dominance states fields ai big data28 ricaurte points cluster countries data extracted consume services offered dominant global technology companies29 countries india acknowledge highlight potential extraction data ignoring potential impacts citizens political elite working closely industry elite countries tend focus protection markets protection citizens commodification citizens questioned—the focus ensuring local capital rather foreign capital benefits commodification ricaurte highlights role governments “data colonization”pointing governments create frameworks validate process contract ai companies public services provided using private data extracted populations meant serve31 clear exploitation south many dimensions might take place entirely within understand “north” data collection monitoring refugees immigrants marginalized populations might also take place entirely within south rising inequality economic models close ties industry government might mean legal frameworks designed facilitate local industry’s extraction data citizens however keeping broader ways global power capital worked past coloniza tion also takes place across borders northern companies “mine” data dirlik “global south predicament promise” id paola ricaurte “data epistemologies coloniality power resistance” television new media –id ricaurte “data epistemologies” nick couldry ulises mejias “data colonialism rethinking big data’s relation contemporary subject” television new medi –ricaurte “data epistemologies” ai global south designing worlds south relatively easily extraction part privatized process32 extraction data compared extractive practices colonialism couldry mejeias33 elite govern countries extraction takes place often complicit extraction burden extraction borne disen franchised recent years southern countries also developed relationships mirroring northsouth extractive practices southern countries—indian chinese businesses expanded southern countries next part chapter il ustrates four models vulnerable southern populations put risk technology technology worlds discussing idea “south” different models exploitation south using technology surfaced four examples used highlight complexity vulnerabilities south first example facebook myanmar classic il ustration technology designed north harmful exported south second example explores exploitation southern populations governing elite within southern countries examining aadhaar india’s national iden tity database third example focuses southern populations northern countries discussion refugees europe last example discusses southsouth exploitation using china’s export surveil ance technology il ustration facebook myanmar among shocking ways data algorithms may affect human rights role facebook played rohingya genocide myanmar prompted un investigators genocide note report facebook “has useful instrument seek spread hate” recommended independent inves tigation extent company’s role34 facebook usbased company brought social media platform myanmar former colony history decades state control classic case business model technological architecture northern country used southern country facebook aggressively marketed platform offering free jim thatcher david o’sullivan dillon mahmoudi “data colonialism accumulation dispossession new metaphors daily data” society space couldry mejias “data colonialism” –report independent international factfinding mission myanmar human rights council september paragraph chinmayi arun cost controversial free basics program35 country time develop healthy media ecosystem myanmar’s press described “not free” freedom house’s freedom press report time criticism government outlawed private publications subject prepublication censorship36 domestic broadcast print media owned controlled gov ernment import foreign periodicals restricted without healthy media ecosystem citizens way ascertaining truth facebook designed society robust media ecosystem protected first amendment clear given thought would happen platform domi nated information ecosystem country like myanmar described rumorfilled society37 bsr human rights impact assessment facebook myanmar pointed facebook used incite coordinate violence clear news reports hate speech went viral facebook myanmar38 military used platform spread hatred39 genocide based interviews bsr argued facebook make effort understand local context better myanmar small country public institutions legal systems offered victims violence little support facebook careful entering making effort understand local context build feedback loop vulnerable people truly marginalized within southern country suffered harm biometric identity database india aadhaar biometrics—based “unique identity” number40 database india crossborder element topdown control heavy system designed powerful elite upper caste men41—a software billionaire nandan nilekani supported catherine trautwein “facebook free basics lands myanmar” myanmar times june available httpswwwmmtimescombusinesstechnology20685facebookfreebasicslandsin myanmarhtml “freedom press ” freedom house washington dc –available https freedomhouseorgreportfreedompressfreedompress2012 bsr “human rights impact assessment facebook myanmar” megha rajagopalan “internet trol using facebook target myanmar’s muslims” buzzfeed news march available httpswwwbuzzfeednewscomarticlemeghara howfakenewsandonlinehatearemakinglifehellforwlgypb4gk paul mozur “a genocide incited facebook posts myanmar’s military” new york times october available httpswwwnytimescom20181015technologymyanmar facebookgenocidehtml information see httpsuidaigovinwhatisaadhaarhtml ian parker “the id man” new yorker october available httpswwwnewyorker commagazine20111003theidman ai global south designing worlds highranking politicians civil servants42—for underprivileged people india initial object give people including migrant workers way access government services43 however system interface people welfare services enrolling database spare impoverished person effort opening bank account acquiring ration card44 limited number consultations serious cost benefit analysis impact assessment studies expensive project experts indian food distri bution welfare schemes lifesaving public services impoverished people india critical project start45 pointed less expen sive models found work better46 nilekani appear willing engage fundamental questions whether aadhaar best way administer state’s welfare systems47 aadhaar mandatory anyone wants access indian welfare system criticized excluding people welfare system owing many ways malfunctions researchers found twentyseven starva tion deaths onwards directly linked aadhaar48 database also breached several times news reports say almost billion records personal identifiable information compromised49 aadhaar played havoc people’s lives caused people starve pre venting accessing government services deliver basic right food addition causing harm within system supposed fix aadhaar tar gets vulnerable people undocumented bangladeshi migrant workers residing india—one stated goals system make easier find deport people50 system also unfriendly impoverished populations built architecture biometric data collection system account happens bodies result living streets51 il ustrates possible within southern state elite force margin alized help construct big data sets used exclude surveil violate rights ways payal arora “the bottom data pyramid big data global south international journal communication –at –see parker “id man” reetika khera “the uid project welfare schemes” economic political weekly xlvi id id see id parker “id man” “aadhaar linked half reported starvation deaths since say researchers” huffington post india september available httpswwwhuffingtonpostin20180925 aadhaarlinkedtohalfthereportedstarvationdeathssince2015sayresearchersa23539768 “billion records compromised aadhaar breach since january gemalto” business line compromisedinaadhaarbreachsincejanuarygemaltoarticle25224758ece arora “the bottom big data pyramid” –id chinmayi arun refugees data collection europe powerful il ustration south exists within see northern countries come dragana kaurin’s work digital agency refugees european union52 european laws international law even humanitarian agencies use technology deprive asylum seekers agency make even vulnerable refugees made give personal data seek asylum european union although physical based usual considered global north asylum seekers vulnerable people receive protection coun tries origin little protection country residence often threat country origin fled host countries law enforcement agencies often mandate find imprison deport them53 vulnerable position law enforcement border control agencies well un aid agencies ngos collect asylum seekers’ refugees’ biometrics kaurin explains use automation harm refugees asylum seekers social media communication devices help maintain ties family seek information humanitarian aid workers move also subject surveil ance private sector government actors harvest data monitor movements54 even wellintentioned efforts using technol ogy put risk example trace face program international committee red cross uses facial recognition technology searches miss ing persons using photos provided families missing migrants either missing migrants blood relatives55 kaurin references interview refugee point chilling fact refugees “are also running away family someone wants hurt them”this il ustration southern populations inhabit global north made vulnerable collection data use technology systems built help refugees asylum seekers adopted technology take needs account kaurin points refugees usual consulted engaged framing policies affect them57 reduce vulnerabil ity increase agency asylum seekers recommends impacted commu nities especial minorities marginalized groups within involved designing processes making decisions asylum seekers58 dragana kaurin data protection digital agency refugees cigi special report may id id id id id id ai global south designing worlds chinese facial recognition technology zimbabwe using strategy similar north’s expansion south china selling surveil ance technology countries like ethiopia59 one might see oppression population one southern country elite within country facilitated another southern country well known china using big data build enhanced systems surveil lance ranging social credit system facial recognition systems predict individuals might threat public safety systems used elite within country control rest population taken crossborder dimension chinese companies make sell closedcircuit television cameras monitoring systems sometimes highdefinition equipped facial movement recogni tion technology countries including brazil ecuador kenya northern countries like germany recently united states taken steps control eign acquisitions control technologies use appears signifi cant market exists technology southern countries country like ethiopia government purchases chinese technology monitor mobile phones inter net activity people four examples might suggest one model southern populations harmed exploited use technology institutional weaknesses leave southern populations southern countries vul nerable technology northern countries make vulnerable technologies southern countries technology developed surveil ance control populations within countries south exported used marginalized populations southern nations ai global south worth reading work scholars think ai discrimination ing southern institutions legal frameworks exacerbate harms discuss southern populations within northern countries might access privileged people institutions within countries autonomous systems used broadly affect economy housing intimate relationships introduce enhance discrimination oppression erase populations failing account existence maya wang “china’s dystopian push revolutionize surveil ance ” httpswwwhrworgnews 20170818chinasdystopianpushrevolutionizesurveil ance chinmayi arun begin discussing autonomous systems systems discrimination move discussing may mean southern populations especial since fragile democracies nondemocracies world offer citizens institutional protections may available united states europe systems discrimination discussion ai context discrimination include big data corpus data means big data inherent biases affect outcome systems61 several stages inaccuracies bias intro duced algorithmic decisionmaking range recording data actual question answered algorithm tendency accept predictions based data sets truth62 even though outcome typical interpretation data63 may inaccurate64 data set could suffer number problems would skew outcome scholars use term “dirty data” refer missing incorrect badly represented data well data manipulated intentional distorted biases65 crawford pointed “not data created even collected equal y”data collection embedded power assumptions recording fingerprints example difficult manual work refugees migrant contract laborers67 design data sets biased result assumptions gaps68 data sets could underrepresent wrongly represent certain populations leading dis crimination exclusion69 even data set accurate structure end discriminating marginalizing people classic example jack balkin “the three laws robotics age big data” ohio state law journal ifeoma ajunwa “the paradox automation antibias intervention” cardozo law review id danah boyd kate crawford “six provocations big data” decade internet time symposium dynamics internet society oxford internet institute kate crawford jason schultz “big data due process toward framework redress predictive privacy harms” boston college law review rashida richardson jason schultz kate crawford “dirty data bad predictions civil rights violations impact police data predictive policing systems justice” new york university law review ajunwa paradox automation based kate crawford “think big data” foreign policy may httpsforeignpolicycom20130510thinkagainbigdata see arora “the bottom big data pyramid” kaurin data protection ajunwa paradox automation id –ai global south designing worlds data sets code people either male female erasing forms gender identity70 data set might discriminate indirectly recording seemingly innocuous fact acts marker identity il ustration employment used infer caste based historic employment marginalized caste people certain tasks manual scavenging71 training data algorithms embed bias72 algorithms trained real world data would replicate real word discrimination73 therefore hospital computer program used sort medical school students based previous admissions deci sions ends discriminating women racial minorities rules learned hospital’s older biased decisions74 big data essential generates corre lations75 although scientists understand difference correlation causa tion rest world tends treat conclusions based big data “enough”the ai institute articulated problem unambiguous terms77 pointed since classification differentiation ranking central ai sys tems systems “systems discrimination” argued bias ai sys tems connected lack diversity ai industry including people build ai tools environment built largescale ai systems come elite university labs technology companies “white afflu ent technical oriented male” spaces78 words technologies designed people north context reintroduced universities study ing ai col aborate social humanities disciplines affected communities civil society organizations79 important account plurality context intersectionality80 southern populations addition changing decisions made design data deployment algorithmic society must give southern populations tools engage effec tively questions affect already proving challenging understand global north countries despite lively debate relatively strong pri vacy antidiscrimination laws companies deploy technologies west et al discriminating systems citizen bureau “caste aadhaar manual scavenger leave past behind” citizen august available wwwthecitizeninindexphpennewsdetailindex211396 casteandaadharhowwillamanualscavengerleavehispastbehind solon barocas andrew selbst “big data’s disparate impact” california law review ajunwa paradox automation barocas selbst “big data’s disparate impact” ajunwa paradox automation id west et al discriminating systems id ai report ai institute new york university west et al discriminating systems chinmayi arun southern countries fewer resources institutions help protect marginalized people’s rights needs remedied high priority systems discussed previous four examples designed people privileged access data data subjects data subjects little control autonomy data typical autonomous systems used data subjects idea access data used81 exacer bated southern countries young democracies lack institutional stability since takes time build institutions institutionalize democratic practices82 milan argues need diverse ways citizens civil society engagement ward datafication practices result oppression inequality83 institutional frameworks southern countries must taken account consider impact ai might south freedom depends politi cal civil rights also social economic arrangement education health care84 development amartya sen argues depends removal sources “unfreedom” systematic social deprivation poverty poor economic opportunities tyranny sen describes poverty terms capability deprivation famously knows “capabilities approach” development julie cohen applied sen’s work build martha nussbaum access knowledge pointed need pay attention relationship net worked information environment human flourishing85 rights southern populations realized efforts made states also eroded governing elite states past southern countries worked together bloc gain access technology capital markets86 shared commitment development opposition colonialism creation equi table conditions socioeconomic development countries evolution southsouth cooperation87 cooperation taking place since non aligned movement developing countries came together negotiate develop ment trade issues developing countries began called southsouth cooperation triangular cooperation also began donors northern partners became involved southsouth initiatives88 danah boyd kate crawford “critical questions big data” information communication society –ethan b kapstein nathan converse “why democracies fail” journal democracy milan treré “big data” amartya sen “introduction” development freedom anchor books new york julie cohen configuring networked self new ct yale university press ch rubin patterson “global trade technology regimes south’s asymmetrical struggle” perspectives global development technology –report un secretary general un general assembly 73rd session role southsouth cooperation implementation agenda sustainable development chal enges opportunities id ai global south designing worlds progress made years southsouth initiatives one might argue cooperation southern states triangular cooperation mixed results years nonstate actors businesses civil society started playing powerful role southern countries countries devel oped groups wealthy influential populations affluent fellow citizens—the extractive exploitative consequences evident aadhaar example southern states developed greater economic influence southern states exploitative nature relationship evi dent chinazimbabwe example international human rights apply clear southern populations varied scattered northern southern countries helps bear mind entitled human rights international law offers standard threshold debates innova tion ai must take account ai affect human rights especial southern populations work underway map rights may affected un secretary general’s highlevel panel digital cooperation acknowledges major documents codifying international human rights written age digital cooperation89 ai could potential impact rights freedom expression privacy social secu rity right discrimination might also violate state parties’ commitment guarantee rights without discrimination un special rapporteur free dom expression david kaye recommended companies account discrimination input output level ai systems design systems nondiscriminatory account diversity90 suggested states companies might obligated conduct human rights impact assessments public consultations design deployment new ai systems existing systems new markets also recommended states ensure human rights central design deployment implementation ai systems91 rec ommendations offer concrete ways ensure states make effort prevent com panies violating human rights build deploy ai recommendation impact assessments technology used new markets especial valuable report un secretarygeneral’s highlevel panel digital cooperation age digital interdependence report special rapporteur promotion protection right freedom opinion expression un general assembly seventythird session id chinmayi arun southern countries since acknowledges risky deploy technology designed north unthinking south accounts context although un special rapporteur extreme poverty human rights yet publish report ai public consultation elicited useful responses human rights organizations responses point discriminatory ai systems might violate right social security92 may also affect states’ obligation ensure people able access right work93 necessitating efforts enable people whose skil jobs affected ai acquire new skil competence able work explore alternative income models like universal basic income94 recommendations ways states must develop institutional frame works guarantee human rights world dominated ai systems useful however much work done need clear framework states assessed monitor progress protecting human rights advancing sustainable development goals develop use ai conclusion degree ai industry willing experiment human populations95 name innovation make us uncomfortable castel reminds us invoking holocaust must remember destructive technology lose wonders96 technology capital drives ai currently rests firmly privileged northern hands vulnerable southern populations particu lar risk surveil ance forms discrimination bias poorly tailored outcomes result ai designed regard local contexts politics design need examined ai systems need studied situated realities97 boyd crawford write powerful “big data emerged system knowl edge already changing objects knowledge also power inform understand communities networks”with every year passes system intertwines institutions permeates societies article universal declaration human rights well article international covenant civil political rights see human rights watch submission un special rapporteur extreme poverty human rights may article international covenant economic social cultural rights amnesty international submission un special rapporteur extreme poverty human rights may ai institute report castells network society west et al discriminating systems boyd crawford “critical questions big data” ai global south designing worlds must heed ricaurte’s call alternative digital futures pluriverses protection cultures resistant governed market99 must work reversing extractive technologies favor justice human rights although scholars scientists un experts cautioned speedy adoption ai may harm vulnerable populations affect agency autonomy100 work necessary account plural contexts global south adopt modes engagement include populations empower design may necessary reimagine models innovation achieve this101 un secretary general’s highlevel panel digital cooperation recog nized called inclusive digital economy society one accounts local conditions human rights barriers faced marginalized groups102 also recognized need develop capacity stakeholders able stand make critical choices emerging technologies although redesigning technology market models know may seem daunting arguments may made efforts contextualize affect ability operate scale late start correa wrote big question architects third world size value projects abiding virtue place sun”bibliography ajunwa ifeoma “the paradox automation antibias intervention” cardozo law review forthcoming couldry nick ulises mejias “data colonialism rethinking big data’s relation contemporary subject” television new media –dirlik arif “global south predicament promise” global south –mahler anne “beyond colour curtain” global south atlantic new york fordham university press milan stefania emiliano treré “big data souths beyond data universalism” television new media –ricaurte paola “data epistemologies coloniality power resistance” television new media –richardson rashida jason schultz kate crawford “dirty data bad predictions civil rights violations impact police data predictive policing systems justice” new york university law review –ricaurte “data epistemologies” stuart russel et al “research priorities robust beneficial artificial intelligence open letter” available httpsfutureoflifeorgaiopenletter report special rapporteur paragraph see milan treré “big data” ricaurte “data epistemologies” un secretarygeneral’s highlevel panel digital cooperation correa “a place sun” chinmayi arun santos boaventura de sousa “epistemologies south future” european south –taylor linnet dennis broeders “in name development power profit datafication global south” geoforum –west sarah myers meredith whittaker kate crawford discriminating systems report new york ai chapter perspectives approaches ai ethics east asia danit gal introduction centuries humanity building technological tools support enhance capabilities allowing us survive flourish years humanity dreamed creating others image leading history rich human statues automata robots artificial intelligence ai usher another era tech nological development faced social consequences dreams—a technology exceeds status tool moving toward partner let us clear ai robots tools yet perception increasingly partners blurring line could partnership broad term context encompasses tools functioning social caretakers friends companions romantic love interests fellow spiritual beings developed used east asia briefly surveyed introductory chapter framing chapter founded claim china japan south korea perceive approach ai robots spectrum ranging tool partner may true countries distinct east asia continuously moving spectrum policy academic thought local practices popular culture observed country place south korea tool range china middle japan along partner range tool perspectives approaches ai robotics seemingly common west technology viewed instrument development danit gal growth also true east asia especial official government corporate policies concerned divergence toward partner range occurs academic thought local practices popular culture readers may tempted categorize partner range spectrum simple act anthropomorphism defined “to attribute human form personality things human”but oversimplification true east asian countries demonstrate preference toward biological inspired humanoid animaloid ai robots much buddhist shinto technoanimism ai robots attributed human traits believed possess spirit spiritual essence addition east asia ai robot partners come viewed friends love interests spiritual psychological emotional perceptions ai robots turn amplified fact ai robots designed look also behave like us human tendency anthropomorphize runs complications ai robots designed relatable interface potential partner intended used tool creates functional emotional paradox designing tools mimicking humans desirable developing natural human emotions response mimicking seen problematic chapter names design contradiction anthropomorphized tools paradox paradox often tightly knit issues female objectification constitutes another notable source growing sociotechnical tensions tensions emanating movement toolpartner spectrum inspired numerous global ai robotics ethics debates throughout years yet place debates feasible social pressing east asia south korea south korea placed tool range due establishment clear human overmachine hierarchy humans highest priority ai robots expected support enhance position dominance caveat hierarchy within human layer exist additional social hierarchies may compromise inclusive potential ai robots south korea also demonstrates clear preference functional ai applications robots mainly focusing human empowerment areas public services like education healthcare social care disaster relief security divergence toward partner range found country’s popular culture awash humanairobots partnership stories merriamwebster dictionary anthropomorphize nd httpswwwmerriamwebstercom dictionaryanthropomorphize perspectives approaches ai ethics east asia policies ethical principles tooldecisive korea institute robot industry advancement kiria published robots ethics charter revised past iterations served foundation allgovernment ethical framework adopted south korean national information society agency nia nia released ethics guideline intelligent information society april guideline aims achieve humanoriented intelligent information society pact principles publicness accountability control ability transparency building robot ethics charter’s comprehensive ethical guidelines developers providers users ethics guideline assumes four unique positions use places responsibility preemptively assessing ai robots’ potential negative social impact providers holds developers responsible elimina tion social discriminatory characteristics ai robotics design making accessible disadvantaged vulnerable groups developers also placed vanguard ai ethics south korea cal refrain developing ai robots “antisocial” characteristics “minimize social resistance disorder universal use” ai robots4 addition ethics charter published nia june reiterates six principles codified version robots ethics charter kiria notable among principles balance protection human dignity first principle common good second principle sunyoung byun professor seoul national university education explains three versions ethics charter approach ai robots tools meant protect human dignity promote common social good notes difficulty humans maintaining harmo nious balance individual collective flourishing balancing act constitutes important moral dilemma complicated introduction ai robots6 documents spell clear humanovermachine hierarchy humans developers providers users protect ai robots protect service humans robots ethics charter iterations published korea institute robot industry advancement kindly translated sunyong byun professor seoul national university education national information society agency nia ethics guideline intel igent information society april httpengniaorkrcommonboarddownloaddobcidx20239cbidx62611fil eno1 id nia ethics charter intel igent information society june httpengniaorkrcommon boarddownloaddobcidx20239cbidx62611fileno2 sunyoung byun remote interview danit gal march information see sunyoung byun hyunwoo shin jinkyu jeong hyeongjoo kim “a study necessity charter robot ethics contents” journal ethics –danit gal academic thought local practices tooloriented south korea’s tool perspectives approaches ai robots also evident winter olympics technology demonstration deployed eightyfive functional robots varying degrees intelligence rescue robots korea advanced institute science technology kaist used torchbearers alongside celebrities robots serviced airport different competition venues7 functional robots immune ethical clashes debates seen international boycott kaist fifty ai researchers due partnership defense company ban lifted shortly kaist ensured research ers develop assist development lethal autonomous weapon systems killer robots8 two months later kaist announced establishment ai ethics subcommittee9 chi hyung jeon assistant professor kaist states subcommittee formed time boycott april hosted first event boycott organizers’ participation drawing line two events10 conjunction ban kaist released code ethics artificial intelligence april unique among four principles third one stipu lating “ai shall follow explicit implicit human intention however execution ai ask people confirm implicit intention several people involved intentions different ai follow person highest priority closest relationship” suggests additional human hierarchies within human layer humanovermachine hierarchy “highest priority” people final say navigating ai see fit kaist’s principle complicates established issue societal inequality south korea12 reinforcing positions power relationship conflict documents calling equal distributed accessible ai robots particular given kaist’s position educational institute principle may also conflict developers’ mandate act eliminators social bias discrimination nia’s ethical guideline tara francis chan “south korea robot volunteers winter olympics including robot torch bearer” business insider december httpswwwbusinessinsider comsouthkorearobots2018winterolympics2017–“ai researchers end ban korean university says ‘killer robots’ ” reuters april httpswwwreuterscomarticletechkoreaboycottairesearchersendbanafterskorean universitysaysnotokillerrobotsidusl8n1rm2hn jihye jun “kaist launches ethics subcommittee ai” korea times june httpswwwkoreatimescokrwwwtech201806129250278html chi hyung jeon remote interview danit gal march kaist institute artificial intelligence kaist code ethics artificial intel igence april httpskiskaistackrindexphpmidkiaio jaewon kim “a ‘lost generation’ south korea bears brunt rising inequality” nikkei asian review december httpsasianikkeicomeconomyalostgenerationinsouth koreabearsthebruntofrisinginequality perspectives approaches ai ethics east asia popular culture partnership exploration tool preference kaist code ethics may challenge nia’s desired harmony within human layer hierarchy south korean popular culture challenging hierarchy korean dramas offer controversial perspective entertaining idea ai robots tools country saw eight dramas ai robots acting family members friends love interests list includes 사랑하면 죽는 여자 봉순이or bong soon—a cyborg love 아이엠 로봇이 아니야 i’m robot 보그맘or borg mom 별일 다 있네or strange things 너도 인간이니or human 사랑은 사람처럼or love like person 절대 그이or absolute boyfriend adaptation japanese story shows conclude human companionship superior ai robots frequently publicly explore idea ai robots transitioning tools partners directly addressing disruption humanovermachine hierarchy jiwon kim head ai policy ministry science ict notes “as people become reliant overuse intelligent social robots risk losing basic ethical values hold humans well authentic human relationships increases” kim states therefore “believe attachment obedient robots could undermine people’s relationships humans”this concern may key explaining nia’s emphasis avoiding “antisocial” development ai robots raises important question degree ai robotics development perceived become increasingly pressing examine chinese japanese perspectives approaches concerns may also response findings study human interactions social intelligent robot south korea14 south koreans seems still prefer functional ai robots study found south korean respondents preferred functional robot biological inspired one com pared japanese peers respondents maintained functional robot made feel like control sense hierarchical preservation believed induced increased sense comfort among south korean users15 observed sense comfort aligns nia’s wishes “minimize social sist ance jiwon kim remote interview danit gal march chan mi park yuin jeong kwangmin jeong haesung lee jeehang lee jinwoo kim growing features real home environments” february httpsocialrobotsinthewildorg wpcontentuploads201802hrisrw2018paper4pdf hyewon lee hyemee kang mingyu kim jaeryoung lee sonya kwak “pepper roomba effective robot design type based cultural analysis korean japanese users” international journal software engineering applications –danit gal disorder universal use” ai robots16 systems take humanoid animaloid shape make interface relatable master biological inspired capabilities better communicate humans sense control comfort likely erode conclusions chapter places south korea tool range spectrum quite comfortably yet note established humanovermachine hierarchy face continued challenges technology evolves human imagination continues run wild fact adherence humanovermachine hierarchy cal avoid “antisocial” development highlight debate humanairobots part nerships also highlights fact social hierarchies exist within human layer said humanovermachine hierarchy amplifies existing social tensions likely increase complexity importance artificial actors join societal mix humanmachine integration inevitable given south korea’s plans create intelligent information society even it’s humanoriented one policymakers south korea elsewhere thus remember technology solve social problems typical exacerbates china much like south korea china holds topdown view ai robots tools progress demonstrated official government corporate policies recom mendations ethical components approach beginning materialize evidence suggests align global guidelines largely viewing ai robots tools china however also presents strong interest imbuing ai robots partnerlike capabilities help realize full positive potential apparent academic thought local practices popular culture china also home intensifying tensions topdown tool bottomup partner approaches perspectives shape inform future local debates practices policies ethical principles tooloriented published july chinese government’s new generation ai development plan cal establishment ethical norms frameworks namely cal establishment “ethical moral multilevel judgement structure nia ethics guideline perspectives approaches ai ethics east asia humancomputer col aboration ethical framework” “an ethical code conduct”according plan’s timeline codification ethical norms codes frameworks slated take place last stretch development plan take long january chinese association artificial intelligence caai statelevel ai organization sitting ministry civil affairs18 announced establishment ai ethics committee tasked cre ating guidelines chinese development19 committee led professor xiaoping chen known leading creation realistic female humanoid “robot goddess” named jiajia embodies anthropomorphized tools paradox female objectification issues20 chen explained uniqueness ai robot ethics saying “a smart humanoid robot could integrate people’s daily lives someday one knows sure kind risks may bring along service”this suggests challenging ethical balancing act technology created act intelligent tool designed characteristics desirable partner early march chinese government hosted 13th national committee chinese people’s political consultative conference 13th national people’s congress known two sessions two sessions ceos baidu tencent submitted proposals discussing ai ethics22 baidu’s robin li yanhong submit ted proposal calling government speed ai ethics research citing impending transition ai simple tool stakeholder many areas partic ular li urged government share distinct chinese wisdom international ai ethics community23 may li also introduced baidu’s four ai ethics principles safety control ability equal access human development freedom24 tencent’s pony huateng submitted proposal calling ethical ai regulations graham webster rogier creemers paul triolo elsa kania “full translation china’s httpswwwnewamericaorgcybersecurityinitiativedigichinablogfulltranslationchinasnew generationartificialintelligencedevelopmentplan2017 last modified october information caai see httpwwwcaaicn phoebe zhang “china’s top ai scientist drives development ethical guideline” south china morning post january httpswwwscmpcomnewschinasciencearticle2181573chinas topaiscientistdrivesdevelopmentethicalguidelines celine ge “meet jiajia realistic ‘robot goddess’ built chinese researchers” south china morning post april httpswwwscmpcomnewschinasocietyarticle1936834meet jiajiarealisticrobotgoddessbuiltchineseresearchers na chen “ai association draft ethics guidelines” chinese academy science january httpenglishcascnnewsroomnews201901t20190110203885shtml masha borak “china wants make rules ai ethics” abacus march httpswwwabacusnewscomfuturetechchinawantsmakeitsownrulesaiethicsarticle3001025 新浪财经综合 “李彦宏三大提案完善电子病历 加强人工智能伦理研究” 新浪财经 march httpfinancesinacomcnreviewjcgc20190304docihsxncvf9583301shtml 博客园 “li yanhong unveiled ‘baidu lost land’ ‘simple search’ without advertisement mass production unmanned vehicles july” china news may httpwwwfonowcomview208592html danit gal use ai social good25 stance line tencent research institute’s framework multiple stakeholders arcc principles available reliable comprehensive control able27 may group leading chinese institutions including beijing academy ai peking tsinghua universities chinese academy science industry leaders like baidu tencent alibaba released beijing ai principles28 aligning existing ai principles beijing principles emphasize ai development benefit humanity notable suggestion princi ples maintains “stakeholders ai systems able receive education training help adapt impact ai development psychological emotional technical aspects”this suggests considerable degree expected psy chological emotional interactions humans ai systems rather functional ones statement sort indeed hovers tool partner range spectrum considering observed alignment international ai ethics discourse would aforementioned distinct chinese wisdom brought discus sions look like miao liao lecturer changsha university science technology believes answer found pluralistic integration chinese government’s twelve “core socialist values”these values divided three groups national values include prosperity democracy civility harmony social values include freedom equality justice rule law individual values include patriotism dedication integrity friendship twelve values explains already integrated national taught graduate engineering ethics 工程伦理 textbook textbook also highlights four unique chinese characteristics comparison western engineering ethical guidelines responsibility precedes freedom obligation precedes rights group precedes individual harmony precedes conflict31 highly likely stateadopted stateapproved ai robotics ethical guide lines incorporate values least reflect spirit case engineering 腾讯研究院 “2019年两会，马化腾提了这7份建议案2万字全文版” march https mpweixinqqcomsyb6oyuivhqjimcnmjsjysw 张志东 “腾讯创始人张志东：信息过载时代，科技如何向善？” 腾讯研究院 january httpsmpweixinqqcoms656xtsvp1rll6sorrs94ew 司晓 “司晓：打造伦理”方舟，让人工智能可知、可控、可用、可靠 腾讯研究院 december httpsmpweixinqqcomscbbsrjrtbrkkjundmhuqq english available zx “beijing publishes ai ethical standards cal int’l cooperation” xinhua may httpwwwxinhuanetcomenglish2019–0526c138091724htmfbclidiwar3vpl45lsmmt0anwolo zkpnhpodqa3bzd9q8dvb6mzurb2xtdxm5vbic beijing academy ai “beijing ai principles” may httpsbaipbaaiaccn enfbclidiwar2htirkjxxy9q1y953h2pmhlbir8pcsixho93btzyfph39vv9v9b2ey miao liao remote interview danit gal march information 工程伦理 textbook see httpwwwtuptsinghuaeducn bookscenterbook06831902html perspectives approaches ai ethics east asia academic thought local practices uniquely partnershiporiented ai ethics initiative departing tool approach ai harmonious artificial intelligence principles haip led yi zeng professor chinese academy science cas institute automation haip code ethics promotes unique concepts like humanization strengthen interactions ai humans empathy altruism ensure harmonious humanai society human empathy toward ai privacy ai humans respect bias machine humans show bias ai humans show similar risks legal constraints humans treat ai ensure harmonious coexistence32 zeng claims safest approach develop ai robots give sense self consciousness able empathize humans believes reciprocity humans ai robots key achieving true harmony ensure technology remains beneficial continues evolve33 approach ai ethics marks clear shift toward partner range spectrum serves rare demonstration ethical principles aiming achieve partnership vision might look like zeng alone belief ai systems ascend higher level con sciousness hanniman huang veteran chinese ai product manager views ai robots new species sees carrier human exploration self limitation relationship heaven man huang believes technologies’ unique advantages ful manifest humans move using substitute tool part society partner coex isting humanairobots symbiosis found far end partner range according huang symbiosis achieved developers possess critical competencies humanistic spiritual realms knowledge practicing buddhism specifical points toward buddha dharma symbolizes natural law harmony thus guides ethical behavior34 huang therefore takes humanairobots partnerships additional step include physical spiritual connections popular culture partnershipembracing aligns chinese buddhist idiom 万物皆有灵，念起莲花开 roughly translating “everything soul believe buddha lotus upon buddha sits bloom” suggests everything cultivated toward enlight enment become buddha principle originated ancient indian buddhist yi zeng harmonious artificial intel igence principle nd httpbiiiaaccnhai yi zeng remote interview danit gal march hanniman huang remote interview danit gal march danit gal scriptures adopted adapted throughout asia deeply embedded chinese tradition among others region35 application found intersection buddhism popular chinese culture intelligent robot monk 贤二 xian’er roughly translating “simple looking virtuous” xian’er introduced october longquan temple’s information technology center preprogrammed robot meant help spread message buddhism36 xian’er received machine learning boost engage buddhist scripters one million social media followers deeper analytical conversational level37 chinese popular culture also provides notable views ai robots partners chinese dramas depicting ai robots love interests since 机器人趣话 funny robot talk later dramas include movie 机器侠 metallic attraction kungfu cyborg 机器男友 robot boyfriend 我的 真芯男友or robot boyfriend 天降机器女仆 robot maid heaven chatbot xiaoice 小冰 created microsoft operated tencent world’s popular social chatbot xiaoice million online users often perceive friend love interest modeled female teenager raising issues female objectification depiction minors xiaoice liked enough considered among china’s top celebrities38 ai robots also present chinese music scene group ai idols named may wei viv 五月薇viv created based looks talents person ality traits chinese idol group snh4839 idea ai replicas intended help celebrities engage fans continue entertaining tirelessly technology showcased china’s spring festival gala four famous human hosts joined ai replicas stage40 also extends creation use three animistic inclination often believed part chinese religions philosophies often result religions philosophies melding country’s longstanding animistic heritage tradition joseph campbel “robot monk blends science buddhism chinese temple” reuters andbuddhismatchinesetempleiduskcn0xj05i jiefei liu “longquan temple using artificial intelligence organize spread buddhist scriptures” technode july httpstechnodecom20180709longquantempletechcrunch hangzhou geoff spencer “much chatbot china’s xiaoice mixes ai emotions wins millions fans” microsoft asia news center november httpsnewsmicrosoftcom apacfeaturesmuchmorethanachatbotchinasxiaoicemixesaiwithemotionsandwinsover millionsoffans snh48 official site 丝芭传媒打造国内首个虚拟偶像组合五月薇 viv 深耕偶像产业 bernard marr “one world’s watched tv shows hosted artificial intelligences” forbes january httpswwwforbescomsitesbernardmarr20190129 theworldsmostwatchedtvshowwillbehostedbyartificialintelligences5cd0ce8e68de perspectives approaches ai ethics east asia holographic ai news anchors china’s xinhua state news agency41 applications demonstrate even ai robots used tools create engaging accessible entertainment audiences likely engage replica idols friends partners much like would like engage humans modeled also extends robots designed attractive human traits even idols like jiajia conclusions despite compelling counternarrative academic thought local practices popular culture present humanairobots partnership majority ai robot applica tions china still perceived tools country rushes develop apply technologies ai robots used across national sectors healthcare education public services military uses expected ful embedded country’s near future operations however nation’s appetite rapid effective development ai robots increases view partners rather tools likely continue increasing prominence chinese government al uded perception ai tool chinese companies taking part developing social ai robots perceived partners addition prominent academics developers expressing ambitions expand previous conceptions ai robots partners china therefore hovering around middle toolpartner spectrum current policy ai robotics ethical considerations applications pulling direction tool developers’ ambitions popular culture pulling direc tion partner tension expected grow local global prominence china pursues leadership position ai robotics also expected aggravate social tensions digital natives grow anthropomorphized tools paradox female objectification ai robots intended used intelligent tools designed look behave like desirable partners japan japan sits partner range spectrum due exceptional strong mix pro humanairobots partnership academic thought local practices popular culture japanese policy approach ai moving toward tool range like south cate cadel “and something completely different chinese robot news readers” reuters november httpswwwreuterscomarticleuschinatechaianchorandnowfor somethingcompletelydifferentchineserobotnewsreadersiduskcn1ne19o danit gal korea china extent societal vision coexistence coevolution ai robots distinct another distinct feature japan strong technoanimistic tradition likely inspired development favorable partnership attitude entails intertwined complex analysis japan’s perspectives approaches ai robots policies ethical principles toolleaning like south korea china japanese policy views ai tool also however seeks integrate ai robots aspects society create environment humans ai robots coexist coevolve japan’s 5th science technology basic plan released january introduces idea society vision ai robotenabled convenient diverse society responds human needs even anticipate respond needs emerge43 likely progressive social vision ai robotics planning date idea able anticipate respond human needs emerge constitutes potential ethical issue may lead push rather pull culture humans necessarily decide needs want fulfilled aforementioned vision fleshed cabinet office council social principles humancentric ai social principles humancentric ai draft document document council sets social framework guide creation aiready japanese society44 end document cal rede signing society “all aspects including japan’s social system industry structure innovation system governance citizen’s character”the document also however warns overdependence ai robots emphasizes need maintain human dignity using tools much like south korean guideline yet document still cal “aibased human living environment”and “society premised ai”a notable aspect document view ai robotics widespread social tools necessitate redesigning japan’s social systems even individual character date japanese government likely one going lengths social accommodate integrate ai robots key part society’s foundation government japan 5th science technology basic plan january httpswww8caogojpcstpenglishbasic5thbasicplanpdf id cabinet office council social principles humancentric ai social principles humancentric ai draft nd httpsearchegovgojpservletpcmfiledownloadseqno id id id perspectives approaches ai ethics east asia academic thought local practices partnershipinspired takehiro ohya professor keio university comments view ai robots tools social principles document intentional ohya explains japanese seem differentiate human beings ai robots lesser degree might make less humancentric least comparison western cultures council member ohya shares among members view humancentrist nature social principles way better communicate achieve consensus western countries also says encouraged council consider acknowledging ai robots legal persons since consideration another species deemed ethical justifiable48 ethical guidelines japanese society artificial intelligence jsai seem diverge point49 article number jsai’s ethical guidelines notes “ai must abide policies described manner members jsai order become member quasimember society”a jsai blog post explains unique article reflects views jsai also follows spirit asimov’s three laws robotics jasi ethics committee entertained various ways ai robots would used future societies believes communicates ambitions japanese ai robotics researchers developers51 japanese views practices build upon country’s long robotic heritage yasuo kuniyoshi director next generation ai research center university tokyo maintains japanese known admiration hardware times software believes japanese inclined trust appreciated embodied ai often form robots bodiless system52 arisa ema assistant professor university tokyo comments japanese times come view robots partners due long history robotfriendly popular culture also notes however significant portion current fascination gen erated perceived ability intelligent robots solve pressing japanese problems care superaging society automation revitalize slowing econ omy53 another widespread use ai robots tools japan aid rescue missions provide operational assistance aftermath natural disasters54 takehiro ohya remote interview danit gal march japanese society artificial intelligence jsai japanese society artificial intel igence ethical guidelines may httpaielsiorgwpcontentuploads201705jsaiethical guidelines1pdf id jsai jsai ethical guideline february httpaielsiorgarchives514 yasuo kuniyoshi remote interview danit gal march arisa ema remote interview danit gal march martin fackler “six years fukushima robots final find reactors’ melted uranium fuel” new york times november httpswwwnytimescom20171119sciencejapanfukushima nuclearmeltdownfuelhtml danit gal popular culture partnershiprich japanese popular culture serves key source inspiration influence shaping academic thought local practices numerous japanese interviewees pointed two famous cartoons source inspiration ai robotics developers first astro boy mighty atom 鉄腕アトム created osamu tezuka first published atom humanoid intelligent robot created replace son science ministry’s head discarded failed grow older human would atom sold circus rescued new head science ministry gives robots human rights builds atom humanoid robot family atom goes attend elementary school save world superhuman strength55 story continues readapted entertain audiences today jun murai codirector cyber civilization research center keio university maintains many japanese researchers influenced astro boy introduced asimov’s three laws robotics importance necessity robot ethics56 second doraemon ドラえもん created hiroshi fujimoto motoo abiko ligent cat robot sent back time japanese kid named nobita decedent hopes changing nobita’s lazy behavior doraemon nobita become close friends go adventures across time space doraemon adapted numerous animated cartoons movies became international beloved character57 become popular japan’s foreign ministry named japan’s first “anime ambassa dor” hirotaka osawa assistant professor university tsukuba notes doraemon serves continued influential icon ai robot developers character remains relevant entertaining today stil existing somewhere tool potential partner softbank’s robot pepper pepper conversational humanoid robot emotional facial recognition capabilities pepper codeveloped institutions function assistant60 even buddhist priest61 softbank commercial titled “future life pepper” company reveals futuristic vision robot acting friend sibling potential love information astro boy see httptezukainenglishcomwppageid138 jun murai remote interview danit gal march yasuyuki yokoyama “celebrating exactly years doraemon’s birthday” nipponcom beforedoraemon’sbirthdayhtml “doraemon named ‘anime ambassador’” japan today march httpsjapantodaycom categoryentertainmentdoraemonnamedanimeambassador hirotaka osawa remote interview danit gal march information pepper see httpswwwsoftbankroboticscomemeaenpepper alex martin “pepper robot buddhist robe new funeral services role” japan times august httpswwwjapantimescojpnews20170816businesspeppertherobot todonbuddhistrobeforitsnewfuneralservicesrole perspectives approaches ai ethics east asia interest entertainer caretaker62 blurs intended use line tool partner pepper functions assistant priest also explicitly envisioned become much partneroriented practical example aibo pet robot dog sony aibo first available official relaunched january reinforced machine learning64 jiro kokuryo professor keio university explains aibo robots mimic real dogs also distinct robotic features avoid uncanny valleyassociated fears65 spite design measures aibo beyond repair owners sent elaborate buddhist burial ceremony demonstrating unique attachment eight hundred buried robot dogs66 sony part approaches ai tool achieve “harmony society” sony group ai ethics guidelines67 treatment robots religious care derives concept animism animism found two major religions japan shinto buddhism shinto complex exclusively japanese religion borders worldly otherworldly blurred polytheistic religion shinto belief holds spirits otherworldly beings eg gods dwell animate inanimate objects like technology suggests deep spiritual connection worldly manifestation otherworldly often referred technoanimism68 japanese buddhism like previously discussed chinese version animate inanimate objects part natural world possess character buddha potential becoming buddha follows saying 山川草木国土悉皆 成仏 roughly translates “all things nature buddha” idiom believed share ancient indian origins aforementioned chinese one another similar line japanese buddhist temple also ai robot monk called android kannon capable delivering full buddhist sermons69 notion japanese technoanimism developed drew inspiration religions creating rich synthesis source animation may different animation technological artifacts principle “future life pepper” youtube video posted “dean khaled” february https wwwyoutubecomwatchva3zllguvqy sonyaibo history nd httpwwwsonyaibocoukhistory “sony starts taking advanced orders new version aibo robot dog” japan times july httpswwwjapantimescojpnews20180719businesstechsonystartstakingpreorders newversionaiborobotdog jiro kokuryo remote interview danit gal march suzuki miwa “in japan aibo robots get funeral” japan times may https wwwjapantimescojpnews20180501nationaljapanaiborobotsgetfuneralxjt2rvwrv0t “sony group ai ethics guidelines” sony september httpswwwsonynetsonyinfo csrreporthumanrightshkrfmg0000007rtjattaiengagementwithinsonygrouppdf casper brunn jensen anders blok “technoanimism japan shinto cosmograms actornetwork theory enabling powers nonhuman agencies” theory culture society –thisanka siripala “an ancient japanese shrine debuts buddhist robot” diplomat march httpsthediplomatcom201903anancientjapaneseshrinedebutsabuddhistrobot danit gal much like china south korea japanese popular culture tel numerous stories ai robots partners particular love interests among 絶対 彼氏 absolute boyfriend readapted multiple asian countries 僕の彼女はサイボーグ cyborg キュートor q10 イヴの時間 time eve ちょびっツ chobits 安堂ロイド～ai knows love ando lloyd—ai knows love unlike south korea china however japan’s mainstream romantic fascination ai robots isn’t limited dramas vinclu inc’s gatebox ai lab creates holographic virtual wife home assistant hybrid mod eled young female character named hikari azuma70 popularity virtual wife underscores pervasive loneliness experienced japan71 tel us trying solve social problems technology already looks like also constitutes rare edge case intentional tool anthropomorphizing female objectification functional home assistant specifically designed act meaningful romantic partner conclusions japan rich source information discussions perspectives approaches ai robots partners policy social principles may moving tool range create international consensus hard ignore overwhelming positive approach demonstrated local culture practices toward humanairobots partnerships creates interesting dual tension politi cal ambitions social values one hand partner ai robots prove useful tools superaging population particularly japan sees automation economic boon threat hand tension pose complicated “antisocial” questions regarding already affects objectified popula tion groups like females might affect attempts repopulate superaging country simply put loves ai robots chapter conclusions discussion conclude south korea china japan share considerable similarities despite placed three different ranges toolpartner spectrum country information see httpsgateboxaihome httpsgateboxainews2018073101 michael hoffman “japan struggles keep loneliness arm’s length” japan times november httpswwwjapantimescojpnews20181110nationalmedianationaljapanstruggleskeep lonelinessarmslength perspectives approaches ai ethics east asia way debates movement across spectrum date south korean policy makes stand partner ai robots popular culture explores idea chinese policy headed direction tooloriented ai robotics ethical guidelines local practices culture experiment idea physical spiritual partnership japan’s social principles also moving tool direction society actively seeks creates partnerlike ai robots technology widespread societal use continue develop expect movement spectrum movement surly highlight plausibly aggravate tensions topdown tool bottomup partner perspectives approaches ai robots sooner later tensions core debating social benefit harm ai robots use three crosscutting ai roboticsrelated ethical issues highlighted chapter female objectification anthropomorphized tools paradox “antisocial” development global shared issue female objectification particularly salient ai robotics alongside decisive disenfranchising effect women fur ther reinforces anthropomorphized tools paradox functional tools given desirable often female companionship characteristics make enticing use put together two ethical issues create vicious cycle subjects women technology biased objectification mostly male ai robots devel opers designers development design choices blur lines ways lead problematic treatment toward women even minors emotional psychological confuse users technology genderless artificial relevant stakeholders would well remember underscores question “antisocial” technology degree ai robots’ socialization capability development considered “antisocial” many human functions substitute hit threshold could anthropomorphized tools paradox serve potential threshold despite clear female objectification anthropomorphized tools paradox fall “antisocial” technology development remain incredibly common need prosocial regulation “antisocial” technology seeking create aiready societies many paths developing designing ai robots ways replace degrade humans humanairobot harmony cannot achieved creating artificial substitutions compensate fact yet achieve al human harmony technical solutions social problems bibliography china beijing academy artificial intelligence beijing ai principles may https baipbaaiaccnenfbclidiwar2htirkjxxy9q1y953h2pmhlbir8pcsixho93btzyfph 39vv9v9b2ey danit gal china institute science technology policy tsinghua university “chapter public perception general impact ai” china ai development report july httpwwwsppmtsinghuaeducnewebeditoruploadfilechinaaidevelopmentreport 2018pdf japan ema arisa ieee ead regional reports ai ethics japan april httpbaijapan orgen2018reportsonaiethicsjapanreprinted ieee ead v robertson jennifer robo sapiens japanicus robots gender family japanese nation oakland university california press south korea statues republic korea intel igent robots development distribution promotion act httpelawklrirekrengmobileviewerdohseq39153typelawnamekeyrobot yoo juyoung “results outlooks robot education republic korea” procedia—social behavioral sciences –additional resources reflecting ai ethics east asian perspectives ethical aligned design 1st edition classical ethics ais march httpsstandards ieeeorgcontentdamieeestandardsstandardswebdocumentsotheread1eclassical ethicspdf zeng yi linking artificial intel igence principles httpwwwlinkingaiprinciplesorg chapter artificial intelligence inequality middle east political economy inclusion nagla rizk introduction recent years middle east plagued persistent economic political inequalities regimes pushed agenda economic growth technological advancement paid less attention economic development inclusion less political engagement participation turn come amidst divides based religion ethnicity spatial disparities inequalities also manifested digital economies exacerbated power dynamics highly concentrated businesses smaller establishments trying carve niche turn effect artificial intelligence divides associated given discourse artificial intelligence ai inequality tends amplified version earlier conversations digital technologies inequality one end spectrum digital technologies aggravate digital divide knowledge inequalities widen developmental gap given pervasiveness fourth industrial revolution power ai technologies conse quences amplified technology data monopolized hands powerful like electricity information technology ai qualifies “general purpose technology” gpt typical characterized “pervasiveness” ability “continuous nagla rizk improvement” eventual reduce costs “spawning innovation” making “easier invent produce new products processes”what makes particular gpt unique scale scope capability components depth capacity selfeducate potential “protracted aggregate impact”within ai’s components—the data algorithm infrastructure—lies trigger potential inequalities societal standpoint biases data black boxes algorithms inaccessibility inadequacy infrastructure serve exclude marginalize ones agile already well positioned adapt capitalizing existing technologies able reap benefits ai end spectrum notwithstanding said pervasive nature ai indeed channeled toward inclusion mitigating inequalities empowerment marginalized examples improving health services generating systems better predict disease better education tuning curricula student’s ability assimilate creating encompassing ecosystem entrepreneurship small businesses built around open data inclusive technologies purpose chapter explore issues related ai inequality middle east north africa mena region within larger global conversation ai ethics important investigate potential ai social economic context ask societies utilize ai tool democratizing knowledge inclusion amid unique challenges face chapter explores tensions opportunities potential challenges equitable deployment ai region dearth information ai use region challenge undertak ing work especial given timeliness topic accordingly addition published works author resorted capturing knowledge interviews airelated conversations experts field talks public conferences chapter includes four sections following introduction second section socioeconomic challenges facets inequality third section “ai mena data infrastructure people” unpacks components ai respective bearing inequality region discusses challenges highlights rays hope fourth section “conclusion ai mena—inclusion inequality” concludes underlines specific tensions shape debate ai inclusion region context region flux middle east north africa homogenous region overall similarities political cultural contexts countries considerable variation economic landscape specifical natural human resources boyan jovanovic peter l rosseau “general purpose technologies ‘engines growth’” journal econometrics –id artificial intelligence inequality middle east size qualifications potential domestic workforce within country key factor considerations impact technology inequality socioeconomic development uprisings parts region last decade shown trickledown economics worked mitigate inequalities improve livelihood marginalized diverse region following world bank classification region clustered groups according availability natural resources namely hydrocarbons also according size populations3 first group includes highincome arab countries tend resourcerich labor importers expatriates representing significant portion population second middleincome arab countries labor abundant—with resource rich algeria others resource poor egypt tunisia jordan lebanon morocco thirdly lowincome arab countries include resource rich labor abundant face political turmoil syria yemen resource poor palestine mauritania4 one commonality shared countries region prevalence youth region houses million people age fifteen twentynine6 half region’s population age twentyfive7 shapers region’s future virtue young age offer ideal potential recipients learning adapting using creating new technologies given right education skilldevelopment training young population unevenly distributed among countries diverse economic landscapes pockets youth unemployment witnessed resourcepoor countries region significant political nuances environments already political fluid variation countries’ socioeconomic conditions also reflected diverse lev els technological development use turn offering different contexts comes ai inequality oilrich countries taken lead fourth industrial revolution taking steps encourage ai adoption government encouraging aibased entrepreneurship united arab emirates uae positioning “socioeconomic context impact events middle east north africa region” menaoecd investment programme httpwwwoecdorgmenacompetitiveness 49171115pdf last accessed january see figure id chapter cover nonarab countries region iran israel arab human development report youth prospects human development changing reality un development programme httparabhdrorgreports20162016aspx last accessed january “meeting needs growing youth population middle east” report abu dhabi oxford business group httpsoxfordbusinessgroupcomanalysisdividendorliabilitymeeting needsregione28099sgrowingyouthpopulation0 last accessed january nagla rizk tunisia lebanon syria iraq bahrain palestinian morocco jordan kuwait territories qatar uae algeria libya egypt saudi arabia mauritania oman sudan yemen djibouti south sudan resource rich labor abundant resource rich labor importing resource poor labor abundant sudan south sudan classified within subsaharan africa world bank figure map arab mena countries classified natural human resources source put together author based data httpsiteresourcesworldbankorgintmena resourcesedp07overviewapril12pdf regional lead ai assigning government minister dedicated ai country pioneered initiatives retrain labor force adopted policies encourage ai inclusion areas health8 countries set benchmark relied revenues natural resources fuel development new industries depending imported technologies human resources hand despite potential laborabundant countries like egypt tunisia relatively trail along face persisting economic difficulties especial unemployment youth females cases educated circumstances talents remain underutilized ascribed socioeconomic statuses sticky social mobility hard inequality becomes one opportunity wealth “artificial intelligence used ‘urgent’ fight tuberculosis says uae minister” national october httpswwwthenationalaeuaehealthartificialintelligencetobeused inurgentfightagainsttuberculosissaysuaeminister1783316 last accessed january artificial intelligence inequality middle east time countries comparatively diversified economies terms manufacturing service industries highincome resourcerich countries analysis chapter pertains cluster middleincome countries resource poor labor abundant inherent tensions paradoxes related ai inequality highest promise may also face challenge opportunity relying endogenous capacity leapfrogging could actual achieve significant successes use ai inclusion currently face challenges level data acquisition resilience local infra structure present initiatives incorporate ai developmental goals nascent initiatives encourage budding startups push ai integration exist limited challenges ample arab spring failure trickledown despite positive macroeconomic indicators years preceding arab uprisings underlying deeply rooted causes drove region fall unrest hardly trickledown seemingly growing economies eve january uprisings egypt tunisia experienced relatively high rates economic growth rates years leading reaching percent –in decade leading socioeconomic indictors failed shed light underlying tensions announced statistics poverty health education showing considerable improvements10 case arab uprisings il ustrates shortcomings topdown macro indicators economic social wellbeing failure predict unrest national policies concerned primarily completely topdownled growth paying little attention key factors promote sustainable devel opment education health civil liberties uprisings demanded economic social political inclusion amid array frustrations highlighted economic political intertwined top structural socioeconomic ailments came persistent unemployment lack opportunities especial youth highly educated women socioeconomic grievances coupled discontent corruption11 limited nonexistent political freedoms12 world bank world bank open data httpsdataworldbankorg last accessed january michael gordon “forecasting instability case arab spring limitations socioeconomic data” wilson center february httpswwwwilsoncenterorgarticle forecastinginstabilitythecasethearabspringandthelimitationssocioeconomicdata last accessed january “socioeconomic context impact events middle east north africa region” gordon “forecasting instability” nagla rizk neoliberal policies reflected technology policies fixation connectivity economic gains little safeguards citizen engagement privacy egypt example expansion information communication technology ict infrastructure backbone economy part neoliberal economic reform structural adjustment program ersap led world bank international monetary fund 1990s objective draw foreign direct investment feed targeted economic growth vein technology innova tion policies within countries tended favor larger foreign corporations westerncentric development paradigms expense supporting local smaller scale entrepreneurial technology initiatives culture openness collaboration nevertheless expansion connectivity brought two empowering outcomes related uprisings first growth entrepreneurial scene fuelled energy youth scene continues flourish despite less ideal circumstances serves testament underlying potential countries egypt tunisia second expanded connectivity paradoxical opened networked public sphere13 engaged growing communities utilize digital communication technologies mobilization regime14 discussion whether icts served inclusion fueled dual use icts first state promote neoliberal policies later control masses also people mobilize engage uprisings thus called revisiting trajectory technological advancement amid paradoxical state stance regarding liberties multifaceted inequality mena inequality region complex multilayered multidimensional extends beyond income inequity inequality opportunity rooted disparities access education health services employment living conditions active citizenry inequalities also exist along gender ethnic origins social background15 realities pertaining minorities underprivileged groups excluded opportunities equal participation political economic processes examples communities living poverty cairo’s city dead ethnic minorities morocco’s western sahara religious minorities lebanon translate exclusion marginalization potential political unrest especially among youth yochai benkler wealth networks social production transforms markets freedom nagla rizk lina attalah nadine weheba “the networked public sphere civic engagement post2011 egypt local perspective” arab networked public sphere httpwww arabnpsorgegypt last accessed january gordon “forecasting instability” artificial intelligence inequality middle east disparities captured mainstream indicators income inequality gini coefficient measures distribution wealth amongst population assumption wealth properly registered documented even alvaredo assouad piketty point serious issue income distribution region16 highlight extreme inequality within countries “the share total income accruing top income earners middle east” compared percent western europe example17 difficulty measuring inequality formal assessment methodologies aggravated inherence informality indeed region largest informal economies world18 figure outlines size informal sector mena region whole remains world average laborabundant countries exception jordan global average results indicate onethird total economic output region remains undeclared fore registered tax purposes additional fact informal employment percentage gdp –algeria egypt jordan lebanon morocco tunisia mena region world figure informal sector size percentage gdp source httpswwwimforgenpublicationswpissues20180125shadoweconomiesaroundthe worldwhatdidwelearnoverthelast20years45583 facundo alvaredo lydia assouad thomas piketty “measuring inequality middle east –the world’s unequal region” review income wealth forthcoming httpsonlinelibrarywileycomdoi101111roiw12385 last accessed january id diego f angelurdinola kimie tanabe “microdeterminants informal employment middle east north africa region” sp discussion paper world bank httpsopenknowledgeworldbankorghandle1098626828 last accessed january nagla rizk constitutes percent region’s labor force19 means twothirds region’s workers access social security work outside statesanctioned laws parameters labor laws line information two particular facets inequality region directly feed potentials challenges ai inclusion first unemployment ai conversation highly associated influence labor second digital divide digital main realm ai thrive following analysis two aspects unemployment youth unemployment rampant laborabundant countries region regional average youth unemployment mena stood percent20 significantly higher world average percent shown figure youth unemployment figures egypt tunisia stood percent percent respectively rates higher witnessed eve arab spring standing percent percent respectively youth unemployment continues pose serious threat near future given demographic construct youth unemployment algeria egypt jordan morocco palastine tunisia mena region world –figure youth unemployment selected mena countries –source compiled author based data httpsdataworldbankorgindicatorsluem1524ne zsend2010start2003 diego f angelurdinola kimie tanabe “microdeterminants informal employment” world bank “unemployment youth total total labor force ages –national estimate” world bank group httpsdataworldbankorgindicatorsluem1524nezsend2010start2003 gordon “forecasting instability” artificial intelligence inequality middle east region ages fifteen twentynine making almost onethird region’s population age fifteen making another third22 unemployment also witnessed among educated quarter holders university degree higher egypt unemployed23 comparative figure exceeded percent tunisia percent morocco past two decades unemployment rate region men advanced degrees fluctuated percent higher figures fellow middleincome countries elsewhere percent bulgaria percent turkey example25 female unemployment also witnessed region’s middleincome countries female unemployment stood percent egypt percent percent percent jordan tunisia morocco respectively26 employ ment gender gap reached nearly percent algeria jordan percent egypt27 even though share women informal employment lower men remains “gender segmentation” women likely concen trated lower quality jobs28 furthermore women represented invisible work goes beyond informal sector house domestic work unpaid adds layers uncaptured inequality takes place informal employment digital inequality digital inequalities exist region world well within countries region divides exist along indicators connectivity also arab human development report youth prospects human development changing reality un development programme httparabhdrorgreports20162016aspx “egypt figures ” central agency public mobilization statistics httpwwwsisgov egupegypt figures 2018egyptinnumbers2018pdf last accessed january “data” arab development portal httpdataarabdevelopmentportalcom last accessed january world bank “unemployment male male labor force modeled ilo estimate” world bank group httpsdataworldbankorgindicatorsluemtotlmazs accessed april world bank “unemployment female female labor force modeled ilo estimate” world bank group httpsdataworldbankorgindicatorsluemtotlfezs accessed march “the future jobs skil middle east north africa preparing region fourth industrial revolution” world economic forum may httpswwwweforumorg reportsthefutureofjobsandskil sinthemiddleeastandnorthafricapreparingtheregionfor thefourthindustrialrevolution last accessed january “the future jobs skil middle east north africa” world economic forum employment globalizing organizing wiego httpswwwwiegoorgsitesdefaultfiles migratedresourcesfilesinformaleconomyarabcountries2017pdf last accessed january nagla rizk use age group education income geographical distribution gender since countries region witnessed exponential increasing internet mobile connectivity29 percentage population internet users reached percent lebanon almost twothirds morocco palestine jordan30 egypt almost forty million internet users representing percent population broadband subscription mobile phones countries region ranged around half twothirds populations except oilrich countries jordan figures exceeded percent32 nevertheless compared regions exception uae qatar lebanon mobile broadband speed region global aver age33 region also characterized high prices limited number users highspeed internet high barriers entry internet market new service providers34 additional although region seen expansion basic voice service mobile infrastructure broadband largely influenced stateowned operators outdated infrastructure mobile operators banning voip apps regional disparities exist infrastructure internet speed uae qatar lead use fiber optic systems deliver internet35 exception recent initiative egypt replace percent copper cables fiber optic ones middleincome countries still rely copper wires37 digital inequalities exist within countries region internal digital divides evident geographical disparities urban rural areas egypt38 lebanon39 relatively affluent coastal regions opposed less world bank “individuals using internet population” world bank group https dataworldbankorgindicatoritnetuserzs accessed april “data” arab development portal “ict indicators quarterly bulletin” ministry communications information technology “data” arab development portal world bank “individuals using internet population” id id “of copper cables replaced fiber ones ” egypt today december httpwwwegypttodaycomarticle26260295ofcoppercablestobereplacedwithfiberones rabah arezki et al “a new economy middle east north africa” middle east north africa economic monitor october httpsopenknowledgeworldbankorgbitstream handle10986304369781464813672pdfsequence11isallowedy last accessed january mona farid badran “young people digital divide egypt empirical study” eurasian economic review –httpslinkspringercomarticle101007s40822 0140008z last accessed january antoine harfouche alice robbin “antecedents digital divide lebanon” mediterranean conference information systems proceedings paper january httpswwwacademiaedu29840864antecedentsofthedigitaldivideinlebanon last accessed january artificial intelligence inequality middle east fortunate rural western southern areas tunisia evidence digital divides age education also documented egypt40 tunisia41 lebanon42 digital divide also present gender evident rates internet access cultured gender roles region shape women’s engagement icts43 tunisia exclusively responsible domestic labor addition employment education inhibits women allocating time would like ict usage limits skill development45 social constructed “second shift” domestic labor reinforces divide digital competencies men women region46 similar trend appears lebanon inequalities work opportunities social constructed gender roles mean occupational level men eskil women47 ai mena—data infrastructure people advent ai context mena comes multiple challenges notably present context pertaining inclusion inequality section attempts unpack conundrum discussion data enabling environment infra structure human capital data—the mine data heart discourse ai inequalities region better data sets enable tuning algorithms give better results biased data cause amplify badran “young people digital divide egypt” –ikram toumi “information computer technology digital divide postrevolution tunisia” phd diss university texas httpsrepositorieslibutexaseduhandle215243646 last accessed january harfouche robbin “antecedents digital divide lebanon” oum kalthoum ben hassine “personal expansion versus traditional gender stereotypes tunisian university women ict” women ict africa middle east changing selves changing societies ed ineke buskens anne webb london zed books httpswwwresearchgatenet publication271699674personalexpansionversustraditionalgenderstereotypestunisian universitywomenandict last accessed january sangeeta sinha “women’s rights tunisian women workplace” journal international women’s studies –httpsvcbridgewedujiwsvol12iss312 last accessed january ben hassine “personal expansion versus traditional gender stereotypes” arlie hochschild anne machung second shift working families revolution home new york penguin httpsbooksgooglecomegbooksidst6kwcpjs8cprintsecfro ntcovervonepageqffalse last accessed january harfouche robbin “antecedents digital divide lebanon” nagla rizk inequalities marginalization quality data lacking region data available subject challenges create amplify biases cause harmful consequences especial marginalized groups data asymmetry markets data asymmetry innate power dynamics given data differentiating market factor data becomes source authority impediment leveling playing field less powerful holds even context limited local data start data inequality manifests underlying forces ai market competition exists large international companies local small medium enterprises large data sets prerequisite developing ai utilizing ai limited afford either buy data brokers research institutions consul tants capacity technical infrastructural financial gather analyze large amounts data companies like google uber facebook amazon massive amounts annotated data see best results ai systems lack access data may actual inhibit access market would limit competition lessen innovation “stifle energy fresh ideas startups smes small medium enterprises bring”this puts smaller companies disadvantage feeds market concentration egypt example large laboratories control market percent country’s health data sets necessarily know make best use them49 data mine offers huge potential small agile companies deploy ai health services like predicting epidemics future responses particular medications concentration data sets market barrier innovation specifical inclusion smal companies market developmentrelated objective data crowdsourcing offered alternative towards mitigating data asymmetry example smaller local initiatives like bey2ollak crowdsourced roadtraffic monitoring application founded egypt collect data via crowdsourcing hence build large data sets albeit much smaller scale larger multinationals application collects considerable amount data million users data lock state data lock amplifies power asymmetry originating data ownership gating state data typical housed national statistics offices clear asymmetry exists state owner national statistics citizen data lock takes place data easily accessed citizens released timely manner datacollection methodologies disclosed data may politicized filtered incomplete censored olivier thereaux “using artificial intelligence open data innovation accountability” open data institute httpstheodiorgarticleusingartificialintelligenceandopendatafor innovationandaccountability last accessed january ahmed abaza “ai inequalities” interview nagla rizk april artificial intelligence inequality middle east data lock region seen lack published highquality data machine readable cumbersome regulations need licenses allow reuse50 open data barometer produced world wide web foundation shows estimated percent data arab world open even though barometer suggests percent surveyed government information available internet remains technical andor legal barriers accessing machinereadable data51 example increased availability data website egypt’s central agency public mobilisation statistics capmas data pdf format countries region made progress toward open government data one example tunisia ministry energy effort partner international organizations promoting open government principles created website publishing hydrocarbon investment contracts associated documents data made available machinereadable format addition metadata country company name resource extracted signature date contract type52 data inaccuracy—blur myopia blindness another main challenge data region inaccuracies end clouding realities ground one possible source inaccuracy data blur aggregates cloud granulations captured disaggregation data example found failure egypt’s aggregate official data capture nuanced effects currency floatation subsequent inflation inequality different groups especial women femaleled households53 related source data inaccuracy shortsightedness coming single dimensional lens looks economic social variables top down—data myopia contention extends data makes national statistics indica tors income inequality education health others case point failure national data defined collected reflect lived realities anticipate arab spring indeed multifaceted inequality sits heart contention around macroeconomic indicators statistics inform especial growth inadequate reflections economic wellbeing shortcomings quantitative macro data put question ability collec tion methodologies reflect complex realties ground including informality “mena data platform open knowledge development mena” httpmenadatanet publicindex last accessed january hatem ben yacoub “why okf global open data index failure” hby consultancy httpwwwhbyconsultancycomblogwhyokfglobalopendataindex2015isafailurehtml wissem heni et al “tunisians access hydrocarbon contracts open data format” natural resource governance institute httpsresourcegovernanceorgblogtunisianscannow accesshydrocarboncontractsopendataformat last accessed january maye kabil “how cover postshock economy” mada masr december https wwwmadamasrcomen20171229featureeconomyhowtocoverapostshockeconomy last accessed january nagla rizk example54 nobel laureate angus deaton provided wealth evidence limited efficacy aggregatelevel data methodology collection55 work cal move away national aggregatelevel methodologies ones bottomup better reflect individual human behavior realities56 data inaccuracy also comes blindness due selectivity data collection excluding communities outside radar formal establishment applies informal employees absent national employment statistics also invisible national statistical radar residents informal dwellings account almost third housing cairo percent morocco seen several periurban areas around greater tunis jordan57 informal hous ing also observed also lower rate richer countries region saudi arabia58 exclusion informal communities national income market censuses immediately translates marginalization exclusion policies related subsidies social safety nets housing broader policy making enabling environment closely linked discussion data enabling environment governs potential democratizing access use data inclusive ai region environment necessary promote comprehensive paradigm openness culture sharing data core data inequalities compounded subpar environment complicates interplay ai inclusion region specifical appropriate environment entails ecosystem legislation supports innovation access markets open data building human capacity technology development figure offers summary mapping legislation around data regulation region freedom information foi frameworks scarce region tunisia jordan adopted foi legislation made official declarations regard59 tunisia established access information authority one bodies mena region jordan joined open government partnership announced ambitious reforms national plans regarding freedom informa tion access information60 legislation also needed safeguard citizen consumer rights privacy data protection laws regulations pertaining data data protection scarce elena ianchovichina “eruptions popular anger economics arab spring aftermath” world bank httpsopenknowledgeworldbankorgbitstream handle10986289619781464811524pdfsequence5isallowedy last accessed january “the prize economic sciences ” royal swedish academy sciences httpswwwnobelprizeorguploads201806press33pdf last accessed january id david sims “the arab housing paradox” cairo review november httpswww thecairoreviewcomessaysthearabhousingparadox last accessed january id “participants” open government partnership httpswwwopengovpartnershiporg ourmembers last accessed january id artificial intelligence inequality middle east morocco tunisia jordan morocco egypt tunisia jordan palestine lebanon tunisia egypt jordan data protection law open data portals foss lebanon data regulation mena lebanon egypt egypt jordan morocco draft law constitutional right telecommunication right privacy regulation data arab convention combatting information foia technology offences morocco tunisia jordan morocco tunisia jordan morocco egypt tunisia jordan open government partnership palestine lebanon palestine lebanon figure data regulation mena source compiled author different sources region existing framework many countries region signatory arab convention combating information technology offences61 convention offers “overview general provisions privacy data protection” provide “explicit stipulations legal protection regulation data privacy”tunisia morocco jordan form reified draft laws data protec tion63 tunisia pioneer mena region terms data privacy protection legislation data privacy protection legal provisions set organic act protection personal data64 setting high standard data protection tunisian act gives range rights individuals whose data pro cessed sets certain obligations organizations individuals charge data processing countries region also taken steps terms data legislation example qatar enacted law concerning personal data protection uae specific data protection provisions exist free zones uae’s abu dhabi global market dubai international financial centre66 bahrain’s latest including algeria egypt morocco tunisia jordan palestine lebanon nagla rizk youmna hashem nancy salem “open data management plan middle east north africa guide” mena data platform october httpmenadatanetresources datasets1539516976opendatamanagementplanpdf last accessed january id republic tunisia organic act n°–of july 27th protection personal data httpstinyurlcomy8o76eau last accessed january “law promulgating protection privacy personal data law” sultan alabdul partners httpscyril aorgendocumentsei6xl6kd6r last accessed january andrada coos “data protection regulations middle east” endpoint protector middleeast last accessed january nagla rizk personal data protection law came effect august step encourage technologyrelated business guaranteeing data protection67 investors fol low data protection legislation home country offers data protection foreign investors remains seen legislation serves protect data country’s homegrown businesses said challenge access data coming absence political wil regimes serve block filter data use data citizen sur veil ance clearly issues privacy feature possible col ateral damage data monitored third parties conflict exist user data state private sector drafting ridesharing legislation egypt major point contention ridesharing companies uber egyptian govern ment revolved around data regulations authorities requests pertaining access storage data collected uber met objections resulted delay passing legislation68 wel enabling environment ai inclusion would benefit clearly defined ai strategies clear vision inclusion equality strategy would include clear stipulation safety nets potential harmed ai biases well anticipated disruptions labor market would part “social contract” comes along fourth industrial revolution69 uae ai strategy tunisia egypt drafted strategies announced later infrastructure issues integral component discussion ai inequality infrastructure infrastructure plays along several axes among uneven access data storage computing capacity limited internet connectivity host issues related algorithms intertwined human context first ai applications necessitate massive volume data hundreds terabytes need accommodated stored processed managed via technical infrastructures computing power resources70 need access massive data storage com puting power infrastructure amazon’s cloud computing software nasa’s mohamed toorani eamon holley “bahrain publishes personal data protection law” dla piper httpswwwdlapipercomenbahraininsightspublications201809bahrainpublishes personaldataprotectionlaw last accessed january ahmed megahid “egyptian parliament approves bill regulating ridesharing apps” arab weekly may httpsthearabweeklycomegyptianparliamentapprovesbillregulatingride sharingapps last accessed january “dialogue series new economic social frontiers shaping new economy fourth industrial revolution” world economic forum httpswww3weforumorgdocswef dialogueseriesonneweconomicandsocialfrontierspdf last accessed january “open data management plan mena region” mena data platform http menadatanetpublicdataset81539516969 last accessed january artificial intelligence inequality middle east open stack71 barrier contribute market inequality available rent payperuse basis cost may prohibitive lower end scale72 additional cloud service may restrict user vendor’s specific pack ages wel clients object data stored cloud73 indeed complaints startups region need data storage com puter power capacity well met74 availability massive data centers com puting power capacity richer countries region like uae could widen regional divide however argue availability cloud option data storage com puting mitigates inequality provides affordable alternative start ups “to scale services grow rather requiring upfront investment infrastructure sunk cost”as wel cloud offers platform internet required components process development ai done offline76 stil usage cloud necessitates strong connectivity data upload training machine dissemination ai enabled applications services espe cial national scale77 wel stronger internet connection certainly ensure efficient seamless synchronization data upload development algorithms ai applications countries stronger connectivity stand lead race ai deployment addition succinct unpacking ai infrastructures impact inclusion looks beyond algorithm human context surrounds different layers ai infrastructures unleash aspects social political contexts cleverly termed “black boxes within black boxes”these include organizational structures trade secrecy way “labor practices untraceable global supply chains rare earth minerals used build consumer ai devices”inequality inherent algorithms dangerous invisible dormant serving amplify biases data humans ground like else mena region algorithms likely developed implemented jects” including marginalized groups subjects algorithms william bryan “openstack cloud computing platform” nasa httpswwwnasagov officesoct40yearsofnasaspinoffopenstackcloudcomputingplatform last accessed january sherif el kassas “ai inequalities” interview nagla rizk march ahmed abaza “ai inequalities” interview nagla rizk april id ashraf abdelwahab hossam sharara “ai inequalities” interviews nagla rizk april nouri sadek “ai inequalities” interview nagla rizk april sadek abdelwahab interviews nagla rizk april ai report ai institute new york university httpsainowinstituteorgainow 2018reportpdf last accessed january id id nagla rizk crucial process developing algorithm gap even larger algorithm taken open source platform like google open source algorithms product coming completely different contexts applied generical local context existing multilayered multifaceted inequality81 additional ai algorithms magnify bias missing significant portion population cause “allocative harms”where people denied services opportunities example merq egyptian startup launched chatbot facebook named sal introduces people credit card systems arabic83 chatbot arabic may seem context specific still exclusive –percent egyptians bank accounts reflecting social reality historical mistrust banks percent egyptians access internet facebook credit rating algorithms may include alternative data neighborhoods magnify socioeconomic differences embedded data bias84 another lock inherent trade secrets algorithm usual held corpora tions thirdparty vendors another black box intellectual content saved privileged mena region likely users producers content hence denied access secrets opaque part ai supply chain algorithms also part bigger political context even algorithm may tech nical sound fair used means harmful ends85 biases inherent facial recognition algorithms example likely exacerbate discrimination tools may offer yet clout regimes new forms surveil ance example israeli security forces’ use facial recognition software control entry alaqsa mosque less favored palestinians metal detectors back fears technology likely used them86 human resource challenge region rich human resources abundance young formally educated youth nevertheless structural market imbalances coupled inadequate skill development shape human resources challenges faced region ahmed abaza “ai inequalities” interview nagla rizk april ai report zubair naeem paracha “egypt’s merq raises sixfigure seed sal facebook chatbot lets users compare credit cards” menabytes april httpswwwmenabytescomegypt merqsee last accessed january ahmed abaza “ai inequalities” interview nagla rizk april ai report amjad iraqi “palestinians reviving agency jerusalem” magazine july httpswww972magcompalestiniansarerevivingtheiragencyinjerusalem rebecca stead httpswwwmiddleeastmonitorcom20180716rememberingisraelsmovetoinstallmetaldetectors atalaqsa last accessed january artificial intelligence inequality middle east advent ai technologies job losses likely amplify already existing labor market imbalances specifical structural unemployment caused insufficient job opportu nities local decisions use “labourenabling” rather “labourreplacing”tech nologies may subject political social factors especial countries youth unemployment political instability rampant elsewhere world risk job loss due automation likely occur mediumskill level skill structure employment countries region show middleskill cohort highest almost half percent work activities egypt susceptible automation adapting currently available technologies88 typical include outsourcing call centers currently accounting direct jobs89 also true highincome countries region like uae percent susceptible90 job loss lack jobs environment unemployment youth educated resulted many educated youth considering new technologybased work opportunities ridesharing becomes example technology based labor opportunities respond positively unemployment counter usual concern technology contributing labor crisis automation far ideal research shown ridesharing egypt allows favorable option prevalent informal work even formal counterparts offer little true health pension benefits91 respondents indicated ridesharing allowed livelihood flexibility offered opportunities engage new technologies adding skill sets potential women work ridesharing offered new opportunities livelihood along safety empowerment92 demand ai economy dire need acquisition new skil skill retraining data science problemsolving digital skil lay chuah norman loayza achim schmillen “the future work race with—not against—the machine” august httpsfowigsnetfutureworkracenotmachine last accessed january michael chui james manyika mehdi miremadi “the countries least likely affected automation” harvard business review april httpshbrorg201704 thecountriesmostandleastlikelytobeaffectedbyautomation last accessed january “the future jobs skil middle east north africa preparing region fourth industrial revolution” world economic forum httpswwwweforumorgreports thefutureofjobsandskil sinthemiddleeastandnorthafricapreparingtheregionforthe fourthindustrialrevolution last accessed january id nagla rizk “a glimpse sharing economy analysis uber driverpartners egypt” social science research network httpspapersssrncomsol3paperscfmabstract id2946083 last accessed january nagla rizk nancy salem nadine weheba “a gendered analysis ridesharing perspectives cairo egypt” urban transport sharing economy era col aborative cities ed fernando bercovich buenos aires center implementation public policies promoting equity growth httpwww cippecorgwpcontentuploads201809urbantransportcompletowebcippecpdf last accessed march nagla rizk needed workers expected displaced ai becomes prevalent93 skil also needed education general data capacities found lacking region’s school curricula specific data science courses outside business contexts found also scarce94 middleincome countries within region homogenous regards workers’ skill sets egypt uae jordan saudi arabia leading way highskilled employment percent labor force considered high skilled95 additional countries also high digital skil com puter skil basic coding digital reading albeit superseded saudi arabia including tunisia96 indeed five countries top source countries one hundred startups chosen world economic forum lead fourth industrial revolution region97 final challenge facing human capital region labor retention local level labor turnover startups join lucrative work larger companies source inequality smaller startups bigger players98 big corporations information technology sector attract top tier talent better pay promises reallocation exposure global markets internal widens market gap large companies startups also take place regional international level local capacities migrate laborabundant middleincome countries like egypt tunisia global north oilrich countries like uae saudi arabia100 migrating businesses however managed keep back offices region given low labor operating costs helps retain skil train young employees102 rays hope despite challenges threaten widen inequalities region remain rays hope first comes growing youth entrepreneurial scene many homegrown startups businesses flourished since uprisings local organic grounds initiatives including small businesses startups carry “artificial intelligence africa opportunity growth development democratisation” access partnership httpswwwaccesspartnershipcomartificialintelligencefor africaanopportunityforgrowthdevelopmentanddemocratisation last accessed january abed khooli “harnessing economic power data middle east north africa “the future jobs skil middle east north africa” global competitiveness report world economic forum october httpswwwweforum orgreportstheglobalcompetitvenessreport2018 last accessed january world economic forum “meet arab startups shaping fourth industrial revolution” httpswidgetsweforumorgarabstartups last accessed march ahmed abaza “ai inequalities” interview nagla rizk april sameh saleh “ai inequalities” interview nagla rizk april jazem halioui “ai inequalities” interview nagla rizk february sherif el kassas “ai inequalities” interview nagla rizk march ahmed abaza “ai inequalities” interview nagla rizk april artificial intelligence inequality middle east promise human development empowerment use possibly production digital technologies ai exception entrepreneurial mindset carries potential novel ways data collection deploying ai solutions link ages serve developmental purposes target inclusion mitigating inequality within hope youth region’s human capital portrays promise foundation basic educational attainment countries tertiary degree holders meet global average percent bahrain saudi arabia egypt countries like jordan achieved near universal basic education103 wel almost half tertiaryeducated individuals region hold degrees science technology engineering mathematics specialize engineering manufacturing construction lesser extent information communication technologies natural sciences mathematics statistics104 also estimated region expand tertiary talent pool percent105 managed wisely region’s human capital serve asset next new phase second ray hope comes focus novel data collection methodologies result accurate reflections realities provide new data source ai way data sets longer controlled select increased availability open data data driven innovation particular profit nonprofit using different technologies data layering cause hope notable examples business civil society academia across region collecting making use innovative sources data innova tunisia106 tunisian based startup uses sentiment analysis data gathered social media online platforms analyze media portrayals gender inequalities harassmap egyptian nonprofit online application allows people mainly women share incidents harassment triangulates crowd sourced data making readily accessible107 research initiatives undertaken within mena founding node open data development108 utilized innovative data collection using affordable censors assemble data combination opensourced crowdsourced existing govern ment data one initiative assessed level safety mobility accessibility reliabil ity transport cairo109 second created heat map black carbon pollution cairo110 another undertaken lebanon researchers created “the future jobs skil middle east north africa” id id “who are” webradar httpwebradarmewhoweare last accessed january “sexual harassment greater cairo effectiveness crowdsourced data” idrc harassmap httpswwwacademiaedu23012454towardsasafercitysexualharassment ingreatercairoeffectivenessofcrowdsourceddata last accessed january access knowledge development center american university cairo school business httpsbusinessaucegypteduresearchcentersa2k4d access knowledge development center american university cairo sets egypt “urban mobility cairo” mena data platform httpmenadatanetpublicproject3 “developing air quality heat map cairo citizencentric approach” mena data platform httpmenadatanetpublicdataset21539400046 last accessed january nagla rizk information policymakers111 wel researchers birzeit university palestine developed data literacy capacitybuilding modules collecting data sets via pol ution sensors ramal ah monitor air quality around schools112 third ray hope comes initiatives taken governments region use ai inclusion building human capital albeit still modest examples uae using ai tuberculosis diagnosis training educating students government employees ai113 egypt data collected within initia tive million healthy lives initiative aimed “at screening citizens age determine prevalence hepatitis c obesity chronic diseases like diabe tes hypertension” data crucial hepatitis disease pervasive percent population diagnosed hepatitis c linked national id insurance possibly health data national data set provide better health services country’s nationals hoped data set founda tion better health services using inclusive ai conclusion ai mena—inclusion inequality discourse ai inequality region intertwined unique political economic social context dynamics ai impact inclusion inequality embedded region’s complexities also sit heart set inherent tensions like elsewhere major tension region lies paradox capacity technology concurrently produce conflicting trends triggering opposite comes like digital technologies ai potential producing dynamics push power away center periphery centrifugal forces function “health system eye” knowledge policy centre american university beirut http wwwhealthsystemeyecom last accessed january abed khooli “tracking air quality iot sensors publishing open data mena” opendataabedkhooli last accessed january samer abu ltaif “ai readiness beyond empowering people achieve more” icrosoft news center middle east africa httpsnewsmicrosoftcomenxm20190201 aireadinessin2019andbeyondempoweringourpeopletoachievemore last accessed january ismail sebugwaawo “include artificial intelligence school curricula say experts” khaleej times july httpswwwkhaleejtimescomnationabudhabiincludeartificialintelligencein schoolcurriculasayexperts last accessed january “million egyptians screened hepatitis c part new campaign” ahram online egyptiansscreenedforhepatitiscasparaspx last accessed january artificial intelligence inequality middle east economic political fronts serve empower small players mitigate inequality paradoxical opposite force also simultaneously triggered ai empower already established hierarchies centripetal forces come expense small players clearly widen inequalities ten sion global becomes pronounced region light weak institutions nascent legislative machinery topdown hierarchies technology creation dissemination mean ownership data opaque black boxes technology locked large companies typical large multinational corporations import technology directly comes tension inclusive local developed technologies solutions adapted local cultures responsive marginalized communities divide creation ownership technology widens internal divide large small entities region also allows large companies acquire smaller ones enhances market concentration example recent acquisition local ridesharing company careem uber early similar scenario occurs political scene tensions persist estab lished political regimes versus opposing citizen voices organic movements seeking inclusion democracy ai technologies groundsup data collection potential serve means citizen empowerment control data ai tools furthering power already established regimes examples include use citizen data surveil ance facial recognition technologies oppressive purposes relates tension well noted arab countries early first arab knowledge report116 focus promoting economic growth expense political inclusion al region characterized expanding economic freedoms generously civil liberties concentrating solely eco nomic “openness” typical intended attract foreign direct investment targets multinational large corporations ends feeding centripetal forces referred earlier shows clearly debate open data access information promoting inclusion citizens decisionmaking enabling environment using data ai good necessitates integrated set freedoms promote comprehen sive paradigm openness culture sharing data core expanding civil liberties related enabling environment data openness inclusive citizens general small businesses innovators particular focus economy alone also meant condition technological determinism accompanying threat decontextualization present context would translate investing solely ai technologies belief provide solutions il related blind belief algorithm disregard sociopolitical context surrounding technology “towards productive intercommunication knowledge” arab knowledge report httpswwwundporgcontentdamrbasreportahdrakr2009engfullreportpdf last accessed january nagla rizk context part “fairness” solutions solely technical technical solutions decontextualized sound unbiased ai system may al appropriate particular socioeconomic political context117 political issues framed solely technical ones according ai report appropriateness efficacy ai system altogether interrogation institutional context ‘fixed’ ai system ultimately applied”investing technology may necessary sufficient achieve inclusion indeed investment solely technology serve exacerbate divides matched investment organizational change including human resources119 broadly ai inclusive needs holistic approach120 ai technology development ensure inclusion region’s human capital active participants new economy also investment region’s political stability interrelated tensions highlight ai serve concurrent trends economy empowering established well new entrants underline gap focus economic political exemplify investment technology alone without enabling environment would fail achieve desired objectives specifical topdown approach focuses expert technocratic solutions issues affect human lives ones involve participatory approaches aggravate divides exclusion underprivileged marginalized together tensions inform debate ai inequality awareness helps mitigate challenges threats ai would exacer bate inequality region acknowledgments author grateful research support team access knowledge development center a2k4d american university cairo’s school business nadine weheba nagham el houssamy nancy salem provided seminal insights various stages research author indebted hana shaltout farah ghazal dana elbashbishy dedicated research assistance special thanks due center’s long time col aborator lina attalah inspiration valuable editorial input ai report id erik brynjolfsson andrew mcafee “creative destruction economics accelerating technology disappearing jobs” race machine digital revolution accelerating innovation driving productivity irreversibly transforming employment economy digital frontier press –erik brynjolfsson et al “artificial intelligence modern productivity paradox clash expectations statistics” national bureau economic research national bureau economic research httpswwwnberorgchaptersc14007pdf last accessed january artificial intelligence inequality middle east bibliography now2018reportpdf last modified december changing reality” un development programme httparabhdrorgreports2016 2016aspx last accessed january arezki rabah et al “a new economy middle east north africa” world bank group middle east north africa economic monitor httpsopenknowledgeworldbankorg bitstreamhandle10986304369781464813672pdfsequence11isallowedy last accessed january access partnership httpswwwaccesspartnershipcomartificialintelligenceforafricaan opportunityforgrowthdevelopmentanddemocratisation last accessed january brynjolfsson erik et al “artificial intelligence modern productivity paradox clash expectations statistics” national bureau economic research httpswww nberorgchaptersc14007pdf last accessed january chui michael james manyika mehdi miremadi “the countries least likely affected automation” harvard business review april httpshbr org201704thecountriesmostandleastlikelytobeaffectedbyautomation last accessed january fourth industrial revolution” world economic forum httpwww3weforumorg docswefdialogueseriesonneweconomicandsocialfrontierspdf last accessed january fourth industrial revolution” world economic forum httpswwwweforum orgreportsthefutureofjobsandskil sinthemiddleeastandnorthafricapreparing theregionforthefourthindustrialrevolution last accessed january gordon michael “forecasting instability case arab spring limitations socioeconomic data” wilson center httpswwwwilsoncenterorgarticleforecasting instabilitythecasethearabspringandthelimitationssocioeconomicdata last accessed january rizk nagla youmna hashem nancy salem “open data management plan middle east north africa guide” mena data platform httpmenadatanetresourcesdatasets 1539516976open20data20management20planpdf last accessed january chapter europe toward policy framework trustworthy ai andrea renda introduction strong emphasis fundamental rights commitment toward sustainable development proregulatory stance visàvis large tech giants europe inevita bly peculiar testing ground policies related artificial intelligence ai compared occurred united states china european union discussion possible regulation ai initial characterized rather dystopian state ments incipit european parliament’s resolution “civil law rules robotics”went far evoking mary shelley’s frankenstein ended calling attributing legal personality well “rights duties” smart autonomous robots idea immediately firmly rejected several academics2 resolution also called european commission reflect creation possible agency ai europe step european commission found premature time may coming age soon explained chapter european parliament ep resolution february recommendations commission civil law rules robotics 20152103inl see open letter european commission artificial intelligence robotics httpsg8fip1kplyr33r3krz5b97d1wpenginenetdnasslcomwpcontentuploads201804 roboticsopenletterpdf andrea renda despite overly negative narrative initiative european parliament merit place ai radar eu policymakers remained since one year later context midterm review eu digital single market strategy council eu invited commission put forward european approach ai3 commission started pave way evolving multistakeholder ethical adherent ambitious policy framework recently president european commission –ursula von der leyen committed adopting “a coordinated european approach human ethical implications artificial intelligence” first one hundred days presidency4 rather unprecedented commitment political leader shows ai become key political dossier potential strategic terms competitive ness standpoint sustainable development however developing fullfledged strategy human ethical implications ai going easy eu institutions one hand europe certainly worldleading region comes setting rules emerging technologies dem onstrated ia adoption general data protection regulation gdpr entered force may expansive use competition rules including state aids counter emerging power large tech giants general europe rely solid legal system fundamental human rights deeply rooted subject specific jurisdiction dedicated court neighboring area risk regulation europe advanced thanks combination precaution experimentation although constitutional endorsed application precau tionary principle denounced many potential hindering innovation5 hand many commentators observed european countries lagging behind levels public private investment ai related technologies observed countries specifical europe traditional lagged behind united states terms private expenditure rd particularly true platform applications layers internet many widespread ai applications deployed potential private invest ment found background surprisingly european leaders decided ground strategy two complementary pil ars definition implementation ambi tious ethical framework ai “made europe” increase public private investment ai improve competitiveness european union crucial domain two pil ars complementary since commission explained stepping investment research capacity ai besides promoting competitive eu institutions european economic social committee also published communications artificial intelligence member states started develop strategies ursula von der leyen “a union strives agenda europe” political guidelines next european commission –see inspiring view jb wiener “the real pattern precaution” reality precaution comparing risk regulation united states europe ed jonathan b wiener michael rogers james k hammitt peter h sand washington dc rff –europe toward policy framework trustworthy ai ness also strengthens europe’s credibility global norm leader space overal europe appears determined revive ai domain approach followed gdpr places fundamental right data protection forefront concession datahungry ai techniques machine learning matter fact gdpr promotes “data minimization” approach applies extraterritorial anyone processes personal data belonging european citizens regardless location6 blueprint translated concrete strategy since april european commission launched communication “artificial intelligence europe”the document adopted positive narrative ai compared european parliament’s initial resolution laid foundations comprehensive ai strategy clarifying main elements intended eu’s “secret sauce ai” main assumption behind eu strategy europe “can lead way devel oping using ai good al building values strengths” key challenge european commission ongoing proliferation national strat egies many member states adopted ai strategies potential cre ating risk fragmentation avoid risk european commission member states jointly adopted coordinated plan december setting ambitious goal “maximise impact investments eu national levels encourage syner gies cooperation across eu exchange best practices collectively define way forward ensure eu whole compete global y” plan aims ia stimulating investment €billion per year throughout next decade encom passing public private sources funding strong focus ethics european union’s ai strategy thus seen context overall strategy aims protecting citizens civil society abuses digital technology also part competitivenessoriented strategy aimed raising standards access europe’s wealthy single market con text one peculiar steps european union’s strategy creation independent highlevel expert group ai ai hleg accompanied launch ai alliance quickly attracted several hundred participants july ai hleg multistakeholder group counting fiftytwo experts tasked definition ethics guidelines final adopted april well extraterritorial impact gdpr given extensive generous interpretation courts dataprotection authorities recently confirmed european data protection supervisor guidelines territorial scope gdpr see andrea renda regulation irc chal enges posed digital transformation report oecd regulatory policy committee forthcoming september communication commission european parliament european council council european economic social committee committee regions—artificial intelligence europe com2018 final communication commission european parliament european council council european economic social committee committee regions— coordinated plan artificial intelligence com2018 final andrea renda formulation “policy investment recommendations” saw light june eu ethics guidelines trustworthy artificial intelligence key challenges ai hleg reach consensus among fiftytwo members independent experts academics whereas others represent vested interests9 go beyond mere enunciation ethical principles ai already spelled international organizations corporations civil society even internal advisory body european commission crowded space ai hleg tried identify ethical principles could made operational fore providing ai designers developers users tool could promote real alignment ai systems ethical values focus ethics soon appeared narrow especial respect legal system already incorporates ethical princi ples umbrel treaty provisions established case law well eu horizontal sectoral legislation moreover discussion within ai hleg soon veered need foster development ai systems european users could find reliable thereby worthy trust need restore sufficient levels reliability trust interaction digital technologies emerged critical need europe especial emergence scandals cambridge analytica10 publication first draft ethics guidelines december followed rapid stakeholder consultation need adopt broader approach ethical alignment emerged clearly european stakeholders called institutions focus “hard ethics” intended compliance ethics “soft ethics” postcom pliance ethics11 opinions also showing mounting fear ai systems however ethical aligned could become easily prey cyberattacks external manipulation also due emerging ai techniques generative adversarial networks proved able develop scary emulations reality known “deep fakes” nutshel european stakeholders seem place trust ethics ethical alignment part overall trustworthiness ai systems see composition ai hleg httpseceuropaeudigitalsinglemarketenhighlevel expertgroupartificialintelligence accessed july cambridge analytica data scandal emerged early revealed cambridge analytica apolitical dataanalysis firm harvested personal data millions facebook users without consent used political advertising purposes see luciano floridi “soft ethics governance digital” philosophy technology europe toward policy framework trustworthy ai hence final version “ethics guidelines trustworthy ai” guidelines goes beyond ethical aligned ai evoking combination three different elements compliance legal rules alignment wellspecified ethical principles trust ai systems belief law ethics needed cases two may even clash example existing legislation reflect technological developments ends forcing market players engage unethical behavior whereas cases complementary ie ethics help interpreting law recommend behavior directly required man dated law quote oxford professor luciano floridi “the law provides rules game indicate play well according rules”legal compliance ethical alignment sociotechnical robustness three pillars trustworthy ai legal dimension entered scope ethics guidelines remained define meant compliance matter fact compliance legal rules merely necessarily imply mere adherence eu legislation even eu treaties ai hleg rather offering detailed explanation applicable rules observes humancentric approach ai requires full compliance fundamental rights independently whether explicitly protected eu treaties13 charter fundamental rights eu fundamental rights ai hleg recal protect individuals certain degree groups virtue moral status human beings independently legal force key foundations legal compliance also alignment ai systems ethical principles even latter binding detail rights centered respect dignity humans subjects “objects sifted sorted scored herded conditioned manipulated” respect right selfdetermination including freedom expression control one’s life respect democracy justice rule law respect equality nondiscrimination solidarity implies ai systems generate unfairly biased outputs especial detriment “workers women persons disabilities ethnic minorities children consumers others risk exclusion” respect citizens’ rights right vote right good administration access public documents right petition administration see luciano floridi “establishing rules building trustworthy ai” nature machine intelligence comment vol june –the european union based constitutional commitment protect fundamental indivisible rights human beings ensure respect rule law foster democratic freedom promote common good rights reflected articles treaty european union charter fundamental rights european union andrea renda moreover eu ethics guidelines identify four key ethical principles defined ethical “imperatives” trustworthy ai significant smaller number com pared preexisting documents setting ethical principles ai example eu level european group ethics science new technologies ege inde pendent advisory body president european commission identified nine principles14 four ethical “imperatives” defined ai hleg respect human autonomy prevention harm fairness explicability see following subsection “four ethical ‘imperatives’ ai” importantly contrary typical occurs consolidated fields bioethics list include impera tive “do good” socalled “beneficence” principle included early drafts guidelines four ethical imperatives selected ai hleg appear common identified similar documents produced developer community national government corporations international organizations specification could expected ended significantly overlapping enunciation fundamental rights final sociotechnical robustness element superficial dealt ethics guidelines focus mostly ethics stil ai hleg observed trustworthy ai needs legal compliant ethical adherent also ai systems cause unintentional harm” essential component trustwor thiness technical perspective ensuring system’s technical robustness appropriate given context application domain lifecycle phase social perspective due consideration context environment system operates robustness requirements also covered legislation combination performancebased legislation stan dards line european union’s approach standardization15 shown later chapter technical robustness safety ended listed also key ethical requirements somehow complicating confusing logical structure document identification three pil ars accompanied proposal create mandatory framework trustworthy ai eu level rather trustworthy ai remains “aspirational goal” words ai hleg specifical legal compliance inevitably mandatory technical robustness whenever rooted legislative regulatory provisions contrary explained following detail ethical alignment social robustness require flexible see european group ethics science new technologies statement artificial intel igence robotics “autonomous” systems march httpseceuropaeuinfonews ethicsartificialintelligencestatementegereleased2018apr24en ege group listed key ethical principles human dignity autonomy responsibility justice equity solidarity democracy rule law accountability security safety bodily mental integrity data protection privacy sustainability see jacques pelkmans “the new approach technical harmonisation standardisation” journal common market studies vol xxv march –europe toward policy framework trustworthy ai approach triggers behavior proportionate risk harm ai system likely generate four ethical “imperatives” ai number critical elements surface analysis four ethical imperatives put forward guidelines first requirement respect human autonomy points need humancentric design principles allocation functions humans ai systems requirement specified leaving meaningful opportunity human choice securing human oversight work processes ai systems critical question whether provision would apply ai systems way age predictive maintenance internet things let alone autonomous vehicles often need take decisions splitsecond requiring con stant manmachine cooperation may become disproportionate utterly inefficient contrary purpose ai system deployed ai hleg ended refining requirement human oversight distinguishing later document cases human must “in” loop cases human “on” loop cases human “in command”the ai hleg clarifies also alternative options come embedded tradeoff extensive testing stricter governance required” turn suggests human oversight accountability intimately linked discussion prevention harm makes explicit mention precau tionary principle contrary european parliament advocated means standard use deciding whether given ai system considered harmful clarified ethics guidelines explained later detail given ai hleg subsequent document containing “policy invest ment recommendations” moreover “fairness” requirement refers substan tive notion need equal distribution benefits costs opportunity protecting individuals’ freedom choice respecting “the principle pro portionality means ends” procedural standpoint offer ing possibility effective redress decisions made ai systems humans operating ai hleg claims requires entity accountable hitl refers capability human intervention every decision cycle system many cases neither possible desirable hotl refers capability human intervention design cycle system monitoring system’s operation hic refers capability oversee overall activity ai system including broader economic societal legal ethical impact ability decide use system particular situation include decision use ai system particular situation establish levels human discretion use system ensure ability override decision made system andrea renda decision identifiable decisionmaking processes explicable led fourth perhaps controversial “imperative” principle explicability ai systems extent invoking full explicability ai systems decisions could jeop ardize use ai techniques deep learning reinforcement learning algorithms choose actions ways often obscure even developers however ai hleg clarified “the degree explicability needed highly dependent context severity consequences output erroneous otherwise inaccurate” circumstances lack explicability may become grounds rejecting ethical grounds use nonexpli cable ai cases use may considered ethical adherent subject first principle described earlier entails form human oversight general ai hleg also acknowledged tensions may arise four ethical principles generical advocated democratic engagement methods accountable deliberation address tensions coupled reasoned evidencebased reflection rather intuition random discretion sure combined effect principles even considered merely “aspirational goal” constitutes important reference ai developers deployers potential paves way articulate policy framework principles requirements partial address indeterminacy ethical principles well tensions ai hleg went describing seven requirements ai systems comply order defined “trustworthy” requirements end repeating greater level detail concepts already put forward description fundamental rights well ethical imperatives first requirement respect human autonomy protection funda mental rights ai hleg specifies risk harming fundamental rights exists fundamental rights impact assessment undertaken prior development ai systems include consideration possible mitigating mea sures mechanisms receive external feedback protection human agency finds specification right make informed autonomous decisions regarding ai systems right subject decision based solely automated process ing produces legal effects users similarly significantly affects another key requirement technical robustness safety ai systems features twice guidelines third pil ar trustworthy ai one seven requirements requirement technical robustness safety imply ai systems developed preventative approach risks manner reliably behave intended minimizing unintentional unexpected harm preventing unacceptable harm addition requirement entails physi cal mental integrity humans ensured ai systems secure resilient europe toward policy framework trustworthy ai attack include fal back plan case problems also general requirement accuracy rather translates obligation disclose likely inaccuracy system especial ai system directly affects human lives potential links transparency accountability requirements specified detail later final robustness implies also reliability reproducibility system’s results another potential critical aspect trustworthy ai may prove neutral respect available ai techniques guidelines observe key elements principle prevention harm protection privacy europe considered fundamental right con trary occurs many legal systems17 adequate data governance cov ers quality integrity data used provisions quite extensive require extreme attention definition access personal data implementation gdpr’s data minimization explicit consent principles trustworthy ai systems must transparent line principle explicability heading ai hleg includes traceability ie documenting data gathering labeling well algorithms used decisions made best possible standard explainability however guidelines acknowledge tradeoffs might made enhancing system’s explainability accuracy ai hleg goes beyond gdpr observing ai trustwor thy right meaningful explanation timely adapted expertise stakeholder concerned eg layperson regulator researcher foreseen ever ai system significant impact people’s lives requirement also implies ai systems identifiable humans informed nonhuman nature ai interfaces system’s capabilities limitations level accuracy ai system expect guidelines include among key requirements respect diversity absence undue discrimination principle fairness requirements appear farreaching imply inclusion diversity enabled con sidered throughout entire ai system’s life cycle besides consideration involvement affected stakeholders throughout process also entails ensur ing equal access inclusive design well equal treatment whenever possible developers hired diverse backgrounds cultures disciplines ensure diversity opinions principle fairness entails data sets used ai systems training operation adequately checked risk inclusion inadvertent historic bias incompleteness bad governance models understanding biases could lead unintended indirect prejudice discrimination certain groups people potential exacerbating prejudice marginalization besides forms unintentional bias ai hleg also cautions intentional exploitation consumer biases algorithmic see andrea renda “cloud privacy law united states european union” regulating cloud policy computing infrastructure ed cristopher yoo jeanfrancois blanchette cambridge mit press andrea renda restrictions competition homogenization prices means col usion nontransparent market18 overal trustworthy ai system biases countered constant monitoring oversight aimed analyzing addressing system’s purpose constraints requirements decisions clear transparent manner besides adequate checks biases unfair discriminatory outcomes trustworthy ai also requires usercentricity universal accessibility depending use case particularly businesstoconsumer b2c contexts users put condition use ai products services regardless age gender abilities characteristics complying requirements likely affected stake holders consulted throughout process feedback regularly solicited ai hleg however goes beyond humancentric ai paves way albeit tim idly also planetcentric approach among requirements part principle prevention harm guidelines also include respect “other sentient beings environment” explicitly encourages ai fosters achievement sustainable development goals including also future generations human beings among ones considered “preventative approach” guide ai development deployment among corol aries requirement also critical examination resource usage energy consumption general environmental friendliness ai system’s entire supply chain another provision potential leaves techniques deep learning rather controversial spot19 beyond environment social impacts also adequately men tioned ranging alteration social agency patterns social relationships possible impacts people’s physical mental wellbeing possible risks democratic process appears allencompassing requirement ai hleg also specifies trustworthy ai must come proportionate degree accountability goes way beyond simple attitude “state mind” requires adequate governance mecha nisms auditability algorithms strengthened case ai systems affect fundamental rights identification reporting proactive mitigation negative impacts ai systems transparent rational treatment tradeoffs measures aimed ensuring adequate redress considered among farreaching distinctive requirements put forward guidelines trustworthy ai ideal inspired ethical principles desire “do harm” throughout process development deployment ai practitioners willing hit aspirational goal trustworthy ai also take action regularly detect mitigate harms offering prompt redress affected users trust ai hleg suggests requires adequate governance see european union agency fundamental rights “bigdata discrimination data supported decision making” httpfraeuropaeuenpublication2018bigdata discrimination see karen hao “training single ai model emit much carbon five cars lifetimes” mit technology review june europe toward policy framework trustworthy ai ai system placed market also adequate attention existing users future users society environment whole hence ai becomes tantamount dangerous activity legal sense goal trustworthy ai likely trigger definition strict liability framework damages caused ai systems may well see possibilities exemptions appears far standard fault based regime one applied torts operationalizing trustworthy ai assessment framework guidelines limit already remarkable attempt specify overall framework trustworthy ai corresponding ethical principles associated requirements perhaps innovative feature document stands compared existing ethical ai frameworks ai hleg’s attempt operationalize requirement detailed assessment framework composed questions presented first draft may constitute guide selfassessment alignment individual ai systems trustworthy ai principles admittedly framework included guidelines rather unrefined perhaps lengthy awkward attempt guide practitioners list questions prompts ai practitioners potential risks negative impacts asking whether ful considered procedures place mitigate way types conducts would appropriate specific use cases existence list marks transition pure enunciation ethical principles toward concrete implementation trustworthy ai terms policies standards ultimately rules importantly acknowledging preliminary nature list ai hleg also kickstarted ambitious piloting phase relies three main initiatives taken second half first detailed survey made available website ai alliance potential available stakeholders second group elicited expressions interest various stakeholders conducted fifty assessment list third order involve also civil society piloting process ai hleg started organizing series sectoral workshops collect opin ions feedback “list” workshops take place early ultimate outcome extensive piloting phase revision assessment list completed ai hleg first half revision may entail addition tailoring list specific use cases development additional guidance legal compliance also including sectoral legislation appropriate well address specific risks ad hoc procedures andrea renda “policy investment recommendations” trustworthy ai selected aspects guidelines received overal warm welcome policymakers inside outside europe well large small companies civil society however document ai hleg specified frontier aspirational goal without dis cussing whether trustworthy ai become concrete policy objective european commission latter specified outset preferred path toward ethical adherent ai one selfregulation rather rush regulate largely unknown subject matter however reflection shape policy framework could trigger convergence toward trustworthy ai led something call selfregulation second deliverable ai hleg dedicated policy investment recommendations offers numerous insights trustworthy ai framework could translated concrete policies document rich encompassing broad range topics research innovation future work modernization government purposes chapter recommendations relate operationalization ethical framework described alone shows entire legal system making respect first perhaps important recommendation ai hleg adopt riskbased policy framework implies accountability liability elements ethics guidelines translated legal regime holds practitioners responsible assessing managing evaluating risk creating society develop deploy ai system risk obviously depend use case specific context ai system deployed means level “diligence” required change case case accord ingly silver bullet legal rule able address problem liability risk “unacceptable” potential consequences catastrophic ai hleg suggests reverting precautionary principle hence avoid deploying spe cific ai system scientific evidence sheds light issue however unclear acceptable unacceptable risks singled similar contexts legal systems seek address problem reconciling innovation precaution agile forms policymaking standardization even caselaw indeed ai hleg shies away excessively prescriptive regulation calling instead principlesbased approach however case ai may prove problematic due breathtaking pace change products lems risk create placed market interacting human beings even interacting algorithms case called “flash crashes” occurred fields algorithmic trading cer tainly case autonomous vehicles europe toward policy framework trustworthy ai result ai hleg also called european commission consider establishment “institutional structure” could help collect spread best practices agile way judges standards lawmakers normal able whether take form agency original invoked european parliament already board case gdpr institutional variant specified ai hleg considered european commission months come decide follow recommendation international examples starting proliferate even absence wellshaped legal system centre data ethics united kingdom similar authorities france germany proposed institutional structure vision ai hleg perform wide range functions including contribution european union’s framework policy trustworthy ai ensuring ai lawful ethical robust advising eu institutions supporting imple mentation framework providing guidance stakeholders assisting application riskbased approach classifying risks acceptable unacceptable coordinating standardssetting organizations eu member states hosting repository best practices raising awareness among stakeholders policy makers evolving landscape ai meets eye ai hleg recommendations example ethics guidelines criticized taking soft stance socalled “red lines” ai applications subject outright ban guidelines despite initial indication redlines ai hleg limited identifying “areas critical concern” including mass surveil ance widespread social credit scoring lethal autonomous weapons laws second document group cal commission consider new regulation ensure individuals subject “unjustified personal physical mental tracking identification profiling nudging ai powered methods biometric recognition emotional tracking empathic media dna iris behavioural identification affect recognition voice facial recognition recognition microexpressions” adding exceptional example case pressing national security stances appli cations would allowed “evidence based necessary proportionate well respectful fundamental rights” importantly ai hleg cal international moratorium development offensive laws proposal new commission president also former german minister defense certainly consider due attention furthermore policy investment recommendations also contain explicit call considering making trustworthy ai assessment ie assessment list refined mandatory ai systems deployed private sector potential significant impact human lives example interfer ing individual’s fundamental rights stage ai system’s life cycle safetycritical applications based statement seems clear ai hleg consider trustworthy ai simply aspirational goal rather founda tion whol new riskbased legal system unacceptable risks subject andrea renda precautionary principle critical applications potentially impinge fundamental rights subject mandatory assessment consequences recommendation become clear time matter fact already mentioned assessment list accompanied scoring system threshold would allow differentiation trustworthy systems nontrustworthy ones commission follow recommendation form certification scoring become inevitable significant consequences ai market europe interestingly recommendation also extends mandating “critical” ai systems ensure appropriate “by default” “by design” procedures enable effective immediate redress case mistakes harms andor rights infringement practical implementation actual contours proposed obligation however unclear “effective immediate” types mistakes would qualify relevant purposes rule final world designed ai hleg children would subject particu lar attention ai hleg proposes eu legislators introduce legal age children receive “clean data slate” public private storage data related children cal european commission monitor development personalized ai systems built children’s profiles ensure alignment fundamental rights democracy rule law general ai hleg cal european commission establish european strategy better safer ai children designed empower children also protecting risks harm what’s next putting european union’s ai ambitions test past two years marked unprecedented acceleration eu strategy digital technologies general ai particular rather competing arm’s length united states china european union tempted perspective dancing different drummer mix strategic autonomy digital sov ereignty relatively strict rules data protection competition unfair commercial practices possibly ambitious plan set ethical rules ai home abroad result came surprise new president european commission placed policy human ethical consequences ai top list promising first steps already first one hundred days presidency european commission convince member states move forward introduce ambitious policy framework artificial intelligence along lines recommended ai hleg would become game changer global level several reasons explained introduction chapter ongoing “digital cold war” united states china leaving space european union play europe toward policy framework trustworthy ai leading role ethical ai help likeminded countries like canada japan backed internal france one first countries focus internal ai strategy sustainability mission vil ani order ful play role european union however show sufficient cohesion ambition support proposed creation intergovernmental panel ai currently meets opposition big superpowers perhaps even importantly international relations european union focus sustainable development establish cooperation agreements maximize uptake ai solutions aligned trustworthy ai principles second order become world leader ethical ai europe must first homework properly going easy european union may end tionism particular imposing data localization working toward develop ment european infrastructure connectivity hand leadership ai convince commentators believe relatively strict regula tory framework ai obstacles data collection processing hamper innovation matter fact academic literature amply demonstrated welldesigned regulation good innovation aligns incentives innovators public interest welldesigned regulation inevitably require adequate governance lie next steps new president european commission may decide take toward creation institution groups european union national level involves industry civil society working toward creation unique environment ethics better trustworthiness remains core ai investment deployment civil society constantly involved critical deci sions acceptable uses ai new developments powerful family techniques observed analyzed interpreted lens trustworthy ai way europe could succeed superpowers currently failing rather asking states ai pursuing many applications ai contribute global good bibliography cath corinne sandra wachter brandt mittelstadt mariarosaria taddeo luciano floridi “artificial intelligence ‘good society’ us eu uk approach” science engineering ethics –european commission joint research centre artificial intel igence european perspective flagship report ai brussels european commission european commission communication commission european parliament european council council european economic social committee committee regions—coordinated plan artificial intelligence com2018 final december brussels european commission andrea renda european commission staff working document liability emerging digital technologies accompanying document communication commission european parliament european council council european economic social committee committee regions “artificial intelligence europe” swd2018137 final april brussels european commission european group ethics ege “statement artificial intelligence robotics brussels european commission floridi l j cowls beltrametti r chatila p chazerand v dignum c luetge r madelin u pagallo f rossi b schafer p valcke e vayena “ai4people white paper twenty recommendations ethical framework good ai society” minds machines –floridi luciano “establishing rules building trustworthy ai” nature machine intel igence comment vol june –high level expert group ai set european commission ethics guidelines trustworthy ai brussels european commission high level expert group ai set european commission policy investment recommendations trustworthy ai brussels european commission renda andrea artificial intel igence ethics governance policy chal enges ceps monograph brussels ceps renda andrea “the trolley problem selfdriving cars crimescene investigation ethics algorithms” ceps policy insight—no brussels ceps p r v cases applications chapter ethics artificial intelligence transport bryant walker smith introduction almost everything world involves transport implicates ethics invites automation simple phone cal example either constitutes transport electrons infor mation displaces transport people physical messages raises ethical questions allocation resources loss facetoface communication fal somewhere along spectrum automation computer certainly operator possibly caller recipient given broad scope single chapter could even survey ethics artificial intelligence transport limitation obviates need precise definitions three operative terms chapter coarsely assumes places selves provide resolve uncertainty using experience popular example potential application artificial intelligence transport automated driving principal focus chapter automated driving systems currently development artificial intelligence plays important roles bryant walker smith correctly perceiving safely navigating complex environments true automation systems ground well air water moreover tools use artificial intelligence are—or likely be—equal critical designing assessing monitoring automation systems words transport products services may involve artificial intelligence foreground background artificial intelligence may replace supplement challenge constrain empower users transport systems also developers operators regulators particular data collection analysis artificial intelligence facilitates likely impact every aspect transport planning logistics emergency response example socalled transportation network companies uberx lyft already rely combination human machine intelligence distribute motor vehicles across areas service drivers wait expect profitable demand materialize based intuition well information incentives provided algorithms used companies even automated vehicles never materialize development algorithms might lower wait times drivers riders reduce deadheading enable multiplepassenger trips progress—whether technology policy—necessarily involves replac ing old set problems new set problems hoping aggregate new problems less old ones wit cars replaced pol ution horse pol ution internal combustion engine ethics important making monitoring predictions ethical issues however necessarily prevent development deployment new technologies important point obscured typical presentation ethical issues “obstacles” innovation rather choices implemented else abdicated crude ethical objections impede technologies way animals road impede trucks although gentler among us indeed try avoid others either case morbidly termed “obstacles” likely slow momentum numerous prominent enough make moving forward especial messy ethics transport moving metaphor value ascribe lives sentient—though far still natural—creatures whether obstacles workhorses chattel—is one example myriad ethical issues always accompanied transport core transport reflects choice move rather stay put—to interact invade escape transport innovations unlock new realms—under water air space—but making movement faster cheaper easier nicer safer ethics artificial intelligence transport cleaner ethics help determine whether assertions correct impacts international intergenerational uncertain included alongside local immediate uncontroverted comparing environmental performance fuels ethics also help determine whether aims desirable faster missiles necessarily better transport professionals responsible many concrete decisions involving explicit implicit ethical considerations consider one mode ground transport motor vehicles designed privilege safety occupants safety pedestrians fact unlike european union american definition crashwor thiness even account nonoccupants1 choice extends design american infrastructure wide lanes forgiving drivers daunting pedestrians breakaway traffic poles shift risks inside wayward vehicle outside it3 larger heavier vehicles impose risks smaller lighter vehicles—and increased emissions everyone else fatalities pol ution general considered part roadway safety measured primarily crash injuries fatalities fatalities have—at least recently—declined per kilometer basis part safety technologies5 yet design systems privileges averagesize male others6 moreover many technologies—in design absence—prioritize autonomy driver motor vehicles alcohol ignition locks meaningful speed limiters ontario trucker even per suaded lower court later overturned appeal speed governor would infringe fundamental right security restricting ability speed safety critical situation7 moreover almost motor vehicle trips treated equal worth physical world “net neutrality” means exceptions bil board advertising truck joyrider doctor way hospital bus full passen gers equal claim congested roadway long paragraph could much longer—and many others could follow example legal social battles african american civil rights movement often involved transport including congress’s law demanding reenslavement escaped north8 supreme court’s approval state laws usc § ttip—car safety analysis eu us relation us eu regulatory standards crash testing httptradeeceuropaeudoclibdocs2016septembertradoc154981pdf manual uniform traffic control devices section 2a19 httpsmutcdfhwadotgov us federal highway administration frequently asked questions breakaway sign luminaire supports httpssafetyfhwadotgovroadwaydeptcountermeasuresfaqsqabslscfm us national highway traffic safety administration traffic safety facts httpscdannhtsagov tsftablestsfarhtm caroline criado perez invisible women exposing data bias world designed men new york abrams r v michaud onca httpwwwontariocourtscadecisions20152015onca0585htm fugitive slave act stat httpsavalonlawyaleedu19thcenturyfugitiveasp bryant walker smith excluding african americans “whiteonly” train cars9 montgomery black community’s –boycott discriminatory bus system use opposition busing tool school desegregation takeaways ethics always belonged transport many ethical issues remain unresolved artificial intelligence another chapter story one might—but probably won’t—read much better status quo far perfect artificial intelligence could ameliorate exacerbate highlight obscure many ethical issues well introduce new ones entirely case automated driving take automated driving many ethical issues implicated shift human drivers chapter considers four automated driving technological solution policy solution consequences safety expectations human authority versus computer authority changing power dynamics technological solution policy solution commuters would attest today’s ground transport system far ideal cars long marketed united states epitome freedom go want want suvs take even freeing imagination owners constraint actual roads yet many ways individual motor vehicle ownership liberating environment built primarily vehicles free cannot drive cannot afford drive free stuck traffic jam motorist stuck trying cross street pedestrian free must inhale vehicles emit free dead motor vehicle crash automated driving panacea problems human driving could help important ways automated vehicles could serve cannot drive could unlock efficiencies transport system ridesharing could plessy v ferguson us httpswwwoyezorgcases1850–1900163us537 ethics artificial intelligence transport reduce individual trip costs expected much safer conventional vehicles—if reason expectation viewed light automated vehicles represent critical technological solution tantamount new medicine cure one many diseases automated driving therefore becomes imperative promoted public policy barriers must removed incentives must offered world one traffic fatality every twentythree seconds10 delay quite literal means death yet policymakers public truly concerned problems motor vehicle solutions could implemented—not day today higher fuel taxes fees based directly distance traveled congestion pricing internalize costs motor vehicle travel support extensive public transit systems alcohol ignition locks speed limiters vehicles automated enforcement roads meaningful vehicle inspections emissions safety holistic systems approach safety vehicles roads road users indeed countries achieved dramatical safer roads others consider four highincome countries perkilometer basis driving united states percent deadlier australia canada—and twice deadly united kingdom united states looks even worse per capita basis driving twice deadly australia canada thrice deadly united kingdom11 see figure many complicated factors contribute reported differences level united states chooses let people die roads aggressively embracing automated driving technological solution—if solution—to roadway safety could exacerbate social problems driving simply automating today’s system motor vehicle transport might encourage even road deaths per billion vehicle km road deaths per inhabitants united states australia canada united kingdom united states australia canada united kingdom figure road deaths united states australia canada united kingdom world health organization road traffic deaths httpswwwwhointghoroadsafety mortalityen international transport forum road safety annual report uk department transport transport statistics great britain httpsassetspublishing servicegovukgovernmentuploadssystemuploadsattachmentdatafile664323tsgb2017print readyversionpdf bryant walker smith travel sprawl13 discourage active mobility use traditional mass transit empower constituencies oppose raising cost reducing convenience personal vehicle ownership use true advent automated driving marks dramatic inflection point—a choice mobility heaven mobility hel —where certain policies might suddenly stand snowbal ’s chance political realities might continue immunize million conventional vehicles united states extensive automated enforcement meaningful maintenance requirements new taxes fees political limitations yet exist approximately zero automated vehicles currently country indeed developers may facing increasingly uncertain political winds viewed light automated vehicles represent technological solution instead critical policy solution development offers unique opportunity rev olutionize policy alongside technology words policy advocates may able achieve automated driving alone cannot achieve conventional driving driving opportunity may even justify policy unintentional slows technology—by example making automated vehicles expensive conventional counterparts thereby discouraging adoption tension two views strategic dilemma matter life death also ethical quandary given widely acknowledged imperfect status quo exploit automated driving technological solution policy solution respect transport policy expecta tions automated conventional driving expect one achieve outcomes lowering raising current expec tations motor vehicle transport discussions civil liability crashes involving automated vehicles il ustrate— complicate—this tension united states notable shifts tort law last one hundred years left deep fault lines contentious battle lines speaking roughly much twentieth century saw theoretical expansion tort law general product liability specifical well practical expansion insurance general automotive insurance specifical y—albeit different degrees differ ent states beginning 1980s socalled tort reform movement began success ful push pendulum direction—again different degrees different states time many states declined keep automotive insurance minimums line inflation vehicle manufacturers accordingly became attractive defen dants even product liability lawsuits became expensive litigate reasons better worse status quo rather messy enter automated driving view automated driving technological solu tion tend inquire could encouraged changes tort law—whether bryant walker smith “managing autonomous transportation demand” santa clara law review httpsssrncomabstract2303907 robin chase “will world driverless cars heaven hell” citylab apr httpswwwcitylabcomtransportation201404willworlddriverlesscarsbeheavenorhell8784 ethics artificial intelligence transport changes seek advantage automated driving remove perceived advantage conventional driving extend perceived advantage automated driving contrast view automated driving policy solution tend approach potential catalyst broader changes want see tort law—whether involve expanding liability limiting liability case proposed changes may subtle dramatic whereas academic proposals would dramatical replace reinvent tort law automated vehicles companies developing automated driving systems notably circumspect us states key actors automotive industry initially push often successfully legislative grants immunity case thirdparty modifications production vehicles federal level key auto mated driving developers tended favor ambiguous legislative language potential preempting tort claims disfavor language limiting use binding arbitration general however priorities companies tend suggest disinterest either associating automated driving tort reform drafting one service relative modesty perhaps companies concluded others15 existing tort law messy nonetheless familiar ultimately tolerable perhaps wary opening cans worms could wriggle far beyond control perhaps waiting know want political power achieve perhaps want make needless opponents automated driving perhaps understand dissonance one hand promising safety asking trust hand promising destruction asking immunity perhaps see automated driving technological solution ultimately best way reduce liability reduce injury consequences safety expectations given automated driving whol eliminate roadway deaths injuries safe safe enough—and safety demonstrated questions certainly important ethical context rich recklessness caution bring death18 predictive however may preempt much philosophical kyle graham “of frightened horses autonomous vehicles tort law assimilation innovations” santa clara law review httpsdigitalcommonslawscuedulawreview vol52iss44 bryant walker smith “automated driving product liability” michigan state law review httpsssrncomabstract2923240 mark geistfeld “a roadmap autonomous vehicles state tort liability automobile insurance federal safety regulation” california law review httpsscholarship lawberkeleyeducalifornialawreviewvol105iss62 nidhi kalra david g groves “the enemy good estimating cost waiting nearly perfect automated vehicles” httpswwwrandorgpubsresearchreportsrr2150html bryant walker smith automated vehicles deployed commercial extraordinarily dangerous risks pose users bystanders worst commensurate posed many human activities including human driving would go even concerned automated driving terrified human driving surprising tragic failures part findable fixable massive systemwide anomaly—such cyberattack shuts every automated vehicle hurricane evacuation—is important caveat also one applies modern life general crashes occur retrospective expectations safety largely apparent least matter law automated driving system unreasonably dangerous less safe human performing maneuver less safe com parable automated driving system third point debatable safer last automated driving system failed company responsible unreasonably dangerous automated driving system likely civil liable—but civil liability moral culpability indeed vehicle manufacturer liable injury caused defect safety system legal obligation install even defect still prevents far harm causes leaves prospective expectations safety safe must automated vehicle deployment prospective safety mean reasonable confidence devel oper vehicle worthy trust19 part one—not even developer—will able prospectively determine precise level safety also safety single metric ascertained single test properly conceived safety ongoing process begins product development continues product disposal among many facets encompasses corpo rate governance design philosophy hiring supervision evaluation integration standards monitoring updating communication disclosure planning eventual obsolescence way safety marriage rather wedding company develops deploys automated driving system necessarily promise explicitly implicitly system reasonably safe promise credible based thorough safety case draws diverse expertise acknowledges technical ethical uncertainties safety case interrogated may well disproved inability disprove affirmative proof given funda mental policy question whether company makes promise worthy public trust socalled trolley problem merits passing mention20 unfortunately highly stylized question die automated vehicle finds ostensibly unavoidable crash often posited paramount—if bryant walker smith “the trustworthy company” forthcoming httpsnewlypossibleorg philippa foot “the problem abortion doctrine double effect” oxford review judith j thomson “killing letting die trolley problem” monist –ethics artificial intelligence transport only—ethical issue raised automated driving neither22 hypothetical crashes far inevitable outcomes far certain predicate deci sions necessarily situational nonetheless two related ethical insights important first human driving automated driving entail risks—that potential harms given probability given magnitude risks human driving familiar risks automated driving remain largely speculative ethics help supply values quantify compare knowns unknowns second corol ary question decision make ultimately authority decide human authority versus computer authority epitomized conflict dave hal space odyssey24 tension human computer authority present today become pro nounced future consider two actual transport examples attacker hijacked truck berlin killed driver drove crowded christmas market truck struck dozens came stop within rela tively short meters investigators attributed truck’s automatic emergency braking system25 two boeing max passenger planes crashed case appears pilots fought unsuccessful malfunctioning automation sys tem repeatedly pushed nose plane downward26 examples il ustrate choice may implicate philosophy much engi neering humans computers ultimate authority given action answer might crudely characterized choice security safety even proxy basic goodness humanity course complicated example bryant walker smith “the trolley pinto costbenefit analysis automated driving cyberphysical systems” texas law review httpsssrncom abstract2983000 heather roff fol trol eys ethical chal enges autonomous vehicles dec httpswwwbrookingseduresearchthefol yoftrolleysethicalchallengesandautonomousvehicles “a space odyssey ” httpswwwimdbcomtitlett0062622 hans leyendecker georg mascolo nicolas richter “lkwbremssystem verhinderte noch mehr tote berlin” süddeutsche zeitung december httpswwwsueddeutschedepolitik terroranschlaglkwbremssystemverhindertenochmehrtoteinberlin13312551 republic indonesia komite nasional keselamatan transportasi knkt preliminary knkt18103504 aircraft accident investigation report httpsreportsaviationsafetynet 2018201810290b38mpklqppreliminarypdf federal democratic republic ethiopia ministry transport aircraft investigation bureau aircraft accident investigation preliminary report ai0119 httpsflightsafetyorg wpcontentuploads201904preliminaryreportb737800maxetavjpdf bryant walker smith copilot flight relied one aviation security technology—the “cockpit door locking system”—in murdering everyone plane28 conversely modern elevators essential trap passengers based part belief trying escape usual dangerous waiting emergency personnel29 many discussions automated driving give question decisionmaking author ity cursory attention30 example sae j3016 prominent technical document defines levels driving automation focuses much complementary roles human user driving automation system conflicts two roles reconciled31 single table merely notes descriptive matter driving automation systems “disengage immediately upon driver request” levels “may delay userrequested disengagement” levels even descriptively dichotomy may turn entirely correct exam ple combination automation connectivity may allow motor vehicles particu larly large trucks travel together closely spaced platoons following distances may close human drivers safely manage platooning system—which may initial operate level —might ful disengage achieves appropriate vehicle spacing analogously advanced crash avoidance sys tem would technical classifiable levels driving automation might override driver inputs seconds fractions second engages overreaction underreaction panicked uncertain driver cause otherwise preventable crash visceral may matter much technical whatever explanations inci dents sudden unintended acceleration motor vehicles scary part represent loss authority cars speed even drivers want slow opposite condition—the deliberate use technology limit speeds—can also engender strong feelings noted previously ontario truck driver argued provincial law requiring speed regulators commercial trucks violated right security person canadian charter rights freedoms32 persuaded one court losing twice appeal key ethical question whether individual human authority—even potential cost lives—is value belongs technical analysis harm human could prevented somehow outweigh harm human caused france bureau d’enquêtes et d’analyses pour la sécurité de l’aviation civile final report bea20150125 httpswwwbeaaerouploadstxelydbrapportsbea20150125enlrpdf schindler elevator corporation emergency operation elevator systems httpswww schindlercomcontentdamwebuspdfssafetyelevatoremergencyoperationpdf bryant walker smith “lawyers engineers speak robot language” robot law httpswwwelgaronlinecomview978178347672500011xml sae international sae j3016 taxonomy definitions terms related driving automation systems onroad motor vehicles httpswwwsaeorgstandardscontent j3016201806 r v michaud onca httpwwwontariocourtscadecisions20152015onca0585htm ethics artificial intelligence transport conversely harm caused malevolently somehow outweigh harm caused innocently negligently33 short think human autonomy changing power dynamics humans computers relevant actors governments companies— acting human agents computer agents—play fundamental roles deployment regulation artificial intelligence transport important consequences power dynamics public domain consider example law enforcement hypothetical world com panies operate large networks automated vehicles assume vehicles sensors computers transmitters enable meaningful collection extensive information environments inside outside assume vehicles designed general comply rules road widespread compliance rules road could dramatical reduce traffic stops—twenty million annual y34—that along crashes account interactions law enforcement public united states35 rather simply disappear however enforcement activity likely shift—in least four ways first traditional officers may focus activities physical domain driving addition conventional human drivers bicyclists scooter riders mass transit riders pedestrians may receive even scrutiny people entering exiting waiting automated vehicles may also targets enforcement laws either specific ridesharing general application loitering applied however dubiously wide range conduct second even law enforcement may shift digital realm loss traffic stops primary means randomly discriminatorily scanning public may used justify—in practice policy law—more electronic surveil ance new tech nologies may also used extend reach physical surveil ance vehicles themselves—and make surveil ance far ubiquitous semirandom traf fic stops could ever achieve perfect enforcement ideal third police departments may cooperate private operators automated vehicle networks—in sky well ground companies might alert law curtis w copeland “how agencies monetize ‘statistical lives’ expected saved regulations” congressional research service httpsdigitallibraryunteduark67531 metadc812693m21highresdr411402010mar24pdf stanford open policing project “findings” httpsopenpolicingstanfordedufindings elizabeth davis anthony whyde lynn langton “contacts police public ” us department justice special report ncj httpswwwbjsgovcontentpub pdfcpp15pdf bryant walker smith enforcement potential illegal activity inside outside vehicles might willingly begrudgingly provide access data realtime sensor feeds behavioral predictions devoid supporting data fourth companies may simply conduct enforcement without involv ing public sector shopping mal generations ago marked shift public private space offer precedent dispute resolution systems credit card providers airlines social networking platforms digital commerce plat forms implemented—and pragmatic legal reasons often act judge jury executioner one hypothetical future pedestrians may enjoy much greater confidence vehi cles stop rather strike many ways would welcome shift longer would people need wait unsignalized crosswalks cars trucks unlaw ful careen them—or run across frantical confidence could even return neighborhood street bustling center human activity—the woonerf—that horses cars came dominate pedestrians may bring confidence larger thoroughfares way unlawful disrupts flow safety motor vehicle traffic course person crosses front properly functioning automated vehicle vehicle make reasonable efforts stop—and traveling speed likely make efforts successful much engineering ethics story unlikely end automated vehicle likely record interaction multitude sensors using artificial intelligence recognize face gait pattern company behind automated vehicle may identify interloper internal acceptable level confidence perhaps share evidence law enforcement perhaps decline involve public authority favor simply banning person automated vehicles—or myriad physical digital services partners provide—in future many loss commercial transport package delivery social media may much deterrent public fine jaywalking way others automated driving may change nature public private personal space may good bad neutral—though certainly mixed change appraised depends implementation also ethical inputs value privacy—or fundamental autonomy value social interaction even expense independence appropriate roles public private sectors governments companies individuals stand point triangle proper allocation power among technological legal economic reasons many questions likely addressed probably indirectly higher levels government many us states municipalities regulate taxis transportation network companies likely true automated equivalents similarly federal motor vehicle standards even mere possibility standards yet enacted likely displace traditional state authority driving—authority general exercised regulation human drivers ethics artificial intelligence transport centralization may mixed wel one hand best automated vehicle deployments likely come partnerships communities developers— partnerships require empowered rather disempowered communities hand powerful residential communities long contributed mobility injustice36 even defining community exercise ethics conclusion chapter concludes technologies millennium institutions—governments companies—of last one us congress considered automated driving legislation general supported many larger automated driving developers one version quickly passed house37 counterpart stalled eventual died senate38 immediate explanations numerous key senators slowed bil ’s momentum trial attorneys local governments became involved technological visions became grounded issues trade emissions preoccupied industry lobbyists everything else preoccupied congress fundamental however automated driving legislation failed pass lack trust technologies institutions influential senators wary automated driving technologies automated driving developers automated driving regulators without trust deference seemed imprudent trust largely empirical question numerous surveys purport measure public acceptance automated driving beyond senate surveys probably little predictive value public fickle words actions two powerful industries behind automated driving yet rev marketing engines neither broad support broad adoption necessary condition broad impact indeed contrary popular conception automated driving happen without new legislation39 contrast trustworthiness much ethical question automated vehicles driven individuals even computers driven companies acting human machine agents essential issue field—and artificial intelligence general y—is companies develop deploy technologies earn trust partnership southern equity opportunity deferred race transportation future metropolitan atlanta httpspsequityorguploads2019102017pseopportunitydeferredpdf self drive act hr httpswwwcongressgovbill115thcongresshousebill3388 av start act httpswwwcongressgovbill115thcongresssenatebill1885 bryant walker smith “congress’s automated driving bil less seem stanford center internet society” httpscyberlawstanfordedublog201710 congresse28099sautomateddrivingbil sarebothmoreandlesstheyseem bryant walker smith trustworthy company shares safety philosophy makes promise public keeps promise40 company shares safety philosophy says effect believe us” promise “we market reasonably believe safe candid limitations failures fail make right” keeps promise appropriately managing public expectations supervising life cycle product service mitigating harms promptly ful publicly transport technologies including certainly limited automated driving complex relationship ethical issues new old four highlighted here—the tension technological solutions policy solutions conse quences safety expectations complex choice human authority com puter authority impacts power dynamics among individuals governments companies others—merit thoughtful public discussion thoughtful discussion must informed informed must involve goodfaith expertise companies developing deploying technologies ethics like transport go get bibliography caro robert power broker robert moses rise fall new york knopf douma frank “using better serve diverse populations” report mndot –german federal ministry transport digital infrastructure report ethics commission automated connected driving httpswwwbmvide shareddocsenpublicationsreportethicscommissionautomatedandconnected drivingpdf kalra nidhi david g groves “the enemy good estimating cost waiting nearly perfect automated vehicles” rand corporation httpswwwrandorg pubsresearchreportsrr2150html rothstein richard color law forgotten history government segregated america new york liveright publishing corp sae international “sae j3016 taxonomy definitions terms related driving automation systems onroad motor vehicles” httpswwwsaeorgstandards contentj3016201806 smith bryant walker “how governments promote automated driving” new mexico law review httpssrncomabstract2749375 smith bryant walker “regulation risk inaction” autonomes fahren edited maurer j gerdes b lenz h winner –berliin springer httplink springercomchapter101007978366245854927 uniform law commission uniform automated operation vehicles act https wwwuniformlawsorgcommitteeaspxtitlehighlyautomatedvehicles bryant walker smith trustworthy company forthcoming httpsnewlypossibleorg ethics artificial intelligence transport united nations global forum road traffic safety wp1 resolution deployment highly ful automated vehicles road traffic ecetranswp1165 httpwwwuneceorgfileadmindamtransdoc2018wp1ecetranswp1165epdf united states department transportation “preparing future transportation automated vehicles ” httpswwwtransportationgovav3 chapter case ethical ai military jason scholz jai galliott introduction significant recent progress ai positively impacting everyday tasks well science medicine agriculture security finance law games even creative artistic expression nevertheless contend ethical grounds military operations immune progress automation artificial intelligence evident areas society example human rights watch stated killer robots—ful autonomous weapons could select engage targets without human intervention—could developed within years human rights watch harvard law school’s international human rights clinic ihrc believe revolutionary weapons would consistent international humanitarian law would increase risk death injury civilians armed conflict primary concern human rights watch ihrc impact ful autonomous weapons would protection civilians times war1 campaign stop killer robots operated consortium nongovernment interest groups echoes sentiment experts artificial intelligence wel science technology luminaries stephen hawking elon musk steve wozniak noam chomsky skype cofounder jaan tallinn google deepmind cofounder demis hassabis expressing problem website allowing life death decisions made machines crosses fundamental moral line autonomous robots would lack human judgment ability international human rights clinic “losing humanity case killer robots” harvard law school httpswwwhrworgsitesdefaultfilesreportsarms1112forupload00pdf jason scholz jai galliott understand context qualities necessary make complex ethical choices dynamic battlefield distinguish adequately soldiers civilians evaluate proportionality attack result ful autonomous weap ons would meet requirements laws war replacing human troops machines could make decision go war easier would shift burden armed conflict onto civilians use ful autonomous weap ons would create accountability gap clarity would legal responsible robot’s actions commander programmer manufacturer robot without accountability parties would less incentive ensure robots endanger civilians victims would left unsatisfied someone punished harm experienced2 acknowledge concerns underlying arguments typical admit shades grey many based mistaken assumptions role human agents development systems relevant systems control yet bold arguments anti–artificial intelligence luminaries interested nuanced argument begin rebalance relevant debate antiai rhetoric permitted dominate dialogue autono mous weapon systems said debate initial proceeded quite cautiously part states responsibility steering discussion basis understood seeking outlaw preemptive ban allowing certain advocate groups sway debate vacuum informed opinion given rise debate ever since heavily onesided meanwhile fears nonexistent sentient robots stalling debate halting technological progress one see news world faces pressing ethical humanitarian problems use existing weapons gun stolen police offi cer used kil guns used mass shootings vehicles used mow pedestri ans bombing religious site guidedbomb strike train bridge unexpected passenger train passes missile strike red cross facility latter might prevented using ai weapons autonomous systems general seem unreasonable question weapons advanced symbol recognition instance could embedded autonomous systems identify symbol red cross abort ordered strike3 similarly location protected sites religious significance schools hospitals might programmed weapons constrain actions guns prevented firing unauthorized user pointing human seem unreasonable question cannot ensconced international weapons review standards campaign stop killer robots “the solution” httpswwwstopkillerrobotsorg thesolution indeed introduced importance discussing questions brief elsewhere see jason scholz jai galliott “artificial intelligence weapons moral imperative minimal autonomy” us air force journal indopacific affairs –we also expanding technical feasibility minai including providing deployable formal model forthcoming book ceding humanity suny press case ethical ai military seek correct lopsided debate address concerns certain advocate groups case minimalist version ethical ai explaining blanket prohibition ai weapons bad idea “life” decisions could times made machines noted lambert scholz4 automobiles rival wars contributor human death yet automobile industry one leaders integrating automated decision makers vehicles much manufacturer’s motivation make auto mobiles safer hold motivation advocate similar application mili tary context simple il ustration along aforementioned lines serves il ustrate consider capability weapon recognize unexpected presence interna tional protection symbol—perhaps red cross red crescent red crystal—in defined target area abort otherwise unrestrained humanordered attack given significant advances visual machine learning last decade recogni tion systems technical feasible inspired vehicle automation ethical ai system purpose weapon inbuilt safety enhancements enabled application artificial intelligence develop safety argument weapons adapting guidelines ethics autonomous vehicles developed germany first wish make case ethical ai context options including impracticability regulation banning weaponized ai bad idea autonomous weapons—the primary systems enabled artificial intelligence—can serious dangerous tools wrong hands doubt fact abovementioned tech entrepreneurs signatories recent open letter united nations put autonomous weapons “can weapons terror weapons despots terrorists use innocent populations weapons hacked behave undesirable ways”but mean united nations ought proceed immediately implementation preventive ban development weaponized artificial intelligence signatories open letter urge one thing sometimes takes dangerous tools achieve worthy ends obvious case humanitarian interventions think rwandan genocide world simply stood nothing autonomous weapons capable discrimination relevant fighters available developed dale lambert jason scholz “a dialectic network centric warfare” proceedings 10th international command control research technology symposium iccrts maclean va june –the future life institute “an open letter united nations convention certain conventional weapons” httpsfutureoflifeorgautonomousweaponsopenletter2017 jason scholz jai galliott states would likely less averse engagement may looked way seems plausible costs humanitarian interventions purely monetary removed sometimes controversial nature weapons deployment foreign soil concerns hold regarding casualty aver sion would easier gain widespread support otherwise might otherwise moral sanctioned interventions6 make point general acknowledged ai technology tremendously beneficial already permeates lives ways people often notice often well placed able comprehend ful given pervasive presence virtual impossibility constraining softwareunderwritten technol ogy already public domain shortsighted perhaps even naive think artificial intelligence technology’s abuse prevented development autonomous weapons halted ban implemented likely consequence would development artificial intelligence–enabled weapons malicious nonstate statebased actors using existing technology worth bearing mind artificial intelligence weapons currently deployed developed states conduct military secu rity engagements broadly line international law public expectations said technology therefore accompanied robust safety mechanisms deployed appropriate zones given known limitations technology—for example sea rather urban conflict zones nefarious actors reason act constrained fashion exists effective enforcement regime hold actors responsible violations international law meaning prevailing autonomous future kind likely bleak consist technology minus existing safeguards fact may well take sophisticated discriminate autonomousweapons systems developed military forces around world currently process developing cases deploying effectively counter much cruder autonomous weapons would likely constructed reprogramming seemingly benign ai technology selfdriving car offtheshelf technologies “preventative” ban implemented developed states world together imperfect moral arbiter moral obligation develop new technologies partly basis responsibility collective population quell uprising crude technology seek harm many7 say consequence ban would deny use ai weapons countermeasure ai autonomous weapons world previously placed prohibitions possession use certain types weapons including chemical biological nuclear potential persistent unexploded ordnance cluster munitions landmines prohibition weapons prevented states nonstate actors developing india pakistan israel north korea developed nuclear weapons iran jai galliott military robots mapping moral landscape farnham uk ashgate id –the case ethical ai military actively developing nuclear weapons program moreover none nations possess nuclear weapons signatory treaty prohibition nuclear weapons9 nevertheless preventing nations nonstate actors acquiring nuclear weapons reasonably effective possible physical control access relatively difficulttoobtain materials required produce case ai autonomous weapons mate rials lacking code algorithms needed autonomous weapons many cases needed autonomous cars mobile phone apps one faces dual use definitional problem possible identify certain types code militarily useful ban construction autonomous weapons component technologies—many public domain— become available matter time nation states area states charged maintaining international order want find lagging behind blanket prohibition “ai weapons” would unintended conse quences due lack nuance building earlier discussion implications halting development ai distinction made regulation policy kinds ai could yield significant humanitarian benefits lack nuance also evident case chemical weapons example pepper spray tear gas chemical agent banned warfare chemical weapons convention making illegal use militaries except law enforcement denial tear gas military forces removes lessthanlethal option inventory could lead unnecessary use lethal force even responsible development often seen abhorrent weapons defended basis might prevent use deadly indiscriminate force moving along spectrum destructive weapons one finds land mines united states course never ratified ottawa treaty rather chose technological solution end use persistent land mines—land mines set selfdestruct deactivate predefined time period—making considerably less problematic used clearly demarcated confined zones korean demilitarized zone dmz10 choosing ratify ottawa treaty united states identified one form crude indiscriminate weapon hands moral scrupulous another weapon may limit need injurious weapons prevent use even deadly indiscriminate application force places like korean dmz alternatives might include options sensitive discrimination child either two decades future rod barton weapons detective inside story australia’s top weapons inspector alexander white matthew paterson “nuke kid town much treaty prohibition nuclear weapons actual change” pandora’s box –lorraine boissoneault “the historic innovation land mines—and we’ve struggled get rid them” smithsonian february httpswwwsmithsonianmagcominnovation historicinnovationlandminesandwhywevestruggledgetridthem180962276 jason scholz jai galliott militaryaged adult period defined hostility case modern land mines also need overcome another common notion behind ban revolves around overly optimistic view technology raises concerns regarding lack human control conception fails acknowledge long causal backstory institutional arrangements individual actors thousands little acts commission omission process design engineer ing development brought continue bring rise technologies long debate autonomous weapons framed primarily terms unlevel policies average citizen soldier programmer must forgiven assuming absolved moral responsibility wrongful harm autonomous weapons risk causing assumption false might prove disastrous individuals deal ai technology exercise due diligence every one us needs examine careful actions inac tions contributing potential dangers technology may integrated means say state intergovernmental agencies important role play wel rather emphasize poten tial dangers autonomous weapons mitigated ethic personal responsibility must promoted must reach way level individual decision maker start utmost importance begin tel ing richer complex story rise ai weapons—a story includes causal contributions decision makers levels see ethical ai would serve enhance accountability take one example ethical ai token technologies curtail accidental firings cases gun stolen used imme diately shoot people similar ai mechanism built military weapon ing even autonomous weapons degree human interaction life cycle technologies might also record events including time location every shot fired providing accountability point world large stockpiles weapons—bombs mines bul lets guns grenades mortars missiles—that inbuilt technical controls related conditions employed perhaps far frightening reality immediate humanitarian concern fictional scenario involving “killer robots” outofcontrol artificial intelligence munitions developed use militaries public general possess inbuilt safeguards prevent used unauthorized persons must remember military forces cannot afford precision weapons regularly legal justified defense state kill enemy combatants firearms bombs sometimes imprecise indiscriminate weapons yet military technology becomes increasingly capable yielding precise outcomes lower cost halting enemy without causing unnecessary suffering harm nearby situation moral philosophers international law might reconsider think best done lens ethical ai case ethical ai military ethical ai spectrum weapon ethical ai takes attack order input makes decision obey order assesses presence unexpected11 protected objects mean protected may include legal identified entities icrc marked objects persons hors de combat policyidentified entities specified rules engage ment recognize ends spectrum range easy difficult techno logical challenges ai12 mean progress toward ethical ai made immediately proposed technical model elsewhere clearly progress would constitute humanitarian enhancement lambert13 termed weapon systems ethical improvements “moral weapons” included mean “ful integrated humanmachine decision making” option “allowing machine times override human” ability assess decline targeting requests rules engagement violations deduced decisions override weapons logged subsequent accountability review term ethical ai rather moral ai avoid potential confusion moral responsibility mean imply weapons possess moral responsibility assert ai weapons likely banned regardless campaign efforts advocate critics general reject concept autonomous weapons might consider new concept reduce casualties current weapons address central concern humans losing control decision making warfare let us discern two ends spectrum ethical capability maximal benefit ensuring ethical obligatory lethal action taken even system engineers lesser system may recognized need possibility rele vant lethal action however maximal ethical robot requires extensive ethical engineering arkin’s “ethical governor” represents probably advanced proto type effort toward maximal system14 ethical governor provides assessment proposed lethal actions consistent laws war rules engagement maximal position apparent explanation operation one may argue adversaries know might “game” weapons posing cover “protection” known case accountable human override ethical weapon use term “unexpected” noting also besides act perfidy case use protected symbols possible consequences perpetrators may fact aid targeting would anomalies respect known red cross locations robert sparrow “robots respect assessing case autonomous weapon systems” ethics international affairs –dale lambert “ubiquitous command control” proceedings information decision control conference adelaide australia ieee –ronald arkin governing lethal behavior autonomous robots boca raton fl crc press jason scholz jai galliott constraint interpreter key part governor “the constraint application proc ess responsible reasoning active ethical constraints ensuring resulting behavior robot ethical permissible”that constraint system based complex deontic predicate logic evaluates proposed actions generated tactical reasoning engine system based equal complex data structure reasoning full scope ethical permissible possible conditions including general distinction combatants noncombatants proportionality unnecessary suffering rules engagement arkin describes hard problem contrast minai “ethical robot” still constraint driven system could oper ate without “ethical governor” proper need contain elementary suppres sor humangenerated lethal action would activate accordance much narrower set constraints may hard rather softcoded meaning far less system “interpretation” would required minai deals ethical imper missible thus assert certain specific conditions distinction proportionality protected conditions may assessed follows force “protected” things objects persons marked protected symbols red cross well protected locations recognizable protected behaviors desire parlay basic signs surrender including beacons potential hors de combat clearly noncomba tants noting course ai solutions range easy difficult— impossible—and continue improve along ai technologies level lawfully authorized determined sufficient meet military necessity minai three things ethical control augment conventional weapon attacked practical achievable state art ai techniques basic technical concept minai ethical weapon augmentation stand ard weapon control system weapon seeker may augmented sensors provides input ethical legal perceptionaction system system uses training data developed tested certified prior operation outputs decision state override target order generate alternate orders control system event world state satisfies minai conditions decision override intended divert weapon another target preoperationspecified failsafe location andor neutralize reduce payload effect accordingly ronald c arkin patrick ulam brittany duncan ethical governor constraining lethal action autonomous system fort belvoir va defense technical information center january httpsdoiorg1021236ada493563 case ethical ai military noteworthy minai always limited technical nature may moral desirable yield outcomes good possibly even better maxai range specific circumstances former never take active lethal nonlethal action harm protected persons infrastructure contrast maxai involves codification normative values rule sets interpretation wide range inputs application complex potential imperfect machine logic complex “algorithmic morality” potential desirable circumstances involves greater possibility actively introducing fatal errors particularly terms managing conflicts interests cognizant foregoing information suggestion terms meeting fundamental moral obligations humanity ethical justified develop minai systems ethical agency said system embedded machine thus technological mediated design engineering operational environment fewer steps removed human moral agency maxai system would suggest maxai development supererogatory sense may moral beneficial particular circumstances necessarily moral required may even demonstrated unethical technical feasibility minai distaste might argued moral desirability minai decrease near future ai underpinning maxai becomes robust move away rulebased basic neural network systems toward artificial general intelligence agi resources therefore dedicated development maximal “ethical robots” clear number algorithm success stories announced recent years across cognate disciplines much attention given ongoing development algorithms basis success alphago16 libratus17 systems competing best human go poker players winning made acquiring deep knowledge games life’s work result preliminary successes dra matic increase media reporting interest potential opportunities pitfal associated development ai accurate negatively impacted public perception ai fueling kind dystopian visions advanced campaign stop killer robots speculation superintelligence foreseeable horizon agi timelines realm twenty thirty years reflects success stories omitting david silver julian schrittwieser karen simonyan ioannis antonoglou aga huang arthur guez thomas hubert lucas baker matthew lai adrian bolton yutian chen “mastering game go without human knowledge” nature –noam brown tuomas sandholm “superhuman ai headsup nolimit poker libratus beats top professionals” science –jason scholz jai galliott discussion recent failures ai many undoubtedly go unreported commercial classification reasons microsoft’s tay ai bot machine learning chatbot learns interactions digital users one example18 short period operation tay developed “ego” “character” strongly sexual racialized ultimately withdrawn service facebook similar problems ai message chatbots assuming undesirable characteristics19 number autonomous road vehicles involved motor vehicle accidents relevant systems incapable handling scenario20 quality assurance practices failed factor events also known currently irresolvable problems complex neural networks successes ai mostly based bottomup sys tems learn well tight domains easily outperform humans scenarios based data structures correlations cannot match topdown rationalizing power human beings open domains road systems conflict zones systems risky environments require strict compliance laws regulations would difficult question interpret explain supervise control virtue fact deep learning systems cannot easily track “reasoning”just importantly intuitive therefore less explainable systems come wide operation may easy revert earlier stage systems human operators become reliant system make difficult decisions danger moral decisionmaking skil may deteriorated time22 event failure total system col apse could occur devastating consequences systems committed missioncritical operation required armed conflict moreover issues associated functional complexity practical computational limits imposed mobile systems need capable de pend ent operation event communications failure computers required agilevel systems may subject miniaturization simply may sufficiently powerful costeffective intended purpose especial military context rafal rzepka kenzi araki “the importance contextual knowledge artificial moral agents development” aaai spring symposium series north america httpswwwaaaiorg ocsindexphpssssss18paperview1754015376 erin griffith tom simonite “facebook’s virtual assistant dead chatbots” wired january httpswwwwiredcomstory facebooksvirtualassistantmisdeadsoarechatbots francesca favarò sky eurich nazanin nader “autonomous vehicles’ disengagements trends triggers regulatory limitations” accident analysis prevention –martin ciupa “is ai jeopardy need promise deliver—the case real useful machine learning” 4th int conf computer science information technology ed dhinaharan nagamalai et al aircc –jai galliott “the limits robotic solutions human challenges land domain” defence studies –jai galliott “defending australia digital age toward full spectrum defence” defence studies –the case ethical ai military autonomous weapons sometimes considered disposable platforms24 hope advocates agi computerprocessing power system compo nents continue become dramatical smaller cheaper powerful guarantee moore’s law supports expectations continue reign true without extensive progress field quantum computing maxai point time whether agi eventuate appears distant goal deliver potential result far guaranteed minai system hand seeks ensure obvious uncontroversial benefits artificial intelligence harnessed associated risks kept control normal military targeting processes action needs taken intercept grandiose visions may eventuate instead deliver positive result technology already exists code minai positive result minai also require finegrained guidance system’s implementation application human rights council un general assembly made recommendation developers lethal autonomous robots practice defining responsible behaviour respect lars”as starting point one might look similar codes related fields july german federal ministry transport digital infrastructure bundesministerium für verkehr und digitale infrastruktur bmvi appointed expert panel scientists legal experts serve national ethics committee autonomous vehicles26 year later made headlines issued “the world’s first ethical guidelines driverless cars”obviously automobiles designed weapons though kinetic energy ubiquity make least deadly practice automation raises number issues terms potential damage life property many normative questions arise result normative frameworks utilized answer said questions similar seem unreasonable take bmvi ethics code basis development analogous code ethical ai may justified consideration relevant prin ciples law armed conflict loac ciupa “ai jeopardy” christoph heyns report special rapporteur extrajudicial summary arbitrary executions ahrc2347 geneva united nations general assembly human rights council christoph leutge “the german ethics code automated connected driving” philosophy technology –david tuffley “at last world’s first ethical guidelines driverless cars” conversation driverlesscars83227 jason scholz jai galliott military necessity military operations use weapons requires said use produce military gains otherwise prohibited international humanitarian law28 bmvi code address issue since presumption automo biles right road purposes transport regardless transporting thus needs augmented part loac distinction ability distinguish civilian population combatants civilian objects military objectives accordingly direct operations military objectives29 case ethical weapons might identify protected symbols noncombatants surrendering persons persons hors de combat order accordingly ai technologies continue advance distinction used german automobile ethics code except priority human persons nonhuman persons ie animals case impending accident included loac proportionality armed conflict noncivilian casualties may justifiable certain circumstances long excessive relation anticipated military advantage il ustrated subject automotive trolley problem studies included german ethics guidelines30 much obliga tion military strategists avoid harm civilian populations customary ihl provides useful protections beyond merely justifying proportionality basis principle double effect including rule precautions attack rule applied following section ethical weapons german ethics code opens general remarks mission statement adapted follows ethical minai mission important decisions made concerning extent use ethical ai weapons required states record failing intervene new weapons technologies even would justified character justification employ ethical weapons could understood three ways first states capability capacity may obliged deploy ethical weapons hence face blame decide otherwise argument capabilities potential obligatory ethical weapons improve humanitarian outcomes reducing accidental deaths etc without impact military effectiveness international committee red cross declaration renouncing use time war explosive projectiles grammes weight saint petersburg international committee red cross geneva conventions additional protocols commentaries jeanfrancois bonnefon azim shariff iyad rahwan “the social dilemma autonomous vehicles” science –the case ethical ai military likely utilize technologies lowcost due commercial scale justification explained galliott31 second development deployment ethical ai could supererogatory sense would good state intervene ethical ai–enabled weapons particular circumstances ethical required third action could justified neither obligatory supererogatory use ethical ai weapons would ethical acceptable likely yield little benefit status quo suggest cases use ethical ai weap ons justified pursuit causes use either ethical obligatory supererogatory much hinges conditions used way designed fundamental level deployment decision reduced fundamental questions much dependence technological complex systems—based arti ficial intelligence machine learning—are willing accept order achieve return safety noncombatants safety military acting behalf society warrant protection better compliance laws armed conflict improved operational efficiency defeat ever improving adversary capabilities precautions needed ensure appropriate competency authority respon sibility technological development guidelines required ensure blur contours human society places trust military commanders freedom action physical intellectual integrity entitlement social respect heart legal regime follows propose fourteen principles guide development minai concept technical implementation adapted military context ethical guidelines purpose primary purpose ethical ai improve safety protected entities non combatants within law armed conflict rules engagement secondary purpose increase freedom maneuver military commanders thereby enabling ethical benefits positive balance risks objective reduce level harm within laws armed conflict ultimate goal zero unintended noncombatant casualties fog war means galliott military robots ch jason scholz jai galliott noncombatant casualties reality twentyfirstcentury warfare minimize toward zero ultimate aim made possible increasing intelligence weapons projectiles effectors kinds adoption ethical ai justifiable promises produce diminution harm human andor political capital comparison conventional weapons avoidance ethical dilemmas extent possible ethical ai prevent noncombatant harm within laws armed conflict wherever practical possible appropriate reduction operator involve ment might reduce risk posttraumatic stress disorder based state art technology designed way critical situations arise first place include dilemma situations ethical ai andor military commanders decide two “evils” perform context entire spectrum technological options used continuously evolved example limiting scope certain control able conditions military environments allowing weapon dynamical cognitively choose payload yield reduction maximum level authorized making payload inert performing weapon avoidance maneuvers producing signals advance warnings persons risk deferring strike alternate points opportunity time space significant enhancement noncombatant safety objective development regulation starting design programming ethical ai tracks defensive anticipatory manner posing little risk possible vulnerable noncombatants still achieving missions armed conflict shall managed mixed initiative agreements statutorily imposed obligation use ethical ai ethical questionable entails submission military commanders technological imperatives prohibition degrading humans subservient elements autonomous network dynamic recorded mixedinitiative agreements humans machines shall subsume hierarchical humanonly command arrange ments ethical ai primacy human life situations prove unavoidable despite technological precautions taken protection humans enjoys priority balancing interests compared damage animals property case ethical ai military military commanders decide sacrifice specific lives ethical ai execute targeting according processes approved military command ers compliance laws armed conflict rules engagement machines minimize innocent casualties event situations death innocent people unavoidable ethical ai shall seek minimize casualties among innocent people military commanders developers defense departments accountable ethical weapons military commanders throughout network command remain accountable use ethical ai ethical ai systems log protocol exchange ethical ai military personnel well critical weapon status knowledge provide accountability postaction review perspectives accountability com manders developers defense departments whole security ethical weapons ethical ai justifiable extent conceivable attacks particular manipu lation information technologies relies upon innate system weaknesses result harm undermine confidence military ethical ai awareness recording responsibility transfers must possible clearly distinguish whether ethical ai system used accountability lies comes option overruling system humanmachine interface must designed clearly regulated appar ent authority competency responsibility lies especial responsibility control distribution responsibilities thus accountability instance regard time access arrangements reliably recorded stored applies especial humantotechnology handover procedures human offtheloop software technology associated ethical ai must designed need abrupt handover control military commanders minimized enable jason scholz jai galliott efficient reliable secure humanmachine communication prevent overload systems adapt human communicative behavior possible rather requiring humans enhance adaptive capabilities communication human appropriately abstracted sufficiently timely feasible noting humanintheloop give way humanontheloop humanofftheloop relationships periods time machine selflearning considerations learning systems selflearning training operation connection scenario databases may allowed extent generate safety gains selflearning systems must deployed unless meet safety requirements ethical ai undermine guidelines fail safe management situations protected marked objects unanticipated noncombatants present ethical ai must autonomously ie without direct human intervention enter “safe condition” identification constitutes safe conditions weapon dis posal recovery planning handover routines required prior ethical ai use may include means control machine place weapon location minimal human impact neutralize explosives weapon example use separated chemical components warhead design diffused prevent future ignition exploitation reduce weapon kinetic energy damage military education training proper use ethical ai form part military commanders’ general education proper handling ethical ai taught appropriate manner training teams commanders ethical ai tested capability certification potential consequences minai concerns may raised minai functionality adopted use military forces technology may result negative positive unintended longterm conse quences might conscious notoriously difficult pre dict technology use easy question answer consider important cases study case ethical ai military complacency responsibility transfer one possible negative affect related human complacency consider hypothesis regard use take less care targeting process leading deaths” response argument would apply equal uses technology targeting process clearly however technology critical enabler intelligence targeting functions complacency seems matter adequate discipline appropriate education training system design32 less desirable outcome would operators abdicate responsibilities targeting campaigners attempted argue creation “responsibility gap” autonomous weapons might resurface application minai sys tem consider hypothesis “if minai technology works well trusted commanders might well authorize weapon release highest possible explosive payload account worst case rely minai reduce yield according whatever situation system finds case leading deaths” response argument assert would like treating minai weapon system maxai weapon system advocate maxai weapons minai weapon reduce explosive payload ai control substitute target analysis last line defense unintended harm com mander would remain responsible result regardless lawful scheme weapon misused machine gun used soldier combat deployed civilian school shooting discipline education training remain critical responsible use weapons denying availability surrender technology combatants machinerecognizable surrender system developed would militaries want issue beacons soldiers fear mass surrender could prove positive military andor moral benefit viewed objectively could mandated beacons offered soldiers stigma culture associated use underuse would course present degree concern conclusion presented case autonomy weapons could make lifesaving deci sions world today minimal ethical ai weapons achieve reduc tion accidental strikes protected persons objects reduce unintended strikes galliott “the limits robotic solutions” jason scholz jai galliott noncombatants reduce col ateral damage reducing payload delivery save lives surrendered hope future significant resources spent reacting speculative fears campaigners might one day spent mitigating definitive suffering people caused weapons lack minimal autonomy based artificial intelligence bibliography arkin ronald governing lethal behavior autonomous robots boca raton fl crc press awad edmond sohan dsouza richard kim jonathon schulz joseph henrich azim shariff jeanfrançois bonnefon iyad rahwan “the moral machine experiment” nature galliott jai military robots mapping moral landscape farnham uk ashgate galliott jai “defending australia digital age toward full spectrum defence” defence studies –galliott jai “the limits robotic solutions human challenges land domain” defence studies –leben derek ethics robots design moral algorithm new york routledge lin patrick keith abney ryan jenkins eds robot ethics autonomous cars artificial intel igence new york oxford university press lin patrick george bekey keith abney autonomous military robotics risk ethics design washington dc united states department navy scholz jason jai galliott “artificial intelligence weapons moral imperative minimal yjust autonomy” us air force journal indopacific affairs –sparrow robert “building better warbot ethical issues design unmanned systems military application” science engineering ethics –chapter ethics ai biomedical research patient care public health alessandro blasimme effy vayena introduction march world health organization announced amid number key reforms establishment new department digital health aim harness “the power digital health innovation supporting countries assess integrate reg ulate maximize opportunities digital technologies artificial intelligence”this commitment global level vein several national plans announced last couple years2 governments began grabble ai health numerous examples aienabled digital health applications available today received market authorization private investment digital health anything go pipeline future digital health products going ful certainly socalled big data revolution instrumental development chapter discuss ethical challenges linked use ai biomedical research patient care public health draw systemic oversight model see httpswwwwhointnewsroomdetail06032019whounveilssweepingreformsindrive towardstriplebilliontargets accessed april lynne e parker “creation national artificial intelligence research development strategic plan” ai magazine corinne cath et al “artificial intelligence –sophiecharlotte fischer “artificial intelligence china’s hightech ambitions” css analyses security policy alessandro blasimme effy vayena governance ai innovation health sector3 discuss possible ways address emerging ethical challenges rapidly evolving domain aim lay groundwork ethical responsible development ai domains health research clinical practice public health ai biomedical research last decade biomedical research become datacentric activity4 enabled novel material experimental practices linked data collection distribution use burgeoning field precision medicine5 instance “omic” data routinely collected alongside clinical data phenotypic data lifestyle socioeconomic data form biggerthanever research cohorts artificial intelligence predicted enable simultaneous computation diverse arrays data thus contributing promise precision medicine bring targeted approaches diagnosis treatment individual patients6 far translational medicine concerned artificial intelligence employed drug discovery screen libraries potentially therapeutic molecules automate searches biomedical literature natural language processing techniques predict experimental dosage on7 machine learning also deployed generate predictive models could help doctors prognostic assessment personalizing therapy rehabilitation individual patients instance aftermath stroke8 effy vayena alessandro blasimme “health research big data time systemic oversight” journal law medicine ethics –alessandro blasimme effy vayena “towards systemic oversight digital health implementation afirrm principles” cambridge handbook health research regulation ed graeme laurie cambridge university press forthcoming sabina leonelli datacentric biology philosophical study university chicago press francis collins harold varmus “a new initiative precision medicine” new england journal medicine february –alessandro blasimme effy vayena medicine” bmc medical ethics alessandro blasimme effy vayena “ ‘tailoredto you’ public engagement political legitimation precision medicine” perspectives biology medicine –bertalan mesko “the role artificial intelligence precision medicine” expert review precision medicine drug development –jia xu et al “translating cancer genomics precision medicine artificial intelligence applications challenges future perspectives” human genetics february –eric j topol “highperformance medicine convergence human artificial intelligence” nature medicine see httpsprecise4qeu accessed april biomedical research patient care public health electronic health records ehr offer opportunity use realworld data generate knowledge outcomes given medical procedure diagnosis prognosis therapy rehabilitation plan9 ai employed mine ehr discover disease familiarity people risk given chronic disease also improve organization health systems providing support triage patient management10 recent study deep learning employed create predictive modeling ehr accurately gauge inhospital mortality readmission odds length stay final discharge diagnoses11 another study machine learning algorithm identified cancer patients high risk thirtyday mortality start chemo therapy palliative curative12 algorithm help decisions chemotherapy initiation enabling rational allocation resources facial recognition technologies based machine learning also developed streamline patient identification detect genetic disorders correspond specific facial traits13 diagnose mood disorders depression14 recently researchers validated system based humancomputer interaction patterns using data smartphone app able recognize authors study call digital biomarkers cognitive function15 lately increasing interest voice analysis algorithms healthrelated purposes research concentrating mental health16 main concern raised ai previously described context quality representativeness data used train machine learning algorithms existing medical data sets adult males caucasian origin strongly overrepresented17 lack diversity likely result biased algorithms trained biased data similarly ehr data used train algorithms may suffer issues missing data institute medicine learning healthcare system workshop summary iom roundtable evidencebased medicine httpswwwnapeducatalog11903thelearninghealthcare systemworkshopsummaryiomroundtableonevidence pavel hamet johanne tremblay “artificial intelligence medicine” metabolism s36–alvin rajkomar et al “scalable accurate deep learning electronic health records” npj digital medicine aymen elfiky et al “development application machine learning approach assess shortterm mortality risk among patients cancer starting chemotherapy” jama network open e180926–e180926 yaron gurovich et al “identifying facial phenotypes genetic disorders using deep learning” nature medicine yu zhu et al “automated depression diagnosis based deep networks encode facial appearance dynamics” ieee transactions affective computing –albert haque et al “measuring depression symptom severity spoken language 3d facial expressions” arxiv preprint arxiv181108592 paul dagum “digital biomarkers cognitive function” npj digital medicine nicholas cummins alice baird björn w schuller “speech analysis health current stateoftheart increasing impact deep learning” health informatics translational data analytics december –latrice g landry et al “lack diversity genomic databases barrier translating precision medicine research practice” health affairs –alessandro blasimme effy vayena misclassification18 example people lower socioeconomic levels may less represented certain diagnostic categories may overrepresented categories emergency care patients may concentrated institution others making research results potential medical relevance meaningful overrepre sented populations minorities social emarginated groups another concern relates sufficiency informed consent ethical safeguard research involving algorithmic processing traditional concept informed con sent already challenged cases data collected conventional research set tings increasingly hard predict accessing data future purposes conditions19 reuse data linkage dis parate data sets makes even notion broad consent—a typical safeguard auton omy future uses human data samples hard anticipate—weak case ai still clear whether research participants shall specifical informed intention use ai algorithms whether informed consent automated processing personal data reflect heightened level protection instance offer possibility opt creation large cohorts deeply phenotyped participants raises doubts huge amounts information initiatives put hands governments private organizations latter include healthcare organizations big tech com panies active field smart technologies stipulate agreements national governments collect analyze data millions citizens consequence issues data privacy security loom large horizon biomedical big data research20 ai adds layer ethical complexity scenario uses data extract additional finegrained information individuals ethical responsibility researchers securely protect information unauthorized access order avoid privacyrelated harms data subjects course research projects unwanted leak healthrelevant information lead discriminative uses information domains employment education insurance problem applies information generated stored researchers information researchers feed back research participants primary secondary incidental find ings return research results enjoys widespread support way show respect interests welfare research participants21 particular precision medicine initiatives us us research program endorse model empowerment milena gianfrancesco et al “potential biases machine learning algorithms using electronic health record data” jama internal medicine –effy vayena alessandro blasimme “biomedical big data new models control access use governance” journal bioethical inquiry omer tene jules polonetsky “privacy age big data time big decisions” stanford law review online susan wolf “return individual research results incidental findings facing challenges translational science” annual review genomics human genetics –httpsdoiorg101146annurevgenom091212–biomedical research patient care public health premised release medical relevant information research participants model laudable consequences instance research data subjects intend buy life insurance policy22 criteria employed evaluation research involving human data human subjects including clinical trials developed postwar period formalized countries since late 1970s criteria—for exam ple social scientific value scientific validity fair selection participants acceptable riskbenefit ratio informed consent consideration participants’ welfare rights23—while still valid formal level adequately capture specifici ties research involving use ai analyze vast amounts personal data24 consider case recent study utilizing deep neural networks analyzed association facial traits selfdeclared sexual orientation order understand whether homosexuals distinct facial characteristics25 besides technical valid ity study aim highly dubitable ethical point view lends support stereotyped views homosexuality—namely idea male homo sexuals effeminate female homosexuals manly moreover hard imagine social beneficial use study expected stig matization discrimination would likely result either intentional uninten tional misuses results study exemplifies ai power new forms classification based association biological personal behavioral social characteristics unprecedented classificatory power ai obviously pro duce tangible intangible harms26 notably particular study reviewed institutional review board passed peerreview eventual published heated controversy followed publication brought light difficulty assessing societalwide effects reviewing research well lack agreedupon criteria assessment another issue ethical relevance context health research emerged col aborations corporations advanced capabilities ai healthcare institutions control health data sets col aborations mutual beneficial several examples date raised concern enthusiasm case deep mind accessing million health records royal free london nhs order test kidney safety app ended information commissioner finding number shortcomings contractual agreements italian government’s alessandro blasimme effy vayena ine van hoyweghen “big data precision medicine private insurance delicate balancing act” big data society david wendler ezekiel j emanuel “what makes clinical research ethical” jama marcello ienca et al “considerations ethics review big data health research scoping review” plos one e0204937 yilun wang michal kosinski “deep neural networks accurate humans detecting sexual orientation facial images” journal personality social psychology vanessa k ing “spokeo inc v robins determining makes intangible harm concrete” berkeley technology law journal alessandro blasimme effy vayena decision grant ibm research unit access citizens’ health records questioned data protection fair competition officials27 beyond question whether data used adequate consent whether social benefit accrued use question benefit distributed forprofit entities exclusive deals national health data organization affect access distribution subsequent ai products still early days understanding implications arrangements articulating fair agreements despite fact litany cases seem raise questions ai patient care aidriven diagnosis certainly one promising fields application ai patient care ai largely demonstrated ability interpret various types medical images xray scans magnetic resonance also photographic images body parts skin eye fundus digitalized pathology slides image interpretation visual pattern recognition therefore among major drivers space obviously limited list examples includes use deep learning techniques train algorithms detect wrist fractures xray scans28 help cardiologists interpret magnetic resonance images29 machine learning software detects diabetic retinopathy automatical interpreting images back patient’s eye30 three applications received clearance marketing us food drug administration fda many appeared literature including algorithms compute cardiovascular risk factors based retinal images31 studies performance algorithms tested benchmark certified specialists’ assessments revealing equal superior outcomes ai system compared human physicians criterion widely used research settings yet established sufficient one ai applications clinical care issue evidence standards obvious implications terms safety efficacy conse quence major issue clear ethical implications reliability evidence favor ai clinical applications see httpswwwrepubblicaiteconomia20171205newsdatisanitariallemultinazionalisenza consensopassalanorma183005262 accessed april time writing initiative hold food drug administration “fda permits marketing artificial intelligence algorithm aiding providers detecting wrist fractures” available httpswwwfdagovnewsevents newsroompressannouncementsucm608833htm accessed april bernard marr “first fda approval clinical cloudbased deep learning healthcare” forbes january available httpswwwforbescomsitesbernardmarr20170120 firstfdaapprovalforclinicalcloudbaseddeeplearninginhealthcare6af6ceef161c see httpswwwfdagovnewseventsnewsroompressannouncementsucm604357 accessed april ryan poplin et al “prediction cardiovascular risk factors retinal fundus photographs via deep learning” nature biomedical engineering biomedical research patient care public health aidriven diagnostic applications also operated directly patient portable devices outside clinical setting one imagine example smartphone apps could incorporate already existing aipowered algorithms inspect nevi detect presence skin cancer32 similarly first smart pill approved fda included ingestible sensor sends signal patient’s device pill taken order help adhere prescription33 commentators highlighted patient perspective ethical issues type devices include concerns autonomy privacy dependability case technical failures34 ethical issues use ai patient care depend specific uses applica tions intuitively plausible think ethical stakes correlate severity condition hand degree reliance ai serious medical tasks diagnosis treatment would wrong however assume automation health system services less likely ethical relevant implications consider case triage aidriven decisions patient treated first one offered chemotherapy35 certainly follow costeffectiveness considerations exclusive reliance algorithms may rule necessary degree flexibility allows healthcare operators calibrate objective criteria reality indi vidual case36 instance system factors risk longer stays decisions hospital admission may discriminate vulnerable patients arguably need care premature say unfair outcomes case ethical relevant aspects automating clinical workflow deserve careful scrutiny use ai diagnostic purposes already mentioned problem biased training data set lead suboptimal performance underrepresented social groups creates ethical bottleneck current ethical debate ai medicine issue whether use ai disclosed patients informed consent procedures still infancy however bigger discussion ongoing whether blackbox algorithms—that algorithms whose selflearned rules complex reconstruct explain—should used medicine37 called duty transparency order dispel opacity blackbox algorithms38 others however highlighted limited requirements andre esteva et al “dermatologistlevel classification skin cancer deep neural networks” nature httpswwwfdagovnewseventsnewsroompressannouncementsucm584933htm craig klugman et al “the ethics smart pil selfacting devices autonomy truth telling trust dawn digital medicine” american journal bioethics –rajkomar “scalable accurate deep learning” elfiky “development application machine learning approach” effy vayena alessandro blasimme glenn cohen “machine learning medicine addressing ethical challenges” plos medicine e1002689 w nicholson ii price “blackbox medicine” harvard journal law technology sandra wachter brent mittelstadt luciano floridi “why right explanation automated decisionmaking exist general data protection regulation” international data privacy law –alessandro blasimme effy vayena sufficient adequately protect moral relevant interests patients machine learning algorithms employed provide care39 important issue concerns shift medical authority human physicians algorithms—the problem socalled “collective medical mind”the risk ai systems introduced decision support tools become central nodes medical decisionmaking scenario uncertain established principles medical ethics beneficence nonmaleficence respect patients still expected play central role patientdoctor relationship have—or least expected have—now mediation aipowered tools fundamentally alter doctorpatient relationship ai especial enables remote care communication via robotic assistants may create interpersonal distance patients physicians incentive use tools could need streamline patient care downside phenomenon patient becomes isolated potential negative repercussions health outcomes considerations made aibased homeassistance platforms principle systems extremely useful instance provie better care elderly people limited mobility however also increase social isolation easiness ai system keep track person’s health perform accurate diagnostic discussed potential source overdiagnosis nonactionable diagnoses instance employing deep learning infer cardiovascular risk factors retinal fundus pictures41 warranted fact could lead lifestyle adaptations may actual improve patients’ condition use images retinal structures biomarkers dementia42 problematic absence concluding evidence regarding efficacy interventions delay slow dementia43 final use algorithms mood detection promises revolutionize mental health44 however privacy issues acquire particular ethical relevance context tools like deepmood allow detection mood based mobile phone typing andrew selbst julia powles “meaningful information right explanation” international data privacy law –agata ferretti manuel schneider alessandro blasimme “machine learning medicine opening new data protection black box” european data protection law review –danton char nigam h shah david magnus “implementing machine learning health care—addressing ethical challenges” new england journal medicine march –httpsdoiorg101056nejmp1714229 poplin et al “prediction cardiovascular risk factors retinal fundus photographs via deep learning” unal mutlu et al “association retinal neurodegeneration optical coherence tomography dementia populationbased study” jama neurology –engineering national academies sciences medicine preventing cognitive decline dementia way forward national academies press david c mohr heleen riper stephen schueller “a solutionfocused research approach achieve implementable revolution digital mental health” jama psychiatry –biomedical research patient care public health dynamics certainly promising45 yet pervasive tracking one’s emotional state least intrusive may affect legitimate interest individual keep control information mood mood mental health dig al tracked sensors capture anything breathing patterns galvanic skin response tone voice sleep patterns facial expressions abouts social media traces46 possibility constantly monitorable emotional states mental health certainly problematic ethical view point sets conditions form granular psychological surveil ance odds values pluralistic liberal societies even tools employed context therapeutic relationship excessive use undermines patient’s capacity remain autonomous maintain sense selfdetermination visàvis doctor ai public health uses algorithms public health research practice significant impact population health47 health affected several social parameters eg income educa tion dietary habits environmental factors community context confined healthcare systems understanding specific effects interactions health various social conditions lead development effective efficient public health programs examples aienabled multilevel modeling using socio markers already demonstrated potential48 particular area ai application public health disease surveil ance surveil ance systems monitor disease incidence outbreaks health behaviors typical systems statefunded state operated purpose monitor health populations subsequently support decisionmaking allocation resources types interventions neces sary improve health datadriven activity surveil ance benefit substantial algorithmic uses algorithms sort variables relevant spe cific health outcomes recognize patterns signals much faster pace used forecast epidemics model trajectories algorithms used mine standard health data collected surveil ance state institutions also realworld data social media seemingly unconventional bokai cao et al “deepmood modeling mobile phone typing dynamics mood detection” mining acm –paddy barrett et al “digitising mind” lancet arash shabannejad martin michalowski david l buckeridge “health intelligence artificial intelligence transforms population personalized health” npj digital medicine eun kyong shin et al “sociomarkers biomarkers predictive modeling identifying pediatric asthma patients risk hospital revisits” npj digital medicine october alessandro blasimme effy vayena approach suffered early blow google flu trend algorithms failed show promised predictive power49 since however aienabled analysis social media data produced several successful examples including better prediction epidem ics50 detection food poisoning cases51 broader field digital epidemiology rapidly evolving field focused epidemiological models based content posted online social network users52 forms ai like natural language processing obviously play crucial role development field ethical challenges domain revolve mainly around consent many commentators stressed terms use social media fall short complying rigorous requirements informed consent domain healthrelated research53 ai combined mobile health applications also offers new avenue delivering public health intervention populations relevance expectations health promotion reach populations marginalized targeting tailored interventions54 area contest public health ethics ethical legitimacy nudging personal behavior healthrelated purposes ai make issue even significant continuous surveil ance tailored nudging paternalistic interven tions generate orwellian form individual control constrained personal freedoms55 states corporations access tools monitor alter healthrelated behaviors exercise significant power large numbers people specific interests democratic accountable state poli cies vetted transparent revised necessary necessarily case everywhere case behavioral manipulation occurs arenas controlled entirely institutions without public accountability significant enthusiasm use ai global health funding agencies international organizations investing already public health activities low middleincome countries world health organization recently committed promote ai achieve universal health coverage many governments interested taking stock digital technologies improve healthcare systems stated resolution digital health adopted 71st world health declan butler “when google got flu wrong” nature news mohammed ali algaradi et al “using online social networks track pandemic systematic review” journal biomedical informatics august –jenine k harris et al “using twitter identify respond food poisoning food safety stl project” journal public health management practice jphmp december –marcel salathé et al “digital epidemiology” plos computational biology e1002616 httpsdoiorg101371journalpcbi1002616 antoine flahault et al “precision global health digital age” swiss medical weekly april w14423 httpsdoiorgsmw201714423 jeffrey p kahn effy vayena anna c mastroianni “opinion learning go lessons publication facebook’s socialcomputing research” proceedings national academy sciences september –brian wahl et al “artificial intelligence ai global health ai contribute health resourcepoor settings” bmj global health e000798 sarah nettleton robin bunton “sociological critiques health promotion” sociology health promotion ed sarah nettleton robin bunton roger burrows routledge –biomedical research patient care public health assembly56 commitment increases likelihood ai entering rapidly domain health adding urgency need identifying addressing ethical tensions ai generates57 pertinent related potential exac erbation health disparities biases perpetuated reinforced aienabled interventions discussed problem misrepresentation certain populations healthrelated data sets several methods currently development compensate bias time problem remains requires attention58 underserved populations present certain negative health outcomes due wellknown social deficits algorithms produce decisions based health comes alone without factoring social causes result significant harm increased health inequalities example poor lesseducated people per formed worse certain health interventions due poor access care working schedules etc algorithm determine people characteristics always perform worse recommend offered intervention first place exacerbate disparity access care attainment good health outcomes importantly make disparity less visible decision bear authoritative objectivity often attributed numbers typical expected automated decisionmaking tools addressing ethical challenges novelty represented ai machine learning particular might verge pushing medical research patient care public health yet uncharted ethical territories impact ai three domains particularly challenging anticipate hard predict whether expected benefits offset emerging risks scenario neither precautionary approach waitandsee attitude compat ible widely accepted need ensure ethical sustainable social robust responsible innovation domain precautionary approach implies erring side containing possible risks evidence given phenomenon evolve scarce stakes high terms potential harms59 far use ai medicine concerned precautionary approach would likely result dispropor tionate constraints might undermine development promising technologies hand permissive “waitandsee” approach see httpappswhointgbebwhapdffileswha71a71r7enpdf accessed april effy vayena lawrence madoff “navigating ethics big data public health” oxford handbook public health ethics ed c mastroianni j p kahn n e kass oxford university press –robert challen et al “artificial intelligence bias clinical safety” bmj quality safety march elizabeth charlotte fisher judith jones rené von schomberg implementing precautionary principle perspectives prospects edward elgar alessandro blasimme effy vayena favorable development rapid uptake aidriven solutions would necessarily rely existing ethical safeguards safeguards seen fall short covering rapidly expanding catalog ethical issues ai poses domain biomedicine collection use reuse increasingly large amounts personal data seen cal question adequacy key components existing regulatory toolkit evidence standards ethics review informed consent60 needed ensure responsible ai innovation governance approach coevolves field incorporating new governance actors experimenting new oversight mechanisms cope ethical challenges arise prac tice governance model primarily drive attention ethical contro versial aspects aidriven innovation biomedicine order ensure emerging risks pass unnoticed second aim ideal governance frame would channeling innovation toward social beneficial outcomes final good governance promote public trust accountability innovation process objectives demand specific systemic approach governing complex phenomenon whose outcomes still largely unpredictable last two decades scholarship governance controversial areas science innovation given substantial consideration socalled adaptive governance model cope uncertainty public policy61 adaptive governance centers around constant monitoring phenomenon stake policy measures deployed control practical terms model invites oversight regulation take stock evidence becomes available promoting social learning among variety different governance stakeholders62 drawing broad frame adaptive governance proposed governance model datadriven innovation bio medicine called “systemic oversight”systemic oversight specifical designed address gives rise ethical issues use big data ai biomedicine seen novel data sources novel data uses increased capacity draw con nections disparate data points uncertainty downstream effects increased classificatory powers systemic oversight approach based six principles offering guidance desirable features oversight structures pro cesses domain dataintense biomedicine adaptivity flexibility inclusiveness reflexivity responsiveness monitoring first letters principles form acronym afirrm effy vayena et al “digital health meeting ethical policy challenges” swiss medical weekly w14571 carl folke et al “adaptive governance socialecological systems” annual review environment resources –brian chaffin hannah gosnel barbara cosens “a decade adaptive governance scholarship synthesis future directions” ecology society vayena blasimme “health research big data” blasimme vayena “towards systemic oversight digital health” biomedical research patient care public health adaptivity refers capacity governance bodies mechanisms guarantee appropriate forms oversight new data sources new data analytics get incorporated research patient care public health activities flexibility capac ity treat different data types based source actual use premised consideration data acquire specific ethical meaning different contexts use inclusiveness stresses need include affected parties delibera tions decisionmaking practices use data algorithms specific ambits component refers particular communities actors histori cal marginalized vulnerable otherwise excluded circuits power minorities patient constituencies reflexivity prescribes careful scrutiny assessment emerging risks short run well long run terms downstream effects big data ai interests rights values example terms fair access healthcare services discrimination stigmatization medicalization overdiagnosis saw earlier ai powerful generator healthrelevant information thus exposes research participants patients data subjects general unwanted leaks personal data information responsiveness refers therefore need adequate mechanisms mitigate effects unauthorized access personal healthrelated information final monitoring expresses need predispose regular scrutiny datarelated activities effects healthrelated practices order anticipate emergence new vulnerabilities undesirable outcomes implementation afirrm frame require consideration well characterized obstacles adaptive governance policy domains particular attention needs paid composition oversight bodies demands inclu siveness example appropriately fulfilled diverse stakeholders share least common understanding intended advantages potential risks using ai biomedicine possible instance automating hospital services aidriven triage systems caters financial interests hospitals rationalizing resource allocation failing meet expectations severely ill patients terms access care consequence inclusion patients’ perspectives decisions adoption systems requires fosters existence shared visions fairness access health services along similar lines oversight mechanisms use effects ai clinical practice must escape purely technical considerations safety efficacy automated clinical decisions downstream effects patientdoctor relationship right patients decide whether open highly automated decisions need considered aim new review processes clinical validation well novel communication con sent requirements established applies research domain researchers interested using large amounts phenotypic data need negotiate terms use data subjects may valueladen views ethical legitimacy certain types research advent ai agenda academic disciplines like clinical research ethics medical ethics public health ethics rapidly adapting incorporate new issues alessandro blasimme effy vayena new controversies given theoretical thematic specificity one may characterize area separate subarea study applied ethics call “digital bioethics” whether scholarship inform emergence new oversight tools remains seen meantime practical proposals criteria best practices governance aidriven innovation biomedicine starting emerge uk national institute clinical excellence nice body advising uk national health service nhs matters related health technology assess ment released guidance clinical validation digital health technologies according function given dht intended perform standards going applied dhts harboring ai component well standalone ai software february nhs released updated version code conduct datadriven health care technologies65 principles proposed code include understanding users’ needs clearly defining expected outcomes benefits lawful data processing transparency evidence safety effectiveness based nice criteria nhs frame criticized lack attention risk ai healthcare space may widen social inequalities66 still united kingdom wellcome trust—a major funder biomedical research country— recently proposed model called “dynamic oversight” emerging science technologies partial resembles systemic oversight approach afirrm principles67 united states american medical association released policy ai document highlights transformative potential ai clinical domain recommends clinical validated ai aligned best clinical practices transparent reproducible immune data biases protect patients’ privacy well integrity personal information united states fda gatekeeper aidriven health innovation statutory oversight power medical devices software medical device europe instead new regulation medical devices69 relies third parties called notified bodies issuing conformity certificates medical devices fda piloting precertification program identify “manufacturers demonstrated robust culture quality organizational excellence committed monitoring see httpswwwniceorgukmediadefaultaboutwhatwedoourprogrammesevidence standardsframeworkdigitalevidencestandardsframeworkpdf accessed april see httpswwwgovukgovernmentpublicationscodeofconductfordatadrivenhealthand caretechnologyinitialcodeofconductfordatadrivenhealthandcaretechnology accessed april melanie smallman “policies designed drugs won’t work ai” nature see httpswellcomeacuksitesdefaultfilesblueprintfordynamicoversightpdf accessed april see httpswwwamaassnorgsystemfiles2019–01augmentedintelligencepolicyreportpdf see httpseurlexeuropaeulegalcontententxtpdfuricelex32017r0745 accessed april biomedical research patient care public health realworld performance products reach us market”in april fda also released proposed regulatory framework ai machine learn ing medical software addressing specific issue algorithms keep training based new data acquired clinical use71 conclusions current proliferation guidelines codes conduct demonstrates need ethical technical points reference rapidly evolving field considering broad scope potential applications research clinical use public health likely specific uses ai covered existing oversight mechanisms reliance existing regulatory tools alone likely fail ensure adequate levels public trust accountability reason advanced systemic sightafirrm approach governance blueprint looking nature ethical issues il ustrated chapter light afirrm principles seems least advisable certain measures implemented short term research domain ethical review committees incorporate reflexive assessment scientific social merits aidriven research aim likely open ranks new professional figures social scientists research funders hand require monitoring responsiveness mechanisms part research plans could set multidisciplinary committees periodical assess data activities order adjust funding policies future aidriven research amounts largescale projects claiming data entire communi ties populations adequate forms inclusion must experimented order ensure social learning across different epistemic communities—including lay publics nonacademic actors domain patient care clinical validation crucial issue ad hoc evidence standards necessary condition responsible clinical innovation sufficient cover breath potential ethical issues saw area hospitals could equip “clinical ai oversight bodies” charged task advising clinical administrators regarding adoption given ai technology monitoring effects patient journeys patients’ engagement throughout continuum care moreover consent requirements need adapted presence highly automated dataprocessing instance domain diagnostics public health sphere new level granularity enabled ai disease sur veil ance health promotion negotiated level targeted com munities result sense disempowerment consequence lack public trust acceptable limits data collection algorithmic analysis see httpswwwfdagovmedicaldevicesdigitalhealthucm567265 accessed april see httpswwwregulationsgovdocumentdfda2019n1185–accessed april alessandro blasimme effy vayena words result communitywide inclusive deliberation especial collecting processing data exact purposes examples initiatives adopted contribute development ai socially robust technology clear beginning foreseen transformation transformation occur real effects may different able anticipate level uncer tainty however shall deter societal stakeholders—including scientific clinical institutions—from experimenting governance arrangements aimed reaping benefits ai human knowledge health time paying sufficient attention emerging ethical challenges bibliography char danton nigam h shah david magnus “implementing machine learning health care—addressing ethical challenges” new england journal medicine jianxing sal l baxter jie xu jiming xu xingtao zhou kang zhang “the practical implementation artificial intelligence technologies medicine” nature medicine january price w nicholson ii “blackbox medicine” harvard journal law technology smallman melanie “policies designed drugs won’t work ai” nature topol eric j “highperformance medicine convergence human artificial intelligence” nature medicine vayena effy alessandro blasimme “health research big data time systemic oversight” journal law medicine ethics –vayena effy alessandro blasimme glenn cohen “machine learning medicine addressing ethical challenges” plos medicine e1002689 yu kunhsing andrew l beam isaac kohane “artificial intelligence healthcare” nature biomedical engineering october –chapter ethics ai law basic questions harry surden introduction use artificial intelligence ai technology administration practice law raises basic ethical issues chapter surveys important ethical topics involving use ai within legal system use within society broadly vantage point united states ethics ai law ethical issues surrounding ai use law often share common theme ai becomes increasingly integrated within legal system society ensure core legal values preserved reflects idea democracies consider certain val ues central legal systems operate among important legal values equal treatment law public unbiased independent adju dication legal disputes justification explanation legal outcomes legal results arising law principle facts rather social status power outcomes pre mised upon reasonable social justifiable grounds ability appeal decisions seek independent review procedural fairness due process fairness design application law public promulgation laws transparency legal substance process adequate access justice integrity honesty creation appli cation law judicial legislative administrative efficiency1 use ai christopher b gray ed philosophy law encyclopedia garland reference library humanities vol new york garland harry surden law may diminish enhance values actual expressed within legal system alter balance relative one another many ethical topics thus examine central values might unintentional intentional change increased use ai legal system example scholars worry use ai technology judicial system may make legal decisions biased certain social groups undermine notions equal treatment2 others concerned automation might subtly elevate values efficiency expense core values due process3 still others query whether use ai law may shift power dynamics among members society elevating knowledge access ai technology detriment not4 broader level questions important implicate basic ordering society use ai within law potential subtly alter political social legal power among societal groups diminish enhance operation fundamental institutional protections nar rower level topics important legitimacy legal systems depend extent reality perception core legal values equal treatment law actual reflected system operates thus extent use ai erodes perceived eroding central legal norms could undermine legitimacy legal system important however establish balanced view ethical issues raised use ai within law first many examinations ai use primarily come negative perspective critiquing ways ai might make legal system less fair clear critical assessments important valid indeed chapter spend significant time identifying similar ethical concerns however important observe use ai law also potential strengthen desired values careful uses ai may actual reduce bias expose existing injustices increase access legal system overall efficiency5 extent ai used enhance values fairness equality access justice legal system soci ety broadly may benefit important exaggerate potential ben efits ai law also essential acknowledge alongside critiques positive points often go underemphasized scholarly literature second many ethical issues raised use ai law truly new rather exist already one form another current legal structure true ethical issues come associated introduction ai technology one reason applying ai technology law often brings forefront latent issues previously implicit example judges police solon barocas andrew selbst “big data’s disparate impact” california law review deirdre mulligan bamberger kenneth “saving governancebydesign” california law review danielle keats citron “technological due process” washington university law review frank pasquale black box society secret algorithms control money information harry surden “machine learning law” washington law review ethics ai law basic questions always undesirable biases often data systematical analyzed ai systems biases become apparent similarly language current laws design institutional processes may implicitly weight values eg effi ciency others eg due process however application ai often results implicit patterns reduced explicit mathematical form often inspected6 thus apply ai algorithms past judicial police data exam ine result may see exposed results biases value weightings lurked undiscovered prior application technology similarly cases com putational efficiency ai technology magnify existing subtle weightings structural imbalances thus use ai certainly introduce new biases cases technology merely exposing magnifying existing biases prefer ences system third important exaggerate relative impact ai law compared societal influences one hard predict degree ai technology incorporated legal system broadly second many societal factors combine influence core legal values actual expressed legal system factors include institutional design political power money social power existing institutional structures tradition use nonai based technologies internet know significant influence ai legal system relative important aspects certainly pay close attention impact ai law ethical questions use raises must also careful overfocus ai simply rela tively new perhaps exotic familiar traditional factors many cases comparative impact legal system altering traditional factor institutional design may substantial outweigh adjustments use ai relevant chapter make broader points said use ai technology within law relatively new ethical issues raised merit close scrutiny impact ai law legal institu tions actors decisions contexts may substantial also hard detect thus chapter’s central theme closely examine way ai tech nology may alter legal system structures effect technological change legal substance values actors institutions often subtle artificial intelligence examining ethical questions raised use artificial intelligence law important first establish “artificial intelligence” means universal harry surden “values embedded legal artificial intelligence” ssrn scholarly paper abstract2932333 harry surden agreedupon definition “artificial intelligence” one useful working description instance outside law ai technology used automate tasks playing chess driving cars considered “artificial intelligence” tasks rather automation tasks general humans engage activities activate higherorder brain functions reasoning judgment decisionmaking vision use abstractions cognitive activities associated human intelligence thus engineers take task requires higherorder cognitive abilities human performs automate using technology common refer application artificial intelligence definition works reasonably well ai used legal domain law many tasks prediction legal outcomes legal analysis factual situations performed judges lawyers engage various aspects human cognition use technology ful partial automate legal tasks common consider use “artificial intelligence” within law different equal useful way think “artificial intelligence” terms underlying technology enables high level artificial intelligence usual treated subdiscipline computer science much research technology emerged domain however ai truly interdisciplinary enterprise involv ing ideas researchers research beyond computer science fields statis tics mathematics economics neuroscience psychology logic philosophy name lower level term “artificial intelligence” refers particular suite technol ogies approaches arisen ai researchers successful used automate various activities involving human intelligence research two broad categories ai technological approaches emerged first group ai technologies broadly known “machine learning” second cate gory referred “knowledge representation rulesbased ai” let’s briefly look broad group turn ai approach used within administration practice law varying degrees roughly speaking machine learning refers category ai approaches algorithms automatical learn patterns large amounts data learned pat terns harnessed automate tasks driving car predicting credit card fraud recognizing handwriting “machine learning” one technique rather refers variety approaches bear family resemblance one another among approaches “neuralnetworksdeep learning” “logistic regres sion” “bayesian inference” common trait ability discern useful patterns data often used make automated decisions new neverbefore seen data new situations often machine learning techniques applied problems involving prediction estimating probabilities7 ajay agrawal joshua gans avi goldfarb prediction machines simple economics artificial intel igence boston harvard business review press ethics ai law basic questions importantly machine learning ai algorithms require data order function example machine learning algorithms able predict probability given credit card transaction fraud previously ana lyzed data set past fraudulent nonfraudulent credit card transactions detected patterns associated fraudulent activity applicability machine learning problem goes hand hand availability data relevant data unavailable limited machine learning approaches general cannot applied notably however machine learning part art part science significant human judgment goes selecting applying data algorithms realworld problems overal machine learning dominant mode artificial intel ligence today people informal speak “ai” usual referring machine learning approach context law discussed machine learning significant impact prediction automated examination legal documents analysis legal contexts second major approach ai known “knowledge representation rules based ai” also plays important albeit lesser role law today general speaking form computer process reason good example knowl edge representation rulesbased system law involves taxcompliance software system models underlying logic meaning us personal income tax code us taxpayers use comply tax laws compute tax liability cre ate system engineers conjunction attorneys accountants might examine us personal income tax laws aim translate underlying logic legal provisions set computer rules accurately reflect underlying meaning general developing knowledgerepresentation system involves modeling realworld process activity using formal computer rules accurately reflect underlying logic structure knowledgerelationships underlying activity knowledgebased ai systems sometimes referred “expert systems” computer rules systems reflect knowledge gleaned domain experts lawyers although knowledge representation approaches ai dominant machine learning today law still represent significant aspect legal ai worth clarifying final point laypeople hear term “artificial intelli gence” often imagine today’s ai involves “machines think” however case today term “artificial intelligence” bit misnomer cur rent ai technology exhibit advanced cognitive abilities normal associate human intelligence rather explained previously ai approaches involve automated approximations—learning computerbased patterns rules heu ristics sometimes used produce “intelligent results without intelligence” certain limited settings unfortunately media corporate advertising often give misimpression today’s ai technology involve computers think reason engage arbitrary novel conversations original topics levels match exceed harry surden human ability vision ai—sometimes known “strong ai” “artificial general intelligence” agi—has long goal artificial intelligence research moment remains merely aspirational writing chapter author’s opinion little evidence strong ai technology coming time soon fivetotenyear time frame reason important clarify current limitations ai important ground discussions ethics ai law within actual capabilities ai technology occasional analysis becomes distracted confused specu lation future technological developments concerning ai may may occur speculation potential future developments uniformed actual evidence rarely leads productive analysis chapter remain firmly grounded evidence current nearterm five years state ai technology use artificial intelligence law part examine representative examples way ai used within legal system ethical questions uses raise helpful conceptual divide users ai within law three groups administrators law eg judges legislators police practitioners law eg attorneys users law tual division useful group plays different role legal system uses ai within law different ways ai use administrators law term “administrators law” meant cover use ai government officials broadly distinguish use ai lawyers ordinary citizens busi nesses administrators law context include government officials ranging judges legislators regulatory officials police government officials play unique role legal system ability official interpret apply law power state sanctions behind use ai legal administrators different valence groups since potential impact societal balances chapter spend major ity focus group ai criminal sentencing bail determinations one prominent example ai use within law comes criminal context judges must make important decisions criminal defendants come including whether release bail trial sentence impose con victed important factor decisions likelihood defendant ethics ai law basic questions commit crime released bail context judge believes defendant likely commit crime released may deny bail sentencing context judge may impose severe sentence defendant seen likely reoffend traditional judges made assessments without significant reliance technology incorporating range information including witness testimony defendant crime defendant’s past criminal history severity crime judge’s intuition overall impressionistic assessments recently however judges also begun rely upon information produced machine learning algorithms include automated indications risk software often referred “criminal riskassessment” “riskdetermination software” purports predict probability particular defendant commit another crime released given information defendant helpful general highlevel understanding ai prediction software created order understand ethical issues raised8 central idea behind machine learning–based risk assessment software uses data past criminal defendants history reoffending predict probabil ity new defendant reoffend today criminal riskassessment software usual created private thirdparty companies license sell govern ment use legal system9 data scientists companies pos sibly help experts law criminal domains apply variety machine learning algorithms historical data see ai system automati cal identify patterns associated increased likelihood reoffending since core machine learning systems data vendor creating software locate source data relevant predicting criminal risk typical sources might include historical government data past criminal de fend ants already come justice system data usual combined information defendants private corporate sources credit score agencies datacollection agencies10 put together data set might contain historical information tens thousands defendants previously passed system defendant might hundreds pieces information defendant also known “variables” “fea tures” “factors” type crime defendant committed educational level address employment history credit score criminal history family circumstances demographic information along information whether defendant ended reoffending released goal creating system use machine learning try identify historical data hundreds potential predictive factors seem reality riskprediction software process creating using much complex simple example given includes many predictive variables il ustration jeff larson julia angwin “machine bias” propublica may httpswwwpropublica orgarticlemachinebiasriskassessmentsincriminalsentencing electronic privacy information center “epic—algorithms criminal justice system” httpsepicorgalgorithmictransparencycrimjustice accessed july harry surden indicative likelihood defendant commit crime upon release instance oversimplifying greatly imagine algorithm examines thousands past defendants individual data points determines two features predictive future offenses defendants previous encounter jus tice system committed crimes shortly release extremely likely future ie data point strong predictor get high fend ie weak predictor get low weighting examples two features factors might used ai system predict future chance offending new defendant identified predictive indicators ai algorithm outputs discovered ai model series “weightings” factors tend predictive reoffending used make prediction new never beforeseen defendant based upon information person’s background circumstances example imagine two new defendants judge judge wants use riskassessment software predict chances either reoffending suppose court collects data defendant deter mines first one unemployed previously committed crime upon release bail previously committed crime also unemployed two potential predictive data points defendant input ai software apply previously discovered model weightings particular data make predictions new defendants analyzing data defendant ai model might predict high probabil ity reoffending first defendant ai model weights previ ously reoffended together unemployed highly predictive lower slightly average probability second ai model weights unemployed slightly predictive software typical output report overall riskscore defendant eg risk rating scale assist judge decision based scores typical judge might decide deny first defendant bail grant second scores merely recommen dations principle judge free disregard importantly creating ai predictive model requires great deal judgment subjective choices part data scientists11 first judgments data sets use data sets may reliable others also judgments data data sets include exclude examin ing data predictive patterns also judgments machine learning algorithms use many different machine learning algorithms type algorithm uses different set mathematical techniques try deter mine “best” “mostpredictive” factors however often work joshua kroll et al “accountable algorithms” university pennsylvania law review ethics ai law basic questions differently different algorithms come different answers even data also judgments validate measure whether model working “wel ” accurately fairly final scientists often create multiple possible predictive models judgments among many ai models choose thus data scientists use combination professional judgment guess ing intuition domain knowledge pick best combination machine learning algorithm data points analyze use ethical issues government officials using ai decisionmaking process discussed earlier central theme ethical inquiries extent core legal val ues impacted increased use ai law criminal riskassessment exam ple instructive il ustrates many common issues arise government administrators use ai systems making official decisions points raised thus translate scenarios involving aiaided government determinations ethical issue equal treatment law equal treatment law regardless status core value legal systems norm posits legal decisions based upon law facts upon party’s socioeconomic political racial ethic gender background variety individual characteristics illegal inappropriate con sider defendants circumstances treated law regardless status use ai systems judges legal officials make decisions raised concerns equality norm scholars worried recommendations made ai systems may disproportionately harm benefit certain social groups expense others12 unequal treatment aibased decisions occur reasons sometimes happens existing structural inequalities society inequal ities become reflected data used ai systems example let’s imagine riskprediction system discussed earlier based partly upon historical police arrest data example ai algorithm discovered feature predictive reoff ense defendant’s history reoffended past encounter justice system highly indicative future offense upon release however let’s imagine police arrest behavior upon data based biased would result subtle potential unjust skews data instance suppose individuals socioeconomic groups commit minor offenses solon barocas andrew selbst “big data’s disparate impact” california law review harry surden patrol look offenses frequently lowincome areas tend stop arrest lowerincome individuals ignoring higherincome individuals observing offense groups disparity police treatment would create misleading bias data offenses lowerincome individuals dis proportionately recorded police data set appear data occur higher rate offenses higherincome individuals omitted data recorded due police discretion patrol decisions ai algorithms good detecting patterns ai algorithm examines biased data likely find skews subtly incorporate ai pre dictive model model mathematical indicate lowincome individuals likely reoffend highincome individuals due true differences offense rates rather due police stop arrest patrol datarecording behavior ai model used predict risk reoffending new defendant using upon information associated socioeconomic status credit score might unjustifiably recommend lowincome defendants receive bail rec ommending similarly situated highincome defendants released bail il ustrates important point machine learning models depend upon data existing societal structural biases may subtly embedded data sets ai systems use data sets skewed various ways biases reflected machine learning models ways extremely hard detect may offer disparate treatment various societal groups based upon inappropri ate categories worse yet widespread ai systems may encode existing structural institutional biases may inadvertently reinforce strengthen biases making automated decisions put certain groups disadvantage merited biases subtly creep ai predictive models hard detect creators ai systems many subjective design decisions make system created operates ai context choices include data sets use data exclude include ai algorithms use ai models select information emphasize deemphasize subtle choices might result less favorable treatment various social groups designers systems therefore great deal power given point designers might make series subtle design decisions might result favorable unfavorable treatment different groups applied broadly society design biases might largely unintentional software engineers make choice based upon personal judgment without realizing choice hap pens benefit people like others worry unethical creators sys tems may intentional make subtle design choices deliberately benefit certain groups expense others13 case use ai systems government decisionmaking broadly may subtly shift social political power dynamics kroll et al “accountable algorithms” ethics ai law basic questions providing favorable automated decisions certain groups others thus one group ethical questions surround question ensure predictions created ai predictive models relied upon government officials facilitating legal values equal treatment law without regard status however making assessment fairness aiaided decisionmaking one must always compare baseline legal processes existed tech nology introduced biases current system prior introduc tion aiaided technology bail sentencing decisions made judges based upon evidence also upon judge’s personal beliefs discretion intuition expe rience judges like humans subject variety conscious unconscious biases14 likelihood many judgebased decisions biased unde sirable ways way ai systems subject software design choices result disparate treatment legal institutions processes subject decision—decisions significantly help hinder various societal groups instance legal system contains myriad structural design choices hours keep courts open ie weekday hours may benefit people higher status jobs job flexibility sophistication language use court documents information emphasize documents ie information placed toward back multipage document may go overlooked language translate official documents ie englishonly documents may disadvantage nonenglish speakers many nontechnical structural design choices legal system made power make decisions always potential benefit certain societal groups others although introduction ai systems raise novel issues software design affect legal social outcomes similar subtle issues preferential legal design always existed legal system15 leads important point—just observe ai legal models explicitly undesirably biased mean biases exhibit neces sarily worse current legal structures contain biases indeed suggested ai systems could actual foster equal treatment law compared existing legal processes cases applying ai mod els legal data enhance value equal treatment exposing unknown existing biases current system may overlooked machine learning systems good identifying patterns patterns might reflect exist ing structural injustices brought fore corrected observed others suggest databased ai systems add consistency bail sentencing daniel kahneman thinking fast slow new york farrar straus giroux michael brownstein “implicit bias” stanford encyclopedia philosophy ed edward n zalta stanford university httpsplatostanfordeduarchivesspr2017entriesimplicitbias jon kleinberg sendhil mul ainathan manish raghavan “inherent tradeoffs fair determination risk scores” 8th innovations theoretical computer science conference itcs ed c h papadimitriou schloss dagstuhl—leibnizzentrum fuer informatik httpsdoi org104230lipicsitcs201743 harry surden legal decisions compared current system involving thousands different human judges different backgrounds experiences conscious unconscious biases applying considerable discretion subjectivity merit point view—as human decision makers cer tainly unbiased—one must take point view critical eye several rea sons much depends upon careful implementation systems recognition limitations one discussed automated decisions ai systems automated computer decisions often provide il usion mechani cal neutrality cases people tendency unjustifiably treat automated outcomes unbiased authoritative compared humanbased decisions however discussed bias creep automated systems might concerned society improperly ignores possibility undesirable mechanical biases unduly treats decisions somehow objectively correct precise truly final concern truly implementing equal treatment legal system focus nuances ai decisionassistance systems may misplaced discussed earlier many factors may substantial affect equal fairly various groups treated legal system institutional design fund ing political choices equal treatment truly societal goal likely changing factors could much stronger overall impact tweaking details ai systems instance actual achieve equal outcomes dis advantaged groups time effort might better spent providing funding public defenders making institutional design changes legal systems processes friendly groups point course ignore details ai legal systems might lead structural biases—of course need pay close attention nuances lest systems poorly implemented rather danger com mentators spend undue amounts time worrying tweaks ai legal systems—a topic relatively novel exotic spending efforts finding marginal improve ments technological systems—while ignoring mundane interven tions might much substantial overall impact improving core legal values transparency explanation another set concerns use ai law surrounds public transparency legal adjudication theory predictions rendered many ai systems transparent ai systems deterministic systems means outputs produce entirely based upon input data goes software ai model used16 words exact inputs applied andrew selbst solon barocas “the intuitive appeal explainable machines” fordham law review march ethics ai law basic questions ai model system produce outputs process completely recorded audited thus principle want query ai system came particular prediction particular defendant able determine exactly happened examining input information de fend ant went eg defendant unemployed ai model information eg took account unemployment weighted lightly numeric able reconstruct computational process led results practice however transparency ai predictions easy recon struct one discussed earlier today many criminal riskprediction systems created nongovernmental private companies companies often make ai models underlying data software necessary reconstructing decision accessible public rather vendors often keep confidential soft ware code ai model weights various factors data upon model created variables model considers making automated output often use law itself—trade secret law nondisclosure agreements— along technical obfuscation keep details ai models automated decisionmaking process secret thus even though principle one might able computational interrogate criminal riskassessment system reconstruct came decision practice access necessary data software details general possible similarly legal systems core value substantive criteria upon legal decisions made publicly promulgated provide notice extent details ai algorithms kept secret difficult know upon basis substantive decisions—such defendant release decisions—were made argue undermines core legal values public promulgation notice thus transparency notice core values legal decisionmaking one might query transparent automated decisions whose details substantive criteria shielded confidential secrecy also impact ability appeal decisions—another core legal value even details ai systems accessible cases still may full transparency decisionmaking process technical reasons men tioned many different machine learning techniques techniques regression decision trees produce answers easy understand inspect contrast machine learning approaches particularly neuralnetwork deep learning approaches produce ai models highly accurate diffi cult impossible humans understand known “interpretability problem” refers fact techniques often encode patterns extremely complex mathematical models readily processable computers interpretable humans meaningful terms even programmers created words ai riskassessment system created using one less interpretable techniques even inspect input data harry surden applied ai model might fully able understand algorithm came predictive decision way meaningful thus extent governmentaided ai decisions made using machine learning techniques relatively less interpretable may concerned value transparency decisionmaking diminished related issue transparency role explanation core requirement many legal systems judges legal officials explain important legal decisions affect people’s lives substantive rights officials often must explicitly justify writing using social legal acceptable reasons17 worried increased use ai legal decisionmaking might diminish ability explain deci sions meaningful way judge follows recommendation ai system output system often traced computational series mathematical calculations produce detailed audit data computer steps led decision even statistical justification decision probabilistical accurate computational exposition amount social acceptable justification satisfactory explanation human defendant18 may little conso lation disappointed defendant “the system analyzed mathematical decided rights denied” legitimacy legal adjudication depends extent performative humanistic aspects legal decisions—the ways parties come away courts feeling like opportunity heard treated fairly social acceptable justifiable way quite apart underlying objective merits case thus extent explanation justification core value legal system critics concerned increased use aibased decisionmaking might undervalue necessary humanistic performative components legal adjudication however ways use ai systems may enhance transparency always important compare critiques ai status quo problems existing processes although ai systems may difficult inspect technologically human mind observable system either inspect inner workings judge’s brain determine arrived decision judges often required publicly articulate reasons reaching particular decision way verify decision actually reached stated reasons contrast one uses ai system least possibility interpretable machine learning technique used decisionmaking process completely reconstructed thus regards increased use ai provided carefully implemented enhance transparency compared current legal processes margot e kaminski “the right explanation explained” ssrn scholarly paper rochester ny social science research network june httpspapersssrncomabstract3196985 tim miller “explanation artificial intelligence insights social sciences” arxiv170607269 cs june httparxivorgabs170607269 ethics ai law basic questions accuracy strong value legal systems coming accurate legal decisions accuracy another way ai predictive systems provide improvements pretechni cal status quo today judges tasked making variety predictive decisions parties probability reoffending reason believe judges particularly well equipped making accurate predictions along lines19 much research shows humans reason poorly comes probability due various cognitive biases20 contexts outside law computeraided pre dictions routinely outperform human predictions21 thus may case care ful constructed careful implemented ai system may accurate predicting actual risk reoffending human judges acting intuition experience however cases judgemade decisionmaking may accurate ai sys tems make decisions based upon encoded data information system creators designed consider limitations might exclude many relevant difficult encode pieces information auto mated analysis witness testimony could highly predictive certain cases contrast judges take account wide range holistic testimonial evidence making decision much unavailable computerized algorithm cannot easily captured data possible given wider set data points judges make accurate decisions certain contexts limited machines empirical research show whose predictions accu rate however extent ai systems turn accurate overal ethical question sense may whether ai systems frequently used predictive tasks order result fairer treatment defendants shifting accountability decisionmaking another set ethical topics concerns accountability official decisionmaking current nontechnological enhanced system judges juries make crucial decisions concerning criminal defendants therefore identifiable points accountability—when decision occurs know official actor body—judge jury—made decision context aiaided decisionmaking may jon kleinberg et al “human decisions machine predictions” working paper national bureau economic research february kahneman thinking fast slow agrawal gans goldfarb prediction machines harry surden subtle shift accountability principle outputs predictive ai systems like riskassessment software merely recommendation judge supposed incorporate holistical along evidence order make consid ered judgment however possibility judges juries using sys tems begin habitual defer automated recommendations made system adopt reflexively aibased system produces automated risk assessment aura mathematical precision objectivity reasons suspect judges might opt routinely adopt automated recommendations default even nomi nal retain final discretion come different conclusion example sys tems often provide scores defendant risk reoffending judge numerical scale least risk maximum risk imagine system pro duces relatively high riskscore given defendant—say maximum hard imagine judge overriding high numeric indication even would come opposite result holistical assessing weight evidence absence automated numeric result indeed judges incentives override automated recommendations imagine judge release de fend ant despite high automated risk score defendant go com mit crime release judge could subject backlash criticism given seemingly precise prediction score record judge chose override safer route judge simply adopt automated recommendation always point numerical riskscore justification decision scenario potential ethical problematic several reasons first despite apparent certainty numerical score “out ” scores suffer problem false precision predictions—even automated predictions—are full uncertainty wide margins error clear probability risk score “”—separate context—is aiming convey thus judges may likely err side caution face seemingly precisely relatively high numeric scores potential problematic subtle shifting accountability substantive decisions away judge toward system currently system con structed human judges called upon make judgments upon humans judges begin routinely adopting default recommendation system results subtle shift responsibility accountability away judge toward ai recommendation systems creators extent value accountability locus decision located publicly appointed elected judge made considered evaluation evidence default adop tion automated recommendations may problematic another related issue shift accountability public sector private sector indeed judges begin routinely adopt automated recommendations without much additional consideration locus decision essential shifts organi zation designed implemented ai system—these days often private compa nies sense balance legal judgments might essential shift public ethics ai law basic questions sphere private sphere subject design decisions private corporations one important value many legal systems public independent adjudication legal disputes thus one potential ethical point concern legal decisionmaking partial ful based upon ai systems shift decisionmaking away public officials toward privately developed systems ethical concerns ai use practitioners law major ethical concerns use ai legal system raised context administrators law judges parallel issues raised use ai practitioners law—lawyers chapter conclude briefly highlighting issues one set ethical issues concerns increasing power ai systems today lawyers called upon make numerous types predictions course work predicting outcome legal issues predicting documents privileged important relevant litigation business matters traditional lawyers produced predictions using combination legal analysis judg ment experience professional analytical skil past several years lawyers begun use ai systems number settings traditional purview legal judgment including automated document analysis automated discovery legal case outcome prediction sake argument imagine near future predictions case comes made lawyers using ai systems begin vastly outperform predictions made traditional lawyers using professional skil s22 future scenario raises several issues one best accurate predictions made law yers using ai systems ethical professional standards shift lawyers obligated use systems rather using unassisted professional judg ment traditional done additional system risks shifting power dynamics law lawyers clients access best aibased pre dictive tools might increasingly significant advantages less resourced lawyers clients true today lawyers clients resources often obtain better outcomes less resourced clients despite rela tive merits positions possible aibased tools could exacerbate divide thus extent access justice adjudication legal outcomes based upon merits central values legal system increased use aibased systems lawyers may undermine norms daniel martin katz “quantitative legal prediction—or—how learned stop worrying start preparing datadriven future legal services industry” emory law journal harry surden conclusion chapter surveyed major ethical issues surrounding increasing use artificial intelligence systems within legal system central ethical challenge identify way use ai may shifting core legal values ensure crucial values preserved technological transition positive view also identifies ways ai technology preserve central values also foster enhance values betterment legal system society overal bibliography agrawal ajay joshua gans avi goldfarb prediction machines simple economics artificial intel igence boston harvard business review press angwin julia jeff larson “machine bias” propublica may httpswww propublicaorgarticlemachinebiasriskassessmentsincriminalsentencing barocas solon andrew selbst “big data’s disparate impact” california law review june httpsdoiorg1015779z38bg31 calo ryan “artificial intelligence policy primer roadmap” uc davis law review citron danielle keats “technological due process” washington university law review kaminski margot e “the right explanation explained” ssrn scholarly paper rochester ny social science research network june httpspapersssrncomabstract3196985 kleinberg jon sendhil mul ainathan manish raghavan “inherent tradeoffs fair determination risk scores” 8th innovations theoretical computer science conference itcs edited c h papadimitriou dagstuhl schloss dagstuhl— leibnizzentrum fuer informatik httpsdoiorg104230lipicsitcs201743 krol joshua et al “accountable algorithms” university pennsylvania law review miller tim “explanation artificial intelligence insights social sciences” arxiv170607269 cs june httparxivorgabs170607269 mulligan deirdre kenneth bamberger “saving governancebydesign” california law review pasquale frank black box society secret algorithms control money information cambridge harvard university press selbst andrew solon barocas “the intuitive appeal explainable machines” fordham law review march surden harry “artificial intelligence law overview” georgia state university law review chapter beyond bias chelsea barabas ai discourse reform term “artificial intelligence” ai come gone popular parlance number times since 1950s used reference wide range computational methods1 rather specific methodological regimen ai best understood sociotechnical concept comprised set logics technocratic practices encode particular way understanding world given context2 context us penal system term “ai” repeatedly invoked part contested discourse reform recent incarnation long lineage state efforts use statistics assert legitimacy times significant social change upheaval3 crime statistics long served foundation intense ideological struggles understand role carceral state managing criminal behavior precise way distinguishing “artificial intelligence” datadriven decisionmaking regimes criminal law mainstream academic discourse ai us penal system encompasses hodgepodge computational techniques ranging pamela mccorduck machines think personal inquiry history prospects artificial intel igence ak peterscrc press madeleine clare elish danah boyd “situating methods magic big data ai” communication monographs –michel foucault powerknowledge selected interviews writings –pantheon naomi murakawa first civil right liberals built prison america oxford university press khalil gibran muhammad condemnation blackness harvard university press tony platt “ ‘street’ crime—a view left” social justice journal crime conflict world order chelsea barabas decadesold actuarial practices machine learning algorithms possible era “big data”broadly speaking technologies mixture new old statistical methods measure strength associations set data points outcome interest techniques correlational core—their outputs typical come form probabilistic distributions read forecasts predictions future events criminal law data used build statistical models usual administrative information collected local police departments administrations court interpreted using proba bilistic computational methods5 contemporary debates regarding ai criminal law occurring time increased demand within law enforcement agencies “upgrade” popular discourse regarding legitimacy carceral state6 last three decades rates incarceration united states skyrocketed united states incarcer ates largest number people world rate four times greater world average7 statistics driven gross overrepresentation minority groups prison—black latinx inmates make percent federal prison population majority state prison populations8 wide range scholar ship documented unprecedented scale impact discriminatory police practices9 mass incarceration10 emphasizing developments neither natural sustainable response challenges legitimacy carceral state authoritative discourse reform emerged one conceives bias inefficiency main issues tackle rubric “evidencebased reform” center efforts call development adoption datadriven technologies ostensibly support fair efficient policing courtroom practices using regression machine learning algorithms context decadesold actuarial tools sarah brayne “big data surveil ance case policing” american sociological review –andrew guthrie ferguson rise big data policing surveil ance race future law enforcement nyu press ruha benjamin “catching breath critical race sts carceral imagination” engaging science technology society –christopher hartney “us rates incarceration global perspective” national council crime delinquency november httpswwwnccdglobalorgsitesdefaultfilespublication pdffactsheetusincarcerationpdf kel lytle hernández khalil gibran muhammad heather ann thompson “introduction constructing carceral state” journal american history –michael w sances hye young “who pays government descriptive representation exploitative revenue sources” journal politics –sharon dolovich “exclusion control carceral state” berkeley journal criminal law craig haney “the psychological impact incarceration implications postprison adjustment” prisoners removed impact incarceration reentry children families communities beyond bias “ethical ai” criminal law rebranded “ai” expanded data collection framed pragmatic political neutral way forward amid increased social upheaval11 term “ai” often used reference development machine learning algorithms “trained” recognize patterns trends large data sets interest algorithms fueled part growing appetite availability data within law enforcement agencies12 state collects increasingly large amounts data commensurate growth interest large technology compa nies ibm palantir amazon partner government agencies order hone state’s data analytics capacities publicprivate partnerships often framed “winwin” col aborations ones enable expansion state crime control capabilities simultaneously giving private tech companies competitive advantage race develop sophisticated analytics platforms partnerships given rise slew new technologies branded “artificial intelligence” sold police departments administrations court across country brand ai often invoked means creating superhuman capabilities within law enforcement—ai machine ingest impartial learn data fumes human experience without ever growing tired13 effort gain access large government datasets industry embraced law enforcement target customer building tools support reproduce operational logics carceral state pursuit “fair accountable transparent” algorithms response growing number studies measure disparate impact criminal justice practices racial minorities14 number leaders across political spectrum called adoption scientific tools could increase accuracy efficiency criminal justice operations checking implicit bias officials context hope regression machine learning algorithms example response growing concerns police brutality fbi director james comey argued “the first step understanding real going gather better data related arrest confront breaking law jeopardizing public safety confront us data seems dry boring word without cannot understand world make better” james comey—address race law enforcement georgetown university speech race law enforcement washington dc httpswww americanrhetoriccomspeechesjamescomeygeorgetownraceandlawhtm sarah brayne “surveil ance system avoidance criminal justice contact institutional attachment” american sociological review –christopher rigano “using artificial intelligence address criminal justice needs” nij journal october httpswwwnijgov443journals280pagesusingartificialintelligenceto addresscriminaljusticeneedsaspx michelle alexander new jim crow mass incarceration age colorblindness new press bruce western punishment inequality america russell sage foundation chelsea barabas used course correct cognitive pitfal implicit biases key decision makers system presenting evidencebased claims likelihood future events framing issue disparate impact way academics government officials effectively circumscribe issue racial disparity terms individual held beliefs preferences rather byproduct widespread organizational practices cultural norms15 hoffmann points technology firms also embraced unconscious bias social challenge effectively overcome help datadriven technology implicit bias understood phenomenon “is somehow apart us yet infect decisionmaking opposed something variously systematical cultivated maintained”in uncritical framing problem historical crime data characterized objective facts neutral “view nowhere”that stands stark contrast flawed fickle opaque subjectivity human decision makers example discourse driving rapid proliferation pretrial risk assess ments across united states sold means overriding judges’ intuitive decisionmaking processes may “erroneously unwit tingly introduce bias acquired stereotypes”or succumb wellknown cogni tive pitfal “availability bias”proponents pretrial risk assessment point growing literature behavioral science il ustrate common cognitive fal acies legal decision makers order make case actuarial tools could support objective accurate decisions20 context contentious social issues massive increases pretrial deten tion rates reframed data processing challenges key decision makers nal noise” making timesensitive decisions potential dangerous individuals21 riskassessment instruments purportedly home predictive murakawa first civil right liberals built prison america anna lauren hoffmann information communication society –hoffmann “where fairness fails data algorithms limits antidiscrimination discourse” donna haraway “situated knowledges science question feminism privilege partial perspective” feminist studies –matthew demichele et al “the intuitiveoverride model nudging judges toward pretrial risk assessment instruments” cass r sunstein “algorithms correcting biases” social research sharad goel et al “the accuracy equity jurisprudence criminal risk assessment” equity jurisprudence criminal risk assessment december chris guthrie jeffrey j rachlinski andrew j wistrich “blinking bench judges decide cases” cornell law review jon kleinberg et al “algorithmic fairness” aea papers proceedings vol aea –richard berk et al “fairness criminal justice risk assessments state art” sociological methods research httpsdoi org1011770049124118782533 demichele et al “the intuitiveoverride model nudging judges toward pretrial risk assessment instruments” goel et al “the accuracy equity jurisprudence criminal risk assessment” kleinberg et al “algorithmic fairness” sunstein “algorithms correcting biases” beyond bias “ethical ai” criminal law factors outcome interest helping minimize occurrence “false positives false negatives” decisions time particularly important contexts risk management framed terms highstakes lifeanddeath situations little room error22 result predictive accuracy often held key selling point tools fact accuracy become fetishized measure tool’s worth—in cases life death doesn’t matter prediction accurate long is23 skeptics algorithmic tools criminal law also centered accuracy bias criticisms growing number researchers investigate ways protected class attributes race gender mediate accuracy outputs produced algorithmic tools including risk assessment predictive policing facial recognition software24 number highprofile studies argued algorithmic tools criminal law accurate burden inaccuracy disproportionately borne historical marginalized groups often subject higher false positive rates25 discrepancy accuracy usual talked terms bias—critics argue algorithmic tools run risk reproducing amplifying preexisting biases system concerns given rise influential community researchers academia industry formed new regulatory science26 rubric demichele et al “the intuitiveoverride model nudging judges toward pretrial risk assessment instruments” goel et al “the accuracy equity jurisprudence criminal risk assessment” sunstein “algorithms correcting biases” example spite fact less percent pretrial defendants arrested violent crime awaiting trial fear rape murder repeatedly mentioned academic literature presents risk assaulted raped killed important issue consider alongside well documented harms detention scholars repeatedly bring rare crimes point contrast welldocumented harms pretrial incarceration fear violent crime repeatedly invoked interviews judges well mainstream press covering issue pretrial release example talk prominent statistician criminologist argued “i’m trying explain criminal behavior i’m trying forecast shoe size sunspots predicts person’s gonna commit homicide want use information even idea works” richard berk forecasting criminal behavior crime victimization chicago ideas httpswww youtubecomwatchvrolfhpeglvqt105s julia angwin et al “machine bias” propublica may httpswwwpropublicaorg articlemachinebiasriskassessmentsincriminalsentencing joy buolamwini timnit gebru proceedings machine learning research kristian lum james johndrow “a statistical framework fair predictive algorithms” arxiv161008077 cs stat october httparxiv orgabs161008077 angwin et al “machine bias” buolamwini gebru “gender shades intersectional accuracy disparities commercial gender classification” jacob snow “amazon’s face recognition falsely matched members congress mugshots” american civil liberties union blog july httpswwwacluorgblogprivacytechnologysurveil ancetechnologiesamazons facerecognitionfalselymatched28 sheila jasanoff fifth branch science advisers policymakers cambridge harvard university press chelsea barabas community criminal law applications served prominent thought exercises used il ustrating tradeoffs different technical choices design implementation algorithmic tools efforts coalesced around two general approaches widely branded “algorithmic fairness” development formal fairness criteria accuracy measures il ustrate tradeoffs different algorithmic interventions development “best prac tices” managerialist standards maintaining baseline accuracy transparency validity algorithmic systems following sections outline two approaches greater detail ultimately arguing technocratic conceptions bias accuracy adequate conceptual anchors discussion since fail interrogate deeper normative theoretical methodological premises predictive systems context criminal law formalized fairness criteria initial focus fat algorithm community map mathematical formalisms onto complex legal concepts discrimination disparate impact equal opportunity affirmative action27 researchers claim goal create foundation robust debates social desirability algorithmic tools providing “conceptual precision” form mathematical formalisms regarding tool’s fairness28 number researchers pointed fairness criteria mutual incompatible29 given rise deeper questions criteria fairness met across groups30 limitations framed terms tradeoffs must debated resolved casebycase basis formalizing tradeoffs widely considered pragmatic approach criminal justice reform example prominent criminologist recently cowrote paper number computer scientists arguing “one cannot expect tool reverse centuries racial injustice gender inequality” criminal justice system31 kleinberg et al “algorithmic fairness” solon barocas ad selbst “big data’s disparate impact” california law review moritz hardt eric price nati srebro “equality opportunity supervised learning” advances neural information processing systems –cynthia dwork et al “fairness awareness” proceedings 3rd innovations theoretical computer science conference acm –berk et al “fairness criminal justice risk assessments state art” richard berk machine learning risk assessments criminal justice settings springer berk et al “fairness criminal justice risk assessments state art” alexandra chouldechova “fair prediction disparate impact study bias recidivism prediction instruments” big data –kleinberg et al “algorithmic fairness” example theoretical impossible design classifier simultaneously satisfies false positive parity “predictive value parity” equal calibration across protected classes chouldechova “fair prediction disparate impact study bias recidivism prediction instruments” berk et al “fairness criminal justice risk assessments state art” beyond bias “ethical ai” criminal law instead argued job technical researchers delineate tradeoffs different decisions quantifiable terms transparently adjusted reflect preferences values different communities hope formalized definitions fairness increase transparency various tradeoffs bolster inclusive public discourse regarding social desirability tools32 context criminal law “equity” “fairness” “accuracy” defined math ematical formalisms pitted one another competing values never ful resolved unless fundamental change “base rates” criminal activity across groups33 researchers argue differences false positive rates across racial populations real differences prevalence criminal activity across groups bias algorithm34 argu ments “unequal base rates” criminal activity uncritical characterized endemic issue across protected groups rather byproduct discriminatory policing courtroom practices35 result number scholars warned attempts balance false positive false negative rates risk assessments could result higher rates victimization communities color would result less accurate risk classifications arguments risk violent crime mur der frequently invoked berk argues “by far leading cause death among young africanamerican males homicide likely perpetrators homicides young africanamerican males legitimate concerns fair risk assessments accused perpetrators concerns consequences fair risk assessments possible victims fair”berk’s assertion based false binary distinction “victims” “perpe trators” violent crime spite growing body literature established significant overlap across victim offender populations—yesterday’s victim likely become tomorrow’s perpetrator vice versa37 moreover berk uses statistics violent death african americans justification racial profiling preemp kleinberg et al “algorithmic fairness” berk machine learning risk assessments criminal justice settings chouldechova “fair prediction disparate impact study bias recidivism prediction instruments” sam corbettdavies sharad goel “the measure mismeasure fairness critical review fair machine learning” arxiv preprint arxiv180800023 goel et al “the accuracy equity jurisprudence criminal risk assessment” kleinberg et al “algorithmic fairness” berk machine learning risk assessments criminal justice settings corbettdavies goel richard berk using ml criminal justice risk assessments—the frontiers machine learning raymond beverly sackler forum httpswwwyoutubecomwatchvgdepprhnu34 anthony w flores kristin bechtel christopher lowenkamp “false positives false negatives false analyses rejoinder ‘machine bias there’s software used across country predict future criminals it’s biased blacks’ ” federal probation –berk machine learning risk assessments criminal justice settings wesley g jennings alex r piquero jennifer reingle “on overlap victimization offending review literature” aggression violent behavior chelsea barabas tive policing african american communities khalil muhammad cal rhetorical strategy “violence card” whereby proponents crimeforecasting tools present statistics face seem speak according people muhammad argues “by knowing black people need conversation responsibility lies outside black community” treatment38 muhammad argues tactic based long tradition respectability politics us carceral discourse whereby harsh pre emptive policing practices communities color understood solely terms deficiencies within communities people seemingly incapable treating even civility39 result “accurate” risk assessments detentionoriented risk management strategies often accompany pos ited interventions serve best interests communities even means subjecting higher rates false positive misidentification managerialist “best practices” light tensions arise given “unequal base rates” criminal activity many researchers fat community made “don’t let perfect enemy good” appeal arguing tool’s social value best understood comparative terms—do algorithmic decisionmaking aids produce accurate predictions human decision maker would make own40 researchers characterize crit icisms algorithmic bias impractical perfectionist arguing current statisti cal practices perfectly accurate provide pragmatic means improving overall accuracy transparency highstakes decisions criminal law41 bolster claims scholars point literature behavioral sciences order argue large algorithms outperform human decision makers accurately predicting outcomes like recidivism42 others tried empirical test “human versus machine” formulation historical crime data however khalil gibran muhammad numbers lie intersectional violence quantification race radcliffe institute advanced study httpswwwyoutubecom watchvbr0zytguw9mt2713s statistics eschew fact vast majority individuals arrested result policies like “stop frisk” arrested nonviolent petty offenses riding bicycle sidewalk public intoxication loitering etc offenses nothing increasing safety african american communities khalil gibran muhammad condemnation blackness—khalil gibran muhammad book talk john jay research new york https wwwyoutubecomwatchvstkbai6874t392s berk et al “fairness criminal justice risk assessments state art” goel et al “the accuracy equity jurisprudence criminal risk assessment” sunstein “algorithms correcting biases” jared sylvester edward raff “what applied fairness” arxiv preprint arxiv180605250 berk machine learning risk assessments criminal justice settings demichele et al “the intuitiveoverride model nudging judges toward pretrial risk assessment instruments” goel et al “the accuracy equity jurisprudence criminal risk assessment” sunstein “algorithms correcting biases” beyond bias “ethical ai” criminal law studies proven challenging criminal justice scenarios counterfactual data available measuring comparative accuracy different decisions ie know incarcerated person would gone commit another crime released challenge stopped researchers taking elaborate measures impute missing data order make bold claims whether algorithmic prediction accurate human forecast43 researchers posit algorithms potential serve force equity appropriate safeguards could put place minimize overall bias maximize accuracy predictions end sought address issues bias accuracy criminal jus tice algorithms reformulating terms narrower technical issues data local jurisdictions44 scholars pointed practices crucial understanding impact changing conditions specific policy interventions criminal justice system time45 end growing body litera ture within academia industry aims outline standards best practices ethical implementation predictive algorithms46 general speaking frameworks aim minimize specific types bias sample bias label bias etc procedural semiregular validations predictive mod els order maximize purported accuracy minimize wellestablished forms statistical bias procedures important first step toward addressing specific subset issues regarding tool’s validity generalizability insuffi cient addressing deeper issues regarding way claims constructed based available data following section argue bias accuracy inadequate con ceptual anchors discussing social implications tools since fail interrogate deeper theoretical methodological premises dataintensive algorithmical mediated systems limits “fat” algorithms previous arguments regarding accuracy objectivity built shared epistemological assumption arrest conviction incarceration data best kleinberg et al “algorithmic fairness” goel et al “the accuracy equity jurisprudence criminal risk assessment” jon kleinberg et al “discrimination age algorithms” ssrn february dg robinson jl koepke “danger ahead risk assessment future bail reform” washington law review megan stevenson “assessing risk assessment action” minnesota law review arnold foundation “arnold ventures statement principles pretrial justice ” httpswww arnoldventuresorgworkpretrialjustice accessed april christopher bavitz et al “assessing assessments lessons early state experiences procurement implementation risk assessment tools” berkman klein center research publication –berk machine learning risk assessments criminal justice settings chelsea barabas interpreted information individual populationlevel criminal activity rather data primarily reflect law enforcement activity deeper histor ical disparities police court officials treat different groups pursue various types crime47 numerous researchers pointed fundamental meas ure ment errors occur people uncritical characterize criminal justice data solely terms individual’s proclivity toward crime48 scholars long argued crime statistics partial biased incompleteness delineated clearly along power lines49 arrest statistics best understood meas ure ments law enforcement practices tend focus “street crimes” carried lowincome communities color neglecting illegal activities carried affluent white contexts50 similarly conviction incarceration data primarily reflect decisionmaking habits relevant actors judges prosecutors probation officers rather defendant’s criminal proclivities guilt51 light criticisms scholars called systematic recharacterization arrest conviction incarceration data data inform important conver sations regarding disparate impact specific policing courtroom practices ochigame argues recharacterization would precipitate fundamental shift attribution agency responsibility made claims based data away “antisocial behavior” “risky individuals” toward carceral system sur veils arrests prosecutes incarcerates people disparate ways52 ultimately scholars argue arrest conviction incarceration data accurate measures crime crime synonymous danger potential harm community yet mainstream characterizations police court data continue fuel deeply problematic conflations concepts like arrest dangerousness53 exam ple kleinberg et al conflate arrest statistics criminal activity order impute data probability defendant recidivating awaiting trial54 delbert elliott “lies damn lies arrest statistics” center study prevention violence sharon dolovich “exclusion control carceral state” berkeley journal criminal law david harris “the reality racial disparity criminal justice significance data collection” law contemporary problems rodrigo ochigame “the illusion algorithmic fairness” march seth j prins adam reich “can avoid reductionism risk reduction” theoretical criminology –platt “ ‘street’ crime—a view left” michelle brown judah schept “new abolition criminology critical carceral studies” punishment society –laura nader “crime category—domestic globalized” crime’s power springer –platt “ ‘street’ crime—a view left” harris “the reality racial disparity criminal justice significance data collection” ochigame “the illusion algorithmic fairness” lauryn p gouldin “distangling flight risk dangerousness” brigham young university law review paula maurutto kel hannahmoffat “assembling risk restructuring penal control” british journal criminology –ochigame “the illusion algorithmic fairness” kleinberg et al “algorithmic fairness” beyond bias “ethical ai” criminal law calculations used bolster argument regarding whether pretrial risk assessments accurate judges predicting future crime conver sation eschews fact pretrial detention constitutional permissible except cases judge finds clear convincing evidence defendant poses significant flight risk danger community robinson koepke point concept “dangerousness” ill defined courts led sig nificant expansion use pretrial detention55 spite persistently low inci dence rearrest violent crime56 given extremely low rates pretrial arrest violent crime proven quite challenging develop actuarial risk assessments meaningful differentiate pretrial population according risk events example public safety assessment average difference failure rates defendants categorized “low” “high” risk violent crime less six percentage points57 however two layers abstraction—a sixpoint ordinal scale “violence flag”— mask meager relative differences across risk categories making challenging practitioners real reckon question risk even relative risk probabi listic terms58 moreover number pretrial risk assessments provide risk score “new crimi nal activity” estimates likelihood defendant rearrested robinson koepke “danger ahead risk assessment future bail reform” illinois circuit court cook county “model bond court initiative” httpwww cookcountycourtorghomemodelbondcourtinitiativeaspx stevenson “assessing risk assessment action” pretrial services agency dc “release rates pretrial defendants within washington dc pretrial services agency dc “performance measures ” httpswwwpsa govqdataperformancemeasures last visited may court services offender supervision agency district columbia fy agency financial report nov many jurisdictions kentucky washington dc cook county rate arrest violent crime pretrial reported low less percent tools specifical aim measure rearrest violent offense psa compas vast majority defendants percent predicted arrested violent offense awaiting trial sandra g mayson “dangerous defendants” yale law journal “psa results reference making release conditions matrix” template nd https psapretrialorg psa optimized predictive accuracy would simply classify defendants offense awaiting trial yet rather optimize accuracy developers psa opted create binary categorization scheme flags defendants rate ordinal scale “high risk” spite fact percent defendants go arrested crimes inevitably generates higher number “false positives” people “flagged” danger go commit violent crime outputs reality masked descriptions characterize defendants flagged danger “three times likely arrested violent crime” billie grobe “plenary guiding pretrial release wpsa” september statement technical true framing masks disturbing fact average difference arrest rates high lowrisk defendants tools like psa less six percentage points “psa results reference making release conditions matrix” chelsea barabas offense awaiting trial59 general recidivism score sometimes provided additional point consideration decision makers spite fact supreme court state high courts recognized likelihood nonviolent rearrest constitutional permissible reason detaining someone prior trial fact date supreme court approved pretrial detention someone accused “a serious crime presents demonstrable danger community”yet uncommon tools actively conflate likelihood rearrest dangerousness example colorado pretrial assessment tool defines risk offenses61 still tools nevada pretrial risk assessment merge flight dangerousness one aggregate risk score poses additional set challenges62 developers assessments often define outcomes terms general recidivism order produce stronger associations inputs outcome variables statistical models results significant expansion number defendants rated “moderate” “high” risk pretrial failure fuels widespread conflation general rearrest dangerousness conflation generalized risk arrest dangerousness serious implications police judges interact justiceinvolved individuals case pretrial risk assessment lead unwarranted detention people convicted crime serious ripple effects terms housing employment instability disruption social support structures increased likelihood conviction63 proponents risk assessment often make perfunctory acknowledgements issues regarding unwarranted pretrial detention go place beside concerns regarding community safety citing murder rape assault serious issues weigh harms widespread pretrial incarceration64 ironical associations likely fuel logical fal acies scholars purport mitigate developing tools placing widespread example pretrial risk assessments florida virginia ohio indiana federal courts purport evaluate public safety risks yet define outcome arrest new crime violent offenses mayson “dangerous defendants” united states v salerno us timothy schnake “ ‘model’ bail laws redrawing line pretrial release detention” center legal evidencebased practices april scholars warned combining flight dangerousness one score lead overestimation types risk make challenging identify effective risk mitigating interventions gouldin “distangling flight risk dangerousness” dobbie jacob goldin crystal yang “the effects pretrial detention conviction future crime employment evidence randomly assigned judges” american economic review –arpit gupta christopher hansman ethan frenchman “the heavy costs high bail evidence judge randomization” journal legal studies misdemeanor pretrial detention” stanford law review dobbie goldin yang randomly assigned judges” berk machine learning risk assessments criminal justice settings kleinberg et al beyond bias “ethical ai” criminal law practice like pretrial detention beside rare occurrence arrest violent crime scholars like sunstein fuel “availability bias” whereby perception violent crime heightened due frequency invoked mainstream academic discourse regarding pretrial release65 conflation may reflect widespread beliefs held justice practitioners associate number prior arrests proclivity toward violence66 rather challenging assumption academic articles industry white papers official government documents tend reinforce confla tion using general rearrest data proxy danger providing risk scores “fundamental misattribution agency”in justice data persistent confla tion rearrest “danger” renders moot conversations regarding accuracy pretrial risk assessment forecasts data used measure accuracy simply representative outcome interest researchers recognize limits available data insist making claims crime prediction framing prob lem question “sample bias” “label bias” effort make tools accurate valid authors provide quick technical fixes addressing narrow conceptualizations bias68 efforts reinforce false association arrest history dangerousness conceal fundamental misat tribution agency69 insistence misleading framings police court data fueled crucial rhetorical role play justifying punitive decisions representative framings data would produce less powerful claims would give rise research ques tions directly challenge practices logics carceral state political economy algorithmic systems rests largely fundamental misattribution agency make authoritative claims individual’s criminal proclivities fuel legitimize decisions punish70 way predictive algorithms based widespread mischaracterizations data underpin moral econ omy justifies exclusion repression marginalized populations construction “risky” “deviant” profiles71 example sunstein argues “if defendants incarcerated longterm consequences severe lives ruined defendants released might flee jurisdiction commit crimes people might assaulted raped killed” kind sidebyside comparison detention versus murder makes prospect unwarranted detention seem rather minor comparison risk lost life sunstein “algorithms correcting biases” theme come repeatedly interviews done judges pretrial justice officials last two years ochigame “the illusion algorithmic fairness” berk machine learning risk assessments criminal justice settings goel et al “the accuracy equity jurisprudence criminal risk assessment” ochigame “the illusion algorithmic fairness” harris “the reality racial disparity criminal justice significance data collection” muhammad condemnation blackness ochigame “the illusion algorithmic fairness” dolovich “exclusion control carceral state” harris “the reality racial disparity criminal justice significance data collection” michael j lynch “the power oppression understanding history criminology science oppression” critical criminology –chelsea barabas critical criminologists long argued interpretations crime data performative enactments power structures ones fundamental shape dis course methods epistemological assumptions criminology law enforcement practices72 yet positivist subfields discipline continue build predictive models forecast “dangerousness” “new criminal activity” “recidivism” based data issue recurring tension within field criminology since turn nineteenth century meaning arrest incarceration statistics census debated early scholars crime73 1920s 30s actuarial methods forecasting criminal behavior relied heavily incorrect framings arrest conviction incarceration order make fal acious claims crime prediction74 wake civil rights movement 1960s critical criminologists argued drastic increases official crime statistics byproduct administrative changes crimes reported result real spikes crime75 pointed alternative sources crime data order resist conflation racial unrest criminality late 1960s76 recently david harris cites numerous examples law enforcement offi cials used arrest incarceration statistics justify racial profiling 1990s77 officials pointed statistics reflect overrepresentation african americans latinx jails order justify racial profiling argued officers stopped searched disproportionate number minorities racial animus quite simply data showed “that’s criminals are”these officials used arrest incarceration data substitute crime rate laid foundation state’s recursive logic whereby used inter nal generated numbers arrest incarceration justification continuing practices fueled numbers discourse regarding “fair accountable transparent” ai recent incar nation historical struggle interpretation justice data date lion’s share research area uncritical embraced epistemological assumptions mainstream criminology continue long tradition centering reforms “sciences oppression” seek profile surveil marginalized brown schept “new abolition criminology critical carceral studies” platt “ ‘street’ crime—a view left” muhammad condemnation blackness bernard e harcourt prediction profiling policing punishing actuarial age vesla weaver “frontlash race development punitive crime policy” studies american political development –platt “ ‘street’ crime—a view left” harris “the reality racial disparity criminal justice significance data collection” id officials conveniently overlook data revealed “false positive” rate much higher african american males meaning number times searched population found nothing much higher racial groups harris pierson et al “a largescale analysis racial disparities police stops across united states” arxiv preprint arxiv170605678 beyond bias “ethical ai” criminal law communities79 scholarship provides mechanism confinement control “dangerous classes” also creates processes populations turned deviants controlled feared summary attempts render tools accurate addressing narrow notions “bias” simply miss deeper methodological epistemological issues regarding fairness tools hoffmann argues must grapple ways dataintensive algorithmical mediated systems reinforce certain discursive frames others—only begin unpack ways systems shape constrain ability collectively pursue particular visions justice80 efforts increase accuracy predictive systems run risk circumscribing deeper ideological epistemological struggles within narrow technocratic debate make tools valid accurate fair way forward challenging fundamental assumptions current political moment conversation regarding fat algorithms proven highly influential shaping state federal legislative efforts reform case pretrial risk assessment number states passed legislation acknowledges risk bias riskassessment tools call establishment oversight committees standards ensure specific types bias minimized semiregular validation using updated data local jurisdictions81 efforts much aligned narrow formulation “bias” embraced many fat community eschewing deeper concerns regarding epistemological soundness tools yet growing number thinkers calling ai applications question fundamental grounds example response highprofile efforts increase representation african americans data sets facial recognition software sake increasing software’s accuracy82 nabil hassein argues reality foreseeable future people control deploy facial recognition technology consequential scale predominantly oppres sors desire faces legible efficient automated processing arnold foundation “arnold ventures statement principles pretrial justice” hoffmann “where fairness fails data algorithms limits antidiscrimination discourse” sarah desmarais evan lowder “pretrial risk assessment tools primer judges prosecutors defense attorneys” macarthur foundation safety justice challenge february buolamwini gebru “gender shades intersectional accuracy disparities commercial gender classification” chelsea barabas systems design struggle liberation struggle diversity inclusion—it struggle decolonization reparations selfdetermination83 contrast mainstream reform efforts hassein recontextualizes issue artificial intelligence within structural critique carceral state fundamental punitive system social control rejects attempts improve accuracy technologies designed make system accurate efficient hassein proposes different set values base counterimaginary future carceral state one centers pursuit agency healing within historical marginalized communities important note approach reject wholesale use data technology carceral state rather requires radical reformulation key concepts assumptions undergird adoption new technologies means reform context—shifting away measuring criminal proclivities toward understanding processes criminalization supporting law order increasing community safety selfdetermination surveil ance risky populations accountability state officials shifting fundamental assumptions important inform questions worth asking data constitute relevant authoritative evidence epistemological assumptions used make claims based available evi dence order truly address ethical stakes artificial intelligence must embrace radical different “sociotechnical imaginary” order redefine “not attainable science technology also life ought ought lived”this requires fundamental shift conceive object analysis datadriven regimes reform rather using data profile manage “risky populations” build systems scrutinize impacts key policies decisionmaking practices well build robust systems accountability authority figures drive outcomes understanding role function carceral state provides us critical framework need order fundamental reformulate questions ask way characterize existing data identify fill gaps existing data regimes carceral state igniting critical sociotechnical imaginary especial important current political moment term “artificial intelli gence” deployed means justifying depoliticizing expansion state private surveil ance amidst growing crisis legitimacy us prison industrial complex authoritative rubric “evidencebased reform” terms technocratic shortcomings issues information access interpretation nabil hassein “against black inclusion facial recognition” digital talking drum blog facialrecognition sheila jasanoff sanghyun kim dreamscapes modernity sociotechnical imaginaries fabrication power university chicago press beyond bias “ethical ai” criminal law efforts increase accuracy predictive evaluative systems run risk circumscribing deeper ideological epistemological struggles within narrow technocratic debate make processes valid accurate fair key question whether predictive tools reflect reinforce punitive practices drive disparate outcomes data regimes interact penal ideology naturalize practices conversations regarding ethical stakes ai criminal law must interrogate default logics assumptions carceral state order address foundational violence law enforcement courtroom practices hope reimagine use data technology explore substanti ate political vision centers creation lasting alternatives punishment imprisonment increasing community safety centering values selfdetermination healing marginalized communities bibliography benjamin ruha “catching breath critical race sts carceral imagination” engaging science technology society –brown michelle judah schept “new abolition criminology critical carceral studies” punishment society –corbettdavies sam emma pierson avi feller sharad goel aziz huq “algorithmic decision making cost fairness” proceedings 23rd acm sigkdd international conference knowledge discovery data mining –acm elliott delbert “lies damn lies arrest statistics” center study prevention violence ferguson andrew guthrie “policing predictive policing” washington university law review harcourt bernard e prediction profiling policing punishing actuarial age university chicago press kleinberg jon jens ludwig sendhil mul ainathan ashesh rambachan “algorithmic fairness” aea papers proceedings vol –aea muhammad khalil gibran condemnation blackness harvard university press ochigame rodrigo “the illusion algorithmic fairness” cambridge march stevenson megan “assessing risk assessment action” minnesota law review chapter age ai kiel brennanmarquez introduction ought know advance law demands them1 something funda mental gone awry much organization state power may exhibit certain functional characteristics legal system longer important sense lawful2 stated formal hard imagine ideal inspiring much pushback elusive practical implications cases dealing “fair notice” problems—vague ness challenges instance—are often long rhetoric short conceptual clarity lon l fuller morality law new yale university press –expounding point memorable example king rex shon hopwood “clarity criminal law” american criminal law review –tracing history “fair notice” principle makes fair notice central rule law interesting question largely leave one side analysis aimed simply enrich concept fair notice assumption concept worth taking seriously trying vindicate passing however note commentary fair notice writ large—why care notice first place—seems focus almost entirely instrumental arguments notice primarily valuable perhaps exclusively valuable facilitating private ordering see scott shapiro legality new york belknap press arguing law “plan” metaphorical speaking extension enables citizens living law make plans robert ellickson order without law cambridge harvard university press friedrich hayek road serfdom chicago university chicago press though one certainly course imagine nonconsequentialist arguments favor notice perhaps tel us something state thinking due process legality today—or state thinking general y—that nonconsequentialist arguments centered dignity say careful developed kiel brennanmarquez spite perhaps hallowedness notice principles persisted many centuries little elaboration unfortunate—for many reasons especial going forward “fair notice” among key concepts regulating scope role ai legal system ai like junior sibling machine learning unleashes historical novel possibility decisionmaking tools powerful accurate inscrutable human stewards subjects3 determine use aibased aiassisted decisionmaking tools consistent requirements hence present chapter develop tripartite model “fair notice” inspired problems—and opportunities—of ai specifical argue lack “fair notice” used interchangeably describe three distinct often overlapping properties notice inputs notice outputs notice inputoutput functionality disentangling forms notice deciding matter contexts reasons crucial proper governance ai particularly respect inputoutput functionality persistent ambiguity mode notice relevant people “on notice” inputoutput function works understanding function necessary must function transpar ent explainable sufficient least circumstances people heuristical understanding function—that pragmatic conception imperfect stable inputs tend lead outputs boiled upshot chapter answer last question “yes” fact may times heuristical understanding superior actual standing inputoutput function better put reason demand actual understanding cultivate heuristical understanding latter ulti mately matters affected parties practice happens significant gov ern ance implication follows independently care about—and could principle dispense with—actual understanding inputoutput functionality long heuristi cal understanding developed means chapter three parts first craft tripartite model notice weaving doctrine drawn us constitutional law normative theory connecting burgeoning questions ai governance second distinguish finely two variants notice inputoutput functionality—actual see solon barocas andrew selbst “the intuitive appeal explainable machines” fordham law review kiel brennanmarquez “ ‘plausible cause’ explanatory standards age powerful machines” vanderbilt law review general background link explainability accountability frank pasquale “a rule persons machines limits legal automation” george washington law review jonathan manes “secret law” georgetown law journal heuristical—and explore reasons might care one rather third close offering remarks implications various categories ai immediate longerterm future tripartite model “fair notice” imagine legal rules inputoutput functions—such given rule described infinitely complex bundle inputsets sufficient trigger output form adverse treatment—then “fair notice” describe three different things first describe notice inputs asking whether one “fair notice” law might asking knew known inputsets occasion adverse treatment straightforward type notice one genuinely know conduct occasions adverse treatment rule law tripped gate4 second describe notice outputs asking whether one “fair notice” law might asking knew known consequences might occasioned inputset relevant question “will conduct x occasion adverse treatment” rather “what kind adverse treatment—or severe adverse treatment—does conduct x occasion” third describe notice inputoutput functionality asking whether one stood process given inputset maps specific adverse treatment conduct x result—or likely result—in consequence three strongest form notice satisfied entails notice first two dimensions wel notice inputs begin beginning conduct—which inputsets—occasion adverse treat ment commentators diverse blackstone kafka trained attention question5 many canonical notice rules strive ensure ordinary people move world least rough beginnings answer example concern notice inputs long understood animate rule lenity canon construction criminal immigration proceedings statute genuinely ambiguous two readings ties go speak defendant otherwise one could subject adverse treatment basis see kiel brennanmarquez “extremely broad laws” arizona law review discussing notice problem—in “notice inputs” sense—in greater detail see william blackstone commentaries franz kafka trial kiel brennanmarquez conduct—or language inputsets—that reasonable person could regarded entirely lawful6 true vagueness challenges vague statutes problematic us supreme court made clear enshrining “unascertainable standards” leave “people common intelligence guess law’s meaning”part problem course arbitrary enforcement danger application unascertain able standards may come “depend” example “on whether policeman annoyed”but iceberg’s tip even setting practical concerns enforcement one side simply unfair “ordinary people understand conduct prohibited”it violates “notions fair play”because leaves people mercy enforcement system even managing avoid egregious miscarriages justice defies comprehension supreme court’s ex post facto jurisprudence also strives ensure people punished conduct could known time limits “basic principle fairness” supreme court made clear reaches back common law11 ordinary people right insist govern ment rather legislating “vindictively” retroactively “abide rules law establishes advance”as madison summarized point ex post facto lawmaking “contrary first principles social compact”people must furthermore concern regarding notice inputs limited adverse treatment ordinary people also reaches adverse treatment state officials supreme court crafted numerous doctrines—qualified immunity promi nently—to shield officials liability decisions reasonable actor could thought lawful fact supreme court even gone far excuse police officers know law performing stops arrests pursuant see eg united states v santos us discussing rule lenity criminal context ins v st cyr us ditto immigration context coates v city cincinnati us quoting connal v general const co us us kolender v lawson us see also johnson v united states ct harsher sentences convictions involving “conduct presents serious potential risk physical injury another”—on ground openended standard “denies fair notice defendants invites arbitrary enforcement judges” connal v general const co us peugh v united states us holding sentencing based guidelines promulgated offense conviction occurred violates ex post facto clause see carmell v texas us holding conviction obtained pursuant rule evidence changed conduct question—but trial itself—constituted ex post facto punishment federalist peugh us supreme court’s recent comprehensive statement qualified immunity doctrine see district columbia v wesby us legal error long error reasonable rationale essence would unfair hold officers accountable mistakes law reasonable person reading relevant statute good faith would notice16 airelated examples inputopacity legion would hardly exaggeration say notice inputs notice concern preoccupied scholars ai governance space date17 simple reason writing status quo impoverished regard notice inputs—since information tech nology developed private sector informationcollection practices ultimately responsible populating airelated inputs poorly understood—the proverbial fruit hangs remarkably low deprecate importance notice regarding inputs latter certainly important often necessary condition mean ingful understanding decisionmaking works18 point simply benefits notice inputs beginning end conversation ai governance notice outputs ought come little surprise notice inputs end line due process doctrine courts also worry good reason notice outputs even little doubt person ought notice conduct x would occasion adverse treatment also entitled understanding ex ante type—and severity—of treatment recent il ustration principle marinel v united states centered usc § 7212a socalled “omnibus clause” internal revenue code sec 7212a criminalizes act “corruptly force threat force obstructing impeding endeavoring obstruct impede due administration taxes”see heien v north carolina us see frank pasquale black box society cambridge harvard university press danielle citron “technological due process” washington university law review –data due process toward framework redress predictive privacy harms” boston college law review explaining “for big data deliver answers seek must accurate include appropriate inputs equal overcome signal problems”—and pointing problems result inputs unclear see eg barocas selbst “the intuitive appeal explainable machines” describing happens “faceless bureaucracies make consequential decisions” affected parties “have understanding” exercise “no input” see also david luban alan strudler david wasserman “moral responsibility age bureaucracy” michigan law review arguing one central purposes law securing “what might call moral intel igibility lives” expounding “horror bureaucratic process” much “officials’ mechanical adherence duty” “individuals’ ignorance” permitted prohibited required citizens see usc § 7212a kiel brennanmarquez dispute kinds “obstruction” “impediment” qualify predicate acts omnibus clause far level actus reus clause reach according government answer simple clause reaches noncompli ance tax rules legal argument equal simple “impediment” means “a thing impedes” doubt deliberate acts noncompliance impede overall administration taxes supreme court disagreed holding petitioner justice breyer argued irs’s construction “impediment” despite tracking word’s definition simply encompassed many lowlevel infractions “interpreted broadly” breyer reasoned withholding taxes leaves large cash tip restaurant fails keep donation receipts every charity contributes fails provide every record accountant”and would violate “fair warning” principle—the identical twin fair notice—that long “led court exercise interpretive restraint”crucial however reason government’s construction flouted “fair warn ing” principle minor wrongdoing—such paying babysitter without withholdings—is permissible plainly violates tax code problem reasonable person could expected aware relevant law ignorance ordinarily excuse violations22 point justice breyer explicitly acknowledged possibility someone pays babysitter without withholdings lated irs rule”the problem one committed minor offense words problem penalty’s severity exactly mismatch penalty’s severity conduct’s relative harmlessness issue marinello—by opinion’s terms—is notice outputs notice inputs idea people fail appreciate paying babysitter table equivalent prohibited idea even assuming prohibition clear well known still gap statute’s clear language rea sonable expectations statute actual enforced words whole point marinello someone fails withhold payments ba sit ter—even knows wrong indeed even knows technical fal within scope usc § 7212a—would never imagine held criminal liable line felony tax obstruction variable formal reach tax law drove “fair notice” analysis id background babysitter example particular see cfr § –1a2017 irs publication –marinello v united states ct see eg edwin meese paul larkin jr “reconsidering mistake law defense” journal criminal law criminology discussing proposition length ct id cases like marinello supreme court explicitly acknowledges mismatch inputsets outputs—conduct penalty—are somewhat rare given longstanding prohibition “proportionality” analysis us constitutional law hardly unheard of25 importantly idea law give people notice likely penalties intuitive point selfevident would clearly insuf ficient legal order hand us laundry list proscriptions without hint conduct less vile less prone harsh consequences26 hypothetical somewhat unrelatable course real world typi cal rely rough correlation malum se malum prohibitum legal order hardly unimaginable—and lack notice particular comes offers glimpse however fleeting nightmare ai context problems regarding notice outputs take variety forms one thing proportionality mismatches along lines marinello—input sets produce outputs seem intuitive sense extreme another thing “resilience” issues circumstances marginal changes inputset result drastic changes relevant output depriving people meaningful another recent example maslenjak v united states ct government argued “false statement” made naturalization process matter innocuous regardless many years decades elapsed since statement occurred sufficient basis revoke someone’s citizenship supreme court made short work position explicitly identifying breadth one infirmities see tr oral arg –maslenjak v united states ct –“roberts looked naturalization form question it’s number ‘have ever committed assisted committing attempted commit crime offense arrested’ time ago outside statute limitations drove miles hour mph zone arrested say answer question years naturalized citizen knock door say guess you’re american citizen al counsel well— roberts right counsel wel would say two things first government would interpret saying form expect everyone list every time drove speed limit take away citizenship” see also mellouli v lynch ct moncrieffe v holder ct raised question whether extremely minor conduct reflected statelevel convictions trigger deportation—in mellouli conduct possessing sock “drug paraphernalia” whereas moncrieffe possessing grams marijuana social use equivalent two three small cigarettes cases supreme court held conduct insufficient occasion severe penalty use language “fair notice” cases certainly understood operate register another example along lines supreme court’s punitive damages jurisprudence defendant may well notice conduct question forbidden—that conduct formed basis liability—but surely notice possible consequences since punitive damages could anywhere 1x 100x actual damage see eg state farm mut auto ins v campbel us “a defendant punished conduct harmed plaintiff unsavory individual business due process permit courts calculation punitive damages adjudicate merits parties’ hypothetical claims defendant guise reprehensibility analysis” kiel brennanmarquez understanding consequences conduct likely bring about27 course two problems perhaps others well operate tandem notice inputoutput functionality third conception “fair notice” people aware inputsets occasion adverse treatment sort adverse treatment likely also process conduct x maps consequence front examples doctrine elusive since supreme court rarely ever articulates fair notice terms relationship conduct legal consequences let alone language “inputoutput functionality” light shines cracks numerous areas criminal procedure example take root principle understand particular inputsets lead particular legal consequences take fourth amendment’s particularized suspicion standard requirement police develop probable cause performing certain kinds searches seizures notice inputs outputs—if x z likely stopped searched arrested also giving people insight process x z might taken justify stops searches arrests namely x z might taken justify stops searches arrests likely seem reasonable observer like indicia wrongdoing likely context give rise plausible inference criminality28 sense particular ized suspicion standard conveys ordinary people inputsets con ducive adverse treatment inferential mechanisms state officials—here police officers—will link inputs outputs point comes crisply perhaps courts navigate boundary investigative searches require particularized suspicion “adminis trative searches” delaware v prouse example supreme court considered whether police may perform suspicionless traffic stops verify—essential spot check—drivers’ licenses vehicular registrations29 state defended program theory core purpose administrative idea encour age compliance licensing registration laws investigate criminal ac tiv ity30 supreme court disagreed holding suspicionless vehicle stops even pursued administrative reasons seemed much like gardenvariety police work “interfere freedom movement inconvenient consume time”see alex stein foundations evidence law oxford oxford university press see also marjorie mcdiarmid “lawyer decision making problem prediction” wisconsin law review –diagnosing lack resilience issue highlighted l jonathan cohen’s famous “gatecrasher” hypothetical background gloss fourth amendment see brennanmarquez plausible cause us id –id fundamental blessing suspicionless vehicle stops would cast pall uncertainty driving times32 fact distinguishes suspicionless stops say road blocks sobriety checkpoints contained particular areas times33 prouse canonical holding rightly second rationale—that suspicionless stops spotcheck licenses registration would cast shadow driving— highlights importance inputoutput functionality government’s position essence subject suspicionless searches condition driving deciding drive delaware would knowingly assume risk endure suspicionless searches knowingly take sorts burdens related driving buying insurance argument hardly sounds crazy indeed may even sound plausible focus solely notice inputs outputs problem simply told driving stops likely occur say matters input “driving” maps output “stop” without understanding functional difference— literal functions indistinguishable—between good faith decisions arbitrary decisions biased decisions pretextual decisions like inputoutput functionality actual notice heuristical notice yet case like prouse even identifies need notice inputoutput functionality establish sort notice required particular tell us whether key variable inputsets actual yield outputs rather inputsets correspond outputs regardless underlying causal mechanisms refer former “actual notice” latter “heuristical notice” ambiguity surprising answer ultimately static depends normative goal motivates call notice goal equip potential affected parties like drivers understanding actions likely invite versus avoid certain outcomes like entanglement law enforcement—a goal might take many forms stem different founts describe umbrel terms “navigability”—heuristical notice inputoutput functionality may sufficient id describing concern terms “substantial anxiety” suspicionless licensecheck regime would create drivers see illinois v lidster us holding suspicionless stops “information seeking” checkpoints okay mich dep’t state police v sitz us likewise sobriety checkpoints see also prouse us emphasizing predictable elements logistics traffic checkpoints “the motorist see vehicles stopped see visible signs officers’ authority much less likely frightened annoyed intrusion” kiel brennanmarquez fact may even superior actual notice insofar latter despite disclosing information fails enhance navigability nonexperts ground hand normative goal something beyond navigability—if point say affirm dignity affected parties help understand avoid certain outcomes—heuristical notice may fall short even al cases true moreover point constrain decisionmaking along certain highsalience dimensions example reason care looking “under hood” certain inputoutput functions forbidden eg marshal variables like race gender unfair ways course heuristical notice substitute actual notice heuristical notice—the observation certain inputs correspond certain outputs—is prompts normative concern alleviates complicating matters demands greater insight inputoutput func tionality easily practice framed terms actual notice even true linchpin heuristical notice—making difficult reason backward types notice people say care credit scores example long area notorious opacity inspiring commentators agitate favor greater transparency34 always clear—in fact frequently unclear—why realm opacity troubling opacity troubling navigability grounds people affected credit system ought control scores heuristi cal notice may sufficient fact noted earlier may preferable actual notice depending level technicality latter operates35 many cases surely useful ordinary person hear “adjustments variables prehensive equationladen “notice” scoring algorithm course problem creditscoring opacity goes beyond simply runs orthogonal navigability heuristical understanding unlikely suffice idea pick sides rather appreciate demand actual notice could either misguided entirely instrumental heuristical notice though articulated misleadingly noninstru mental terms—and either errors could occur without parties front lines policy debates aware last point especial important given rhetorical appeal actual notice inputoutput functionality aspiration actual notice—understanding world actual operates—is natural call arms absence inspires outrage possi bility represents easy focal point mobilization dynamics notwithstand ing always clear actual notice matters fact clear even absent dynamics least bracketing argument’s sake take demands actual notice entirely seriously given confusion surrounds fair notice general see danielle citron frank pasquale “the scored society due process automated predictions” washington law review see barocas selbst “the intuitive appeal explainable machines” describing feature heuristical understanding terms “intuitiveness” practical speaking two risks first demands actual notice fall short political consequently quote old maxim perfect prove enemy good say heuristical notice matters actual notice becomes ral ying cry danger end neither—no actual notice inputoutput functionality represents heavy lift heuristical notice either heuristical notice emphasized first instance second risk sense graver risk actual understanding—even assuming proves tenable ideal practice—will deliver heuristical understand ing al possible understand inputoutput functionality literal sense without “ready hand” navigable understanding function operates practice last point consider simple nonai example mary wants know likely stopped police central park violating “antivagrancy” statute essence wishes know constitutes “vagrancy” functional merely mal sense answer question would mary better served read munici pal antivagrancy statute attend police training enforcement priorities parks ing municipal antivagrancy statute observe patterns actual police conduct local park weeks answer course depends kind understanding mary looking statute unlikely much help course also unlikely entirely useless—at least assump tion municipal codes bear relation police actual also likely aspects relevant inputoutput functionality elude formal cod ification making likely either attending training observing officers “in wild” promising methods giving mary actual sense police conduct business yet distinction two methods training access point actual understanding whereas patterns observed park access point heuristical understanding one mary care depends goal goal would surely case many ordinary people better cali brate behavior avoid intrusion police clear method superior could sitting police training would tell patterns park—since al training pull back curtain departmental priorities—but could also observing police sustained period time paying scrupulous attention variables correspond intrusion practice tell more36 possibilities along lines abound take one particularly obvious sadly uncommon example suppose reality vagrancy stops occur much frequently based race target pattern unlikely presumably surface training though may well surface observational patterns kiel brennanmarquez hypothetical underscores relationship actual heuristical understanding often flux making important precise ultimate goals goal make decisionmaking system navigable possible ordinary people heuristical understanding ought priority hardly means actual understanding irrelevant—it may serve functions importantly may operate service heuristical understanding—but help keep goal focus relates ai ambiguity actual heuristical understanding anything even severe absolute limits least given existing technology capacity ai systems principle convey actual understanding operation means put bluntly actual understanding aspiration necessity aibased systems may simply disallowable—at least time hand goal heuristical understanding suspect many cases aibased systems verboten simply require observation aspect natural world immediately understand anal ogy cognitive extrapolation may need test aibased systems best figure behave affected parties might best respond hardly cause pessimism alarm contrary experimentalism long operative mechanism heuristical knowledge makes good news bad news level news namely many set tings care actual understanding—making socalled “black box” problem many guises overstated—but care heuristical understanding means acclimation matters need time adjust aibased decisions real decisionmaking system yet ingrained course humans work different register different timeframe machines little surprise would need fair notice principles would necessitate time get bearings concluding thoughts ai closing want offer thoughts tripartite model notice applies ai immediate future longer term much existing debate ai governance mobilized around “notice inputs” problem soon— perhaps quite soon—cease focal point policy discussion short order find world notice inputs though important plainly insuf ficient render ai systems accountable soon come embrace reality grasping ai systems work beyond access data propels ultimately matters nevertheless remains open question whether comes notice input output functionality ai cal actual understanding heuristical understanding contexts goal navigability answer may principle least heuristical understanding sufficient raises natural next question heuristical understanding best achieved contrast example like mary wishing know antivagrancy statute operates many us least present lack capability—in terms resources skil tools expertise—to observe operation aisystems “in wild” capability certainly developed indeed may come pass natural worth considering wil require particular two issues may limit capability develop heuristical understanding aidriven systems first “intuitiveness” problem second—and level mirror image—is “stationarity” problem “intuitiveness” problem ai outputs insusceptible meaningful human interpretation say human observer aware inputset leads particular output—can even tested outcome scientifical assured understands heuristical “how system works” par ticular context—but still idea why37 course ignorance may prove ephemeral learning world observing instances ai system’s operations simply thinking problem may il uminate underlying causal dynamics yet possibility nonintuitiveness even face robust heuristical knowledge persists—representing important bound heuristical understanding38 “stationarity” problem contrast way human modeling lags behind static patterns reality way static human modeling even temporarily right outpaced changes reality internal dynamic ten dency data thus datadriven systems reason nonstationary systems prove difficult navigate operation opaque human understanding rather human understanding quickly becomes obsolete39 short aibased systems defy intuitive modeling even ample time observe them—and even intuitive modeling possible easily drained value aibased system adapts course issues nonaibased systems wel mary tries discern enforcement patterns park always possible observe patterns resist everyday causal narrative andor observe patterns that—maybe even mary’s observations— see james grimmelmann daniel westreich “incomprehensible discrimination” california law review online explaining intuitiveness problem exploring various statistical solutions practice clear intuitive conception causality neither necessary sufficient capture actual causality even putting aside deep philosophical issues attend causality general clear people embrace “narratives” causality deeply flawed still delivering discovered ai system—that actual correct nevertheless deeply unintuitive given one’s current understanding world dynamics see barocas selbst “the intuitive appeal explainable machines” –see motoaki kawanabe masashi sugiyama machine learning nonstationary environments cambridge mit university press kiel brennanmarquez longer hold mary’s case least likely outward indicators understanding wears thin observe patterns facts jibe existing causal theory reevaluate experiment craft new heuristical account operation however demands sense context aisystems—at least given current technology—lack40 going forward one thing need determine much “sense” responsible ultimately safeguarding heuristical understanding systems power shape lives—and whether sense might replicated fastapproaching world ai answer suspect lies fate bibliography barocas solon andrew selbst “the intuitive appeal explainable machines” fordham law review brennanmarquez kiel “ ‘plausible cause’ explanatory standards age powerful machines” vanderbilt law review brennanmarquez kiel “extremely broad laws” arizona law review citron danielle “technological due process” washington university law review citron danielle frank pasquale “the scored society due process automated predictions” washington law review crawford kate jason schulz “big data due process toward framework redress predictive privacy harms” boston college law review grimmelmann james daniel westreich “incomprehensible discrimination” california law review online manes jonathan “secret law” georgetown law journal pasquale frank black box society cambridge harvard university press pasquale frank “a rule persons machines limits legal automation” george washington law review see hubert dreyfus computers still can’t critique artificial reason cambridge mit university press chapter ai migration management petra molnar introduction highrisk experiments new technologies migration experiments new technologies migration management increasing unprecedented number people move due conflict instability environ mental factors economic reasons receiving countries contend influx large populations straining resources challenging border enforcement national security result many states international organizations involved migration management exploring technological experiments manage migration big data predictions population movements mediterranean canada’s use automated decisionmaking immigration refugee applications artificial intelligence ai lie detectors deployed european borders states inter national organizations un high commissioner refugees unhcr keen explore use new technologies yet often fail take account profound human rights ramifications real impacts human lives introduction new technologies effect processes outcomes associated decisions would otherwise made administrative tribunals immigration officers border agents legal analysts officials responsible administration immigration refugee systems border enforcement refugee response management technological implementations often come promise increased fairness efficiency however technological implementation exposes existing power relations society technology inherently democratic human rights impacts particularly important consider humanitarian forced migration contexts ethics go far enough—what needed focus rights responsibilities enforcement mechanisms international human rights law petra molnar framework particularly useful codifying recognizing potential harms technology development inherently global transnational develop ment use new technologies migration management largely unregulated oversight accountability mechanisms safeguard fundamental rights freedom discrimination privacy rights procedural justice safeguards right fair decision maker rights appeal technologies margins ai making decisions ai machine learning automated decision systems predictive analytics series overlapping terms refer class technologies assist replace judg ment human decision makers systems process information form input data using algorithm generate output migration context training data body case law collection photographs database statistics precategorized labeled based designer’s criteria technologies used various ways augment even replace human decision maker various facets migration management technology developing rapid pace states engaged international race ai leadership “new gold rush”this influx interest investment made ai machine learning attractive wellfunded research areas public private sectors alike yet rush innovation occurs without robust global governance mechanisms climate global innovation experimental new tech nologies injected management migration whether border spaces refu gee camps administrative decisionmaking response complex issues like global migration millions states organizations eager see new technologies quick solution otherwise tremendously complex often intractable policy issues however algorithms widely criticizes socalled black boxes2 algorithm’s source code training data inputs may pro prietary shielded public scrutiny bases intellectual property legislation confidential business assets moreover algorithms used immigration refugee matters form nexus issues national security shul “in global race ai ensure we’re creating better world” centre international governance innovation february httpswwwcigionlineorgarticles globalraceaihowdoweensurewerecreatingbetterworld see f pasquale black box society secret algorithms control money information explainability practical guide managing risk machine learning models” future privacy forum june httpsfpforgwpcontentuploads201806beyondexplainabilitypdf ai migration management input data source code may also classified3 however without able scrutinize input data understand algorithm starts make decisions iterate improve upon unpredictable unintelligible ways logic becomes less less intuitive human oversight speed new technologies developed introduced various aspect public private life quite extraor dinary particularly given limited safeguards discussions around regulation given already problematic track record discrimination grounds race4 gender5 human rights civil liberties infringements introducing new technologies opaque discretionary space migration management risks unintended consequences profound impacts human lives mechanisms redress oversight6 immigration irisscanning iborderctrl new technologies migration management immigration refugee decisionmaking sits uncomfortable legal nexus impact rights interests individuals often significant even degree deference high procedural safeguards weak also seri ous lack clarity surrounding courts interpret administrative law principles like natural justice procedural fairness standard review automated decision system concerned four major areas concern emerging technological experimentation migration management data collection biometrics informed consent crimi nalization surveil ance automated decisionmaking datadriven humanitarianism automated decisionmaking technologies require vast amount data learn7 states international organizations increasingly experimenting petra molnar lex gil “bots gate human rights analysis automated decision making canada’s immigration refugee system” httpsihrplawutorontocasites defaultfilesmediaihrpautomatedsystemsreportwebpdf see shapiro “reform predictive policing” nature january httpswwwnaturecom newsreformpredictivepolicing121338 see example simonite “machines taught photos learn sexist view women” wired august archived httpspermacc8kuqlpjc molnar gil “bots gate” j balkin “free speech algorithmic society big data private governance new school speech regulation” university california davis law review petra molnar using socalled big data predict population flows conflict deliver humanitarian aid services based predictions8 big data analytics require extremely large sets analyzed patterns associations make determi nations likelihood future human behavior multiple organs united nations begun relying big data analytics inform policies example international organization migration’s displacement tracking matrix9 monitors populations move better predict needs displaced people data sets used make predictions include mobile phone call records geotagging well analyses social media activity data analytics also used predict likely successful outcomes resettled refugees based preexisting community links united states10 also rise use biometrics acteristics” migration management biometrics11 include fingerprint data retinal scans facial recognition well less wellknown methods recognition person’s vein blood vessel patterns ear shape gait among others united nations relying populating data sets biometrics collecting bio data eight million people12 fleeing conflict needing humanitarian assistance however data collection apolitical exercise particularly powerful global north actors states international organizations collect information vulnerable populations regulated methods oversights accountability increasingly fervent collection data migrant populations criticized potential result significant privacy breaches human rights concerns13 example case collecting biometric data rohingya refugees myanmar socalled datafication refugee responses result oppressive governments easily de backer “big data international migration” united nations global pulse pulse lab diaries june httpswwwunglobalpulseorgbigdatamigration united nations development programme undp testing online tool used country offices aggregating visualizing data collecting order facilitate tracking analyzing risks local contexts crisis risk dashboard undp httpwwweuropeundporgcontent genevaenhomepartnershipstheglobalriskplatformhtml international organization migration “displacement tracking matrix ” httpswww globaldtminfo accessed march shashkevich “stanford scholars develop new algorithm help resettle refugees improve integration” stanford news january httpsnewsstanfordedu20180118 algorithmimprovesintegrationrefugees biometrics institute “what biometrics” httpswwwbiometricsinstituteorgwhatis biometrics accessed march enormous data sets notoriously hard track also include retrofitting old data newly collected biometrics see example statements publicly made unhcr officials humanitarian congress berlin germany httphumanitariancongressberlinorg2018 j crisp “beware notion better data lead better outcomes refugees migrants” chatham house march httpswwwchathamhouseorgexpertcomment bewarenotionbetterdataleadbetteroutcomesrefugeesandmigrants ai migration management identifying groups removing encampments14 china also collecting facial recognition location tracking muslim minority uighur populations socalled “muslimtracking database”this data collection marginalized groups deeply historical often openly jus tified group power necessary16 example nazi germany strategical collected vast amounts data jewish communities facilitate holocaust including various registration schemes food slave labor jews largely part nership international business machines corporation known today ubiquitous ibm17 various genocides also relied systematic tracking groups tutsi registries based ethnicity identity cards facilitated magnitude genocide post united states also experi mented various modes data collection suspicious populations us department homeland security’s national security entryexit registration system collected photographs biometrics even firstperson interview data flagged individuals coming mostly arab states registration new individuals program ceased collected data remains within purview us government state official publicly stat ing underlying regulatory framework remains place event spe cial registration “needed again”not long trump administration echoed sentiments plans create socalled “muslim registry” upheld us supreme court20 plans “extreme vetting initiative” dis cussed greater detail later chapter efforts highlight common goal tracking particular groups guise data always better even global efforts global compact safe orderly regular migration foreground preoccupation collecting data listing data collection first twentythree objectives21 e thomas “tagged tracked danger rohingya got caught un’s risky biometric database” wired march httpswwwwiredcoukarticle unitednationsrefugeesbiometricdatabaserohingyamyanmarbangladesh c cimpanu “chinese company leaves muslimtracking facial recognition database exposed online” zdnet february httpswwwzdnetcomgoogleamparticlechinesecompany leavesmuslimtrackingfacialrecognitiondatabaseexposedonlinetwitterimpressiontrue r baretto “emerging algorithms borders belonging” humanity action https wwwhumanityinactionorgknowledgebase779emergingalgorithmsbordersandbelonging e black ibm holocaust strategic al iance nazi germany america’s powerful corporation new york ny dialog press z rahman “dangerous data role data collection genocides” engine room httpswwwtheengineroomorgdangerousdatatheroleofdatacollectioningenocides arab american institute “national security entryexit registration system nseers” httpwwwaaiusaorgnseers accessed march trump v hawaii –us united nations general assembly “intergovernmental conference adopt global compact safe orderly regular migration” aconf2313 signed december petra molnar increasingly antiimmigrant global landscape criticisms also surfaced migration data also misinterpreted misrepresented political ends22 example affect distribution aid dol ars resources inaccurate data also used stoke fear xenophobia seen characterization23 group migrants attempting claim asylum us–mexico border societal fear used justification increasingly hardline responses contravene international law present profound concerns around basic civil liberties human rights biometrics consent collection vast amounts data particular groups also presents issues around data sharing access24 exchanging data humanitarian crises biometric iden tification often presented way increase efficiency interagency interstate cooperation benefits collection accrue equal data collection use new technologies particularly spaces clear power differentials raise issues informed consent ability opt example people jordanian refugee camps irises scanned order receive weekly food rations experimental new program able meaningful say live discomfort experience biometric data collected want feed families week contexts like efficiency seems trump human dignity investigation inside azraq refugee camp25 refugees interviewed uncomfortable technological experiments felt could refuse wanted eat consent cannot truly informed freely given given coercion even coercive circumstances masquerade effi ciency promise improved service delivery moreover individuals choose participate activities use biometric digital devices social media— whether due privacy concerns simply matter preference—may also subject prejudicial inferences credibility trustworthiness simply “opting out”further unclear collected biometric data going whether affected groups access data jordanian irisscanning pilot project nature editorial team “data movements refugees migrants flawed” nature flawed121568 accessed march silverman “the bogus demonization ‘migrant caravan’ ” conversation december httpstheconversationcomthebogusdemonizationofthemigrantcaravan107562 lyon “biometrics identification surveil ance” bioethics –b staton “eye spy biometric aid system trials jordan” irin may httpwww irinnewsorganalysis20160518eyespybiometricaidsystemtrialsjordan j vertesi “my experiment opting big data made look like criminal” time may httptimecom83200privacyinternetbigdataoptout ai migration management unhcr expressly reserved right collect share data third parties27 including private sector without clear safeguards significant privacy concerns united nations’ world food programme wfp also recently criticized partnering datamining company palantir technologies us45 million con tract sharing million aid recipients’ data palantir heavily criticized providing technology supports detention deportation programs run us immigration customs enforcement ice department homeland security28 yet clear datasharing accountability mechanism place wfppalantir partnership whether data subjects able opt similarly criminal justice context recent investigation united states also revealed voice prints “unique digitized vocal signatures enable authorities conduct voice recognition analysis cal s”are col lected people pretrial custody texas collection developed securus technologies prison telecommunications firm particularly problematic given legal norm people pretrial custody presumed innocent immigra tion context voice recognition routinely used canadian immigration deten tion alternative incarceration30 yet unclear whether data collected shared government agencies private sector fulsome discus sion human rights ramification particular technology beyond scope chapter noted data sharing people administrative detention fewer procedural safeguards criminal justice context likely breach various domestic international protected rights31 unhrc also contracts data management international firm accenture see example unhcr’s accenture contract httpswwwsciencedirectcomsciencearticlepii s0969476515301004 httpswwwaccenturecomt20161026t063323zwusenacnmedia accentureconversionassetsdotcomdocumentsglobalpdfdualpub15accentureunhcr innovativeidentitymanagementsystempdf k hao “amazon invisible backbone behind ice’s immigration crackdown” mit technology review october httpswwwtechnologyreviewcoms612335amazonisthe invisiblebackbonebehindicesimmigrationcrackdown see also k conger “amazon workers demand jeff bezos cancel face recognition contracts law enforcement” gizmodo june httpsgizmodocomamazonworkersdemandjeffbezoscancelfacerecognitio1827037509 lawsuit also recently launched new york civil liberties union httpswwwtheverge com2018121218138243nyclulawsuiticeimmigrationriskassessmenttool g joseph nathan “prison tech company questioned retaining ‘voice prints’ people presumed innocent” appeal february httpstheappealorgjailsacrossthe usareextractingthevoiceprintsofpeoplepresumedinnocent blanchfield “canada use voice recognition monitoring technology keep migrants detention” global news july httpsglobalnewscanews4350419canadamigrant detentionpolicy mayhew “canada turns biometric voiceprint tech monitor refugee claimants” biometric updatecom july httpswwwbiometricupdatecom201807 canadaturnstobiometricvoiceprinttechtomonitorrefugeeclaimants see also p molnar “algorithms new jailers use new technologies immigration detention human rights implications” special issue—refuge journal fall petra molnar criminalization securitization autonomous technologies also increasingly used monitoring securing border spaces example frontex european border coast guard agency testing various unpiloted militarygrade drones mediterranean sur veil ance interdiction migrants’ vessels hoping reach european shores facili tate asylum applications32 roborder project aims create “ful yfunctional autonomous border surveil ance system unmanned mobile robots including aerial water surface underwater ground vehicles”various dronerelated projects also explored morocco countries serve jumpingoff points frontiers socalled fortress europe united nations also experimenting drones various humanitarian spaces better deliver aid drone corri dor malawi34 usage military quasimilitary autonomous technology bol sters nexus immigration national security increasing push toward criminalization migration global states particularly frontiers large numbers migrant arrivals using various ways preempt deter seeking legal apply asylum35 normative shift toward criminalization migration works justify increasingly hardline intrusive technologies drones various borderenforcement mechanisms like remote sensors inte grated fixedtowers infrared cameras mitigate “threat environment” border36 technologies drastic results socalled “smartborder”technologies called “humane” alternative trump administra tion’s cal physical wal studies documented policies prevention deterrence using new surveil ance technologies along usmexico border actual increased migrant deaths pushed migration routes toward dan gerous terrains arizona desert38 chambers et al found migrant r csernatoni “constructing eu’s hightech borders frontex dualuse drones border management” european security –european union “aims objectives” eu horizons research project https robordereutheprojectaimsobjectives accessed april un secretary general “secretarygeneral’s strategy new technologies” available httpwwwunorgennewtechnologiesimagespdfsgsstrategyonnewtechnologiespdf see general atak j simeon criminalization migration context consequences ibid similar technologies also deployed various sited throughout european union see example european commission “technical study smart borders” available httpsec europaeuhomeaffairssiteshomeaffairsfileswhatwedopoliciesbordersandvisassmart borders docssmartbordersexecutivesummaryenpdf canada’s official position goes far say one main strategies “push borders out” using prescreening informationsharing enforcement cooperation mitigate risk far away borders possible see government canada “customs border management border management canada” january httpswwwcanadainternationalgccaeuuepoliciespolitiquesborderdouanesaspxlangeng ga boyce chambers launius “democrats’ ‘smart border’ technology ai migration management deaths tripled since new technologies introduced39 creating anthropologist de león called “land open graves”echoing rising numbers deaths mediterranean use technologies border enforcement likely increase “militarized technological regime”of border spaces without appropriate public consultation accountability frameworks oversights mechanisms individual automated decisionmaking immigration refugee decisions deal multiple complex migration crises states also experimenting auto mating various facets decisionmaking example since least canada using form automated decisionmaking immigration refugee system42 university toronto report examined human rights risks using ai replace augment immigration decisions argued processes create laboratory highrisk experiments within already highly discretionary opaque system43 ramifications using automated decisionmaking immigration refugee space farreaching hundreds thousands people enter canada every year variety applications temporary permanent status44 many come wartorn countries seeking protection violence per secution canadian government confirmed currently type technol ogy confined augmenting human decisionmaking reserved certain immigration applications only45 transparency oversight future development new technologies needed jurisdictions experiments automation already full force example wake trump administration’s executive orders enforcing immigration429454democratssmartbordertechnologyisnotahumanealternativetotrumps chambers g boyce launius dinsmore “mortality surveil ance tertiary journal borderlands studies httpswwwtandfonlinecomdoiabs101080088656552019157 0861journalcoderjbs ibid j de leon land open graves living dying migrant trail university california press csernatoni “constructing eu’s hightech borders” k keung “canadian immigration applications could soon assessed computers” toronto star january httpswwwthestarcomnewsimmigration20170105immigration applicationscouldsoonbeassessedbycomputershtml molnar gil “bots gate” government canada annual report parliament immigration available httpswwwcanadacaenimmigrationrefugeescitizenshipcorporatepublicationsmanuals annualreportparliamentimmigration2019html example temporary visa applications india china conversations immigration refugees citizenship canada author petra molnar increasingly hardline measures stem immigration vice media investigation revealed ice amending baildetermination algorithm usmexico border justify detention migrants every single case46 ice also unveiled mine probability applicant would “positively contributing member society” national interests predict whether intend commit criminal terrorist acts entering country47 countries australia new zealand also experimenting using automated facial recognition technology based biometrics identify socalled future “troublemakers” civil society organizations fighting grounds discrimination racial profiling48 discussed previously instances bias automated decisionmaking facial rec ognition type technology widely documented49 algorithms rely biased data produce biased results biases could farreaching results embedded emerging technologies used experimental migration example airports hungary latvia greece new pilot project company called iborderctrl introduced aipowered lie detectors border checkpoints50 passengers’ faces monitored signs lying system becomes “skeptical” series increasingly complicated questions person selected screening human officer however unclear system able handle cultural differences communication account trauma effects memory dealing traumatized refugee claimant51 refugee immigration claims filled nuance complexity qualities may lost automated technologies leading serious breaches international domestical protected human rights form bias discrimination privacy breaches due process oberhaus “ice modified ‘risk assessment’ software automatical recommends detention” vice june httpsmotherboardvicecomenusarticleevk3kw icemodifieditsriskassessmentsoftwaresoitautomatical yrecommendsdetention glaser “ice wants use predictive policing technology ‘extreme vetting’ program” slate august httpwwwslatecomblogsfuturetense20170808icewantstouse predictivepolicingtechforextremevettinghtml k weil “algorithm may decide httpswwwthedailybeastcomalgorithmmaydecidewhoisacontributingmemberofsociety civilrightsgroupswarn l tan “immigration nz’s data profiling ‘illegal’ critics say” new zealand herald april httpswwwnzheraldconznznewsarticlecfmcid1objectid12026585 see example j vincent “gender racial bias found amazon’s facial recognition technology again” verge january httpswwwthevergecom201912518197137 amazonrekognitionfacialrecognitionbiasracegender r picheta supra n hungary greece crucial entry points refugee claimants mainland europe perhaps accident locations chosen site experimentation issues also course exist human decision makers increasingly cogent critiques officers misunderstanding psychological effects repeated trauma impacts person’s ability testify appear “truthful” see example work h evans cameron refugee law’s factfinding crisis truth risk wrong mistake cambridge university press ai migration management procedural fairness issues among others example discussed greater detail following yet clear right fair impartial decision maker right appeal decision upheld use automated decisionmaking systems also increasing proliferation automated border gates stream travelers based facial recognition present major airports european union also criticized potential inculcating faulty facial recognition discrimination based euronormative tropes problematic private sector products designed support individuals interfacing immi gration refugee system also create new privacy risks example visabot facebook messengerbased ai application designed help users apply visas green cards schedule appointments us citizenship immigration service visabot also launched service specifical assist young immigrants53 qualify daca deferred action childhood arrivals program although program designed help atrisk migrants potential immigrants comes significant privacy security tradeoff—facebook compa nies like operates within business models primarily rely aggregation anal ysis resale users’ private information third parties advertisers unfortunately government surveil ance policing immigration enforcement border security programs incentivize reward industry developing rights infringing technologies54 among amazon’s “rekognition” surveil ance facial recognition system marketed explicitly use law enforce ment using deep learning techniques rekognition able identify track analyze individuals real time recognize one hundred people single image ana lyze collected information mass databases faces “persontracking” serv ice allow government identify investigate monitor “people interest” including crowded group photos public places airports technology already criticized american civil liberties union demanded amazon stop allowing governments use technology citing “profound civil liberties civil rights concerns”amazon shareholders also criticized company’s sale technology citing longstanding issues bias also increasing proliferation automated border gates stream travelers based facial recognition present major airports european union also criticized potential inculcating faulty facial recognition discrimination based euro normative tropes problematic “social sorting” see r barreto “emerging algorithms borders belonging” humanity action httpswwwhumanityinactionorgknowledgebase779emerging algorithmsbordersandbelonging k johnson “visabot helps cut greencard red tape” venture beat july httpsventurebeatcom20170711visabothelpsyoucutgreencardredtape n duarte “ice finds can’t automate immigration vetting what” cdt blog may httpscdtorgblogicecantautomateimmigrationvetting cagle n ozen “amazon teams law enforcement deploy dangerous new face recognition technology” american civil liberties union north california may httpswww acluncorgblogamazonteamslawenforcementdeploydangerousnewfacerecognitiontechnology petra molnar facial recognition software threat false positives risk markets technology would expand include authoritarian regimes abroad—all may impact company’s stock valuation increase financial risk amazon’s work force led call demanded amazon cut ties56 controversial data analytics firm called palantir technologies palantir responsible providing technology supports detention deportation programs run ice department homeland security amazon workers decried refugees immigrants nevertheless also encouraging developments example auto matic robotic life raft called emily emergency integrated lifesaving lanyard deployed waters around greek islands assist rescuing refugees58 unhcr experimenting bot examining xenophobia racism refugees online59 help advocacy strategies various ai techniques also used try predict likely success resettlement integration united states using historical data60 new digital verification technologies also made analyzing data coming conflict zones reliable beneficial refugees requiring evidence bolster claims protection61 machine learn ing also deployed mexico assist determining likely locations mass graves62 whole sector also proliferated around creating various apps assist refu gees accessing social services healthcare banking language acquisi tion including various initiatives techfugees foster entrepreneurship among refugee communities whose tagline “empowering displaced technology”however piecemeal interventions guise empowerment fail consider issues around emerging technologies management migration k conger “amazon workers demand jeff bezos cancel face recognition contracts law enforcement” gizmodo june httpsgizmodocomamazonworkersdemand jeffbezoscancelfacerecognitio1827037509 ibid j franz “it’s buoy it’s life raft it’s emily—the robotic craft that’s saving refugees coast greece” pri may httpswwwpriorgstories20170501itsbuoyitslife raftitsemilyroboticcraftssavingrefugeescoastgreece r moreno “teaching ‘robot’ detect xenophobia online” united nations high commissioner refugees httpwwwunhcrorginnovationteachingrobotdetectxenophobiaonline oxford university “using ai improve refugee integration” october httpwwwox acuknews20181002usingaiimproverefugeeintegration see example amnesty international’s digital verification project httpswwwamnestyorg enlatestnews201711amnestyinternationalandtrulymediajoinforcesinfightagainstfakenews j porup “hunting mexico’s mass graves machine learning” ars technica april httpsarstechnicacominformationtechnology201704huntingformexicosmassgraves withmachinelearning techfugees “techfugees empowering displaced technology” httpstechfugees com accessed march ai migration management inherent use technology rather used monopolies knowledge created function consolidate power authority technological development states private actors setting stage possible64 unequal distribution benefits technological development privileges private sector primary actor charge development states governments wishing control flows migrant populations bene fiting technological experiments governments primary agents benefit data collection65 affected groups relegated margins therefore surprising regulatory legal space around use tech nologies remains murky underdeveloped full discretionary decisionmaking privatized development uncertain legal ramifications international human rights law migration management technologies number international protected rights already engaged increasingly widespread use new technologies manage migration however currently integrated regulatory global governance framework use automated tech nologies specific regulations context migration management much global conversation centers ethics without clear enforceability mechanisms international human rights law framework useful codifying recognizing potential harms technology development inherently global translational ihrl states must commit preventing violations occur ring establish monitoring oversight provide remedy redress rights vio lations hold violators accountable66 also includes obligations state protect individuals harms perpetrated third parties including private entities67 however states willing experiment new unregulated technologies space migration precisely discretionary space opaque decision making moreover much migration management also enacted international organizations unhcr various bodies nonstate actors operating discussion algorithms impacts human imagination see e finn algorithms want imagination age computing mit press r okediji “does intellectual property need human rights” nyu journal international law politics un human rights committee “general comment nature legal obligation imposed states parties covenant” may un doc ccprc21rev1add paras –un human rights council “report special representative secretarygeneral issue human rights transnational corporations business enterprises john ruggie guiding principles business human rights implementing united nations petra molnar various legal quasilegal authorities regulations global international organizations “arenas acting power relationships”without beholden responsibilities states protect human rights life liberty farreaching impact new technologies lives security persons affected underestimated right life liberty one fundamen tal international protected rights highly relevant migration refugee con texts multiple technological experiments already impinge right life liberty stark example denial liberty migrants placed administrative detention usmexico border immigration detention already opaque discretionary phenomenon69 justification increased incar ceration basis algorithms tampered shows far state willing justify incursions basic human rights guise national security border enforcement cases individual faces psychological threat deportation country face substantial risk torture threat torture “security person” interest also engaged70 errors miscalibrations deficiencies training data result rightsinfringing outcomes equality rights freedom discrimination given problematic track record automated technologies race gen der plausible similar issues wil already occurred migration example proxies discrimination country origin used make problematic inferences leading discriminatory outcomes algorithms vulnerable decisionmaking concerns plague human decision makers transparency accountability discrimination bias error71 opaque nature immigration refugee decisionmaking creates environment ripe algorithmic discrimination decisions system—from whether refugee’s life story “truthful” whether evans p wilson “regime theory english school international relations comparison” mil ennium journal international studies silverman p molnar “everyday injustices barriers access justice immigration detainees canada” refugee survey quarterly –see example canadian supreme court jurisprudence suresh v canada minister citizenship immigration scc z tufekci “algorithmic harms beyond facebook google emergent challenges computational agency” colorado technology law journal –httpctljcoloradoedu wpcontentuploads201508tufekcifinalpdf ai migration management prospective immigrant’s marriage “genuine”—are highly discretionary often hinge assessment person’s credibility72 extent technologies used assess “red flags” “risk” “fraud” also raise definitional issues remains unclear parameters markers example experimental use ai lie detectors eu airports unclear constitute truthfulness differences crosscultural communication dealt order ensure problematic inferences encoded reinforced sys tem complexity human migration easily reducible algorithm privacy rights privacy consumer property interest human right rooted foun dational democratic principles dignity autonomy73 differential impacts privacy infringements must considered analyzing experiences migrants example collected information shared repressive governments refugees fleeing ramifications lifethreatening automated decision making systems designed predict person’s sexual orientation infiltrated states targeting lgbtq community discrimination threats life liberty likely occur facial recognition algorithm developed stanford university already purports discern person’s sexual orientation photos74 use technology particular ramifications refugee immigration context asylum appli cations based sexual orientation grounds often rely prove one’s persecu tion based outdated tropes around nonheteronormative behavior75 furthermore data collected using technologies could shared intercepted repressive governments person claiming asylum unsuccessful returned country origin76 power pattern recognition extract personal details available data concerning particularly given current proliferation surveil ance technologies already use authoritarian regimes77 see v satzewich points entry canada’s immigration officers decide gets ubc press v satzewich “canadian visa officers social construction ‘real’ spousal relationships” canadian review sociology httpsdoiorg101111cars12031 see l austin “we must treat data like natural resource” globe mail july httpswwwtheglobeandmailcomopinionarticlewemustnottreatdatalikeanaturalresource h murphy “why stanford researchers tried create ‘gaydar’ machine” new york times reehag “patrolling borders sexual orientation bisexual refugee claims canada” mcgill law journal see molnar gil “bots gate” privacy international submission evidence house lords select committee artificial intelligence london uk september petra molnar principles natural justice fair process discussion pertinent human rights migration must also include analysis administrative legal frameworks principles natural justice inherent much migration management example immigration refugee decision making procedural fairness dictates person affected administrative pro cesses right heard right fair impartial independent decision maker right reasons also known right explanation right appeal unfavorable decision however unclear administrative law han dle augmentation even replacement human decision makers algorithms example technologies often presented tools used human deci sion makers line machinemade humanmade decisionmaking often clear given persistence automation bias predisposition toward con sidering automated decisions accurate fair remains unclear rubric human decision makers use determine much weight place algorith mic predictions opposed information available including judgment intuition furthermore person wishes challenge algorithmic decision appropriate standard review look like inappropriate deference given algorith mic decisionmaking widely documented78 unclear tribunals courts assign reasonableness automated decisionmaking standards review used mechanisms redress look like technology far neutral reflects norms values power society development technology occurs specific spaces open everyone benefits accrue equal decisionmaking around implementation exper imentation occurs without consultation even sometimes without consent affected groups growing role private sector governance new tech nologies highlights movement away state responsibility create governance structures accordance domestic international principles guise pro prietary technology private interests discretion however private sector already independent responsibility ensure technologies violate international human rights79 technologists developers engineers responsible building technology also special ethical obligations80 ensure work facilitate human rights violations also emerging conversations around see koliska n diakopoulos “disclose decode demystify empirical guide algorithmic transparency” routledge handbook developments digital journalism studies ed scott eldridge ii b franklin routledge see also wilson “algorithms everyday” information communication society –united nations human rights office high commissioner “guiding principles businesses human rights implementing united nations ‘protect respect remedy’ framework” ke martin “ethical implications accountability algorithms” journal business ethics ai migration management taxation implications need require global governance around proprietary reliance public data81 tension private public regulation also highlights overall lack institutional capacity effectively regulate technology disjuncture develop migrationrelated technology private sector public sector deploy specific populations socalled ai divide gap able design ai broadening highlights problematic power dynamics participation agency comes rollout new technologies often viewpoints affected excluded discussion particularly around areas nogo zones ethical fraught usages overal lack contextual analysis thinking impact new technologies resulting great ethical social political harm conclusions accountability oversight mechanisms urgently needed currently global regulatory framework exists oversee use new technologies management migration much technological development occurs called “black boxes” intellectual property laws proprietary considerations shield public access data sets full understanding technology operates states private sector able develop test technologies without meaningful participation affected populations conversations around ethics data technology taking place ethics go far enough nec essary analyzing rights freedoms impacted setting meaningful regulatory frameworks accountability broad global strategies regional mechanisms explored need sharper focus oversight mechanisms private sector actors already de pend ent responsibility ensure technologies develop violate interna tional human rights technologists developers engineers responsible building technology also special ethical obligations ensure work facilitate human rights violations unfortunately government surveil ance immigra tions enforcement border security programs incentivize reward industry developing rightsinfringing technologies emerging technologies raise complex legal ethical issues businesses engineers alike going forward companies r medhora “ai global governance three paths towards global governance artificial intelligence” united nations university centre policy research october httpscprunu eduaiglobalgovernancethreepathstowardsaglobalgovernanceofartificialintelligencehtml petra molnar engaged sale new technology cannot turn blind eye ultimately used potential threat human rights states international organizations must also commit creating enforcing accountability oversight mechanisms bots gate report canada’s use automated decisionmaking immigration refugee applications highlights sev eral recommendations also applicable global commit transparency report publicly technology developed used adopt binding direc tives laws comply international protected human rights obligations establish independent body oversee review use automated technologies migration management foster conversations policymakers aca demics technologists civil society risks promises using new technologies emerging conversations also address affected communities’ lack involvement technological development rather developing apps technology “for” “about” refugees migrants collecting vast amounts data people lived experience migration center discussions around emerging technologies integrated refugee camps border security refugee hearings al bibliography austin l “we must treat data like natural resource” globe mail july httpswwwtheglobeandmailcomopinionarticlewemustnottreatdatalikea naturalresource benvenisti e “ejil foreword upholding democracy amid challenges new technology role law global governance” global trust working paper january chambers g boyce launius dinsmore “mortality surveil ance tertiary deterrence” journal borderlands studies httpswwwtandfonlinecomdoiabs 1010800886565520191570861journalcoderjbs carens j ethics immigration oxford university press crisp j “beware notion better data lead better outcomes refugees migrants” chatham house march httpswwwchathamhouseorgexpertcomment bewarenotionbetterdataleadbetteroutcomesrefugeesandmigrants csernatoni r “constructing eu’s hightech borders frontex dualuse drones border management” european security –farraj “refugees biometric future impact biometrics refugees asylum seekers” columbia human rights law review –johns f “data detection redistribution sensible international law” american journal international law magnet biometrics fail gender race technology identity durham duke university press mcgregor l murray v ng “international human rights framework algorithmic accountability” international comparative law quarterly –ai migration management molnar p lex gil “bots gate human rights analysis automated decision makin canada’s immigration refugee system” httpsihrplawutorontoca sitesdefaultfilesmediaihrpautomatedsystemsreportwebpdf noble us algorithms oppression search engines reinforce racism nyu press staton b “eye spy biometric aid system trials jordan” irin may httpwww irinnewsorganalysis20160518eyespybiometricaidsystemtrialsjordan zuboff shoshana age surveil ance capitalism fight human future new frontier power profile books chapter robot teaching pedagogy policy elana zeide overview today many people discuss problematic aspects artificial intelligence ai opacity notorious “black box”as scholars discussed lack transparency poses problems ensuring accuracy fairness contestability individual determinations group outcomes2 algorithmic opacity makes difficult individuals institutional actors understand basis decisions evaluate accuracy opacity particularly troubling institutions use machine learning make highstakes decisions individuals whether receive loan qualify job get parole3 academic media scrutiny use algorithmic tools predict suspects’ risk recidivism example revealed often inaccurate perpetute existing bias unintentional y4 scholars lawsuits see joshua krol solon barocas edward w felten joel r reidenberg david g robinson harlan yu “accountable algorithms” university pennsylvania law review danielle keats citron frank pasquale “the scored society due process automated predictions” washington law review kate crawford jason schultz “big data due process toward framework redress predictive privacy harms” boston college law review pauline kim “datadriven discrimination work” wil iam mary law review digital enlightenment yearbook –algorithmic accountability see eg nicholas diakopoulos et al “principles accountable algorithms social impact statement algorithms” fatml blog april httpwww fatmlorgresourcesprinciplesforaccountablealgorithms see citron pasquale “the scored society” kim “datadriven discrimination work” rebecca wexler “life liberty trade secrets intellectual property criminal justice system” stanford law review –see julia angwin surya mattu jeff larson lauren kirchner “machine bias there’s software used across country predict future criminals it’s biased blacks” elana zeide object public reliance algorithmic tools outcomes shielded oversight trade secret claims5 critics call regulations require transparency data sources algorithmic models group outcomes6 chapter highlights another important aspect public reliance privately developed ai tools displacement professional authority institutional account ability public policymaking education considers example ai instruc tional platforms often called “personalized learning systems” today’s technologies give schools ability outsource whole bundle tasks think “teaching” software must also define relevant subject matter metrics learning objectives—decisions traditional made highly democratic governance public school policymaking instructional software however rarely subject careful consideration community scrutiny applied facetoface teaching7 neglect cannot continue ai instructional platforms require trans parency public accountability avoid de facto delegation pedagogical policy choices shape america’s education system personalized learning systems since industrial revolution many proposed predicted “teaching machines” would automate part instruction process ai pioneer marvin minsky articu lated vision computercontrolled education still resonates today someone’s particular circumstances difficulties needs would help telling read stepping solutions teaching subject ways found effective textbooks could replaced systems know explain ideas particular would know background skil best learn8 propublica blog may httpswwwpropublicaorgarticlemachinebiasriskassessments incriminalsentencing see wexler “life liberty trade secrets” –state v loomis nw 2d wis see lauren kirchner “new york city moves create accountability algorithms” ars technica december margot e kaminski “binary governance lessons gdpr’s approach algorithmic accountability” southern california law review citron pasquale “the scored society” crawford schultz “big data due process” kim profiling era” –danielle keats citron “technological due process” washington university law review see infra “policy procurement” marvin l minsky push singh aaron sloman “the st thomas common sense symposium designing architectures humanlevel intelligence” ai magazine –robot teaching pedagogy policy today’s education technology still chases minsky’s dream schools increasingly turn technology automate teaching part however machine teachers embodied humanoid robots software driven artificial intelligence “per sonalized learning systems” mimic dynamic human teaching—that communicating information assessing student comprehension choosing appropriate feedback another educational experience response9 collect data learn ers’ every interaction digital platforms log much video watch even passages highlight use machine learning real time track students’ progress infer competency choose educational experience provide next—which might instructional materials practice exercises test questions struck feedback hints encouragement10 software uses historical data students similar profiles fared determine choice likely lead student success automated instruction easiest apply rulebased subject matter math computer science languages however personalized learning systems also employ natural language processing speech recognition semantic analysis assess learning textbased subjects english composition make noncogni tive inferences students’ emotional states motivation metacognitive skil col aborative problemsolving11 sum personalized learn ing systems may perform many functions expect human teachers classroom tracking learners’ progress real time adapting instruction accordingly robotic teachers become reality although go less threatening terms “personalized learning systems” “virtual teaching assistants” “smart” classrooms “intelligent tutors”potential benefits automated instructional systems offer several benefits13 proponents—including prominent philanthropists us department education—present automated rose luckin “towards artificial intelligencebased assessment systems” nature human behaviour march httpsdoiorg101038s41562016–edsurge decoding adaptive london pearson httpsd3e7x39d4i7wbecloudfrontnet staticassetspearsondecodingadaptiveweb2pdf luckin “towards artificial intelligencebased assessment systems” benjamin herold “what personalized learning mean whatever people want to” education week november httpswwwedweekorgewarticles20181107whatdoes personalizedlearningmeanwhateverpeoplehtml office education technology us department education “what personalized learning” personalizing learning experience insights future ready schools blog january httpsmediumcompersonalizingthelearning experienceinsightswhatispersonalizedlearningbc874799b6f see eg edsurge decoding adaptive rose luckin wayne holmes mark griffiths laurie b forcier “intelligence unleashed argument ai education” london pearson httpdiscoveryuclacuk14757561pearsonintelligenceunleashedfinalpdf nazeema alli rahim rajan greg ratliff “how personalized learning unlocks student success” educause blog elana zeide adapative education software way schools move past onesizefitsall factory model education14 reformers vendors promise big data–driven education wil improve individual student performance engagement15 promote personalized learning systems way improve quality education underserved overcrowded classrooms reduce disparities educational achievement inside classroom adaptive software may improve instruction measuring student process precisely automatical incorporating latest learning science insights personalized learning supporters predict automated tools free time teachers turn attention individual student work small group different topic16 example automated assessment tools greatly reduce amount time teachers must devote grading17 discuss later systems track student learning extraordinary granularity platforms also automatical incorporate latest learning science pedagogical research example many personalized learning systems present concepts spaced intervals improve recall retention18 systems also expand scope instruction minimal cost developed online courses reach unlimited number students without consuming physical resources requiring investment additional teachers19 learners access instruction take tests anytime anywhere mobile platform “on demand”possible perils proponents highlight algorithmic decisionmaking consistent humans evaluating student performace21 however machine assessment learning help close attainment gap” acrobatiq blog november httpacrobatiq comhowpersonalizedlearningcanhelpclosetheattainmentgap andrew calkins kel young “from industrial models ‘factory schools’ exactly” edsurge march httpswwwedsurgecomnews20160303fromindustrial modelsandfactoryschoolstowhatexactly last visited march audrey watters “pearson knewton big data promise personalized learning hack education” httphackeducationcom20111101pearsonandknewtonbigdataandthe promiseofpersonalizedlearning last visited july tom vander ark “the future learning personalized adaptive competencybased dreambox learning” httpswww dreamboxcomwhitepapersthefutureoflearning vander ark “the future learning” hubertai “ai education—automatic essay scoring” hubertai blog march httpsmediumcomhubertaiaiineducationautomaticessayscoring6eb38bb2e70 last visited december hubertai “ai education—spaced interval learning” hubertai blog february httpsmediumcomhubertaiaiineducationspacedintervallearningb7ff1826d825 see eg jack balkin julia sonnevend “the digital transformation education” april httppapersssrncomabstract2759022 b hirsch jwp ng “education beyond cloud anytimeanywhere learning smart campus environment” international conference internet technology secured transactions icitst –ieee viktor mayerschönberger kenneth cukier learning big data houghton mifflin harcourt robot teaching pedagogy policy may offer consistency objectivity algorithmic analysis machine learning lead biased assessments many reasons may stem inadvertent design decisions incomplete datasets patterns reflect existing inequities historical discrimination22 computerized consistency reduces teachers’ classroom autonomy big data sorts individuals populations based probabilities inevitably creates situa tions students’ instruction evaluation credentials correspond specifics ground cuts highly contextualized decisionmaking characteristic physical classroom settings goes longstanding endeavor treat students equal regardless group affiliations—espoused big data– oriented reformers well critics final systems sufficiently novel minimal evidence fact effective result equitable results23 stage impossible predict difficult detect impact unintended conse quences may occur24 comparing human robot teaching school adoption education technology edtech often raises concerns whether machines replace dramatically reduce importance human wendy nelson espeland mitchell l stevens “commensuration social process” annual review sociology –neil selwyn distrusting e ducational technology critical questions changing times routledge audrey watters “the overselling education technology” edsurge march https wwwedsurgecomnews20160316theoversellingofeducationtechnology audrey watters “trend watch failure edtech platforms” hack education april http2016trends hackeducationcom20160430platforms beth hawkins “does personalized learning work research scant new nuanced give clear yes no—at least now” million blog march httpswwwthe74millionorgarticledoespersonalizedlearningworktheresearchistooscant toonewandtoonuancedtogiveaclearyesornoatleastfornow benjamin herold andrew r molnar “are companies overselling personalized learning” education week november httpswwwedweekorgewarticles20181107arecompaniesoversellingpersonalized learninghtml benjamin herold “personalized learning modest gains big challenges rand study finds” ed week blog july httpblogsedweekorgedweekdigitaleducation201707 personalizedlearningresearchimplementationrandhtml john f pane elizabeth steiner matthew baird laura hamilton joseph pane informing progress insights personalized learning implementation effects santa monica ca rand corporation httpswww randorgpubsresearchreportsrr2042html ryan baker “stupid tutoring systems intelligent humans” international journal artificial intel igence education june –httpsdoiorg101007s4059301601050 see eg benjamin herold “ ‘teach one’ personalizedlearning model effect students’ math scores federal evaluation finds—digital education—education week” ed week blog february httpsblogsedweekorgedweek digitaleducation201902teachtoonepersonalizedlearningnoeffecthtml elana zeide teachers25 schools outsourcing instruction assessment credentialing functions companies end outsourcing fundamental decisions wel following section compares mechanics personalized learning systems tasks performed teachers differentiating instruction physical classrooms first gives background account teachers’ primary tasks differentiating instruction explains machinelearning models personalized learning systems seek mimic differentiation process order provide adaptive instruction personalized learning systems build upon ideal onetoone tutors con stantly evaluate student progress tailor feedback instruction accordingly notsosimple endeavor involves several different tasks including communicating information assessing learning evaluating pedagogical options also presumes teachers draw knowledge subject matter structure rep ertoire instructional techniques convey information prior teaching expe rience inform pedagogical choices lastly assumes larger structure chooses learning materials defines curricula sets standards performance attainment described next section traditional purview administrators school boards state federal education agencies communi ties serve human teaching teachers deliver instructional content ideal engage dynamic communication pupils adjust approach response students’ immediate needs teachers provide differentiated instruction observing student performance assessing progress informing evaluating realtime pedagogical decisions response likely promote student success differentiated teaching involves communicating complex concepts way timely effective given myriad contextual considerations automated teaching software discussed later creates machinelearning models perform tasks teaching current conceptualization involves dynamic communication instructors pupils26 traditional teachers personalize learning informal part derek briton “big data learning analytics ‘new’ teaching machine” precarious future education ed jan jagodinski springer bill ferster teaching machines learning intersection education technology johns hopkins university press audrey watters hackeducationcom20140702personalizationteachingmachines gay l bisanz joanne striley “from teaching machines intelligent tutoring systems new insights automated instruction” psyccritiques –see eg larry cuban “will teaching learning become automated part ” larry cuban school reform classroom practice blog january httpslarrycubanwordpress com20150121willteachingandlearningbecomeautomatedpart3 sarah sparks articles20150128differentiatedinstructionaprimerhtml lisa goldstein “kindergarten teachers robot teaching pedagogy policy interactions physical learning environments observing students assessing proficiency adjusting instruction broadly speaking teachers following collect information students real time analyze data evaluate student progress shortcomings regarding skil concepts knowledge subject hand consider various teaching options different pacing content choose activity likely support student learning progress act implement choices teachers also observe students class performance assignments tests see puzzled looks students’ faces observe majority class raises hand eagerly certain topics hear confidence student’s voice based information evaluate student’s realtime progress problems example student learning multiplication says × teacher may guess student confusing multiplication division emphasize difference two even though planned move next topic teachers ultimately determine whether students demonstrated enough profi ciency pass class give grades intended reflect student performance attainment classrooms teachers also periodical administer tests measure student mastery scores incorporate official grades traditionally summative assessment involves separate set information collected explicitly summative evaluative purposes formal tests assignments educational institution uses summative assessment determine award students credits move next grade level whether place honors basic classes standardized tests also common means summative assess ment created states testing services college board’s sat short teaching involves act adapting instruction requires consideration pedagogical institutional infrastructure27 robot teaching subsection analyzes components automated instructional system illustrate scope significance choices made technology developers automated personalized learning systems rely data models place human institutional decisionmaking processes formal assessment data models making ‘streetlevel’ education policy wake child left behind” early education development may –see richard edwards “software hidden curriculum digital education” pedagogy culture society april –ben williamson “the hidden architecture higher education building big data infrastructure ‘smarter university’ ” international journal educational technology higher education december httpsdoiorg101186 s4123901800941 paul prinsloo “fleeing frankenstein’s monster meeting kafka way algorithmic decisionmaking higher education” elearning digital media elana zeide create define digital curricula textbooks lesson plans syl abi education standards learner models continuously evaluate student progress proficiency serve functions pop quizzes exams grades also predict student potential like standardized tests create credentials used place grades transcripts instead embed assessment using information students’ interactions digital platform actual answers submit system example might extrapolate learner progress using information much students read ebooks whether selected incorrect answer submitting correct one like teachers pedagogical models datadriven systems use realtime profile updates input calculate content pace activity likely promote pre defined goals take example personalized learning system “aiassess” automatical dif ferentiates instruction using machinelearning models offer suitable math science instruction based students’ realtime progress28 aiassess provides edu cational content typical associated textbooks classroom activities divided discrete modular experiences assess develop conceptual knowledge include tasks increasing difficulty well related hints tips aiassess maps relevant subject matter might algebraic concepts “knowledge component” includes finegrained information steps involved reaching correct answer receiving related feedback like classroom teachers system evaluates students’ progress real time determine show students next assessing student mastery metacognition based steps complete hints use difficulty question results stored constantly updated learner profile like grade book tracks students’ progress docu ments performance aiassess visualizes inferences students’ performance particular tasks set tasks complete tasks data dashboard29 displays diagnostic conclusions teachers digital dashboard tools analyze data charts categories30 platform may example organize data show “skill meter” visually graphs learners’ mastery monitored skills31 however students teachers luckin “towards artificial intelligencebased assessment systems” id –andrew gibbons “review interactive instruction feedback” educational technology research development –dan kohenvacs et al “evaluation enhanced educational experiences using interactive videos web technologies pedagogical architectural considerations” smart learning environment albert corbett john r anderson “student modeling mastery learning computerbased programming tutor” intel igent tutoring systems second international conference ’ed claude frasson gilles gauthier gordon mccal springer –robot teaching pedagogy policy parents cannot peer specific automated assessments adaptations shape student’s education trajectory determine learned32 obscured transparency attenuated accountability lack transparency hinders studentparent agency educator oversight use ai human profiling prediction contexts degree legibility “explainability” prerequisite ensuring accurate fair decisions individuals systemic legitimacy33 students’ parents’ rights access challenge personal identifiable student information school records core component student privacy policy fortyfive years34 teachers administrators need sufficient understanding software’s inner working able exercise professional judgment use information outcomes especial respect minority underserved populations similarly crucial schools school boards stakeholders serve enable informed decisions various machine teaching options even rare cases schools customize aspects personalized learning systems choices typical subject pub lic input scrutiny discuss following section contrasting democratic codified policymaking much conversation personalized learning systems focuses parts mimic teachers’ inclass teaching neglecting rest information infra structure significant shaping education automated instruction requires considerable information construct necessary pedagogical infrastructure includ ing “the curriculum subject area learning activities student com pleting details steps student takes complete activities counts success within activities within steps towards completion activity”each components involves choices sigrid hartong “between assessments digital technologies big data growing influence ‘hidden’ data mediators education” european educational research journal see eg citrom pasquale “the scored society” family educational rights privacy act ferpa usc § 1232g elana zeide review spring luckin “towards artificial intelligencebased assessment systems” elana zeide epistemology pedagogy policy decisions traditional made educators policymakers communities serve—decisions made code created private companies democratic pedagogy policy choices education content pedagogical approaches learning objectives typical subject considerable public input debate scrutiny american public education highly democratic enterprise36 schooling long seen crucial individual collective success understanding reflected public funding schools states’ mandatory attendance requirements education’s importance also surfaces hotly contested public debates content students learn best teach school standards meas ure success many decisions occur local state level school boards con siderable impact district policies37 decentralized governance accommodates highly heterogeneous nature student bodies communities across country facilitates direct stakeholder input accountability parents offering opinions school board meetings local teachers schools policymakers take unique circumstances class school community account close proximity readily accessible students parents stakeholders serve adapt local needs values part participatory democratic process charac terized public schooling america century receive respond stu dent parent stakeholder input held accountable decisions determine individual student trajectories school districtlevel choices shape education policy america’s k–education governance highly decentralized “rooted local policy local management local financial control deeply embed ded historic national political culture”while legislatures set broad education policies details come control education agencies particu larly local level39 local boards define policy public school districts state determines curricula textbooks education standards despite recent increase federal influence academic substance standards amy gutmann democratic education princeton university press id michael w kirst “the political policy dynamics k–education reform implications changing postsecondary education” research priorities broadaccess higher education stanford cepa see patrick mcguinn paul manna “education governance america leads everyone charge” education governance twentyfirst century overcoming structural barriers school reform ed paul manna patrick mcguinn brookings institution press –robot teaching pedagogy policy within schools teachers traditional enjoy considerable autonomy lesson plans pedagogical choices classroom instruction student evaluation adjusted fly context circumstances america’s public education system operates local control pragmatic philosophical reasons40 educational theorists historians see participation crucial component america’s education system41 lead better tailored instructional choices informed student assessment academic policies aligned community values discretion also course leave room biased inconsistent decisions respect individual students particular demographics however educational autonomy community accountability core american education system since progressive movement42 highly public participatory nature pedagogical policy choices stands stark contrast black boxes invisible infrastructures personalized learning systems example textbook choices often battleground communities different worldviews involve debates whether cover intelligent design evolution cover climate change43 mechanisms selecting textbooks formal complex contested44 florida allows citizen weigh textbook choice45 texas’ education agency engages multiyear process select textbooks46 publishers submit textbooks reviewed panel including com munity members university professors public school teachers parents businesses industry representatives education agency holds hearing open public comments posts submitted comments online convenes second hearing additional comments ultimately putting submissions vote47 janet hansen marguerite roza “decentralized decisionmaking schools new promise old idea” rand corporation –michael w kirst “the political policy dynamics k–education reform” gutmann democratic education michael w kirst “the political policy dynamics k–education reform” see eg gail collins “how texas inflicts bad textbooks us” new york review books history textbooks approves others” edsource nov httpsedsourceorg2017 afterhoursoftestimonystateboardrejectstwohistorytextbooksapproves10others590118 vincent scudel “state textbook adoption” education commission states sept httpswwwecsorgclearinghouse01092310923pdf see also “textbook review public schools” findlaw blog july httpseducationfindlawcomcurriculumstandardsschoolfunding textbookreviewinpublicschoolshtml “in florida new law hitting textbooks” science friday blog july httpswww sciencefridaycomsegmentsinfloridaanewlawishittingtextbooks dylan baddour “explained texas picks textbooks” houston chronicle sept httpswwwhoustonchroniclecomlocalexplainerarticleexplainedhowtexaspicksitstextbooks 9225732php id elana zeide codified pedagogy policy pedagogy personalization complex governance structures around adopting textbooks pose sharp contrast unilateral obscured policymaking occurs personalized learning systems without sufficient mechanisms transparency oversight discussed earlier personalized learning systems perform many functions based choices embedded platform design data processing personalized learning systems provide educational content textbook lecture also scope subject matter curricula learning pathways material instructional choices teachers physical classrooms observation informal tools pop quizzes similar standardized tests exams performs summative assessments document students mastered material outputs feed learner profile functions like detailed grade book used transcript policy procurement schools outsourcing functions private vendors nothing new however recently much outsourcing related ancil ary services supported schools’ core education functions thirdparty software performed organizational institutional processes academic ones automated instructional tools ever educators delegate entire instructional process including pedagogical policy decisions shape school curricula metrics standards communities free desired however displacement authority account ability happen consideration scrutiny applied textbook standardized test selection today however k–school districts evaluate acquire education technology products haphazardly48 schools rarely conduct formal needs assessments49 educators students play limited role edtech procurement50 curriculum directors technology information officers make many dispositive decisions impacting school technology choice51 school treatment education software—even learning see natasha singer “privacy pitfal education apps spread haphazardly” new york times oversightandstudentprivacyisamongtheriskshtml digital promise improving edtech purchasing identifying key obstacles potential solutions discovery acquisition k–personalized learning tools nov available httpsdigitalpromiseorg20141113improvingedtechpurchasing jennifer r morrison steven ross alan ck cheung “from market classroom edtech products procured school districts interacting vendors” educational technology research development april –httpsdoiorg101007s11423019096494 digital promise improving edtech purchasing morrison ross cheung “from market classroom” digital promise improving edtech purchasing morrison ross cheung “from market classroom” robot teaching pedagogy policy platforms—as simply another piece technology reflected fact funding districts use purchase systems supplemental budget primary one curricular instructional needs52 procurement decisions often depend anecdotal evidence small pilots mar keting materials peer references53 technology vendors rarely share rigorous proof edtech efficacy conduct formal ongoing oversight ensure positive equal comes schools policymakers demand transparency proof “companies perceive little incentive produce rigorous evidence”after pro curement schools resources train teachers administrators aidriven systems’ strengths weaknesses55 teaching transparency public accountability schools education policymakers wait public outcry take proactive approach examples democratic education decisionmaking noted ear lier demonstrate communities willing devote time attention resources oversee pedagogical policy choices way forward requires algorith mic decisions explainable accountable replace judgment publicly answerable actors involves transparency individual determinations also deliberate public conversation impact outsourcing pub lic decisionmaking private entities parents teachers students need understand parameters used assess promote learning administrators need able tell technological tools working specific student population policymakers parents want know school pedagogy subject matter matches community values stakeholders minimal ability evaluate elements adaptive learning tools due inscrutability algorithmic calculations invisibility ped agogical policy decisions embedded invisible information infrastructure displacement continuing human elements reduces teachers’ autonomy administrator authority policymakers’ accountability without tools greater transparency decisions embedded code shut students parents educators loop56 instead readily available classroom teachers onsite administra tors corporate entities handle important decisions obvious authority petition explanation redress students parents teachers manage obtain information underlying decisionmaking may still able make sense complex algorithms probabilistic decisions driving personalized learning digital promise improving edtech purchasing digital promise improving edtech purchasing morrison ross cheung “from market classroom” digital promise improving edtech purchasing id hartong “between assessments digital technologies big data” elana zeide responsibility reform rests schools policymakers much technology developers stakeholders act adopting rigorous documented procedures edtech procurement implementation evaluation requiring ven dors offer sufficient access underlying data information outcomes cultivating data literacy among stakeholders procurement process impose transparency requirements aimed teachers local policymakers much student parents ideal schools school boards example would conduct formal instructional needs assessments clarify implementation goals least requests information require vendors supply adequate proof effi cacy procurement mandate sufficient mechanisms transparency indi vidual decisions access outcomes relevant populations protected classes enable ongoing review school administrators make choices respect significant pedagogical policy choices public open platforms commentary participation similar already place traditional edu cational material institutional standards conclusion personalized learning software students parents cannot observe let alone challenge many decisions shape academic outcomes subsequent life trajec tories teacher school officials cannot assess accuracy efficacy fairness individual determinations group outcomes private companies rather commu nity members public servants set pedagogy policy practice schools remain relevant educational proc ess opposed packaging context educators stakeholders must proactive demanding infor mation technology providers setting internal protocols ensure effective consistent implementation choose outsource instructional functions sufficient transparency mechanisms place ensure professional oversight guided wellinformed debate aidriven software includes components make choices previously vested teachers school administrators education agencies personalized learning systems extreme example displacement professional expertise policymaking machines without protocols transparency systems may undermine important trust institutions—not efficacy also ultimate fairness transparency important algorithmic school accountabil ity also students’ ability exercise agency education educators stakeholders policymakers must least examine assumptions embedded computer code software developers vendors must create technical systems resources facilitate transparency respect individual design decisions education professionals policymakers must time cultivate sufficient technical data literacy able understand strengths limitations robot teaching pedagogy policy implications aidriven teaching tools schools adopting new teaching tools must also implement accompanying oversight governance structures match important pedagogical policy decisions never inadvertent invisible explicit accountable professionals public leaders working col aboration communities bibliography edsurge decoding adaptive london pearson httpsd3e7x39d4i7wbecloudfrontnet staticassetspearsondecodingadaptiveweb2pdf edwards richard “software hidden curriculum digital education” pedagogy culture society april –httpsdoiorg1010801468136620149 herold benjamin “what personalized learning mean whatever people want to” education week november httpswwwedweekorgewarticles20181107what doespersonalizedlearningmeanwhateverpeoplehtml molnar michele benjamin herold “are companies overselling personalized learning” education week november httpswwwedweekorgewarticles20181107are companiesoversellingpersonalizedlearninghtml murphy robert f “artificial intelligence applications support k–teacher teaching review promising applications challenges risks” santa monica ca rand corporation httpswwwrandorgpubsperspectivespe315html office education technology us department education “what personalized learning” personalizing learning experience insights future ready schools blog whatispersonalizedlearningbc874799b6f selwyn neil technology good education cambridge polity watters audrey “the histories personalized learning” hackeducation blog june httphackeducationcom20170609personalization williamson ben “the hidden architecture higher education building big data infrastructure ‘smarter university’ ” international journal educational technology higher education december httpsdoiorg101186s4123901800941 zeide elana “the structural consequences big datadriven education” big data chapter algorithms social organization work ifeoma ajunwa rachel schlund social organization work much organizational theorizing conducted role brokers institutional intermediaries connecting disparate groups within organizations1 occluding lacunae network corporate entities2 recently scholarly atten tion shifted role technology intermediary mediating access work experience work3 shoshana zuboff observed introduction new technology “wields power slowmoving hand turning rim kaleidoscope” zuboff argues technology never introduced without effect—rather new technology must parsed affordances foreclosures4 harry braverman’s seminal analysis technology taylorist management labor process demonstrated managerial control exerted technology michael burawoy noted ethnography visible control technology david obstfeld “social networks tertius iungens orientation involvement innovation” administrative science quarterly –ronald burt structural holes social structure competition cambridge harvard university press hyman louis temp american work american business american dream became temporary new york viking ifeoma ajunwa daniel greene “platforms work automated hiring platforms new intermediaries organization work” research sociology work forthcoming –shoshana zuboff age smart machine future work power new york basic books ifeoma ajunwa rachel schlund factory assembly line5 line coerced workers keep pace risk penalties monetary social proliferation automated algorithms workplace raises questions might used service control coercion scholars argued machine learning algorithms “prompted datacentric reorganization workplace” quantification worker manner degree previously unseen history6 chapter considers ethical issues implicated three algorithmicdriven work technologies automated hiring platforms wear able workplace technologies customer relationship management automated hiring platforms automated hiring platforms ahps “digital intermediaries invite submission data one party preset interfaces structured protocols process data via proprietary algorithms deliver sorted data second party”the use ahps involves every stage hiring process initial sourcing candi dates eventual selection candidates applicant pool section describes ahps assist companies stage hiring process—sourcing screening interviewing selecting8 initial sourcing stage hiring process companies use ahps source find attractive candidates using targeted advertising matching technology9 targeted advertising involves use machine learning algorithms build predictive models based data job seekers online activity automatical gener ate pool jobseekers predetermined soughtout characteristics companies use target exclude job seekers viewing advertisements10 case matching technologies companies typical use personalized job boards automatical generate list potential job candidates match characteristics company looking job candidate11 harry braverman labor monopoly capital degradation work twentieth century 25th anniversary ed new york monthly review press michael burawoy “between labor process state changing face factory regimes advanced capitalism” american sociological review –ifeoma ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” st louis law journal forthcoming ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” miranda bogen aaron rieke “help wanted examination hiring algorithms equity bias” washington dc upturn id pauline kim sharion scott “discrimination online employment recruiting” st louis university law journal –sirui yao bert huang “beyond parity fairness objectives col aborative filtering” 31st conference neural information processing systems nips –algorithms social organization work following initial sourcing stage hiring process companies typical use ahps screen candidates—assessing candidates’ potential excel job position using predictive models12 example companies may embed behavioral personal ity assessments within ahps predict likely job candidate work well others steal company13 companies also use ahps automatical review job candidates resumes predict closely given resume matches compa ny’s minimum desired qualifications14 screening stage ahps typical cull bottom percent applicant pool transmitting remaining applicant pool interview stage hiring process15 ahps aid interviewing stage hiring process creating interview guides hiring managers based areas concern indicated assessments used screening process16 ahps may also make use video interviews—job appli cants’ interviews recorded responses vocal tone facial expressions analyzed using machine learning algorithms compare current job applicants’ responses past interview responses company’s top employees17 final step hiring process selection phase employers use ahps making final hiring decision automating background checks helping negotiate job offer terms automated background checks typical assess job appli cant criminal history authorized work18 recently ahp vendors also offer social media background checks—a job applicant’s social media online history deployed predict likely job candidate engage toxic workplace behavior bul ying sexual harassment drug use19 employers also use ahps help negotiate job offer terms example ahps use companies’ data regarding previous job offers acceptances create predictive models assess likely given job candidate accept given job offer20 predictive models provide companies potential ways increase likelihood given job applicant accept given job offer increasing salary bonus benefits21 bogen rieke “help wanted examination hiring algorithms equity bias” ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” mariotti robinson “society human resource management talent acquisition benchmarking report” shrm ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” id josh bersin “talent trends hr technology disruptions productivity design intelligence reign” deloitte university press bogen rieke “help wanted examination hiring algorithms equity bias” nathan j ebnet “it protect credit score regulating social media preemployment screening fair credit reporting act” minnesota law review –bogen rieke “help wanted examination hiring algorithms equity bias” nagaraj nadendla “introducing oracle recruiting cloud” filmed openworld san francisco ca video httpsvideooraclecomdetailvideosmostrecentvideo 5701490825001openworld2017introducingtheoraclerecruitingcloud ifeoma ajunwa rachel schlund current state use use ahps rise according society human resource management approximately percent organizations used automated screening review job applicants’ resumes survey conducted deloitte university press revealed approximately percent companies surveyed proc ess redesigning human resources hr programs utilized digital mobile ahps percent companies surveyed process redesigning companies use digital business models additional percent hr teams included survey using artificial intelligence ai implement hr solutions survey included data companies across world including western europe percent latin south america percent asia europe percent nordic countries percent oceania percent middle east percent companies surveyed also variety industries includ ing professional services percent financial services percent consumer business real estate percent percent22 thus use ahps worldwide spans variety industries criticisms pitfalls coercive hierarchical design ahps resemble hierarchical coercive structures aimed maximize profit— clearly diverging public democratic social relations23 ahps coercive necessitate workers consent information asymmetries command structures embedded design ahps order gain employment one must attain afford basic needs housing food24 one view coercive hierarchical nature ahp design descendant technologies control dictated social organization work since rise scientific management nineteenth century25 although technologies nineteenth century assembly line stopwatch monitoring il ustrates overt forms technical control jeff schwartz et al “rewriting rules digital age deloitte global human capital trends” deloitte university press ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” e anderson private government employers rule lives don’t talk burawoy “between labor process state changing face factory regimes advanced capitalism” algorithms social organization work ahps although less overt also exert technical control coercing job applicants’ consent hierarchical information asymmetries information asymmetry use ahps results steep information asymmetries job applicants employers since job applicants must provide volumes personal information attain employment however employers reciprocate information insight attain job applicants—employers share information attain job applicants job applicants job applicants receive additional information employers26 privacy concerns coercing consent job applicants take part personality assessments reveal identifying information used gather additional information appli cants thirdparty vendors renders enormous amount personal information information stored analyzed shared among industry partners ways unknown job candidate27 collection distribution storage job appli cant’s personal information create numerous privacy concerns regarding security confidentiality sensitive employee data encoding bias ahp designers claim automating hiring process reduce hiring bias promise reduced hiring bias derives belief automated hiring systems blind protected characteristics gender age ethnicity sexual orientation28 however ahp autonomous agent predictive models used select employees applicant pools built training data selected company training data typical derived company’s current highsales employees’ data used detect patterns data build predictive models select similar job applicants—a process sometimes referred “cloning best people”the process “cloning best people” result encoding human bias idea “systematically biased data produces systemically biased analyses regardless quality analyses”for example women racial minorities underrepresented company’s demographics ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” id j meredith “ai identifying steady workers erecruiting firm offering tool determine long job seeker stay around” chicago tribune july httparticleschicagotribune com20010716business01071600131unicruneuralnetworks employee overholt “true false you’re hiring right people” fast company february httpswwwfastcompanycom44463trueorfalseyourehiringrightpeople ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” ifeoma ajunwa rachel schlund training data would create predictive model would similarly undervalue applicants underrepresented groups31 discrimination encoding human bias predictive models used ahps lead discriminatory hiring practices initial sourcing stage hiring process use targeted advertising result discrimination employers use protected charac teristics ethnicity gender age target advertisements targeted advertising also result discrimination employers use variables correlated protected characteristics target job advertisements zip code32 screening stage hiring process discrimination result using biased train ing data predict minimum qualifications33 furthermore behavioral personality assessments used screening process demonstrated discriminate people color34 interview stage hiring process use video interviews analyze job applicants responses vocal tone facial expressions lead discriminatory outcomes people regional nonnative accents speech impediments visible disabilities darker skin tones due design flaws speech recognition facial analysis software35 selection phase hir ing process use social media background checks reveal information job applicants employers legal permitted use inform hiring decisions ethnicity sexuality disability pregnancy status wearable workplace technologies wearable technologies designed workplace—wearable workplace technologies— exist variety forms vary terms design use wristbands used track employee location productivity exoskeletons used assist employees performing strenuous labor36 examples wearable workplace technologies include ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” kim scott “discrimination online employment recruiting” ajunwa greene “platforms work automated hiring platforms new intermediaries organization work” craig haney “employment tests employment discrimination dissenting psychological opinion” industrial relations law journal –rachael tatman “gender dialect bias youtube’s automatic captions” proceedings first acl workshop ethics natural language processing acl –joy buolamwini timnit gebru “gender shades intersectional accuracy disparities commercial gender classification” proceedings 1st conference fairness accountability transparency pmlr –timothy l fort anjanette h raymond scott j shackelford “the angel shoulder prompting employees right thing use wearables” northwestern journal technology intel ectual property –dov greenbaum “ethical legal social concerns relating exoskeletons” acm sigcas computers society –algorithms social organization work smart glasses wrist fingerworn wearables smart caps helmets exoskele tons—among many others37 wearable workplace technologies form smart glasses exist variety designs including seethrough smart glasses enhanced visual aid smart glasses equipped thermographic camera artificial reality glasses smart glasses monocular view38 seethrough smart glasses enhanced visual aid essential consist glasses properties static computer—allowing employees con sult manuals guides transcript notes look records variety industries use seethrough smart glasses enhanced visual aid construction manufactur ing field service healthcare among others39 smart glasses equipped ther mographic camera typical used construction manufacturing assess machine fatigue monitoring surface temperature temperature distribution predict machine overheat artificial reality ar smart glasses project vir tual information onto employee’s physical surroundings allowing employee distinguish virtual information physical information il ustrate factory employees fix machines use ar glasses project visual markers schemat ics guide work40 smart glasses monocular view afford employees wider viewing angle surroundings produce highresolution images many industries implemented smart glasses monocular view including telemedi cine remote assistance warehousing41 wrist fingerworn wearable workplace technologies also come variety designs provide different affordances examples fingerworn workplace wearables include rings equipped scanners bluetooth technology allow employees scan inventory communicate handsfree42 examples wristworn workplace wearables include bracelets bands equipped gps track employee location biosensors record analyze employee biometric data heart rate accelerom eters track employee movement activity wearable computer interfaces43 ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” frost sullivan “wearable technologies industrial applications smart glasses wristworn devices huds improve productivity efficiency industrial sector” frost sullivan june greenbaum “ethical legal social concerns relating exoskeletons” frost sullivan “wearable technologies industrial applications” jp gownder “the technologyaugmented employee emerging technologies like artificial intelligence reshaping future work” forrester httpswwwforrestercomreport thetechnologyaugmentedemployeeeres125811 ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” frost sullivan “wearable technologies industrial applications” jp gownder “the technologyaugmented employee emerging technologies like artificial intelligence reshaping future work” frost sullivan “wearable technologies industrial applications” id fort raymond scott “the angel shoulder prompting employees right thing use wearables” frost sullivan “wearable technologies industrial applications” ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research ifeoma ajunwa rachel schlund wristworn workplace wearables used across variety industries global market revenue projected reach us70 billion smart caps helmets designed workplace equipped augmented reality bluetooth technology voice recognition even sensors detect brain ac tiv ity45 example smart caps helmets equipped augmented reality used project blueprints instructions employees performing tasks welding construction46 smart caps helmets equipped sensors detect brain activity used measure employee’s level fatigue alertness47 vari ety industries adopted smart caps helmets fieldwork transportation construction manufacturing product design48 wearable workplace technology form exoskeletons essential wearable robotics typical designed assist employees performing arduous tasks increasing strength agility49 example exoskeletons used construction manufacturing assist employees lifting heavy tools50 exoskeletons even equipped technology allows employers monitor employees’ location mood physical health51 variety industries implemented exoskeletons construction manufacturing geriatric care52 current state use wearable workplace technology proliferated workplace report frost sullivan revealed january december approximately patents registered united states wearable technology designed agenda employment labor law” fort raymond shackelford “the angel shoulder prompting employees right thing use wearables” frost sullivan “wearable technologies industrial applications” id karen turner “are performancemonitoring wearables affront workers’ rights” chicago tribune august httpswwwchicagotribunecomblueskytechnologyctwearables workersrightswpbsi20160807storyhtml ben coxworth “smartcap monitors workers’ fatigue levels reading brain waves” new atlas january httpsnewatlascom smartcapmeasuresfatiguebrainwaves21271 ajunwa “algorithms work” frost sullivan “wearable technologies industrial applications” turner “are performancemonitoring wearables affront workers’ rights” ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” ben coxworth “smartcap monitors workers’ fatigue levels reading brain waves” frost sullivan “wearable technologies industrial applications” greenbaum “ethical legal social concerns relating exoskeletons” ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” greenbaum “ethical legal social concerns relating exoskeletons” ana viseu “simulation augmentation issues wearable computers” ethics information technology –greenbaum “ethical legal social concerns relating exoskeletons” algorithms social organization work workplace—illustrating flourishing development wearable workplace technologies53 majority patents registered united states wearable workplace technologies january december consisted patents wrist fingerworn wearables wristwatches ring scanners wrist bands—indicating wrist fingerworn wearables designed workplace remain significant trend54 implementation wearable workplace technologies also rise survey conducted forrester revealed percent information workers use wearable work technologies demonstrating percent increase addi tional survey conducted forrester revealed percent telecommunications organization executives described implementation wearable workplace technolo gies priority organization grown percent adoption wearable technology corporate wellness programs also increasing survey conducted worldatwork revealed approximately percent organizations surveyed used wearable technology encourage employee health wellness57 report gartner revealed estimated percent cor porate wellness programs include use wearable technology58 trend predicted increase—gartner estimates percent wellness programs include wearable technology59 criticisms pitfalls privacy concerns increased use wearable workplace technologies presents numerous privacy concerns regarding employee data wearable technologies collect volumes sensitive personal data employees creating issues regarding collection use distri bution employee data employers60 wearable workplace technologies frost sullivan “wearable technologies industrial applications” id boris evelson michael facemire enterprise business intel igence always hand smartwatch forrester httpswwwforrestercomreportenterprisebusinessintelligence jp gownder “deliver digital operational excellence digital customer experience innovation wearables” forrester httpswwwforrestercomreportdeliverdigital leseres103381 worldatwork “inventory total rewards programs practices” worldatwork https wwwworldatworkorgdocsresearchandsurveyssurveyreportinventoryoftotalrewards programsandpracticespdf christy pettey “wearables hold key connected health monitoring” gartner https wwwgartnercomsmarterwithgartnerwearablesholdthekeytoconnectedhealthmonitoring id ifeoma ajunwa kate crawford joel ford “health meets big data ethical framework health information collection corporate wellness programs” journal law medicine ethics no1 –ifeoma ajunwa rachel schlund typical afford employers ability observe track employees’ location physiological activity—a practice may violate national labor relations act61 moreover wearable workplace technologies collect large amounts sensitive employee data remains stored companies’ servers—leaving sensitive employee data vulnerable hacking third parties62 discrimination wearable workplace technologies also present concerns regarding discrimination since wearables collect employee health data technologies could potential reveal med ical information could used discriminate employees example use wearable technologies could facilitate discrimination employees medical condition disability prevents reaching productivity standards63 additionally wearables used corporate wellness programs collect employee data outside workplace activity levels weight heart rate sleep quality64 collection use employee data regarding health lifestyle outside workplace present discrimination concerns data could used determine employee benefits compensation65 employee safety compensation wearable workplace technologies improve worker performance lead reductions workers’ compensation injuries example wearable workplace technology designed assist workers arduous tasks may allow injured workers return work sooner would without wearable technologies assis tance reducing paid leave workplace injuries66 use data collected wearable workplace technology could used deny employee compensation claims67 example employee causes accident leads injury work employer could use biometric data collected wearable workplace technology determine employee sleepdeprived shifting blame onto employee68 ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” usc “national labor relations act” § frost sullivan “wearable technologies industrial applications” ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” helen nissenbaum heather patterson “biosensing context health privacy connected world” quantified biosensing technologies everyday life ed dawn nafus alexander h tran “the internet things potential remedies privacy tort law” columbia journal law social problems –greenbaum “ethical legal social concerns relating exoskeletons” ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” antigone peyton “a litigator’s guide internet things” richmond journal law technology –ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” algorithms social organization work wearable workplace technologies also present concerns regarding employee safety example wearable workplace technologies seethrough smart glasses enhanced visual aid virtual reality glasses cause distractions could lead injury69 furthermore poorly designed exoskeletons could potential damage muscles tendons nerves70 injuries caused wearable workplace technologies could lead employee lawsuits employers71 inaccurate predictions data collected wearable workplace technologies always accurate example employees “game” wearable workplace technology design flaws skew results data72 use wearable workplace technology also form surveil ance could make individuals nervous thus skewing accuracy data collected73 customer relationship management customer relationship management crm approach managing current potential customer interaction experience company using technology74 crm practices typically involve use customer data develop customer insight build customer relationships75 customer data collected wide range resources company’s website telephone email live chat advertising social media industry partners third parties76 primary purpose crm improve jeremy p brummond patrick j thorton “the legal side jobsite technology” construction today june httpwwwconstructiontodaycomsectionscolumns2752thelegalside ofjobsitetechnology garry mathiason et al “the transformation workplace robotics artificial intelligence automation employment labor law issues solutions legislative regulatory response” littler httpswwwlittlercompublicationpresspublication transformationworkplacethroughroboticsartificialintelligenceand ajunwa “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” ifeoma ajunwa kate crawford “when fitbit expert witness” atlantic november httpswwwtheatlanticcomtechnologyarchive201411whenfitbitistheexpert witness382936 oliva solon “wearable technology creeps workplace” sydney morning herald august httpswwwsmhcomaubusinessworkplacewearabletechnologycreepsintothe workplace20150807gitzuhhtml pennie frow et al “customer management crm addressing dark side” journal services marketing –william boulding et al “a customer relationship management roadmap known potential pitfal go” journal marketing –musfiq mannan choudhury paul harrigan “crm social crm integration new technologies customer relationship management” journal strategic marketing –satish jayachandran et al “the role relational information processes technology use customer relationship management” journal marketing –ifeoma ajunwa rachel schlund company’s relationships customers—increasing customer value—to attract potential customers retain current customers increase sales growth—increasing company value77 definition crm implementation use remains debated academic litera ture78 pennie frow adrian payne conceptualize crm implementation use five integrated processes strategy development value creation multichannel integration consumer experience information management perfor mance assessment strategy development process involves assessing firm’s busi ness strategy develop customer strategy creates base implementing crm valuecreation process involves utilizing firm’s business associated customer strategy determine value firm offer customers value customers offer firm integrate exchange customer company value multichannel integration customer experience process involves deciding channels eg ways firm interacts customers use integrate improve customer experience information management process involves col lection analyzation use customer data develop customer insight inform marketing practices final performance assessment process involves evaluating implementation use crm ensure achieving intended results lined firm’s business strategy79 michael fayerman provides alternative conceptualization describing imple mentation use crm consisting three components—operational analytical col aborative operational crm involves integration automation sales marketing customer support analytical component crm involves col lection analyzation utilization customer data develop customer insight inform marketing strategy practice final col aborative crm involves creating partnerships third parties share customer data across organizations firms use enhance customer experience customization80 current state use customer relationship management widely used organizations trend increasing according survey conducted forrester approximately percent small mediumsize organizations defined organizations twenty ninety employees surveyed use crm software percent planned implement crm jayachandran et al “the role relational information processes technology use customer relationship management” william boulding et al “a customer relationship management roadmap known potential pitfal go” id adrian payne pennie frow “a strategic framework customer relationship management” journal marketing –michael fayerman “customer relationship management” new directions institutional research no1 –algorithms social organization work estimated percent large organizations defined organizations one thousand employees surveyed use crm software percent planned implement crm additional organizations increasingly implementing use social media crm strategy example survey conducted aberdeen group revealed percent organizations use social media advertise consumers83 additional survey conducted mit sloan management review revealed approximately percent organizations used social media develop insight market shifts84 criticisms pitfalls differential treatment customers crm claims sales profits increase focusing enhancing companycustomer relationships however practice crm leads differential treatment customers focusing enhancing certain companycustomer relationships expense others85 idea favoritism profitable customers lead increased profits86 however practice favoring certain customers expense others leads inequality may increase profits favoritism results unequal distribution outcomes—the favored group cus tomers receive explicit targeting promotions group customers favored receive explicit targeting promotions unequal distribution outcomes caused favoritism may lead perceptions unfairness may cause favored customers feel guilty uneasy advantaged position customers favored may feel angered outraged disadvantaged position87 essential use crm favor certain groups customers expense others leads perceptions unfairness damage company’s reputation leading customers disengage company spread negative kate leggett “the five crm trends shape engagement relationships revenue” forrester httpswwwforrestercomreportthefivecrmtrendsin2019that willshapeengagementrelationshipsandrevenueeres148555 id sumair dutta “social media customer service listening engagement” svc1902160pdf david kiron et al “social business shifting first gear” mit sloan management review –boulding et al “a customer relationship management roadmap known potential pitfal go” bang nguyen sooyeon nikki leewingate lyndon simkin “the customer relationship management paradox five steps create fairer organization” social business –bang nguyen lyndon simkin “the dark side crm advantaged disadvantaged customers” journal consumer marketing –monroe xia j cox “the price unfair conceptual framework price fairness perceptions” journal marketing –ifeoma ajunwa rachel schlund information company88 effect targeted promotions could also seen form digital redlining disadvantages lower income customers population large overlaps racial minorities89 exploiting customer relationships premise crm “dual creation value” company customer information reciprocity90 idea customers give companies informa tion companies reciprocate providing enhanced shopping buying experience91 essential companies attain customer information cus tomize enhance customer’s shopping buying experience increases likelihood customer continue purchase company—creating value customer ie enhancing shopping buying experience company ie customer retention increased profits however practice cus tomer information reciprocated leads information asymmetry customer company customer always aware data collected used company92 information asymmetry customer company may cause customer distrust company information93 facebook–cambridge analytica data scandal presents illustrative case94 revealed facebook permitted data analytics firm cambridge analytica collect information millions facebook users order target political campaign ads users95 information misuse privacy concerns essential component crm entails collection storage consumer data consumers typical unaware data collected used nguyen simkin “the dark side crm advantaged disadvantaged customers” jennifer lyn cox “can differential prices fair” journal product brand management –fm feinberg krishna zj zhang “do care others get behaviourist approach targeted promotions” journal marketing research –margaret hu “algorithmic jim crow” fordham law review –cathy o’neil “no safe zone getting insurance” weapons math destruction big data increases inequality threatens democracy new york ny crow –satish jayachandran et al “the role relational information processes technology use customer relationship management” william boulding et al “a customer relationship management roadmap known potential pitfal go” jayachandran et al “the role relational information processes technology use customer relationship management” pennie frow et al “customer management crm addressing dark side” william boulding et al “a customer relationship management roadmap known potential pitfal go” carole cadwal adr emma grahmharrison “revealed million facebook profiles harvested cambridge analytica major data breach” guardian march https wwwtheguardiancomnews2018mar17cambridgeanalyticafacebookinfluenceuselection id algorithms social organization work companies creates numerous privacy concerns furthermore companies sell customer data firms without customers’ knowledge permission exacerbating privacy concerns96 dishonesty crm practices may sometimes entail misleading confusing customers hiding relevant information may cause customers make buying decisions dis advantage example companies use crm generate complex pricing schemas make difficult customers compare pricing service providers additional companies use crm generate continuous price rate changes customers time compare pricing alternatives service pro viders accurately crm performance measurement systems employee reward structures encourage dishonest company behavior overcharging upselling customers97 discrimination collecting analyzing consumer data generate consumer insight inform mar keting practices targeted advertising constitutes essential component crm98 companies collect analyze consumer data predict profit able customers target advertisements promotions customers customers share similar characteristics99 practice targeted adver tising using predictive analytics leads certain groups customers receive targeted advertising promotions excluding groups customers known “dig ital redlining”digital redlining lead discrimination companies exclude certain groups customers based protected characteristics ethnicity101 pennie frow et al “customer management crm addressing dark side” joseph turow lauren feldman kimberly meltzer “open exploitation america’s shoppers online offline” philadelphia anneberg public policy center university pennsylvania detlev zwick nikhilesh dholakia “whose identity anyway consumer representation age database marketing” journal macromarketing june –lilian edwards michael veale “slave algorithm ‘right explanation’ probably remedy looking for” duke law technology review –ifeoma ajunwa yourhealthdataatrisk pennie frow et al “customer management crm addressing dark side” id anthony danna oscar h gandy “all glitters gold digging beneath surface data mining” journal business ethics –id margaret hu “algorithmic jim crow” cathy o’neil “no safe zone getting insurance” marcia stepanek “weblining companies using personal data limit choices—and force pay products” bloomberg business week april httpswwwbloombergcom newsarticles20000402weblining elliot zaret brock n meeks “kozmo’s digital dividing lines” msnbc april httpswebarchiveorgweb20001217050000httpwwwmsnbccomnews373212aspcp11 latanya ifeoma ajunwa rachel schlund religion102 pregnancy status103 gender104 proxies protected characteristics105 example propublica investigation revealed companies excluding customers ethnic group viewing targeted advertisements facebook using determine customer ethnicity—a proxy protected characteristic ethnicity106 future directions research recent empirical research investigating bias online hiring platforms also crm customer relationship management hannak et al investigated effect race gender online freelance marketplaces107 specifical hannak colleagues examined perceived gender race influence worker evaluations customers language worker evaluations customers differed workers different perceived genders races workers’ perceived gender race significantly associate search result rankings online freelance marketplaces108 overal findings demonstrate support effect race gender bias online freelance marketplaces hannak colleagues hypoth esized biased customer evaluations workers might indirectly cause biased ranking workers words since customer evaluations workers revealed bias function perceived race gender worker rankings also revealed bias function perceived race gender biased customer evaluations workers might also cause biased rankings workers sweeney “discrimination online ad delivery” communications acm may julia angwin terry parris jr “facebook lets advertisers exclude users race” propublica october httpswwwpropublicaorgarticlefacebookletsadvertisersexcludeusersbyrace samuel gibbs “google alters search autocomplete remove ‘are jews evil’ suggestion” guardian december httpswwwtheguardiancomtechnology2016dec05google alterssearchautocompleteremovearejewsevilsuggestion kashmir hil “how target figured teen girl pregnant father did” forbes teengirlwaspregnantbeforeherfatherdid amit datta michael carl tschantz anupam datta “automated experiments ad privacy settings tale opacity choice discrimination” proceedings 15th privacy enhancing technologies symposium –angwin parris jr “facebook lets advertisers exclude users race” id hannák c wagner garcia mislove strohmaier c wilson “bias online freelance marketplaces evidence taskrabbit fiverr” proceedings acm conference computer supported cooperative work social computing –id algorithms social organization work hannak colleagues argue online freelance marketplace designers actively seek mitigate biases present online freelance marketplaces hannak colleagues present several examples including limiting number customer evaluations workers viewed limiting customers’ ability pick workers process automated adjusting individual workers’ ratings product systematic biased evaluation customers furthermore hannak colleagues call future research investigate impact working conditions propensity women people color leave freelance workforce researchers also call future research investigate causal mechanisms behind effect biased customer evaluations workers hiring decisions109 automated hiring recruitment chen coauthors conducted audit study three resume search engines notably conducted experimental studies investigate resume search engines directly used inferred gender rank job seekers’ posted resumes110 findings support existence indirect gender discrimination individual group level resume search engine rankings—presenting several key implications chen col leagues argue adoption ranking algorithms account indirect discrimi nation making ranking algorithms “group fair design” words hiring websites use ranking algorithms ensure ranking algorithms rank male female job candidates rate proportional distribution popula tion furthermore chen colleagues call future research investigate hir ing websites actual hirers recruiters use resume search engines111 bibliography ajunwa ifeoma “the paradox intervention antibias intervention” cardozo law review forthcoming ajunwa ifeoma “age discrimination platforms” berkeley journal employment labor law forthcoming ajunwa ifeoma “algorithms work productivity monitoring platforms wearable technology new datacentric research agenda employment labor law” st louis law journal forthcoming ajunwa ifeoma daniel greene “platforms work automated hiring platforms new intermediaries organization work” research sociology work forthcoming –id l chen hannak r c wilson “investigating impact gender rank resume search engines” proceedings chi conference human factors computing systems id ifeoma ajunwa rachel schlund boulding william richard staelin michael ehret wesley j johnston “a customer relationship management roadmap known potential pitfal go” journal marketing –greenbaum joan windows workplace technology jobs organization office work 2d ed new york monthly review press nissenbaum helen heather patterson “biosensing context health privacy connected world” quantified biosensing technologies everyday life edited dawn nafus –cambridge mit press pasquale frank black box society secret algorithms control money information cambridge harvard university press srnicek nick platform capitalism cambridge uk polity press zuboff shoshana age smart machine future work power new york basic books chapter smart city ethics “smart” chal enges democratic governance ellen p goodman introduction artificial intelligence coming city ai coming city whether sometimes hurtling embrace internet things “smart city” agendas ways give control city functions citizen information private companies impenetrable algorithms public control accountability winnertakeall market logic big tech turn city another platform exploitation personal data microtargeted services cities adopt policies distribute power protect public authority make space alternative visions term “smart cities” describes growing role data analytics sensors urban life1 projects may relatively modest directed particular urban fea ture like efficiently timed traffic lights may involve wholesale construction new city oriented start around collection flow data2 technologies city deploys mundane stormwater sensor controversial facial recognition may owned managed private company anthony townsend smart cities big data civic hackers quest new utopia new york ww norton rob kitchin “the realtime city big data smart urbanism” geojournal caspar herzberg smart cities digital nations petaluma ca roundtree press cisco’s efforts create smart cities asia orit halpern et al “testbed urbanism” public culture technocratic visions trials anonymized global companies” ellen p goodman like ondemand mobility many cases ostensibly public applications actual publicprivate hybrids cities work private vendors design implement management systems smart mobility smart sanitation urban functions common feature rob kitchin cal “datadriven urbanism” reliance systems managed real time”some integrations information technologies urban governance happen contexts typical associated “smart city” moniker involve instrumentation physical space sensors cities may use data analytics frequently outsourced private tech companies allocate resources school assignments social welfare services policing thereby creating systems algorithmic governance4 like placebased data analytics applications intermediate citizens services using data collection analytics deliver promised efficiencies performance relation smart technologies cities sit abreast two different interests one protect public private exploitation data city another regulate serve using data capabilities developed operated large part private entities critical energy around smart cities focused first interest growing literature making case public intervention limit private data accumulation “surveil ance capitalism”one possible intervention city control access privately collected data public empowerment way data may produce cities augmented surveil ance abilities use realtime moni toring state regulatory control example los angeles wanted protect excessive private exploitation public rights way ridesharing scooters mobile applications safeguard public authority required ridesharing vehicles share trip origins destinations city application programming interface api6 cabining private power intervention enhanced city’s surveil ance powers concerns power exercised tech nology—whether power sufficiently transparent constrained subject democratic control—arise respect public private exercises chap ter focus concerns related private power bracketing set concerns related state power chapter smart city ethics preliminaries scope definition consider theory ethics smart city would entail whole range ethical obligations urban governance including employment housing sustainability rob kitchin “the ethics smart cities urban science” philosophical transactions royal society mathematical physical engineering sciences cathy o’neil weapons math destruction big data increases inequality threatens democracy new york crown shoshanna zuboff age surveil ance capitalism fight human future new frontier power new york public affairs city los angeles dockless ondemand personal mobility conditional permit rules guidelines—october httpsladotlacityorgsitesgfileswph266fladotdocklesscppdf “smart” challenges democratic governance one could simply attach use data analytics urban governance normative goals equity inclusivity economic opportunity sustainability meaningful discussion smart city ethics special set considerations requires narrower focus distinctive technological affordances data flows general question makes set normative goals “ethics” opposed “policies” difference may matter time—ethics policy prescriptions nascent form—or matter compulsion—ethics aspirational policy prescriptions prudential political reasons best left selfregulation rather enforced law chapter identifies normative concerns addressable variety modalities various levels government follows first brief review smart city “problem” democratic gov ern ance emerged interdisciplinary literature geography law urban studies fields next part surveys early ethical frameworks seek shape smart city deployments final part distil smart city discourse practice set three normative concerns privatization platformization domination smart city problem smart city projects branding efforts attract capital management strate gies improve urban operation branding front cities like kansas city united states fight winnertakeall economy advertise “the first true smart city world”london’s smart city plan “roadmap transform london smartest city world”india’s smart cities mission develop one hundred smart cities aims produce “global” cities attractive global capital9 management front smart city proponents city hal seek greater efficiency technology often data collection analytics10 anthony townsend puts “a smart city pursues goals effective services efficient city systems realtime monitoring control”adam greenfield identifies smart city kansas city request proposals “comprehensive smart city partnership kansas city missouri” rfp ev2556 httpkcmogovwpcontentuploads201806 rfpcomprehensivesmartcitypartnershipwithkcmofinalpdf seeking “a firm provide fully integrated suite sensors networks data analytics platforms” greater london authority smarter london together httpswwwlondongovuksites defaultfilessmarterlondontogetherv166publishedpdf evgeny morozov francesca bria rethinking smart city democratizing urban technology anthony townsend “green gadgets smartcities movement urban environmental policy” remaking urban social contract health energy environment ed michael pagano –champaign university illinois press margarita angelidou “the role smart city characteristics plans fifteen cities” journal urban technology –robert goodspeed “smart cities moving beyond urban cybernetics tackle wicked problems” cambridge journal regions economy society –critiquing smart city discourse application urban cybernetics ellen p goodman “a place instrumentation urban fabric people moving city driven desire achieve efficient use space energy resources”smart city rhetoric managerial goals often intersect version sustain ability discourse idealized smart city instrumented environmental sensors resource management apps reduce carbon emissions increase carbon absorption cisco one dominant corporations smart city market made early splashy entry smart city development field around design songdo south korea city “was prototype sustainable urban life example city could reduce carbon footprint resource usage world everincreasing population climaterelated problems”as climate change events threaten cities sizes floods drought fire sudden temperature swings city managers struggle adapt without necessary budgets harden repair infrastructure one selling points smart city technologies improve climate mitigation strategies make cities “resilient” data collection thus smart city narrative “two discourses financial austerity sustainable environments intersect”what generates purported benefits smart city interventions flow data15 thought data generated surveil ance things people pro duce effective allocation resources cities prioritize services replacement water pipes according need16 provide dynamic parking curb congestion pricing roads combining topographical data motor vehicle data cities better predict needs help hurricane crowdsource realtime information emergencies smart city implementations like smart grid school truancy data trash disposal touch directly resident decisions expectation data “nudge” users toward better choices17 notwithstanding extensive criticism public objections lobbed predictive policing sentencing hope criminal justice datadriven decisionmaking yield efficient deployment government power applications datagenerated actions may unfair suspect motivation adam greenfield radical technologies design everyday life new york verso “if ambition beneath instrumentation body nominal selfmastery home convenience ambition heart smart city nothing control” herzberg smart cities chris muellerleile susan l robertson “digital weberianism bureaucracy information technorationality neoliberal capitalism” indiana journal global legal studies rob kitchin “the realtime city” brandon brooks alexis schrubbe “the need digital inclusive smart city governance framework” umkc law review –discussing use water sensors flint michigan detect pipes carrying leadpol uted water need replacing karen yeung “ ‘hypernudge’ big data mode regulation design” information communication society –how “smart” challenges democratic governance doubt motives authoritarianleaning regimes data flows explicitly part system population control smart city systems able ingest analyze even act autonomously integrated data digital physical realm facilitating control movement activities city residents18 flow data comes deliver smart city promises lead smart city problems often mapped layers resemble internet’s design bot tom infrastructure hardware ibm “sensors actuators pro grammable logic controllers distributed intelligent sensors”the middle layer data flows interconnect integrate data rendered visible city managers kind control center api also called tional power analytics produce performance dashboards predictions even automated actions21 critiques smart city projects focused principal loss personal lib erty surveil ance22 loss public control small number technol ogy companies come manage obtain preferential access essential digital infrastructure throughout city23 connected larger critiques informa tion platforms neoliberal privileging urban private24 technological archi tectures aggregate power platforms extract value personal data instantiated public space physical infrastructure intensify dangers data extraction shoshanna zuboff cal “surveil ance capitalism”these loss individual freedom entailed constant evaluation prediction private tech embedded public realm another danger transfer common wealth private corporations accelerate26 section entitled tion particular smart city projects ethical frames kent e calder singapore smart city smart state washington dc brookings michael kehoe et al “a foundation understanding ibm smarter cities” ibm redguides business leaders ellen p goodman julia powles “google’s urbanism” fordham law review forthcoming shannon mattern “mission control history urban dashboard” places journal janine hiller jordan blanke “smart cities big data resilience privacy” hastings law journal –kelsey finch omer tene “welcome metropticon protecting privacy hyperconnected town” fordham urban law journal maryiam saifuddin chad marlow stop “smart cities” becoming “surveil ance cities” washington dc sunlight foundation adam greenfield smart city jathan sadowski frank pasquale “the spectrum control social theory smart city” first monday richard c schragger “the political economy city power” fordham urban law journal capital markets almost canonical” zuboff age surveil ance capitalism jathan sadowski roy bendor “selling smartness corporate narratives smart city sociotechnical imaginary” science technology human values –ellen p goodman added specific critiques generalized skepticism technological determinism propels smart city projects framing public governance often whether certain surveil ance technologies manage data smart city projects mine open contestation general whether use city sandbox product development rather allocate intellectual property rights manage deployment determinism ben green says like looking world “tech goggles”it new phenomenon part tradition urban utopianism puts city planning beyond politics smart city implementations— especial infrastructure layer—can make technological determinism reality building capacity iteratively example streetlight upgrade leds city includes modules future surveil ance technology city already part way toward implementation technology public neither considered approved scenario recapitulates private sector patterns google shipped nest thermostats containing inoperative microphones millions consumers became much likely devices would used future record home prospect future connectivity may hidden present product feature becomes sur veil ance reality without deliberation consent technological creep kind may efficient also subversive one challenges policymakers ethical issues posed tech city cross many siloed domains reach far future officials responsible permitting public rights way infrastructure layer hardware example suddenly confronted data privacy issues prevalent digital intelligence lay ers add possibility sort tech used infrastructure layer eg 5g wireless transmitters comes specify configuration city functions data sharing protocols challenges managing smart city risk daunting attempt mitigate risks scholars policymakers citizen stakeholders developing frameworks address smart city norms next section surveys representative sample ethical codes field privacy welldeveloped area interdisciplinary scholarship law information science geography urbanism rob kitchin proposed data subjects “have full details data generated additional data inferred shared control benefit data relating subsequently used”lilian edwards applied eu law make similar ben green smart enough city cambridge mit press rob kitchin “the ethics smart cities urban science” defining universe ethical issues include “privacy datafication dataveil ance geosurveil ance data uses social sorting anticipatory governance” “smart” challenges democratic governance proposals29 proposals designed safeguard individual auton omy drawing human rights frameworks connecting general pre scriptions ai ethics30 another stream scholarship deals cybersecurity cal requirements secure smart city connected devices hacking cyberattack31 privacy security data governance critiques coalesce attempts fashion comprehensive data policies cities go beyond whatever national privacy law conventions apply civil society actors moving create functioning ethical codes smart cities different emphases basque declaration sustainability focused roadmap acclaimed hundreds european towns cities32 commits adherents among things good” structure support needed groups equal access information digital services” controlled private actors” sharing cities declaration statement agreement group larger cities including athens barcelona new york seoul sao paolo principles regarding platform economy33 statement privileges certain models ridesharing cohousing jobs provision platformmediated services city models favored col aborative open provide fair working conditions prevent discrimination support health safety promote environmental sustainability pro tect citizens’ digital rights data sovereignty protect city sovereignty regulatory compliance promote development local economic ecosystems preserve public spaces promote affordable housing separate statement digital rights espousing “rights privacy security information selfdetermination neutrality lillian edwards “privacy security data protection smart cities critical eu law perspective” european data protection law review –luciano floridi et al “ai4people—an ethical framework good ai society opportunities risks principles recommendations” minds machines –scott r peppet “regulating internet things first steps toward managing discrimination privacy security consent” texas law review fritz al hoff adam henschke “the internet things foundational ethical issues” internet things ––identifying informed consent privacy trust information security physical safety principal ethical issues “the basque declaration new pathways european cities towns create productive sustainable resilient cities livable inclusive europe” eighth european conference sustainable cities towns “common declaration principles commitments sharing cities” httpwww sharebarcelonadeclaration fortytwo larger cities agree principles regarding platform economy ellen p goodman giving citizens choice happens digital identity uses data online purposes” also requirement platforms “enable algo rithmic accountability portability users’ data digital identity reputations” cities access “relevant data firms operating territories” another international consortium cities digital rights group pro duced highlevel declaration city support digital rights including “open ethical dig ital service standards”dozens us cities signed onto internet things set best practices drafted city new york36 code focuses data management infrastructure respect privacy transparency prescribes data col lected transmitted processed used legitimate purposes anonymized default made accessible maximize public benefit transparency sensors deployed clear expectations maintaining security infrastructure data flows synthesizing academic city civil society proposals francesca bria formerly city barcelona advocated various degrees implemented alternative democratical controlled vision smart city37 basic thrust vision cities must take control digital futures exercise “technological sovereignty” sovereignty entails promoting alternative data ownership regimes alternative digital infrastructures alternative models service provision view towards resisting private enclosure data specifical version smart city ethics would insist “data commons” private corporations bound share data commons lack incentive overcollect data proprietary use data commons could also used foster col aborative alternatives private ride sharing housing platforms many policy technological prescriptions survey might include partial picture quickly emerging set reactions even faster moving deployment technologies frameworks kaleidoscopic reflecting breadth smart city implementations nevertheless possible distill frameworks three central normative concerns relate maintenance dem ocratic governance addressed following challenges democratic governance focusing private power exercised data flows section identifies three normative concerns running ethicsfocused smart city literature theo bass emma sutherland tom symons reclaiming smart city personal data trust new commons nesta httpsmedianestaorgukdocumentsdecode2018report smartcitiespdf httpscitiesfordigitalrightsorg httpsiotcityofnewyorkus morozov bria rethinking smart city –how “smart” challenges democratic governance stakeholder response technologies privatization public functions assets databased platformization services threat domination concentrated technologies pose individuals public entities competitive markets privatization public partnerships technology companies may end privatizing fundamental public planning regulatory enforcement functions along ownership public assets smart city movement started csuites major telecommunications technology companies like cisco ibm microsoft set products marketed city managers serious urban problems considerable resource constraints38 cities subject financial austerity susceptible promises greater operating efficiency private financing dependent vendors development implementation technological change late twentiethcentury neoliberal faith markets private capital shrunk public capacity solve problems39 environment natural cities welcome privatepublic partnerships finance smart city deployments also using partnerships signal city innovative “open business” role private venture smart city partnerships varies kind degree amsterdam smart city “innovation platform” example involves com panies well educational institutions nonprofits smart energy mobility pilots40 largely experimental distributes participation among many partners using mostly open data cases vendor operates fulfill public service outsourced private sector role uber plays example partnership city columbus united states fill public transit gaps vendors often engaged kind datasharing agreement city dal example ericsson aggregating analyzing traffic data manage traffic real time early smart city visions proffered cisco ibm put single company center integrated smart city nervous system like ibm’s intelligent operations center data generated diverse urban functions run company’s control41 newer approaches evolving toward participation multiple companies single company serving city’s brain42 partnerships vendor relationships tend vest significant power private technology companies virtue companies’ control data dangers evgeny morozov save everything click fol technological solutionism new york public affairs jason hackworth neoliberal city governance ideology development american urbanism ithaca ny cornell university press margarita angelidou “four european smart city strategies” international journal social science studies donald mcneil “ibm visual formation smart cities” smart urbanism utopian vision false dawn ed simon marvin et al london routledge –mckinsey global institute smart cities digital solutions livable future ellen p goodman basque declaration’s barcelona’s principle open data sharing cities declaration’s principle data access seem addressed notion underlying data shared resource ability make use data benefit widely dispersed whatever merits open data policy solve problem concentrated power dominant companies like alphabet huge advantage data data analytics leverage insights gained pre dictive models probably never opened scrutiny trade secret protection access data may less important competition perspective access resources including data analytics even access data key market entry wherewithal clean utilize massive amounts data may scarce asset concentrated big tech companies thus require open data policies ensure private data power overwhelm public interest distributed benefits sort private data power vest companies quasipublic planning func tions transportation development investment toronto google affiliate sidewalk labs joined waterfront toronto public authority responsible waterfront development city “thinking partner” cocreate master innovation development plan43 public entity delegated much initial public engagement data gathering priority setting company private entity case merely consultant partner planning responsibilities along downstream opportunities land development technology contracts one advocacy group described arrangement “governance mercenaries” instead debating policies public making government responsible regulation accountability”vendors deploy smart city applications also become responsible later stage regulatory functions45 consider algorithm directs police target particular neighborhoods residents interventions vendors control algorithms exercising form regulatory power policy choices—such assess crime risks prioritize—their programs implement46 another example delegated regulatory control building context common smart city aspiration maximize flexible use streets structures physical assets increase efficiency outcomebased zoning code tool achieve flexibil ity setting usage limits eg occupancy levels building otherwise per mitting mixed use sort code make generalpurpose buildings adaptable goodman powles “google’s urbanism” canadian civil liberties association “governing mercenary” january httpsccla orggoverningbymercenary criticizing sidewalk labs control waterfront toronto planning mireille hildebrandt “algorithmic regulation rule law” philosophical transactions royal society rebecca wexler “life liberty trade secrets intellectual property criminal justice system” stanford law review –robert brauneis ellen p goodman “smart” challenges democratic governance residential business use extent private vendor designs code collects data controls analytics required assess compliance taken charge basic regulatory function zoning using example hard imagine private enforcement wel use building exceeds allowable limits outcomebased code enforcement take form fines denial access code violations enforcement deputized private entity overlap private contract violations private rights action adjudicated algorithm suppose example landlord tenant dispute property use landlords exploit realtime “smart” rental hous ing adjudication locking tenants upon perceived breach contract47 unless due public process vendor code smart contract effectively law enforcer case one first smart city applications red light cameras one policy strategy confront challenge simply ban tech nology states new jersey ohio done concluding must delegate public police power vendors whose interest collecting fees red light traffic violations another strategy cabin functions private data com pany case redlight cameras another jurisdiction allowed vendor make preliminary determinations ultimately subjected official review48 addition regulation enforcement smart cities entail privatization public assets data best example cities collect data residents environ ment physical objects within jurisdiction access data companies may able extract value without making return public value taken new york city tried address contract another google affiliate intersection company provide wifi kiosks city streets return allowed advertise residents based data49 city negotiated receive share advertising revenue thereby staking claim monetary value resi dent data city deployed revenueshare model microsoft partner developing domain awareness system network sensors databases hardware software puts “information realtime analysis intelligence directly hands police officers”in return city’s contribution data system receives cut revenue microsoft sel system cities tension values privacy return investment soon city obtains revenue share exploitation citizen data incentives market participant exploit data time role regulator incentives safeguard resident dataprivacy interests dual role city alfred ng “your landlord turns apartment smart home what” cnet jimenez v state florida sc161976 ava kofman “are new york’s free linknyc internet kiosks tracking movements” intercept september gr halegoua j lingel “lit left dark failures imagination urban broadband networks” new media society –new york police department “developing nypd’s information technology” ellen p goodman venture partner citizen protector root second set normative concerns discussed following platformization “city platform” key concept smart city discourse raises concerns kinds social arrangements platform privileges51 recognized value public data—data city already collects may collect future— cities inviting service providers innovate “on top” data “open data plat forms” whereby cities make available public data becoming relatively common recommended codes discussed earlier model networked nodes circu late data stored cloud governmental private entities operationalize data run algorithmic processes personalize services eg housing employment nudge residents toward certain behaviors eg conservation voting construct differential opportunities eg education commerce city platform model effect converts public private services—treating same—to applications “edge” network along lines internet52 principal concern platform values platforms mine data trails human activity ever minutely observed curated data flows propel users toward particular technosocial arrangements depending platform wants optimize53 might engagement facebook value office real estate highflying wework coworking platform social political economic arrangements city platform tries optimize commercial platform technologies city like uber airbnb provided significant consumer value time produced negative externali ties forms congestion increased housing costs unregulated consumer risk unfair labor practices information platforms proved market segmentation personalization satisfy consumers also means degrading social solidarity wellbeing subjecting relationships market rational ity open create new markets benefit buyers sellers also displace nonmarket relationships produce externalized social costs borne buyers sellers characteristics platform markets raise normative ques tions smart city extensions platform model sarah barns platform urbanism negotiating platform ecosystems connected cities singapore palgrave macmil david bollier city platform digital networks changing urban life governance washington dc aspen institute stephen goldsmith neil kleiman new city os power open col aborative distributed governance washington dc brookings institution press tim o’reil “government platform” innovations technology governance globalization –tarleton gillespie “the politics ‘platforms’ ” new media society –how “smart” challenges democratic governance efficiency principal value digital platforms smart city implementations inflect urban governance “instrumental rationality” insisting efficient solu tion public needs measured precisely quantification data54 city platform also city “marketplace” products services traded quintessential public goods like utilities education participation health care smart city imaginaries designed toronto sangdo users order city amenities like park space parking places portal app much would car food delivery may make efficient use public resources produce consumer value civic exchanges personalized risk collective indeed sense collective networked architec ture distributed internet individuals interact platform connecting service providers disintermediates civic institutions political organiza tions networked nodes connect individuals services flows data obvious institutions like schools libraries political parties community organizations fit model market rationality interrupt forms civic life yet cannot reduced measurable data served via app55 values efficiency like equity sociability may driven exchange part address concerns sharing cities declaration tries privilege cooperative structures provide benefits platform exchanges commodification long prevailing platform models rely mining behavioral data profit problems “privacy” better denoted blows liberty reason ethical codes cited earlier include data privacy protections context smart cities protections limited utility existing notice choice regimes cannot scale ubiquitous instrumentation place privacybydesign solutions rely deidentification vulnerable ease reidentification exploitation inferences derived even anonymized data56 data mobile phones alone provide granular records life even de identified57 notice choice norms protect privacy smart cities simply work data gathering happens outside zones choice feasible opt refuse opt systems data collection embedded public shannon mattern “methodolatry art measure new wave urban data science” places evgeny morozov save everything click critiquing “solutionism” urbanism orit halpern et al “test bed urbanism” public culture benjamin de la peña “embracing autocatalytic city” citylab criticizing model city machine tuned rather “stochastic chain choices adding emergent whole” sandra wachter brent mittelstadt “a right reasonable inferences rethinking data protection law age big data ai” columbia business law review sandra wachter subjects end time data collected therefore data protection laws fail guard potential harms inferential analytics” jennifer valentinodevries et al “your apps know last night they’re keeping secret” new york times december ellen p goodman realm workplace shared rental housing utilities inadequacy current data privacy regimes especial captive residents argues consideration data collection sharing bans city bans facial recognition technology may harbingers move possible approaches include enforceable duties care imposed entities touch data well data trusts subject public realm data independent control equity final concern raised platformization one promises smart city projects improve governance governmental responsiveness egovernment initiatives give residents voice urban governance access government processes adopted early continue feature vendor marketing surveys cities reported responsive gov ernment one foremost smart city goals58 whether responsive “city platform” also equitable city depends part data inputs data derive data corpus constructed measurement political59 everyone everything counted counts inaccurate data used train relevant artificial intelligence narratives drawn models data correlations determinations made throughout process shape resources rights allocated example park rarely used safety concerns might show data park one wants exists unserved demand park need fundamental change improve safety may show data extent smart city data analytics “see” residents precision interest feature longstanding “digital divide” problem data divides add reinforce traditional “digital divide” problem past referred inequities distribution digital connectivity hardware older problems wel new salience smart city context danger exclusion digital disadvantage grows basic functions rendered exclusively digital platform basque declaration makes explicit connection digital inequality smart city ethics mandating attention digital divide issues potential increased economic domination platformization create one form domination—the subject next section domination ethical norm autonomy correspondingly nondomination runs everything discussed thus far city mediated apps portals authentication protocols makes residents dependent technologies cannot interrogate united states conference mayors cities 21st century better governance one top three objectives mayors mcneil “ibm visual formation smart cities” “smart” challenges democratic governance meaningful resist public officials reliant vendors private partners basic operations may similarly dependent information asymmetries network effects confer extraordinary durable power entities take control data effectively ways smart city implementation poses risks domination individual systemic levels cal strategies distribute power interests freedom technical insecurity exposes smart city residents risk domination mal function networked technology buggy brittle susceptible viruses hacks data breaches power failures smart city systems become complex interre lated risks catastrophic failure grow example “cloudcomputing outages could turn smart cities zombies” power connectivity outages undermine biometric authentication used “determine rights privileges move city—granting physical access buildings rooms personalizing envi ronments enabling digital services content”a smart city instal ation south korea example provides realtime information water supply sensors software systems owned private companies supply data city sensor fails city shut system coordinate among com panies resolve problem61 another form systemic domination market control digital markets tend toward concentration companies like ibm google uber take positions smart city deployment may well end dominating market opportunities city contracts concerned competitive procurement policies mitigate threat however policies usual loophole specialpurpose vendors—an exemption frequently exploited technology area dominant companies unique datagathering analytics capabilities case state illinois example smart city company replica another google affiliate benefited “solesource” contract transport analytics replica merges private data mobile phones social media data public realm like licenseplate read ers bikeshares show real time “the total number people highway local street network mode they’re using trip purpose”once gain preferred position big data companies entrench city functions data dominance leads recursively even data power especial company plays platform role mediating residents services bria morozov observed “many smart city projects conceived proprietary urban operating systems leads market domination handful corporate actors intensifies pervasive targeting consumers sensor technologies surveil ance mechanism”anthony townsend “smart cities buggy brittle” places journal october sawyer clever et al “ethical analyses smart city applications” urban science ava kofman “google’s sidewalk labs plans package sell location data millions cellphones” intercept january morozov bria rethinking smart city ellen p goodman urban operating system public officials frontline workers may dependent platform user may access data api processing order understand algorithmic rules recommendations tasked implementing humans need know lot system produced outputs did64 consider example algorithmic prediction deployed family services context social worker may presented two cases flagged intervention one higher risk score worker cannot exercise profes sional judgment prioritizing cases without knowing scores devel oped much distance relevant features absent understanding social workers police teachers inspectors become deskilled ever reliant directions machine understand fear secondguessing65 material cities become dependent systems lock propri etary data software criminal justice data vendor palantir enticed city police departments use data analytics product low cost free cities dependent company access data palantir made difficult go elsewhere develop capabilities inhouse66 cities became data vassals companies data power concern addressed basque declaration’s privileging procurement using “decentralised local solutions” presum ably neutralize power large concentrated companies sharing cities declaration’s emphasis city “sovereignty” addresses concerns smart city security internet things best practices seek harden networked infrastructure ultimately cybersecurity best practice rescue citizens systems failure challenge build redundancy reduce dependencies whether means technical workarounds alternative business models public workforce remains decisional loop conclusion smart city deployments raise normative concerns health democratic gov ern ance individual freedom especial spearheaded private companies publicprivate partnerships risks data collection data analytics concentrate power unaccountable entities entities able michael ananny kate crawford “seeing without knowing limitations transparency ideal application algorithmic accountability” new media society –john danaher “the threat algocracy reality resistance accommodation” philosophy technology raising concerns deference algorithmic output human decision makers cannot understand algorithms work mark harris “how peter thiel’s secretive data company pushed policing” wired august “smart” challenges democratic governance shape resident experiences opportunities without consent possibly even knowledge specific form threats fall categories privatization platformization domination policy responses required preserve public authority algorithmic governance public assets make space forms service provision platform distribute power urban governance bibliography edwards l “privacy security data protection smart cities critical eu law perspective” european data protection law review –halpern et al “test bed urbanism” public culture kitchin r “the realtime city big data smart urbanism” geojournal marvin luqueayala c mcfarlane eds smart urbanism utopian vision false dawn london routledge morozov e f bria rethinking smart city democratizing urban technology new york rosa luxemburg stiftung townsend smart cities big data civic hackers quest new utopia new york ww norton yeung k “ ‘hypernudge’ big data mode regulation design” information communication society –index note figures indicated f following page number aaai see association advancement responsibility –artificial intelligence review –aberdeen group security abiko motoo system behavior –ableism teaching –absolute boyfriend transparency –abstraction units analysis –error 183n7 verifiability –judgment –380n26 accountability responsibility ab testing transparency art –f abu dhabi global market –accounting accountability –academic thought accuracy law china –aclu see american civil liberties japan union south korea acm see association computing techlash –f machinery accenture acquisitiveness 401n128 access –acquisti alessandro accountability –actant –238n8 agency –acting 68n46 see also deception art –f actornetwork theory ant –computer systems –acyclic graphs see directed acyclic graph corporate law –ada see algorithms data ai fat 166n10 –adaptability art –f fate adaptive flocking behavior fatml adaptive governance center governance goal –adaptivity flexibility inclusiveness reflexivity hipaa responsiveness monitoring law ethic –mechanisms –adi see artificial design intelligence migration technology –adm see algorithmic decisionmaking normative fidelity –administrators law –oversight –adobe personalized learning systems –dreamcatcher personalized learning systems –scene stitch recordkeeping –sensei ai index advanced technology external advisory airbus council –airlines adversarial exemplars aksamija ajla ––advertisements alarp see low reasonably practicable advertising systems alcohol abuse advisory board meetings aldus pagemaker aec see architecture engineering alexa virtual assistant construction agr affect theory 395n104 auditory cues affordable housing crisis consent affordance –wil theory afirrm see adaptivity flexibility alexander christopher inclusiveness reflexivity responsiveness alexander michelle monitoring algeria f f–f see also african american 175n44 middle east north africa ahps algorithm 108n5 ai design –accountability criminal law ––750n78 anthropology –crm –architectures –faculty members f auditability names –automation design –power imbalance –bias –predictive policing –in design –segregation discrimination –women –in fabrication –afst see allegheny family screening tool guardrail pairing –agamben giorgio –guardrails –agency –inspection –accountability –in migration technology –causal 198n9 ml –6n8 intentional 198n9 planning –agent neutral project management –the age spiritual machines kurzweil segmentation agi see artificial general intelligence algorithmic decisionmaking adm agr see automatic gender recognition –ahp see automated hiring platforms transparency –ai see artificial intelligence algorithmic governance ai4people algorithmic judgment –aiassess human displacement –aibo robot dog human judgment –ai hleg see highlevel expert group algorithmic oppression artificial intelligence algorithmic society ai uk ready wil ing able algorithmic syntax –ai institute algorithmic transparency –ai report problematizing –airbnb algorithms data ai ada guardrails algorithmwatch platformization alien film franchise –index alife community 347n9 anthropology ai alkhatib ali algorithms –allegheny family screening tool afst conclusions –allen colin –intelligence –all us research program us –introduction –alm model see autor levy murnane personhood –model robots –alphabet anthropomorphism –alphago female objectification altari anthropomorphized tools paradox alterity politics nealon 549n36 altruism –antiartificial intelligence alzheimer’s patient anticipatory ethics amazoncom antidiscrimination efforts –alexa antiimmigrant cloud computing software –retrenchment consent antiuniversalist sentiment criminal law antivagrancy statute echo look –aoir see association internet researchers facial recognition technology api see application programming interface gender bias –application programming interface granular measurement apple hiring model –face id 246n20 inactivity reports privatesector investment lab126 siri nsf col aborative project –smartphones –privatesector investment application programming interface rekognition surveil ance ––shareholders appriss retail techlash appropriation worker displacement aq11 amazon go ar see artificial reality american civil liberties union arab convention combating information technology offences american institute architects arabic translation –american medical association arab knowledge report amnesty international –arab spring –amsterdam netherlands arbitration fairness act analytical engine arcc see available reliable anders günther comprehensive control able ando lloyd—ai knows love architecture engineering construction android kannon animal liberation singer –arendt hannah animals see also harm human cruelty –62n23 argic serdar harm –ariane rocket failure –protection laws –62n23 aristotle ant see actornetwork theory technē –index arizona us –risk reallocation –arkin ron risks –armenians robots –arpanet sexuality –art see accountability responsibility trustworthiness –transparency wellbeing –294n19 art artificial intelligence laboratory work ––artefact inc worker displacement –artifacts ––444n8 –artificial intel igence russell norvig accountability –artificial reality ar glasses external cognitive artificial superintelligence see superintelligence work –artificial schneider artificial design intelligence adi –ashkenazi jews artificial general intelligence agi asilomar principles ai –asimov isaac rights –first law robotics artificial intelligence ai robot algorithmic governance –three laws robotics anthropology –379n17 automation origins –f low reasonably practicable alarp codes standards –requirement 90n39 consciousness –298n28 association advancement artificial consent –intelligence aaai design –association computing machinery acm designed artifact –code conduct fairness –code ethics ––glistening simulacrum fat conference 166n10 governance –association international accountants handoff model –association internet researchers human replacement –human rights –astro boy human rightscentered design –atari video games ict –athens greece intelligence –atm see automated teller machine law regulation –attenuated accountability legal definition –audit company love –auditable algorithms mena –f f–f f auditory cues narrative –australia overview –transport f policy framework –authenticity private sector incentives –authority transport –professional norms –autobraking system race gender –autocad responsibility –autodesk rightholders –294n18 298n3 auto draw google index automated driving systems see selfdriving available reliable comprehensive vehicles control able arcc automated hiring platforms ahps ayala saray –azraq refugee camp bias –criticisms –b2c see businesstoconsumer current use babbage charles –discrimination bacon program –information asymmetry bahrain f –privacy concerns baidu –automated teller machine atm bail determinations –automatic gender recognition agr –bail predictions automation see also work balancedodds criterion design –balanced scorecard concept failure bangalore origins –f bangladeshi autonomous decisionmaking –barcelona spain –ahps –barcelona declaration –in migration technology –barocas solon autonomous power barrett lisa feldman deceive –basic statistics destroy –basque declaration –to hurt –bateson gregory autonomous vehicle av see also bathroom gender transport ethics bathroom breaks crash dilemma battlefield robots see autonomous weapons ethics –system guardrails –battlestar galactica autonomous weapons system bauhaus banning –bayesian inference complacency bayesian networks control –bayesian probability ethics –bayesian test judgment –bci see braincomputer interfaces autonomy ––de beauvoir simone art –f behavior see also system behavior control –cognitive behavioral therapy control relinquishing –directing mechanisms –deep learning networks –eyegazing –introduction –flocking autonomycritical aspect –gazing –autonomy space intelligence –autor david h selfharming autor levy murnane model alm systems transparency model ––av see autonomous vehicle unethical –index beijing academy ai biometrics beijing ai principles brainwaves –bel emily fingerprints –the bell curve india –beloussovzhabotinsky chemical irisscanning –reaction migration –benefit humanity technologies bengio yoshua wearable technology –benjamin david –bisexuality benjamin ruha blackbox benny jack algorithms –bentham jeremy machine learning –beqiri rron –in migration technology berger theodore opacity –bergin michael responsibility –bernstein phil transparency bess michael black box society pasquale best practice software engineering –black mirror betrayal –see also deception blackstone william commentaries bharadwaj raghav laws england bias –blackstone group ahps –blade runner –codes standards bletchley park economic value –bluetooth technology facial analysis tools –bmvi see german federal ministry judgment –transport digital infrastructure race gender –boden margaret –347n9 bicyclists boeing max airplane 378n13 bidirectional information access bong soona cyborg love big data booker cory algorithmic tools boolean logic –contextualization boolean searches discrimination –border enforcement –in health care –borg mom learning –bostrom nick 6n5 –in migration –bots see chatbot robots quasinormative principles –bots gate report smart cities botto bistro bim iq autodesk brain binns rueben based materialism –biocentric individualist –biometrics –bioethics –brainwave id –bioinformatics google project biological enhancements –hacking biomarkers implants biomedical ethics technological singularity biomedical research ––index brain chips see also technological capital investments singularity capitalism –braincomputer interfaces bci capmas see central agency public neuralink –mobilization statistics branding carebots brandt commission paro braverman harry careem ridesharing company brazil caregivers breton andré carpo mario bria francesca carr nicolas 319n34 bridle james cartesian ego british colonialism cartwright nancy british national health service –cas see chinese academy science broadband mena casa see computer social actor brock andre casebased comparison –brown eric castel manuel buddha casual considerations statistical models buddhism –and –f–f budget planning causal agency 198n9 building information research knowledge causality –base 579n29 statistical models –building system planning f buolamwini joy –causal knowledge –burawoy michael –cave stephen –bush pump zimbabwe –cctv cameras businesstoconsumer b2c cde see controlled direct effect butler chris cds see computational data science butler samuel cell phones see mobile phones byun sunyoung center mind design –central agency public mobilization caai see chinese association artificial statistics capmas intelligence centre data ethics uk calarco matthew cephalopods calibration group ––certain measures calo ryan certification cambridge analytica certified safety auditors facebook data –cfaa see computer fraud abuse campaign stop killer robots chalmers david canada 776n37 changsha university science governance technology transport f charters rights canadian charter rights chatbot –freedoms sal canadian directive automated xiaoice decisionmaking 100n70 chemical agents digital computers think turing chemical weapons convention capek karel –chemotherapy index chen le acm ––childbirth 15n37 artificial intelligence –children caregivers codes standards china advantages –academic thought –conclusions –facial recognition technology dangers –google –introduction –new generation ai development value concepts –plan –varieties –polices –code violation popular culture –codified pedagogy –reputation score coeckelbergh mark –robots –cognitive ability see social credit score also technological singularity uighur population cognitive behavioral therapy china room thought experiment –cognitive enhancements –329n8 cognitive prints ibm chinese academy science cas cognitive science humancentered chinese association artificial intelligence approach –cohen richard chobits cold war –chomsky noam collective medical mind chuang john colonialism churchland paul –colorado pretrial assessment tool cisco systems colton simon smart cities columbia journalism school cities digital rights group columbus us citizenship robots coming technological singularity city planning commissions civil law rules robotics committee digital economy civil liberties –policy –claimright 290n6 291n11 common good –305n46 communication clark andy hpcc act –clashmep building system planning ict classlabor surveil ance intelligence –clickbait headlines compas software –cloning compensation f cloud computing software –claims cluster atmospheric research satellites undercompensation –coast guard agency wearable technology –code conduct see also professional work –norms competition rules datadriven healthcare competitive concerns ethics –complacency weapons systems code ethics see also professional compliance see accountability norms component handoff model –238n8 index computational creativity group scope –computational data science cds –voluntariness –predictive science –consequentialism computational models –see also conservative ideologies statistical models constant capital –transparency constitution us 246n24 247n25 computational therapist see virtual –therapist due process computer social actor casa first amendment computer fraud abuse cfaa –fifth amendment 246n24 247n25 computerized lottery sixth amendment computer systems fourteenth amendment accountability –constitutional law see constitution us intelligence –construction sites –as mathematics –contextual norms sentience control computing machinery intel igence autonomy –handoff analysis conceptual act theory sexual relinquishing –orientation controlled direct effect cde conditional independence –control problem conference artificial intelligence conventional enhancements confidence values conversational ai confidentiality cooperation ––confinement social –cooperative consent –confounder –f f cooperative inverse reinforcement confounding learning congress us copyright conitzer vincent corporate codes consciousness accountability –ai –298n28 norms –biological enhancements techlash ––correa charles –intelligence corrective justice philosophy correctness mathematical standard sentience –––72n58 cost color monk consent costs background conditions –of individual liberty conclusion transmission –fairness –council europe –interpersonal model –counterfactual fairness criterion –introduction –counterfactual reasoning –190n24 knowledge –counterfactual thinking migration technology –courtroom practices moral core –cranor lorrie political philosophy 272n56 –crawford kate power dynamics –creationism –index creative adversarial networks csíkszentmihályi mihály ––creativity ai origins –ctda see critical technocultural discourse credit card fraud analysis credit card providers culpably ignorant creditrating agencies culture evolving credit risk prediction customer relationship management credit scores consent –criticisms –fairness –current use –law future –transparency cyberassets creditworthiness cyberattack crenshaw kimberlé –cyber civilization research center crime hot spots –cybersecurity –crimes humanity design crime statistics ––threats 283n57 criminal history cyborg criminalization –cyborg manifesto haraway –criminal justice system –cyborg data cylons facial recognition –psa 747n56 747n58 daca see deferred action childhood sentencing –arrivals software dag see directed acyclic graph criminal law dal us african americans ––dalton 750n78 daniels jessie –best practices –dartmouth college decisionmaking –dartmouth summer research project facial recognition –artificial intelligence –false negatives –darwin charles –false positives –747n58 750n78 data fat algorithms –asymmetry pretrial detention –blur reform –colonization violent crime 741n22 747n58 dominance –criminal risk assessment migration technology –modeling se –criminal sentencing –myopia crisis risk dashboard 772n8 privacy critical internet studies rights –critical technocultural discourse analysis scholarship stewardship crm see customer relationship management transparency –crumple zones vehicles 445n9 data commons cryptographers datadriven sorting system see algorithm cryptography datadriven urbanism index data protection laws domination –consent ––platformization –dataset nutrition label privatization –datasheets datasets demographic parity ––da vinci leonardo –dennett daniel –dconnection denning peter deadly dilemma –deoxyribonucleic acid dna deaths despair recombination deaton angus replication –deception see also transparency department defense us autonomous power –department education us –creation –68n46 department homeland security us decisionmaking adm –department labor us ahps –depression autonomous –depthmapx space syntax canadian directive 100n70 descendent –in criminal law –the descent man selection relation humanitarianism –to sex darwin law –design automation migration –algorithms –migration technology –fashion design –transparency –of graphic design –deep fakes introduction –software ml –6n8 deeplearning algorithms product design –autonomy –race gender –cardiovascular risk designed artifact –incentives destroy see also autonomous weapons deepmind –system deepmood tool –autonomous power –deep neural networks determinism –deep value pluralism dht see digital health technology defense advanced research projects dick philip k agency darpa digisexuality –deference 390n75 digital artifacts see artifacts deferred action childhood arrivals digital bioethics digital clones deflationary view –digital commerce platforms degraffenreid emma digital consent –see also dehumanization see also technological consent singularity digital divide europe digital health technology dht delaware v prouse –763n33 –demanddriven disclosures –digital redlining ––dementia digital revolution –democratic governance see also governance dipaola steve index directed acyclic graph dag –driverless cars –f–f see also statistical drones papers models drone technology program –directed duty –292n13 drug abuse directionality rights dualist theories disciplinary power dubai international financial centre –discrimination –due diligence ahps proof algorithms ––duplex voice assistant antidiscrimination efforts –durham police force 100n69 big data –dutton tim crm –duty –economic value –dwell magazine freedom –dystopian nightmares global south –dystopian views –in migration technology –national transgender discrimination ead see ethical aligned design survey –earp brian police practices –easa see european aviation safety agency substrate nondiscrimination east asia ai wearable technology china –discrimination rule discussion –disease diagnosis introduction –disengagement concern sexuality japan –dishonesty see also trust south korea –in crm ebay displacement work –echo look –dispute resolution echr see european convention distribution license human rights diversity –see also race gender ecodesigner star responsibility economic forecasts dividual cyborg economic reform structural adjustment dmz see korean demilitarized zone program ersap dna see deoxyribonucleic acid economic value androids dream electric sheep biases –discrimination –doctor script ethics –document collection fairness –dogs robot –human autonomy –aibo inequality –domain awareness system introduction –domaincrossing skil 523n7 novel externalities –doppelgänger superintelligence –doraemon ecpais see ethics certification program doteveryone autonomous intelligent systems dreamcatcher adobe ecuador driveai edmund pettus bridge selma us index education see also teaching engineering bottlenecks –ferpa –engineering ethics textbook governance –engines anxiety espeland nsf –sauder –race gender –enhancement see technological singularity rights –enlightenment –women –ensmenger nathan edwards lilian –enthusiastic consent eeg see electroencephalogram eod see explosive ordinance disposal egalitarianism see also fairness ephemera ege see european group ethics epistemology science new technologies ethics –egypt see also middle east epsrc see engineering physical north africa sciences research council uber equality rights –ehr see electronic health records equalized odds –––einstein albert equity see also human rights elasticity algorithms –centered design eldercare robot –criminal law electroencephalogram eeg platformization –electronic health records ehr –erewhon butler elimination occupations see also erie canal –worker displacement error analysis eliza program –ersap see economic reform structural ellerbe associates adjustment program ellison harlan espeland wendy –email –essential contested –emergency integrated lifesaving lanyard ethical ai ethical governor –emergent selforganization –347n9 ethical guidelines trustworthy ai 85n26 emily see emergency integrated lifesaving ethical aligned design ead –lanyard –emotion 72n58 ethical os toolkit emotional support –see also sexuality ethical theory empathic computer holden modeling –empathy –standards employee lawsuits ethical weapons employee safety –ethics ai employment history av example –encryption see also handoff analysis biomedical research –endtoend boards smartphones –codes standards –endtoend encryption conceptual ambiguities –end user license agreement eula design –enforced selfregulation 90n38 east asia –engineering physical sciences research economics –council epsrc epistemology –index ethics ai continued european space agency fairness –f european strategy better safer ai fair notice –761n25–children function –european union eu handoff analysis –ai hleg ––humancentered approach –algoaware project 85n25 implementation –borders individual user models –cloning law –data protection directive oppositional approaches –data regulations within –origins –ethical guidelines trustworthy patient care –ai 85n26 philosophy –ethics guidelines –predictive science –gdpr –privatesector incentives –general data protection regulation public health –internet studies centers responsibility –f legal order risks –oecd –robots –personal sovereignty smart cities –sextracking apps social failures –trustworthy ai –systemic approaches –evans dylan transports –f evidence –trust –f evolution theory ethics certification program autonomous existential risk superintelligence –and intelligent systems ecpais exogenous random noise ethics guideline intelligent information exoskeletons –see also society technological singularity ethics guidelines eu –explainability –ethics washing explainable ai xai ethiopia see also middle east explicit ethical agents north africa explosive ordinance disposal eod ethnicity see also race gender robots ahps external cognitive artifacts eu see european union external ethics review board eula see end user license agreement externalities euroamerican contexts discrepancies –european aviation safety agency easa superintelligence –european border coast guard extreme vetting initiative agency eyes –european commission –health systemeye ––irisscanning –european convention human rights faa see federal aviation administration european group ethics science facebook –new technologies ege 656n14 advertising platform european parliament –cambridge analytica –index consent principles –ethics –sentencing –hate speech –state ai –language statistical modeling –f–f myanmar –f–f f–f news feed –techlash –f –f privatesector investment voice recognition –public commitments 84n23 fairness accountability transparency sal chatbot techlash acm 166n10 translate –algorithm limits –user data –algorithms –face id 246n20 fairness accountability transparency facial characteristics machine learning fatml facial recognition fairness accountability transparency ahps ethics fate amazon fairness unawareness ban 178n57 fair notice consent conclusions –criminal law –heuristical understanding –fairness ––guardrails inputoutput functionality –in migration technology ––inputs –race gender –introduction –sexual orientation output –761n25–smart cities tripartite model –761n25–in zimbabwe us supreme court –761n25–factory farming fair process migration –fail safe management fair trade –failure modes –see also social false negatives failure modes criminal law –fair credit reporting act racial groups –fair labor standards act flsa false positives 246n20 –control fairness see also human rightscentered criminal law –747n58 750n78 design racial groups –arbitration fairness act false universalism consent –family anthropology counterfactual fairness criterion –fashion credit scores –fashion design –criteria –f–f fast food jobs criteria models –f–f fat see fairness accountability economic value –transparency ethics –f fate see fairness accountability ethics origins –transparency ethics natural justice –fatml see fairness accountability oblivious fairness criteria –transparency machine learning index fault –forced transparency –fauxtomation fordism fayerman michael forensic analysis –9n13 fda see food drug administration formalism fear –forrester survey –federal aviation administration faa forsythe diana e federal educational rights privacy act fortress europe foucault michel female objectification see also sexuality foundation responsible robotics feminism –fourteenth amendment ferpa see federal educational rights us constitution privacy act fractal geometry –fiber optic systems fragility algorithms –fiduciary france fifth amendment us constitution governance 246n24 247n25 trustworthiness years unfairness hutchinson frank lily mitchell frankenstein shelley films fraud alien –cfaa –battlestar galactica detection prediction –blade runner –free basics program –in china –freedom see also constitutional law cyborg manifesto –of assembly discrimination –i robot expression –in japan –of opinion –in south korea –of religion terminator thought –a space odyssey freedom house species meet –freedom information foi final jeopardy mena –f financial incentives –regulations –the financial times f 164n3 freedom press report fingerprint id –freud sigmund 340n12 fingerprints –248n32 frey carl –first amendment us constitution friedman milton flocking behavior frontex see european border coast florida us guard agency floridi luciano –frow pennie flsa see fair labor standards act fujimoto hiroshi foerst anne –funding matters 175n45 foi see freedom information funny robot talk food drug administration fda futurists us –public health ––gaai see generalized autonomous ai food safety gabora liane index game theory glauber transparency –global compact safe orderly regular gan see generative adversarial network migration gandhi global initiative ethics autonomous garcia martinez antonio intelligent systems ––gardner howard global north gartner report global positioning system gps –gatebox ai vinclu inc –gaussian linear model –global south gauthier david ai impact –gazing behavior –biometrics india –gdpr see general data protection regulation developing countries –gebru timnit –discrimination –geminoids facial recognition technology gender see also race gender international human rights –the gender gift strathern introduction –gender recognition gender myanmar –reductionism refugee data collection gender segmentation mena gm see general motors gender shades buolamwini gebru go board game gender studies goffman erving 68n46 general data protection regulation goldman sachs good irvin john 653n6 goodhart’s law –general intelligence google agi –adm superintelligence alphago generalized autonomous ai gaai assistant sentience ––auto draw general motors gm brain project general purpose technology gpt –china –generative adversarial network gan consent corporate codes –genetics deepmind –genomic data domination geographybased governance duplex voice assistant georgia tech university ethics advisory council –gerdes anne ethics ––german federal ministry transport flu trend algorithms –digital infrastructure bmvi –glass –452n21 germany –internal review structure –trustworthiness language gestel –maps gibson j j material design gillespie tarleton nest gini coefficient pagerank girling rob –photo app index google continued hagendorff thilo –privatesector investment hai see humancentered artificial search intelligence techlash haip see harmonious artificial intelligence walkout principles gore al –hal j storrs gottman institute handoff analysis governance access control –accountability –affordance –in education –boundaries –fair notice –761n25–catalyst –responsibility –face id 246n20 governance effects –passthoughts –governance toolbox passwords –governments privacy security –law –responsibility –transparency –sociotechnical systems –238n8 gpa see grade point average handwriting recognition gps see global positioning system hannak –gpt see general purpose technology hanson robotics grade point average gpa haraway donna –granular measurement hardware registers graphical models harm see also trust dag ––f–f rights 298n28 pdag f–f –f–f –of robots –graphic design –harmonious artificial intelligence principles great firewall china –greece harris david greenfield adam –harris kamala grimmelmann james harris sam gropius walter harrison bergeronesque noise f gross oskar hart algorithm grossklags jens hassabis demis grouplevel identity hassein nabil –group hate speech –groups genes pinker hatsune miku guardrails hauskeller michael algorithms –hawking stephen temptation –healthcare diagnostics guidedbomb strike ethics –güzeldere güven health insurance portability accountability act hipaa ha’aretz health systemeye –habermas jürgen healy kieran hacking hebron patrick human brain hedonism wearable technology hegelian sublation –index heidegger martin –341n15 hpcc see highperformance –communication computing helicopter research hr see human resources helmets huang hanniman helmreich stefan huateng pony –henriksen lance human authority –her film human autonomy –see also heritage foundation autonomy heteronormativity human brain see also brain heterosexuality see also sexuality hacking heuristical understanding ––humancentered approach see also human heuristics rightscentered design hewlettpackard hp deflationary view –hi i’m saori harming robots –hicks marie –human responsibility –highlevel expert group artificial implications –intelligence ai hleg robots –––humancentered artificial intelligence highperformance communication computing hpcc act –human component 238n8 ––hikari azuma character humanitarianism hildebrandt 86n27 102n72 benefit –hil kashmir migration technology –hipaa see health insurance portability humanities f f accountability act see also origins ai hippocratic oath human judgment see also human rights hirevue centered design hiring models ––algorithmic governance –ahp –displacement –interview guides human labor –see also work platforms flsa –social organization surveil ance history access human migration see migration technology hitchbot –human problem solving newell hobbes thomas simon hoffmann anna lauren human relationship ai holden constance creation –68n45 holm ian current status –holmes w 396n105 introduction –holocaust precursors –homosexuality see also sexuality scope –hopkins thomas sentience –hospital admission social mirror –hot standby human resources hr see also automated house lords select committee hiring platforms artificial intelligence managers hp see hewlettpackard mena –f –index human rightscentered design incentives conclusions –102n72 algorithms –f core principles –deeplearning ethical standards –ethics –introduction –responses –f se practice –inclusion responsibility –human rights council un income tax code –see also human rights watch internal revenue code us human teaching –independence –f –f human use human beings india –biometrics –hume david food distribution humphrey john –indigenous art hungary indigenous culture hunt james indigenous people f hutchinson ben indirect rights individual liberty robot cost ia see intelligent assistant individual privacy –i am… individual user models –ibm see international business machines industrial revolution –corporation inequality ––iborderctrl information communication ice see immigration customs technology ict enforcement information asymmetry ict see information communication informed consent technology inframarginality id3 innate mechanical setup idol ators online community –inpo see institute nuclear power ieee see institute electrical operations electronics engineers input –ignorance –invalid –f mouth must scream notice –sensory 72n58 ihrl see international human rights law valid –f illinois institute technology inputoutput pairings image recognition software 396n106 fair notice –imitation game see turing test institute humancentered artificial imitative gestures intelligence immigration customs enforcement institute electrical electronics engineers immortality ecpais humans –ethical aligned design i’m robot institute nuclear power operations impact algorithms imperial college london instore sensor networks inactivity reports productivity instrumental theory index instrumentation standards insurance companies –udhr –insurance prices –f international human rights law intel corp intelligence see also artificial intelligence international monetary fund activities international organization migration’s anthropology –displacement tracking matrix definition –internet things iot ethics –ethics –ml –trustworthiness prior communication –interpersonal model consent –sentience ––intersectionality –intelligence quotient iq –intimacy ––see also sexuality scans intuit turbotax 385n57 intelligent assistants ias –invalid inputs –f intelligent operations center ibm iot see internet things intelligibility iq see intelligence quotient principles –iran air flight intention iran nuclear deal algorithms –f irisscanning –sentience –isaacs william systems –ishiguro hirochi intentional agency 198n9 isolation social –interaction art –f israel –interdisciplinary initiatives italy –intergovernmental panel ai internal revenue code –see also james kay coles income tax code japan internal steering committee academic thought international business machines corporation androids –east asia –cognitive prints films –in criminal law komatsu city domination policies intelligent operations center popular culture –programmer aptitude test science technology basic plan smart cities japanese advisory board artificial supercomputers –intelligence human society techlash japanese society artificial intelligence watson –international committee red java cross jennings ken international conference machine jeon chi hyung learning jeopardy –international human rights –see also jetson ai computing human rightscentered design jetsons echr jewish community index jiajia zheng ––killer robots see autonomous weapons jiajia robot system jibo social robot kill switches 249n34 jobs see also work worker displacement kim jiwon advertisement –f–f king dr martin luther jr application –kiria see korea institute robot industry loss 278n32 –advancement jobs steve kissinger henry johnson deborah kitchin rob jordan see also middle east north africa koepke j l refugee camps –kokuryo jiro jsai see japanese society artificial komatsu japan intelligence kondo akihiko ––judeachristianislamic god korea advanced institute science judgment technology kaist –algorithmic governance –korea institute robot industry algorithmic judgment –advancement kiria capacity 465n2 korean demilitarized zone dmz –deference 390n75 kuniyoshi yasuo displacement –kurzweil ray 336n11 turing test –judges ––lab126 amazon judicial transparency –lacan jacques –jurisprudence 761n26 de laet marianne –justice –see also criminal justice lambert craig system fairness land ethic leopold justificatory interest theory 293n15 language processing tools –lar see lethal autonomous robot latinx kafka franz sentience kaist see korea advanced institute latvia science technology law see lethal autonomous weapon kaminski margot law ethics –kansas city us accountability –kant immanuel accuracy animals administrators –sentience –bail determinations –kantian paradigm conclusion kardashian kim 572n4 criminal law –kaurin dragana criminal sentencing –kaye david decisionmaking –keio university explanation –kel walt 340n13 fat algorithms –kenya see also middle east north judgment –africa judges ––keyword indexing 389n72 loac –kidney safety app machine learning –index natural justice –light switch practitioners linkedin profile professional norms –lippert christoph theory –the living design firm transparency –loac see law armed conflict law enforcement loan repayment –f–f rekognition –locke john law armed conflict loac –loebner prize –laws see lethal autonomous weapon logging systems logicbasedt ethical robot laws robotics see robotics methodology –laws war logojoy –lawyers lomas natasha leadership values see professional norms london uk lebanon see middle east north africa loss see also harm legal agreements detection –legal environment prevention technologies fair notice –761n25–lottery transparency –love see also sexuality legal personhood ––ai –overextension lovelace ada ––legal protection design lpbd 86n27 love like person 102n72 lpbd see legal protection design legitimacy principle –lucas george leopold aldo lum kristian lessig larry lumpsum transfer lethal autonomous robot lar see also lyft autonomous weapons system lethal autonomous weapon systems maccormick neil machine creativity beats modern trustworthiness art levinas –machine learning ml levy karen –black box –lgbtq community –deflationary view –antilgbtq design –in migration technology fatml runaway feedback loops –law –sentience moral rights –li feifei –opacity –liability 191n26 761n26 professional norms –liao miao public health –liberalism –the machine question gunkel liberation movement machine selflearning liberty migration mackenzie donald libratus macy conferences lichtenberg knife maher mary lou lifecycle malfeasance index malle bertram –mauritania f malthusian trap maxai see maximal ethical machine malthusian world maximal humanlike automata mha management maximal ethical machine maxai based regulation 90n38 crm –may wei viv fail safe mcarthur neil migration technology –mccarthy john projects –mccarthyism 340n13 risk –mcdonald aleecia managerial technology mcgill university compensable work –mckinsey analysis worker displacement mead margaret mandatory sentencing meaningful human control 472n11 mandelbrot benoît –media lab mit 178n58 manipulation see also trust media studies transparency –mediator –f –f mantalerohas alessandro medical ethics marciano avi medicine marginalized voices –ai ethics –marinel v united states –diagnosis markov condition –doctors martin wayne 396n108 –professional body martindale colin –mediterranean –marx melanesia –marxian analysis memories mas see multiagent systems mena see middle east north africa maslenjak v united states 761n25 menabrea luigi federico massachusetts institute technology mental health –mental illness –interdisciplinary initiatives merge enhancement bundle –media lab 178n58 merq schwarzman college computing metaautonomy sloan management review metadata technology review metaethical epistemology mass incarceration metal ic attraction kungfu cyborg mass morality metaphysical humility –mass transit riders metaregulation 90n38 master innovation development approaches plan metz cade matching technology mexico material design google border mathematics see also science technology mha see maximal humanlike automata engineering mathematics michigan integrated data automated system branch –standard microchips matthen mohan microsoft corp index ai principles –military ethics conversational ai guidelines –banning weaponized ai –corporate codes –ethical guidelines –open letter –introduction –privatesector investment maxai sexual harassment minai code –tay ai bot –minai consequences –techlash minai mission ––midas see michigan integrated data scholarship automated system spectrum –middle east north africa mena military technology see region also autonomous weapons system ai –f miller nate 579n29 arab spring –mil charles human resources –mimesis infrastructure –mimicry –introduction –minai see minimal ethical ai multifaceted inequality –mindmachine merger see also f–f technological singularity region –f minduploading regulatory environment –f minimal ethical ai minai rideshare companies code –youth unemployment –feasibility –f mission –mighty atom minority report film migration technology minority report dick accountability –minority tax automated decisionmaking –minsky marvin biometrics –mission vil ani border enforcement –mr data –civil liberties infringements mit see massachusetts institute –technology consent –mitchel margaret criminalization –mitigation procedures decisionmaking –ml see machine learning equality rights –mobile phones –facial recognition ––digital consent –fair process –encryption –humanitarianism –in mena ihrl –police search –introduction –mode handoff model ––liberty model cards model reporting management –modern bureaucracy theory –oversight mechanisms –mol annemarie –privacy rights molecular duplicate securitization –mol ai web designer surveil ance –monetary value –index monk ellis nasa see national aeronautics space monotheism administration montreal declaration –nash equilibrium solution mood disorders –nass clifford moor james national aeronautics space moore george edward administration nasa ––moore’s law national health service nhs moral agent –national information society agency nia moral character cryptographic work south korea national institute clinical excellence morality freedom raz 293n15 294n18 moral machine experiment –national labor relations act moral magic national retail security survey moral patiency national science foundation nsf moral philosophy see philosophy amazon col aborative project –moral responsibility –report moral rights see also consent undergraduate computer science conclusion –education –interest theory –294n18 national security 300n32 national security entryexit registration introduction –289n3 system kinds –290n6 national statistics offices –objectivelist view –300n32 national transgender discrimination reasons –291n8 293n15 survey –subjectivist views –294n19 national transportation safety board theory –305n46 us morocco see middle east north africa national wealth –f mortality risk prediction natural justice –motion sensor natural language movies see films popular culture processing tools –muhammad khalil software multiagent systems mas nazi germany –multivariate normal distribution socialist ideals mumford louis nealon jeffrey 549n36 murai jun negativesum murder negroponte nicholas musk elon –the negro’s place nature hunt neuralink –nemitz paul 77n1 muslim populations –neoliberal ideologies muslim registry boredom 341n16 myanmar nest google biometric data –outdoor security facebook –my robot boyfriend net neutrality neural information processing systems nanoscience neuralink –narrative views singularity –neurophysiology index nevada pretrial risk assessment northpointe newell alan compas algorithm –new generation ai development plan norvig peter china –no self view –new jersey us notice inputs –new jim code notice outputs –news feed facebook –npr see nonphotorealistic rendering news platforms –nsf see national science foundation newsweek nuclear fission new world order nuclear weapons –new york city us nurturing 68n45 new york times nussbaum martha new zealand 328n6 nvidia graphics next generation ai research center nyholm sven ng andrew ngo see nongovernmental organization oakland ca nhs see national health service obama barack nia see national information society objectivelist view –300n32 agency oblivious criteria nice see national institute clinical oblivious fairness criteria –excellence obscured transparency nicomachean ethics aristotle obsolescence nietzsche friedrich obsolescence man anders nike footwear ochigame rodrigo nilekani nandan –o’donnel kathleen nissenbaum helen 191n26 odysseus depth problem –oecd see organisation economic nonaligned movement cooperation development noncompete agreements ohio us nondisclosure agreements ohya takehiro nongovernmental organizations ngos old testament –omnibus nonhuman agents see also robots omnibus clause –sentience –million healthy lives nonjustificatory interest theory –years study ai report nonphotorealism strange things nonphotorealistic rendering npr online chatbot norman donald online dating sites normative fidelity –online media control 304n44 ontario works quasinormative principles –on origin species darwin –rights 290n7 291n8 opacity normative values machine learning –implementation –opaque black boxes –north africa see middle east open data barometer north africa open data development mena north korea –node –index open government partnership pasquale frank open letters –passthoughts –to un passwords –open stack nasa –paternalistic utilitarianism operating system os patiency oracle patient autonomy o’regan j kevin patient care –organic act protection personal patient privacy data patriarchy organisation economic cooperation payne adrian development oecd pdag see probabilistic directed acyclic –graphical automation risk pearl judea ––committee digital economy pedagogy –policy –pedestrians –orgil davey safety origins ai penetration testing creativity –pennsylvania turnpike –lovelace –pentagon us –overview –f people color see african american technē –pepper robot –turing –perceptual enhancement –os see operating system percival thomas osawa hirotaka perkins wil –osborne michael –personal identity otherness –codes standards –ottawa treaty singularity –outcomes transparency –personalized learning systems oversight see also accountability accountability –accountability –aiassess mechanism codified pedagogy –oxford university conclusions –governance –pain human teaching –theory –overview –pakistan –perils –palantir technologies policymaking –in criminal law potential benefits –palestine see also middle east transparency –and north africa personhood see also human rightscentered palestinian language translation –design technological singularity palo alto ca ai –panic augmentation –parachute research phantom requests parity signal –pharmaceutical drugs parks rosa philosophical anarchists 372n59 paro artificial baby harp seal 68n45 philosophy parsons talcott altruism –index default settings –porn industry –levinas –pornographic videos outcomes –posen zac relationalism –positive immortality relational turn –549n36 positivesum philosophy mind possessive individualism phoenix joaquin postal privacy physical failures –posthuman hybrids –physician’s pledge posthumanism –340n12 pichai sundar postimplementation monitoring piloting phase trustworthiness posttraumatic stress disorder pilots –378n13 pinker steven predicative judgment theory place sun correa predictive analytics planning algorithms –bail sentencing platform companies ––ethics –platformization –predictive parity plato predictive policing –playboy magazine –predpol pluralism 396n108 presentation cost poe edgar allen –pretrial detention –polanyi michael –principalagent police departments –problem policy investment recommendations relationships trustworthy ai theory policymaking principle legitimacy committee digital economy principlesbased approach policy –trustworthiness frameworks –prior computation –pedagogy –prisoner’s dilemma surveil ance –prison populations think tanks privacy ––in work –of ahps political desiderata –in crm –political economy 278n32 handoff analysis –of algorithmic systems mass –in mena –f–f f platformization –political philosophy sexuality consent 272n56 –transparency polarization wearable technology –pooling equilibria privacybydesign solutions –popper karl privacy rights popstar robots migration popular culture see also films policies china –violation risk japan –privatesector incentives south korea –algorithms –f f popular sovereignty ethics –index privatesector incentives continued public goods game guardrails –public health –performance –public opinion –responses –f public oversight privatization –public policy 481n3 proactive transparency –public safety assessment psa 747n56 proattitudes 747n58 probabilistic determination purloined letter poe –probabilistic directed acyclic graphical pwc pygmalion shaw –pygmalion myth probability theory 395n105 bayesian q role –qatar f product design –quantum computing production costs quasinormative principles –productivity –quebec city canada –national wealth f queer studies professional norms accountability mechanisms –race gender ai professions –ai design –future –bias –governance effects –education –implementation –facial analysis –introduction –judgment –in law –marginalized voices –public opinion –in migration technology –programmed inequality hicks –power imbalance –programmer aptitude test ibm runaway feedback loops –project management –stereotypes –project maven –racism prometheus radin margaret jane –proof –raji inioluwa deborah concept randomized controlled trials rcts property rights raso jennifer acquisitiveness 401n128 rawls john 372n56 whol owned property raz joseph 293n15 294n18 proprietary law rct see randomized controlled trial propublica recidivism score –prouse delaware v –763n33 recommender systems –see also proxy voting –autonomous decisionmaking psa see public safety assessment recordkeeping see also accountability psychological continuity –accountability –psychology ehr –psychometric tests recruitment ptsd see posttraumatic stress disorder red crescent public documentation red cross index red crystal robots –redistribution –wellbeing –redlining ––responsibility gap redundantly encode restaurant inspection reeves byron rethinking creativity röder –referredrights retroactively presupposited žižek –refugees review accountability –of azraq revit software data collection rhino software decisionmaking –ricaurte paola –of rohingya –richmond cedric unhcr ––rideshare companies regan tom compensable work –regulation responsibility –in mena regulation medical devices productivity –rehabilitation –rights see also consent constitutional law reinforcement learning human rightscentered design moral rekognition surveil ance ––rights relationalism –claimright 290n6 291n11 relationality rights 305n46 relational turn –549n36 harm 298n28 religious needs workplace scope –remediation rio de janeiro brazil –replacing “view nowhere” risk benefit ratio replica company calculations replicants blade runner –credit prediction reputation score china criminal assessment requirements analysis –crisis risk dashboard 772n8 rescue robots deeplearning algorithms research development rd determination software governance –ethics –research grants –management –resource curse mortality prediction responsibility nevada pretrial risk assessment accountability –oecd ai narrative –privacy violations art –f reallocation –certification recidivism software code conduct shifting –conclusions –superintelligence –governance –roberts sarah handoff –robertson jennifer inclusion diversity –robinson g introduction –roborder project participation –robosexual see sexuality regulation –robot abuse 469n5 index robot boyfriend rousseau jeanjacques robot ethics charter royal free london nhs robotics rudd anthony first law rule ––principles rule james scholarship rule consequentialist three laws 379n17 rules engagement robot maid heaven rules robotics see robotics robots runaway feedback loops –ab testing rur capek –anthropology –russel stuart j china –russia citizenship rutgers university dogs –rutter brad eod robots rwandan genocide –harming –rwandans hitchbot –humancentered approach –sae j3016 technical document jiajia safety case movement 91n43 lars safety expectations ethics –love –san francisco ca paro facial recognition ban 178n57 pepper –sao paolo brazil personalized learning systems –sap se rescue robots corporate codes –responsibility –external ethics review board rightholders –294n18 298n3 sat score example –f rur –sauder michael –sex –saudi arabia see also middle east socialization –and north africa sophia sawchuck andrew –as surgeons sawyer keith –in surgery scaffold learning tamagotchi –scene stitch adobe teaching –schechtman marya robustness –scheduling –rocket guidance software scher paula röder seda –scheutz matthias –rogaway phillip schmidhuber jürgen –rogerian psychologist schneider susan –rogers carl schufa creditscoring algorithm –rohingya genocide schwarzman stephen –refugees –schwarzman college computing –roosevelt eleanor –science technology engineering rosenblat alex –mathematics stem –rossum’s universal robots capek –science technology basic plan rotimi charles japan index science technology studies sensecam science fiction sensei ai adobe scooter riders sensitive characteristic –scope rights ––f scott james c sensitivity algorithms –f f scott ridley sensory input 72n58 scraping sentencing scratch memory ethics –screenshop 572n4 fairness –se see software engineering predictive analytics search engines sentience ethics animals –62n23 transparency consciousness –––searle john 329n8 72n58 second life –creation –68n45 second machine age –empathy –the second sex beauvoir fear –securitization –gaai ––security intelligence ––accountability intention –handoff analysis –nonhuman agents –securus technologies otherness –sedol lee posthumanism –340n12 seestatements scenarios –segmentation social mirror –selbst andrew traditional regimes –select committee artificial turing test –57n8–intelligence seoul south korea selfawareness seoul national university education selfdriving vehicles separation ––f f–f control –sex assistants –responsibility sexism transport ethics –sex robots –trolleyproblem 353n26 sex slaves –waymo sex tracking apps –selfevaluation sexual harassment selfgoverning see also autonomous programming ––decisionmaking sexuality autonomy –ai –selfharming behavior conceptual act theory selfmonitoring conclusion selforganization –347n9 facial images selfregulatory model –84n18 84n20 introduction –selfselecting groups love –selinger evan privacy semantic heuristics sex assistants –sen amartya sex work senate us shadow work index shareholders –snh48 idol group amazon snowden disclosures sharing cities declaration –social contract theorists 372n56 social credit score shaw george bernard social failure modes shell company ai ethics –shelley mary conclusions –shinto belief ethical dimensions –sidewalk labs failure modes –silicon valley google glass –simmons john 372n59 452n21 simon herbert –introduction –simulated sentience see sentience social media singer peter ––chatbots –singleaxis paradigms metrics singularity kurzweil 336n11 narrative structures singularity hypothesis –see platforms also technological singularity public media –siri virtual assistant social networks agr ethics consent platforms wil theory trust –the six mil ion dol ar man haraway social norms –sixth amendment us constitution social organization sketchup plugins ahps –skidmore owings merrill som automated hiring skynet terminator franchise customer relationship skype management –sloan management review recruitment small medium enterprises sme wearable technology –smart cities 572n3 social robots conclusion –indirect rights –democratic governance –nonsentience domination –tamagotchi –ethical codes –social safety net healthcare social sorting introduction –social theory platformization –social wellbeing see wellbeing privatization –sociologists –problem –future smart cities mission incentives smart city initiatives sociotechnical systems –smart corporations capacity –smart glasses –complexity smart replies handoff analysis –238n8 sme see small medium enterprises handoff concept –smith david harris –human –index nonhuman –calibration group –transparency –socrates casual considerations –f–f söderberg lena –conclusions –software artifacts conditional independence –software engineering se confounder –f f algorithm inspection –dag ––f–f appropriation data transparency –best practice –demographic parity ––cybersecurity descendent –data modeling –equalized odds –––instrumentation fairness criteria –f–f logging graphical models –f–f requirements analysis –independence –f –validation –f verification –introduction –software verification job advertisement example –f–f som see skidmore owings merril loan repayment example –f–f sony group ai ethics guidelines markov condition –sophia robot mediator –f –f south korea oblivious criteria academic thought policies –parity signal –popular culture –pdag f–f –f–f space syntax –spain –sensitive characteristic –speciesism –f speech production separation ––f spell checking f–f sufficiency criterion ––squarespace –f staffing –see also automated hiring statistics platforms statustoday –stahl steenson mol wright –standardized testing –stem see science technology engineering stanford institute humancentered mathematics artificial intelligence stepford wives stanford university stereotypes –hai –f stitch fix 572n4 interdisciplinary initiatives stitzlein sarah marie –law school –st lawrence river –stapleton claire stoddart jim star trek next generation –stop frisk policy 744n39 startups mena –strathern marilyn star wars stroke star wars film franchise structural causal models statistical models structured data index structures accountability –targeted advertising see also style check service –discrimination subjectivist views wellbeing –taxfiling services 385n57 294n19 omnibus clause –subsidized systems taxis substrate nondiscrimination taxpayers suchman lucy tax revenue suffering tay ai bot microsoft –sufficiency criterion –––taylor astra f taylorism suffolk contracting firm –tcav see testing concept activation suicide vectors sullivan mark te see total effect superintelligence teaching autonomy accountability –economic value –of humans –existential risk –personalized learning systems –general intelligence robots –sentience –virtual assistants steering progress –tear gas superintelligence bostrom tech billionaires supply chains techfugees supreme court us –761n25–tech lab perkins wil –surgeons techlash –f surprise egg videos academic responses –f surrealism corporate responses –surveil ance capitalism –technē –surveil ance technology –technical feasibility children technoanimism ethiopia technological artifacts 444n8 migration technology –technological singularity public health –biological brain –rekognition –caveats –sustainability certification cognitive enhancements –sustainable development goals concerns –synthetic biology consciousness –syria f introduction –system behavior metaphysical humility –accountability –narrative views –transparency –perceptual enhancements –personal identity –tacit dimension –psychological continuity –tahrir square egypt radical enhancement –tailor brands –suggestions –tallinn jaan transhumanists –tamagotchi pet toy –technological sovereignty tanner johnny technology assisted review –index teenage girls tay –transformations –teleological –transgender communities –temporal instability –sentience temptation –transhumanists –tencent research institute tri –translation programs terminator film franchise ethical design –terms consent see consent facebook –terms employment transparency terms service tos accountability –agreements –adm –testing concept activation vectors algorithm enacting –art –f texas us codes standards –textparsing program competitive concerns tezuka osamu cost thaler stephen disclosures ––theft –gaming –theoretical biology –law –a theory judgment martin 396n108 legal context –therac25 rocket failure manipulation –thirdparty companies personalized learning systems –thirdparty cookies privacy thirdparty organizations –problematizing –thought experiments sociotechnical complexity china room –329n8 temporal instability –trolley problem –understandability –threat environment transparency threat modeling 3dprinted garments –transphobic views thresholds transport ethics setting 384n55 automated driving –time eve computer authority –toivonen hannu conclusion –toronto canada dynamics –toronto declaration 85n26 human authority –tort law introduction –tos see terms service safety –total effect te –f travel booking touch id 246n21 treaty ai –townsend anthony treaty prohibition nuclear traceability –weapons trace face program tri see tencent research institute trade secret tribe lawrence protection trickledown mena –traduttore traditore trigger –tragedy commons trolley problem 353n26 –training data –transfer rights –truedepth camera system index trump administration –uighur population trust –see also fairness uk see united kingdom ai hleg ––uk house lords select committee cheating –on ai ethics –f ulam stanislaw europe –ultimatum game –innovation –un see united nations piloting phase uncanny valley –principlesbased approach undergraduate computer science social failures –education –trustworthiness –understandability –laws undirected duty –292n13 robustness –undp see united nations development tselentis jason programme tunisia see middle east north africa unequal base rate –turbotax intuit 385n57 unethical behavior –turing alan –unhandled error ai origins –un high commissioner refugees turing award turing test –57n8–unicef judgment –unilever turkle sherry –united arab emirates uae –turow joseph ––twist markie united kingdom uk twitter centre data ethics chatbots –colonialism tay –durham police force 100n69 twofactor authentication epsrc twofactor model –facebook data –a space odyssey governance house lords uae see united arab emirates internet studies centers uberland rosenblat nhs uber technologies nice careem select committee artificial compensable work –intelligence domination transport f egypt women guardrails –united nations un judgment –academic ai interventions –platformization aid agencies pricing autonomous weapons –productivity –migration technology 772n8 selfdriving car ––uberx open letter udhr see universal declaration human resolution rights secretary general index sophia speech valid inputs –f special rapporteur –value alignment udhr valuesensitive design vsd united nations development programme velmans max velvet revolution united states us venter lab academic ai interventions –f venture capitalists american medical association verbeek p p antitrust laws veridicality citizenship immigration service verifiability –data regulations within –accountability –education –versioning –facebook data –vertov yury fda ––vice media –food drug administration video surveil ance systems ice ––vincenne uss indirect rights vinclu inc internet studies centers vinge vernor mexico border violence see also nsf ––autonomous weapons system racism violence card surveil ance violent crime 741n22 747n58 taxpayers virtual assistants wearable technology –alexa unit analysis –siri unity 3d stereotyping –universal declaration human rights teaching virtual therapist –universal ethics eliza –universalism –virtual wife universities visibility theory university southern california –visual cues university tokyo voice recognition fairness –university toronto voip apps university tsukuba voluntariness consent –unmanned weapons von der leyen ursula urban outfitters von neumann john 336n11 us see united states voting –usable transparency –vsd see valuesensitive design usenet arguments vulnerability –user experience ux –us news world report –wage theft utilitarianism –wal ach wendel –ux see user experience wall street journal walton kendal vagrancy war crimes validation –war theory –index waterfront toronto wikipedia watson ai system –wilczek frank watt governor steam engine theory –305n46 waymo wilson kenneth weapons systems see autonomous weapons winfield alan system winograd terry wearable technology winter olympics compensation –witt andrew discrimination wix adi –employee safety –woebot conversational entity hacking wolff robert paul 372n59 inaccurate predictions women see also race gender privacy concerns –ai design –smart glasses –bias –weber max crm –weinberger david –education –weirdnearness facial analysis –weizenbaum joseph ––female objectification welfare 294n17 see also equity marginalized voices –humancentered approach ai migration technology –and –power imbalance –schemes runaway feedback loops –wellbeing see also human rightscentered staffing design stem ai –294n19 stereotypes –arab spring –wood hannah –objectivelist view –300n32 work responsibility –ai origins –subjectivist views –294n19 artifact –wenar leif compensable work –western liberalism –displacement –wework –policy recommendations –wfp see world food programme productivity evaluation –wgp see white guy problem risk reallocation –whanganui river 328n6 social organization –when species meet haraway –workarounds –whistleblowing worker displacement –whiteboard interviewing algorithmic governance –white guy problem wgp workplace automation 278n32 see white supremacy –also automated hiring platforms whittaker meredith wearable technology –wholegenome sequencing data worldatwork survey whol owned property world bank wifienabled device world economic forum wifi kiosks world food programme wfp wiggins geraint world health organization –wikiart database world trade organization protests index world war youtube world war ii –kids channel world wide web foundation safe content wozniak steve techlash wristworn wearables yudel michael xai see explainable ai zeller frauke –xenophobia zeng yi xerox zen garden xiaoice chatbot zerilli linda 305n104 xray scans zeroth law zimbabwe yanhong robin li zimbabwe bush pump –yelp žižek slavoj ––yemen f zuboff shoshana youth unemployment –f zuckerberg mark document outline cover oxford handbook ethics ai copyright contents editors’ preface list contributors part introduction overview chapter artificial intelligence ethics artificial intelligence introductory overview law regulation intelligence ordinary process ai including machine learning occurs design performance designed artifacts readily explainable intelligence increases exploiting prior computation ai cannot produce fully replicated humans models wrong ai cannot dissuaded law treaty ai ict impact every human endeavor who’s charge ai governance summary robots acknowledgments references chapter ethics ethics ai introduction conceptual ambiguities agent autonomy intelligence risk overestimation underestimation overestimations existential threats ai underestimation ai risks implementing ethics making machines moral modeling ethical reasoning learning values intrinsic limitations epistemic issues ethical implications predictive science crisis causal knowledge epistemic crisis could become ethical crisis oppositional versus systemic approaches conclusion bibliography chapter ethical issues relationship artificial entities introduction scope definitions precursors turing weizenbaum ethics relationship seemingly sentient ethics creating seemingly sentient entities sentient entities social mirror bibliography part ii frameworks modes chapter ai governance human rights–centered design deliberation oversight end ethics washing introduction human rights lie core ai ethics human rights–centered design deliberation oversight ai human rights–centered design deliberation oversight core principles human rights–centered design deliberation oversight principle design deliberation principle assessment testing evaluation principle independent oversight investigation sanction principle traceability evidence proof getting research agenda requirements analysis understanding collecting analyzing data verification cybersecurity design validation penetration testing appropriation algorithmic transparency inspection instrumentation logging conclusion bibliography chapter incompatible incentives privatesector ai performances ethics algorithms create incentives incentives drive responses responses demand guardrails guardrails create temptation temptation needs policing acknowledgments bibliography chapter normative modes codes standards introduction varieties codes standards ai ethics advantages codes standards dangers codes standards watch key value concepts used ai codes standards challenges ai artificial intelligence developed common good benefit humanity note codes standards ethical theory conclusions bibliography chapter role professional norms governance artificial intelligence introduction ai professions norms ai professions norms ai professions governance effects implementation norms accountability mechanisms court public opinion professional norms law looking ahead acknowledgments bibliography part iii concepts issues chapter we’re missing moral framework justice artificial intelligence limits failings ethics fairness year techlash origins ethics ethics reimagined justice academic corporate responses techlash critique overview academic ai interventions overview corporate ai interventions synthesizing summarizing state ai fairness conclusion bibliography chapter accountability computer systems definitions unit analysis artifacts systems structures accountability lie accountability oversight review accountability accounting recordkeeping verifiability accountability responsibility accountability normative fidelity accountability governance goal accountability versus transparency mechanisms accountability ai whither accountability ai bibliography chapter transparency accountability transparency algorithms enacting algorithmic transparency made transparent algorithms human involvement data model inferences transparency disclosures problematizing algorithmic transparency gaming manipulation understandability privacy temporal instability sociotechnical complexity costs competitive concerns legal context discussion bibliography chapter responsibility artificial intelligence introduction art ai taking responsibility governance responsible ai regulation certification codes conduct inclusion diversity ai narrative conclusions bibliography chapter concept handoff model ethical analysis design catalyst handoff model access control handoff lens case study beginning userselected passwords password fingerprint fingerprint face id face id passthoughts access control lens handoff responsibility privacy security articulating boundaries system bibliography chapter race gender datadriven claims race gender perpetuate negative biases day using past data determine future outcomes results runaway feedback loops unregulated usage biased automated facial analysis tools aibased tools perpetuating gender stereotypes power imbalance exclusion marginalized voices ai design ethical ai starts given seat table education science engineering needs move away “the view nowhere” bibliography chapter future workin age ai displacement riskshifting ai worker displacement rhetoric reality kinds tasks ai execute complicated reality ai risk reallocator staffing scheduling defining compensable work detecting predicting loss fraud incentivizing evaluating productivity displacement riskshifting policy acknowledgments notes bibliography chapter ai moral rightholder introduction rights rights kinds rights rights interest theory rights ai interest theory subjectivist views wellbeing ai consciousness ai objectivist views wellbeing ai theory rights ai theory conclusion bibliography chapter could merge ai reflections singularity radical brain enhancement technological singularity cognitive perceptual enhancement background concerns personal identity radical enhancement suggestions making radical brain enhancement decisions distinguish issue personal identity survival time consciousness stance “metaphysical humility” support regulations brain enhancement devices require consumers informed personal identity debate way forward psychological continuity narrative views caveats conclusion humble approach bibliography chapter sentient ais persons traditional rights regimes sentient nonhuman agents plausible otherness fear four scenarios human posthumanism humanities bibliography chapter autonomy introduction autonomy control relinquishing control final twist bibliography chapter troubleshooting ai consent introduction consent crisis moral core consent background conditions scope knowledge voluntariness fairness power dynamics another model conclusion bibliography chapter human judgment necessary artificial intelligence algorithmic governance law algorithmic judgment displacement human judgment human judgment necessary suggested readings chapter sexuality introduction ai sexual identity ai sexual assistance ai love conclusion bibliography part iv perspectives approaches chapter perspectives ethics ai computer science ethics ai important function ethics positivesum negativesum interactions cooperation trust social norms representing ethical knowledge fairness economy ethics research ai community human nonhuman members society method analyzing specific cases trust ethics example trust ethics autonomous vehicles deadly dilemma ethical principles encourage trust example individual user models perils correct individual models perils incorrect individual models conclusion example sharing wealth fairness economy create new jobs conclusions bibliography chapter social failure modes technology ethics ai engineering perspective introduction case —the quebec bridge case —google glass social failures ethics ai talking stuff breaks brief primer physical failures failure modes social failures social failure modes zimbabwe bush pump social failure dynamics two social failure modes ethical dimensions social failures social failure mode analysis microsoft’s tay conclusions bibliography chapter humancentered approach ai ethics perspective cognitive science putting robots place implications humancentered approach harming robots robots extensions human responsibility conclusion bibliography chapter integrating ethical values economic value steer progress artificial intelligence introduction economics ethics two conflicting value systems introductory example job lossesfrom automation ai economic value often prevails ethical values progress ai inequality industrial revolution future technological progress redistribution redistribution utilitarianism inequality steering progress ai progress ai creating novel externalities ai discrimination biases fairness hacking human brain curtailing human autonomy externalities steering progress ai race toward superintelligence superintelligence inequality economic viability humans superintelligence externalities existential risk superintelligence steering progress ai bibliography chapter fairness criteria lens directed acyclic graphs statistical modeling perspective introduction graphical models probabilistic directed acyclic graphical models causality three criteria fairness demographic parity independence equalized odds separation calibration group sufficiency fairness criteria two scenarios scenario loan repayment independence separation sufficiency scenario job advertisement independence separation sufficiency understanding separation incompatibility separation sufficiency parity signal causal considerations scenario college admissions scenario insurance prices conclusion acknowledgments bibliography chapter automating origination perspectives humanities lovelace turing programs live amidst work artifact age artificial intelligence ethics ai “every technē concerned origination” bibliography chapter perspectives ethics ai philosophy standard operating presumptions default setting substantive problems terminological problems epistemological problems moral problems thinking otherwise relational turn relationalism radically empirical altruistic outcomes conclusions bibliography chapter complexity otherness anthropological contributions robots ai introduction robots ai fetish “intelligence” ai systems algorithmic power plays new forms personhood conclusion bibliography chapter calculative composition ethics automating design introduction automating fashion product graphic design algorithmic architectures planning project management design fabrication bibliography chapter ai global south designing worlds introduction worry global south global south technology worlds facebook myanmar biometric identity database india refugees data collection europe chinese facial recognition technology zimbabwe ai global south systems discrimination southern populations international human rights apply conclusion bibliography chapter perspectives approaches ai ethicseast asia introduction south korea policies ethical principles tooldecisive academic thought local practices tooloriented popular culture partnership exploration tool preference conclusions china policies ethical principles tooloriented academic thought local practices uniquely partnershiporiented popular culture partnershipembracing conclusions japan policies ethical principles toolleaning academic thought local practices partnershipinspired popular culture partnershiprich conclusions chapter conclusions discussion bibliography china japan south korea additional resources reflecting ai ethics east asian perspectives chapter artificial intelligence inequality middle east political economy inclusion introduction context region flux diverse region arab spring failure trickledown multifaceted inequality mena unemployment digital inequality ai mena—data infrastructure people data—the mine data asymmetry markets data lock state data inaccuracy—blur myopia blindness enabling environment infrastructure issues human resource challenge rays hope conclusion ai mena—inclusion inequality acknowledgments bibliography chapter europe toward policy framework trustworthy ai introduction eu ethics guidelines trustworthy artificial intelligence legal compliance ethical alignment sociotechnical robustness three pillars trustworthy ai four ethical “imperatives” ai principles requirements operationalizing trustworthy ai assessment framework “policy investment recommendations” trustworthy ai selected aspects what’s next putting european union’s ai ambitions test bibliography part v cases applications chapter ethics artificial intelligence transport introduction ethics transport case automated driving technological solution policy solution consequences safety expectations human authority versus computer authority changing power dynamics conclusion bibliography chapter case ethical ai military introduction banning weaponized ai bad idea ethical ai spectrum technical feasibility minai code minai ethical minai mission ethical guidelines purpose positive balance risks avoidance ethical dilemmas extent possible armed conflict shall managed mixed initiative agreements primacy human life military commanders decide sacrifice specific lives machines minimize innocent casualties military commanders developers defense departments accountable ethical weapons security ethical weapons awareness recording responsibility transfers human offtheloop machine selflearning considerations fail safe management military education training